Permutation feature importance
==============================

Permutation feature importance estimates the importance of each feature by measuring the drop in a chosen score when the feature’s values are randomly permuted. This approach is model-agnostic: it does not rely on model internals beyond the ability to score predictions.

Overview
--------

- For each feature, the feature’s column is permuted across samples, breaking its relationship with the target while leaving other features intact.
- The model score is computed with the permuted data. The decrease from the baseline score (computed on the original, unpermuted data) is the feature’s importance.
- The process is repeated n_repeats times to obtain stable estimates. The result reports the mean and standard deviation of the importances across repeats.
- Supports single or multi-metric scoring. Scorers can be specified as a string, a callable, a list/tuple of scorers, or a dict of scorers. When multiple scorers are provided, importances are computed accordingly for each scorer.

Parameters
----------

- estimator: The fitted estimator used to generate predictions and scores.

- X: array-like of shape (n_samples, n_features). Input samples.

- y: array-like of shape (n_samples,) or None. Target values. May be None if the chosen scorer does not require y, or when a compatible scoring configuration is provided.

- scoring: Scoring function or strategy. Can be a string, a callable, a list/tuple of scorers, a dict of scorers, or None. If multiple scorers are supplied, importances are computed for each scorer.

- n_repeats: int. Number of permutation repeats per feature (default is 5). More repeats yield more stable estimates.

- n_jobs: int or None. Number of parallel jobs to run. None means 1 (no parallelism); -1 uses all available cores.

- random_state: int, RandomState instance, or None. Controls randomness for permutation and bootstrapping when max_samples is used.

- max_samples: int or float or None. Maximum number of samples to use for permutation testing. If max_samples < n_samples, a bootstrap sample of size max_samples is drawn and permutation is performed on that subset.

- sample_weight: array-like or None. Sample weights to use when scoring.

Returns
-------

- A Bunch with the following attributes:
  - importances_mean: ndarray of shape (n_features,). Mean permutation importance for each feature.
  - importances_std: ndarray of shape (n_features,). Standard deviation of importances across repeats.
  - importances: ndarray of shape (n_features, n_repeats). Raw permutation importances for each feature and repeat.

Notes
------

- The method is model-agnostic and can be used with any estimator implementing fit and a compatible scoring method.

- Permutation importance can be biased in the presence of correlated features; groups of correlated features may share importance.

- If max_samples is set to a fraction, results are computed on a bootstrap sample of the data, which can speed up computation while providing approximate estimates.

Examples
--------

Basic usage with a classifier

.. code-block:: python

   from sklearn.ensemble import RandomForestClassifier
   from sklearn.datasets import load_iris
   from sklearn.inspection import permutation_importance

   X, y = load_iris(return_X_y=True)
   clf = RandomForestClassifier(n_estimators=100, random_state=0)
   clf.fit(X, y)

   result = permutation_importance(clf, X, y, n_repeats=30, random_state=0, n_jobs=-1)

   # Features sorted by importance
   sorted_idx = result.importances_mean.argsort()
   print("Feature importances (sorted):", result.importances_mean[sorted_idx])

See also
--------

- sklearn.inspection.permutation_importance (full API reference)

