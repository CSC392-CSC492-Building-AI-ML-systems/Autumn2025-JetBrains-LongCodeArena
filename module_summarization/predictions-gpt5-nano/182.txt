Developing estimators
=====================

This section covers how to develop new estimators in scikit-learn, with emphasis on meta-estimators that wrap a base estimator to extend its capabilities (e.g., multioutput support).

Overview
--------

- Estimators implement a common interface (fit, predict, get_params, set_params) and often extend BaseEstimator and related mixins.
- Meta-estimators take a base estimator as a parameter and apply the base estimator to multiple targets or in combination with other estimators.
- The codebase provides utilities for wrapping, cloning, fitting, and validating sub-estimators, as well as machinery for conditional parameter exposure based on sub-estimator capabilities.

Multioutput estimators
----------------------

The module implements multioutput regression and classification via meta-estimators that require a base estimator in their constructor. The main ideas:

- Base: a single-output estimator is extended to handle multiple targets by wrapping the base estimator.
- Meta-estimators included: MultiOutputRegressor, MultiOutputClassifier, ClassifierChain, RegressorChain.
- Key pattern: a wrapper holds a sub-estimator and delegates fitting and prediction to clones of the sub-estimator.
- Internal helpers:
  - _fit_estimator(estimator, X, y, sample_weight=None, **fit_params): clone the sub-estimator, fit it, and return the fitted estimator.
  - _partial_fit_estimator(estimator, X, y, classes=None, partial_fit_params=None, first_time=True): support incremental fitting when the sub-estimator implements partial_fit.
  - _available_if_estimator_has(attr): produce a gating function to expose parameters only if the sub-estimator provides the given attribute (e.g., fit, partial_fit, or other methods).
- Core class: _MultiOutputEstimator is a base class (MetaEstimatorMixin, BaseEstimator) that enforces constraints such as:
  - estimator must have fit and predict
  - n_jobs may be an integer or None
  - __init__(self, estimator, *, n_jobs=None) stores the sub-estimator and configuration

Design and implementation guidance
----------------------------------

- Use a base class like _MultiOutputEstimator when implementing a new multioutput or chained estimator. This ensures consistent behavior and interfaces with existing utilities.
- Validate the sub-estimator using HasMethods(["fit", "predict"]) to enforce required capabilities.
- Provide a clean __init__ signature:
  - def __init__(self, estimator, *, n_jobs=None)
  - store self.estimator and self.n_jobs
- Utilize clone(estimator) when fitting to ensure a fresh copy is used for each fit, avoiding unintended state sharing.
- For incremental training, implement partial_fit paths and expose them via _partial_fit_estimator where appropriate.
- Expose parameters conditionally with _available_if_estimator_has to reflect capabilities of the wrapped estimator (e.g., a parameter only relevant if the sub-estimator supports partial_fit).
- Keep __all__ up to date with the estimator classes you provide (as in MultiOutputRegressor, MultiOutputClassifier, ClassifierChain, RegressorChain).
- Write tests that cover:
  - basic fitting with a simple base estimator
  - proper cloning of the sub-estimator
  - behavior of partial_fit when supported
  - parameter exposure depending on the sub-estimator’s capabilities

Internal utilities to leverage
------------------------------

- Cloning and parameter handling: clone, get_params, set_params
- Validation helpers: HasMethods, StrOptions
- Metadata routing and parameter exposure: MetadataRouter, MethodMapping, _raise_for_params, _routing_enabled, process_routing
- Conditional exposure: available_if
- Classification checks: check_classification_targets
- Parallelism and scheduling: Parallel, delayed
- Validation checks: _check_method_params, check_is_fitted, has_fit_parameter
- Utility components: Bunch, _print_elapsed_time, check_random_state

Extending with your own estimator
---------------------------------

- Decide whether you need a meta-estimator wrapper (e.g., to apply the same estimator to multiple targets or to chain estimators) or a standalone estimator.
- If wrapping another estimator, implement __init__ to accept the sub-estimator and any relevant options (e.g., n_jobs), and enforce required capabilities on the sub-estimator.
- Implement fit and predict (and partial_fit if applicable) by delegating to clones of the sub-estimator, handling per-target semantics as needed.
- Use _fit_estimator and _partial_fit_estimator to centralize wrapping logic and ensure consistent behavior across estimators.
- Use _available_if_estimator_has to expose additional parameters only when supported by the sub-estimator.
- Follow existing coding patterns within the estimators module to maintain consistency and testability.

Examples of supported estimators
-------------------------------

- MultiOutputRegressor wraps a regressor to handle multiple targets.
- MultiOutputClassifier wraps a classifier to handle multiple targets.
- ClassifierChain and RegressorChain connect a sequence of estimators to model target dependencies.

Testing and quality
-------------------

- Ensure tests cover that the wrapper delegates correctly to the sub-estimator.
- Verify cloning, parameter propagation, and optional partial_fit behavior.
- Validate that parameter gating via available_if aligns with the sub-estimator’s capabilities.

This guidance aligns with the multioutput estimator implementation pattern used in the codebase, where a base estimator is wrapped to provide multi-target support and optional incremental fitting, while preserving a consistent interface and robust parameter management.