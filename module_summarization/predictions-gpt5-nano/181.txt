Dataset loading utilities
=========================

Overview
--------
These utilities support loading datasets from OpenML and handling local caching, retries, and error handling. The primary public API is fetch_openml, which downloads datasets from OpenML and returns them in a Bunch-like structure. Internal helpers power caching, gzip handling, and robust network access.

Main API
--------
- fetch_openml: Download and cache datasets from OpenML. Returns a Bunch-like object containing dataset data, target, feature names, description, and related metadata. The loader leverages the OpenML API endpoints and the local cache to provide efficient data access.

Caching and local storage
-------------------------
- Caching location: When a data_home is provided, resources are cached under data_home/openml.org and stored as openml_path.gz.
- Local path computation: _get_local_path(openml_path, data_home) builds the path to the cached gzip file.
- Atomic cache updates: Downloads are written to a temporary directory and atomically moved into place to ensure cache consistency under concurrent usage.
- Decompression: If the server indicates gzip encoding, the cached file is decompressed on access as needed.

Retry and error handling
------------------------
- Network retries: _retry_on_network_error decorates functions to retry on URLError/TimeoutError up to n_retries times with a delay. HTTP 412 errors are treated as non-retriable OpenML errors.
- Cache invalidation: _retry_with_clean_cache decorates functions to remove an invalid cached file and retry, ensuring fresh data on subsequent calls. It can be configured to avoid retry for a specific exception type via no_retry_exception.
- OpenML errors: OpenMLError represents HTTP 412 OpenML-specific errors.

OpenML HTTP helper details
--------------------------
- _open_openml_url(openml_path, data_home, n_retries, delay): Retrieve a resource from OpenML. When caching is enabled (data_home not None), the resource is cached locally with an atomic write. The function handles gzip-encoded content by returning an appropriate file-like object (either a gzip file or a plain stream) for downstream processing.
- Content handling: The code detects Content-Encoding: gzip and wraps streams accordingly to transparently provide decompressed data.

JSON API helper
---------------
- _get_json_content_from_openml_api(url, error_message, data_home, n_retries, delay): Helper to fetch and parse JSON payloads from the OpenML API, with retry behavior and optional caching. Returns a dictionary representing the parsed JSON content.

Usage example
-------------
.. code-block:: python

    from sklearn.datasets import fetch_openml

    # Example: fetch the Iris dataset from OpenML
    ds = fetch_openml(name="iris", version=1)
    X, y = ds.data, ds.target

Notes
-----
- If data_home is None, caching is disabled and data is fetched fresh on every call.
- The internal helpers optimize for reliability and concurrency when accessing OpenML resources.