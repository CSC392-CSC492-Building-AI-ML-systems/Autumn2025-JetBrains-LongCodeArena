Probability calibration
=======================

CalibratedClassifierCV performs probability calibration for a classifier by fitting a secondary calibration model on top of the classifier's scores. It uses cross-validation to estimate the calibration parameters and (optionally) to train multiple calibrated classifiers that are averaged to produce final probabilities.

Overview
--------

- Calibrates the predicted probabilities of a base estimator.
- Supports two calibration methods:
  - sigmoid: Platt scaling (logistic regression on top of the base estimator’s scores)
  - isotonic: non-parametric isotonic regression
- Works with cross-validation to obtain unbiased calibration or to train an ensemble of calibrated models.

Estimator and calibration methods
-------------------------------

- estimator: The classifier to be calibrated. If not provided, a default classifier (LinearSVC) is used.
- method: {'sigmoid', 'isotonic'}, default 'sigmoid'
  - 'sigmoid' applies Platt scaling (logistic regression on the base estimator’s scores).
  - 'isotonic' applies isotonic regression for non-parametric calibration.
  - Isotonic calibration can overfit with very small calibration sample sizes (roughly < 1000 samples).

Cross-validation and fitting strategy
------------------------------------

- cv: Cross-validation scheme. Could be an integer (number of folds), a CV splitter, an iterable of (train, test) indices, or "prefit".
  - If cv is None, the default 5-fold cross-validation is used.
  - If "prefit" is used, the provided estimator is assumed to be already fitted and all data is used for calibration.
- ensemble: If True (default), for each cross-validation split:
  - fit a copy of the base estimator on the training data
  - calibrate it using the testing data
  - predictions are averaged across the calibrated classifiers
  - results in an ensemble of calibrated classifiers
- ensemble = False uses cross_val_predict to obtain unbiased predictions for calibration, and at prediction time the estimator trained on all data is used.
- When cv = "prefit" or ensemble = False, the length of calibrated_classifiers_ is 1.

Prediction and calibration basis
-------------------------------

- The calibration uses the base estimator’s decision_function if available; otherwise it uses predict_proba.
- The final probability estimates are obtained by calibrating the scores/probabilities produced by the base estimator.

Pre-fit usage and deprecations
------------------------------

- base_estimator: Deprecated alias for estimator. Use estimator instead.
- If cv = "prefit", no cross-validation is performed; all data is used for calibration, and the user must ensure that the data used for fitting the estimator and calibration are disjoint.

Attributes
----------

- classes_: ndarray of shape (n_classes,)
  The class labels.
- n_features_in_: int
  Number of features seen during fit.
- feature_names_in_: ndarray of shape (n_features_in_,)
  Names of features seen during fit (if available).
- calibrated_classifiers_: list
  Length is equal to the number of cross-validation folds (or 1 if cv = "prefit" or ensemble = False).

Usage notes
-----------

- This estimator is useful when you want to produce well-calibrated probability estimates for classifiers whose raw outputs are not well-calibrated.
- Appropriate for binary and multiclass classification problems.
- The default behavior balances bias and variance through cross-validation and, if enabled, ensembling of calibrated models.

See also
--------

- User Guide: Calibration
- Reference: CalibratedClassifierCV documentation

Example
-------

.. code-block:: python

   from sklearn.calibration import CalibratedClassifierCV
   from sklearn.svm import LinearSVC
   from sklearn.datasets import make_classification

   X, y = make_classification(n_samples=1000, n_features=20, random_state=0)
   base_clf = LinearSVC()
   calibrator = CalibratedClassifierCV(base_clf, method='sigmoid', cv=5)
   calibrator.fit(X, y)
   proba = calibrator.predict_proba(X)