Optimization Utilities
======================

Overview
--------
This module provides general-purpose optimization routines that can be used with any model fitting task. The approach is to decouple these utilities from a specific LikelihoodModel so they can be reused across different modeling contexts.

Public API
----------

_check_method(method, methods)
    Validate that the provided fit method is among the supported methods.
    - method: str
        The method name to validate.
    - methods: iterable
        A collection of supported method strings.
    Raises ValueError if method is not in methods.

Optimizer
---------
A helper class that exposes a generic fitting interface for an objective function.

- _fit(self, objective, gradient, start_params, fargs, kwargs, hessian=None,
        method='newton', maxiter=100, full_output=True, disp=True,
        callback=None, retall=False)

  Fit function for any model with an objective function.

  Parameters
  ----------
  start_params : array_like, optional
      Initial guess of the solution for the optimization.
      Default is an array of zeros.
  objective : callable
      The objective function to minimize (or maximize, depending on convention).
  gradient : callable
      The gradient (Jacobian) of the objective.
  fargs : tuple
      Extra arguments passed to the objective function, i.e., objective(x, *fargs).
  kwargs : dict
      Additional keyword arguments passed to the objective/gradient.
  hessian : callable, optional
      Hessian of the objective. If None, the solver may approximate it.
  method : str
      Solver to use. Options may include 'newton', 'nm', 'bfgs', 'powell',
      'cg', 'ncg', 'basinhopping', or a generic 'minimize' wrapper for
      scipy.optimize.minimize.
  maxiter : int
      Maximum number of iterations to perform.
  full_output : bool
      If True, return a detailed set of results from the solver in the
      mle_retvals attribute (format dependent on the solver).
  disp : bool
      If True, display convergence messages.
  callback : callable, optional
      A function called after each iteration with the current parameter vector.
  retall : bool
      If True, return a list of solutions at each iteration (where supported).

  Returns
  -------
  xopt : array
      The optimal parameters found by the solver.
  retvals : dict or None
      Solver-specific output when full_output is True; otherwise None.
  optim_settings : dict
      The parameters that were passed to the solver (the optimization settings).

  Notes
  -----
  - The 'basinhopping' solver ignores maxiter, retall, and full_output.
  - The set of optional arguments shown above corresponds to the solver
    specifics available through scipy.optimize.

  Optional arguments for the solvers (as available in Results.mle_settings)
  are extensive and solver-specific (e.g., tol, xtol, ftol, maxfun, gtol, etc.).
  See the solver documentation (scipy.optimize) for details.

Usage example
-------------
.. code-block:: python

    from optimization_module import Optimizer
    import numpy as np

    def objective(x, *args):
        return np.sum((x - 1.0)**2)

    def gradient(x, *args):
        return 2.0 * (x - 1.0)

    opt = Optimizer()
    x0 = np.zeros(3)
    xopt, retvals, settings = opt._fit(objective, gradient, x0, fargs=(), kwargs={}, method='nm')

Documentation Notes
-------------------
- This module is designed to be independent of any specific model class.
- It provides a flexible interface to various SciPy optimization solvers while exposing consistent return values and settings to the caller.

See Also
--------
- scipy.optimize for solver specifics and option details.