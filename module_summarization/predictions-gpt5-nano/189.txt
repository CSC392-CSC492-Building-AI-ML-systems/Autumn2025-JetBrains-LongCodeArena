Kernel Ridge Regression (KernelRidge)
=====================================


Overview
--------
Kernel ridge regression (KRR) combines ridge regression (linear least squares with l2-norm regularization)
with the kernel trick. It learns a linear function in the feature space induced by the chosen kernel.
For non-linear kernels, this corresponds to a non-linear function in the original input space.

The form of the model learned by KRR is identical to that of support vector regression (SVR),
but KRR uses squared error loss with l2 regularization. Unlike SVR, KRR admits a closed-form
solution and is typically faster for medium-sized datasets. However, the learned model is generally
dense and not sparse at prediction time.

This estimator supports multi-target regression (i.e., y can be a 2D array with shape
[n_samples, n_targets]).


Parameters
----------
alpha : float or array-like of shape (n_targets,), default=1.0
    Regularization strength; must be positive. Regularization improves conditioning and reduces variance.
    If an array is provided, penalties apply per target.

kernel : str or callable, default="linear"
    Kernel mapping used internally. This parameter is passed directly to
    pairwise_kernels.
    If kernel is a string, it must be one of the metrics in pairwise.PAIRWISE_KERNEL_FUNCTIONS
    or "precomputed".
    If kernel is "precomputed", X is assumed to be a kernel matrix.
    If kernel is a callable, it is called on each pair of instances (rows) and should return
    the corresponding kernel value for that pair. Callables from sklearn.metrics.pairwise are not
    allowed because they operate on matrices, not on individual samples.

gamma : float, default=None
    Gamma parameter for the RBF, Laplacian, polynomial, exponential chi2, and sigmoid kernels.
    Interpretation of the default value is kernel-dependent. Ignored by kernels other than those above.

degree : int, default=3
    Degree of the polynomial kernel. Ignored by other kernels.

coef0 : float, default=1
    Zero coefficient for polynomial and sigmoid kernels.
    Ignored by other kernels.

kernel_params : dict, default=None
    Additional parameters (keyword arguments) for the kernel function passed as a callable
    object.

Attributes
----------
dual_coef_ : ndarray of shape (n_samples,) or (n_samples, n_targets)
    Representation of the weight vector(s) in kernel space.

X_fit_ : {ndarray, sparse matrix} of shape (n_samples, n_features)
    Training data used for fitting, which is also required for prediction.
    If kernel == "precomputed", this is the precomputed training kernel matrix of shape
    (n_samples, n_samples).

n_features_in_ : int
    Number of features seen during fit.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (n_features_in_,)
    Names of features seen during fit. Defined only when X has feature names that are all strings.

    .. versionadded:: 1.0


See Also
--------
sklearn.gaussian_process.GaussianProcessRegressor : Gaussian Process regressor providing
    automatic kernel hyperparameters tuning and predictions uncertainty.
sklearn.linear_model.Ridge : Linear ridge regression.
sklearn.linear_model.RidgeCV : Ridge regression with built-in cross-validation.
sklearn.svm.SVR : Support Vector Regression with a large variety of kernels.

References
----------
* Kevin P. Murphy, "Machine Learning: A Probabilistic Perspective", The MIT Press
  chapter 14.4.3, pp. 492-493


Examples
--------
>>> from sklearn.kernel_ridge import KernelRidge
>>> import numpy as np
>>> n_samples, n_features = 10, 5
>>> rng = np.random.RandomState(0)
>>> y = rng.randn(n_samples)
>>> X = rng.randn(n_samples, n_features)
>>> krr = KernelRidge(alpha=1.0)
>>> krr.fit(X, y)
KernelRidge(alpha=1.0)