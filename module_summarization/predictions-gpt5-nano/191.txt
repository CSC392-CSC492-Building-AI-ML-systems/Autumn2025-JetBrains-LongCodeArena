Validation curves: plotting scores to evaluate models
=====================================================

Validation curves help you understand how a model’s performance changes as a specific hyperparameter is varied. By plotting cross-validated scores (e.g., accuracy, AUC) against parameter values, you can select a value that yields good generalization.

What is shown
------------
- The curves display mean scores across cross-validation folds, with optional bands or error bars representing score variability.
- You can plot training scores, cross-validated test scores, or both.
- The y-axis shows the chosen score (e.g., accuracy, F1), and the x-axis shows the parameter values being varied.

Plot options
------------
- std_display_style
  - "fill_between": show the mean score with a shaded region representing ±1 std deviation.
  - "errorbar": show error bars around the mean scores.
  - None: plot only the mean scores (no variability shading or error bars).
- score_type
  - "train": plot training scores only.
  - "test": plot cross-validated test scores only.
  - "both": plot both training and test scores.
- score_name
  - Label for the y-axis. If not provided, a name derived from the scoring parameter is used.
- log_scale (deprecated)
  - This parameter is deprecated. See the plotting utility notes for guidance on axis scaling.
- x-axis scaling
  - The x-axis scale is chosen to best present the parameter range (linear, log, or symlog), depending on the parameter values and scale considerations.

Usage (typical API)
-------------------
Validation curves are typically produced via the validation_curve function and then displayed with a display class (e.g., ValidationCurveDisplay). The display is created from the computed scores and parameter values, and then plotted.

Example
-------
.. code-block:: python

   from sklearn.model_selection import validation_curve
   from sklearn.svm import SVC
   from sklearn.datasets import load_digits
   import numpy as np
   from sklearn.model_selection import ValidationCurveDisplay

   # Load data
   X, y = load_digits(return_X_y=True)

   # Define parameter to sweep
   param_name = "C"
   param_range = np.logspace(-3, 2, 6)

   # Compute validation curve scores
   train_scores, test_scores = validation_curve(
       SVC(), X, y,
       param_name=param_name,
       param_range=param_range,
       cv=5,
       scoring="accuracy",
       n_jobs=-1,
   )

   # Create and plot the display
   display = ValidationCurveDisplay(
       param_name=param_name,
       param_range=param_range,
       train_scores=train_scores,
       test_scores=test_scores,
       scoring="accuracy",
   )
   display.plot()
   display.show()

Notes
-----
- The curves help identify:
  - The parameter values that maximize test performance.
  - Values that cause overfitting or underfitting (e.g., very high or very low parameter values).
- When comparing models, use the same parameter range and cross-validation settings to ensure fair comparisons.

See also
--------
- sklearn.model_selection.validation_curve: Compute the validation curve data (param_name, param_range, scores).
- sklearn.model_selection.LearningCurveDisplay: For learning curves, which plot performance as a function of training set size.