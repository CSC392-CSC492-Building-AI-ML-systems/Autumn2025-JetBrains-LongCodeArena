Manifold learning: Multidimensional Scaling (MDS)

Overview
- Multidimensional Scaling (MDS) is a classic manifold learning technique for nonlinear dimensionality reduction. It seeks a low-dimensional embedding of data such that pairwise dissimilarities in the original space are preserved as closely as possible in the embedding space.
- The approach operates on a dissimilarities matrix (pairwise distances or dissimilarities) and produces coordinates X in a target dimensionality (n_components) that best reproduce those dissimilarities.
- MDS supports both metric and non-metric formulations. In the metric case, the embedding aims to preserve the actual dissimilarities. In the non-metric case, only the rank ordering of dissimilarities is preserved, using isotonic regression to map dissimilarities to monotone disparities.

How it works
- Input: A symmetric matrix of pairwise dissimilarities D of shape (n_samples, n_samples).
- If metric MDS is used, the disparities are set equal to D.
- If non-metric MDS is used, a monotone regression (isotonic regression) maps the sorted dissimilarities to a monotone function, producing disparities that preserve the order of D.
- Stress measures how well the embedding reproduces the dissimilarities:
  - Stress ≈ sum of squared differences between the original dissimilarities and the embedding-induced distances, typically scaled by 1/2.
  - If normalized_stress is requested, Stress-1 (a normalized version) is returned.
- The core update uses the Guttman transform (classic MDS update) to produce a new embedding X from the current estimates of distances and disparities.
- Iteration proceeds until convergence, determined by the change in stress relative to a small threshold eps.
- The algorithm returns:
  - X: coordinates of shape (n_samples, n_components)
  - stress: final stress value (or Stress-1 for normalized non-metric MDS)
  - n_iter: number of iterations performed

Key options
- dissimilarities: array-like, shape (n_samples, n_samples). Must be symmetric.
- metric: bool
  - True for metric MDS (preserves actual dissimilarities).
  - False for non-metric MDS (preserves the order, using monotone regression to derive disparities).
- n_components: int, default 2
  - Number of dimensions for the embedding space.
- init: array-like or None
  - Starting configuration of the embedding. If None, a random initialization is used.
- max_iter: int, default 300
  - Maximum number of iterations per run.
- verbose: int, default 0
  - Level of verbosity during optimization.
- eps: float, default 1e-3
  - Relative tolerance for convergence with respect to stress.
- random_state: int, RandomState instance, or None
  - Seed or RNG for random initialization to ensure reproducibility.
- normalized_stress: bool, default False
  - If True and metric is False, returns Stress-1 (normalized stress) instead of raw stress.

Notes on multiple runs and parallelism
- To improve robustness and avoid poor local optima, MDS can be run multiple times with different initializations (n_init) and the best result is selected.
- Parallel execution may be used to run multiple initializations in parallel (controlled by n_jobs).

Output
- X: ndarray of shape (n_samples, n_components)
  - Coordinates of the embedding in the target dimensionality.
- stress: float
  - Final stress (or Stress-1 when normalized_stress is True and metric is False).
- n_iter: int
  - Number of iterations used to reach convergence.

References
- Kruskal, J. (1964). Nonmetric multidimensional scaling: a numerical method.
- Kruskal, J. (1964). Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis.
- Borg, I., & Groenen, P. (1997). Modern Multidimensional Scaling — Theory and Applications.

See also
- isotonic.IsotonicRegression for non-metric MDS via monotone regression.
- metrics.euclidean_distances for computing pairwise distances.
- utils.check_array, utils.check_random_state, and related utilities for input validation and reproducibility.