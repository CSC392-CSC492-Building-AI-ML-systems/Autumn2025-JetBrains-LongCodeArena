# Linear Mixed Effects Models Documentation

Linear mixed effects models are regression models for dependent data. They can be used to estimate regression relationships involving both means and variances. These models are also known as multilevel linear models and hierarchical linear models.

The `MixedLM` class fits linear mixed effects models to data and provides support for some common post-estimation tasks. This implementation is most efficient for models in which the data can be partitioned into independent groups. Some models with crossed effects can be handled by specifying a model with a single group.

The data are partitioned into disjoint groups. The probability model for group i is defined as:

Y = X*beta + Z*gamma + epsilon

where:
- n_i is the number of observations in group i
- Y is a n_i dimensional response vector
- X is a n_i x k_fe dimensional design matrix for the fixed effects
- beta is a k_fe-dimensional vector of fixed effects parameters
- Z is a design matrix for the random effects with n_i rows
- gamma is a random vector with mean 0
- epsilon is a n_i dimensional vector of iid normal errors with mean 0 and variance sigma^2

The marginal mean structure is E[Y | X, Z] = X*beta. If only the mean structure is of interest, Generalized Estimating Equations (GEE) is an alternative to using linear mixed models.

Two types of random effects are supported:
1. Standard random effects are correlated with each other in arbitrary ways.
2. Variance components are uncorrelated with each other and with the standard random effects.

The primary reference for the implementation details is the paper by MJ Lindstrom and DM Bates (1988) titled "Newton Raphson and EM algorithms for linear mixed effects models for repeated measures data" published in the Journal of the American Statistical Association.

For more information and user perspectives, refer to the following documents:
- [Mixed Effects Implement PDF](http://econ.ucsb.edu/~doug/245a/Papers/Mixed%20Effects%20Implement.pdf)
- [lMMwR Document](http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf)
- [Longitudinal-4 Slides](http://lme4.r-forge.r-project.org/slides/2009-07-07-Rennes/3Longitudinal-4.pdf)

Notation:
- `cov_re` is the random effects covariance matrix
- `scale` is the error variance
- `vcomp` is a vector of variance parameters

Three different parameterizations are used in different places: user parameterization, profile parameterization, and square root parameterization. These parameterizations differ in how the variance parameters are handled.

The optimization methods for linear mixed effects models include score methods with respect to the random effects covariance matrix and the Cholesky square root of the random effects covariance matrix.

Overall, linear mixed effects models provide a flexible framework for analyzing data with dependent observations and capturing both fixed and random effects in the regression relationships.