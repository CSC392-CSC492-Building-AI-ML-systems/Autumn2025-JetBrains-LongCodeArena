# Three Types of Algorithms for Parameter Estimation

This documentation provides an overview of three types of algorithms that can be used for estimating the parameters of a model. These algorithms are implemented in the `Optimizer` class, which offers flexibility and reusability for fitting models with different optimization methods.

## 1. Newton-Raphson Method
- **Method Name:** 'newton'
- **Description:** The Newton-Raphson method is a root-finding algorithm that uses an iterative process to find the local maxima of the objective function. It is suitable for models where the objective function is smooth and well-behaved.

## 2. Nelder-Mead Method
- **Method Name:** 'nm'
- **Description:** The Nelder-Mead method, also known as the downhill simplex method, is a heuristic optimization technique that does not require the calculation of gradients. It is useful for optimizing functions that are not differentiable or have discontinuities.

## 3. Broyden-Fletcher-Goldfarb-Shanno (BFGS) Method
- **Method Name:** 'bfgs'
- **Description:** The BFGS method is a quasi-Newton optimization algorithm that approximates the inverse Hessian matrix of the objective function. It is efficient for optimizing smooth functions and is widely used in practice.

These algorithms offer different trade-offs in terms of convergence speed, memory usage, and robustness. Users can choose the appropriate method based on the characteristics of the model and the optimization problem at hand. The `Optimizer` class provides a unified interface for utilizing these algorithms and customizing optimization settings to achieve the desired results.