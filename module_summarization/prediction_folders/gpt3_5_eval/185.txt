Tuning the hyper-parameters of an estimator involves finding the optimal settings for the parameters that are not directly learned within the estimator itself. This process is crucial for achieving the best performance of the estimator on unseen data.

One common approach to tuning hyper-parameters is through grid search, where a grid of hyper-parameter values is defined, and the estimator is evaluated for each combination of values. This allows for a systematic exploration of the hyper-parameter space to identify the combination that results in the best performance.

The `GridSearchCV` class in scikit-learn provides a convenient way to perform grid search with cross-validation. By specifying the estimator, the parameter grid, and the cross-validation strategy, `GridSearchCV` automates the process of fitting the estimator with different hyper-parameter values and selecting the best combination based on a specified scoring metric.

To use `GridSearchCV`, you first need to define the estimator you want to tune, along with the hyper-parameters and their respective values to search over. You can then create a `GridSearchCV` object with the estimator, parameter grid, and cross-validation strategy. Finally, you can fit the `GridSearchCV` object to the data, which will perform the grid search and identify the best hyper-parameter values.

By tuning the hyper-parameters of an estimator using grid search, you can optimize the performance of your model and improve its ability to generalize to new, unseen data.