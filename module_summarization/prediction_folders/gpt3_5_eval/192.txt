Manifold learning is a powerful approach to non-linear dimensionality reduction that aims to uncover the underlying structure of high-dimensional data by embedding it into a lower-dimensional space while preserving the essential relationships between data points. One popular method for manifold learning is Multi-dimensional Scaling (MDS), which is used to visualize the similarity relationships between data points in a reduced space.

The SMACOF algorithm, implemented in scikit-learn, is a variant of MDS that can handle both metric and non-metric dissimilarities. In the context of non-linear dimensionality reduction, SMACOF iteratively optimizes the embedding of data points in a lower-dimensional space based on the pairwise dissimilarities between the points. By minimizing the stress function, SMACOF finds an embedding that best represents the original data relationships in a lower-dimensional space.

Key parameters of the SMACOF algorithm include the number of components (dimensions) in the embedding space, the initialization method, maximum number of iterations, convergence tolerance, and random state for reproducibility. The algorithm iterates until convergence, updating the embedding based on the computed disparities and distances between points.

The output of the SMACOF algorithm includes the coordinates of the points in the reduced space, the final stress value indicating the quality of the embedding, and the number of iterations performed. By tuning the algorithm parameters and interpreting the stress value, users can assess the quality of the dimensionality reduction and adjust the embedding as needed.

References:
- Kruskal, J. "Nonmetric multidimensional scaling: a numerical method" Psychometrika, 29 (1964)
- Kruskal, J. "Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis" Psychometrika, 29 (1964)
- Borg, I.; Groenen P. "Modern Multidimensional Scaling - Theory and Applications" Springer Series in Statistics (1997)