```rst
w_pdist
=======

.. program:: w_pdist

Calculate time-resolved, multi-dimensional probability distributions of WE datasets.

Source data
-----------

Source data is provided either by a user-specified function (--construct-dataset) or a list of "data set specifications" (--dsspecs). If neither is provided, the progress coordinate dataset ``pcoord`` is used.

To use a custom function to extract or calculate data whose probability distribution will be calculated, specify the function in standard Python MODULE.FUNCTION syntax as the argument to --construct-dataset. This function will be called as function(n_iter,iter_group), where n_iter is the iteration whose data are being considered and iter_group is the corresponding group in the main WEST HDF5 file (west.h5). The function must return data which can be indexed as [segment][timepoint][dimension].

To use a list of data set specifications, specify --dsspecs and then list the desired datasets one-by-one (space-separated in most shells). These data set specifications are formatted as NAME[,file=FILENAME,slice=SLICE], which will use the dataset called NAME in the HDF5 file FILENAME (defaulting to the main WEST HDF5 file west.h5), and slice it with the Python slice expression SLICE (as in [0:2] to select the first two elements of the first axis of the dataset). The ``slice`` option is most useful for selecting one column (or more) from a multi-column dataset, such as arises when using a progress coordinate of multiple dimensions.

Histogram binning
-----------------

By default, histograms are constructed with 100 bins in each dimension. This can be overridden by specifying -b/--bins, which accepts a number of different kinds of arguments:

- a single integer N: N uniformly spaced bins will be used in each dimension.
- a sequence of integers N1,N2,... (comma-separated): N1 uniformly spaced bins will be used for the first dimension, N2 for the second, and so on.
- a list of lists [[B11, B12, B13,...], [B21, B22, B23,...],...]: The bin boundaries B11, B12, B13,... will be used for the first dimension, B21, B22, B23,... for the second dimension, and so on. These bin boundaries need not be uniformly spaced. These expressions will be evaluated with Python's ``eval`` construct, with ``np`` available for use [e.g. to specify bins using np.arange()].

Output format
-------------

The output file produced (specified by -o/--output, defaulting to "pdist.h5") may be fed to plothist to generate plots (or appropriately processed text or HDF5 files) from this data. In short, the following datasets are created:

- ``histograms``: Normalized histograms. The first axis corresponds to iteration, and remaining axes correspond to dimensions of the input dataset.
- ``/binbounds_0``: Vector of bin boundaries for the first (index 0) dimension. Additional datasets similarly named (/binbounds_1, /binbounds_2,...) are created for additional dimensions.
- ``/midpoints_0``: Vector of bin midpoints for the first (index 0) dimension. Additional datasets similarly named are created for additional dimensions.
- ``n_iter``: Vector of iteration numbers corresponding to the stored histograms (i.e. the first axis of the ``histograms`` dataset).

Subsequent processing
---------------------

The output generated by this program (-o/--output, default "pdist.h5") may be plotted by the ``plothist`` program. See ``plothist --help`` for more information.

Parallelization
---------------

This tool supports parallelized binning, including reading of input data. Parallel processing is the default. For simple cases (reading pre-computed input data, modest numbers of segments), serial processing (--serial) may be more efficient.

Command-line options
---------------------

The following command-line options are available:

- -b/--bins: Specify the number of bins for histogram binning.
- -o/--output: Specify the output file name.
- --construct-dataset: Specify a custom function to extract or calculate data.
- --dsspecs: Specify a list of data set specifications.
- --serial: Use serial processing instead of parallel processing.

```