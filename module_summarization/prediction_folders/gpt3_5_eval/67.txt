```rst
Generate documentation for this module
======================================

The ``sklearn.feature_extraction.text`` submodule provides utilities for constructing feature vectors from text documents. It includes the following classes and functions:

- ``HashingVectorizer``: A vectorizer that converts a collection of text documents to a matrix of token occurrences.
- ``CountVectorizer``: A vectorizer that converts a collection of text documents to a matrix of token counts.
- ``ENGLISH_STOP_WORDS``: A set of common English stop words.
- ``TfidfTransformer``: A transformer that applies term frequency-inverse document frequency (TF-IDF) normalization to a matrix of token counts.
- ``TfidfVectorizer``: A vectorizer that combines the functionality of ``CountVectorizer`` and ``TfidfTransformer``.
- ``strip_accents_ascii``: A function that removes accentuated Unicode symbols and transforms them into ASCII characters.
- ``strip_accents_unicode``: A function that transforms accentuated Unicode symbols into their simple counterparts.
- ``strip_tags``: A function that removes HTML/XML tags from a string.

Additionally, the module provides the following utility functions:

- ``_preprocess``: A function that applies a series of text preprocessing steps to a document, such as lowercasing and handling accented characters.
- ``_analyze``: A function that chains together text processing steps to convert a document into n-grams, with options for tokenization, preprocessing, and stop words handling.
- ``_check_stop_list``: A function that checks and returns a stop word list, with built-in support for English stop words.

The module also includes the ``_VectorizerMixin`` class, which provides common code for text vectorizers, including tokenization logic and decoding strategies for input data.

For detailed information on each function and class, refer to the corresponding docstrings in the source code.
```