# Probability Calibration

The `CalibratedClassifierCV` class in scikit-learn provides functionality for probability calibration using isotonic regression or logistic regression. This class uses cross-validation to estimate the parameters of a classifier and subsequently calibrate it. 

When `ensemble=True`, the class fits a copy of the base estimator to the training subset for each cross-validation split and calibrates it using the testing subset. Predicted probabilities are then averaged across these individual calibrated classifiers. 

Alternatively, when `ensemble=False`, cross-validation is used to obtain unbiased predictions, which are then used for calibration. The base estimator, trained using all the data, is used for prediction in this case. This method is particularly useful for SVM estimators with the `probabilities=True` parameter.

Already fitted classifiers can be calibrated by setting `cv="prefit"`. In this scenario, no cross-validation is performed, and all provided data is used for calibration. It is important to ensure that the data used for model fitting and calibration are disjoint in this case.

The calibration process is based on the `decision_function` method of the estimator if available; otherwise, it falls back to using `predict_proba`.

For more detailed information and examples, refer to the [User Guide on Calibration](https://scikit-learn.org/stable/modules/calibration.html).