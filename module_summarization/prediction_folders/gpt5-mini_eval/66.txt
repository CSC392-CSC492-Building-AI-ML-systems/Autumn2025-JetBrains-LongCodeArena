Pipeline tutorial
=================

This tutorial introduces the Pipeline utility for composing a sequence of data
transforms with a final estimator. Pipelines are a convenient way to assemble
preprocessing and modeling steps that can be treated as a single estimator for
fitting, predicting and model selection (for example, in grid search).

Overview
--------

A Pipeline chains a sequence of (name, transform) pairs followed by a final
estimator. Intermediate steps must be "transforms" implementing fit and
transform; the final step must implement fit (and typical supervised estimators
also implement predict/score). A pipeline ensures that preprocessing steps are
applied identically during cross-validation and model selection and allows
setting sub-estimator parameters using a double-underscore ('__') separator.

Key points:

- Steps are given as a list of (name, estimator) tuples.
- Intermediate steps must implement fit and transform.
- The final step need only implement fit (and will usually implement predict,
  transform or predict_proba depending on the estimator).
- Replace a step by setting its name to another estimator, or remove it by
  setting it to 'passthrough' or None.
- The last step is never cached even if caching is enabled.

Basic usage
-----------

Create and use a pipeline like any other estimator:

.. code-block:: python

    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import StandardScaler
    from sklearn.svm import SVC

    pipe = Pipeline([
        ('scaler', StandardScaler()),
        ('svc', SVC())
    ])

    # fit and score as a single estimator
    pipe.fit(X_train, y_train)
    score = pipe.score(X_test, y_test)

Accessing steps and parameters
------------------------------

- Inspect step objects:

.. code-block:: python

    pipe.named_steps['scaler']        # access scaler estimator
    pipe.steps                        # list of (name, estimator) tuples

- Set parameters of sub-estimators using '__' syntax:

.. code-block:: python

    pipe.set_params(svc__C=10).fit(X_train, y_train)

- Replace or remove steps:

.. code-block:: python

    # replace the svc step
    pipe.set_params(svc=SomeOtherEstimator())
    # remove a step
    pipe.set_params(scaler='passthrough')  # or None

Caching intermediate transformers
---------------------------------

Pipelines can cache fitted intermediate transformers to avoid recomputation
when fitting repeatedly (e.g., with cross-validation). Use the ``memory``
parameter to provide a joblib.Memory location or object. Note that:

- The last step is never cached.
- Enabling caching clones transformers before fitting; the original instances
  passed into the pipeline are not modified in-place.
- Use the pipeline's ``named_steps`` or ``steps`` attributes to inspect the
  estimators stored in the pipeline.

Example with caching:

.. code-block:: python

    from joblib import Memory
    mem = Memory(location='cache_dir', verbose=0)
    pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())],
                    memory=mem)
    pipe.fit(X_train, y_train)

Using pipelines in model selection
----------------------------------

Pipelines integrate naturally with cross-validation and model selection
routines such as GridSearchCV. Parameters of sub-estimators can be included in
the search by referring to them with the step name and '__' separator.

.. code-block:: python

    from sklearn.model_selection import GridSearchCV
    param_grid = {
        'scaler__with_mean': [True, False],
        'svc__C': [0.1, 1, 10]
    }
    grid = GridSearchCV(pipe, param_grid, cv=5)
    grid.fit(X_train, y_train)

Transform vs fit_transform vs predict
-------------------------------------

- For transformable intermediate steps, call ``transform`` or
  ``fit_transform`` to obtain transformed features. The pipeline exposes
  ``transform`` which applies all transforms up to (but not including) the
  final estimator if the final step is not transformable.
- If the final estimator implements predict, calling ``predict`` on the
  pipeline applies all transforms and delegates prediction to the final step.

Output configuration
--------------------

Pipelines support configuring the output container of transform and
fit_transform via the ``set_output`` API. Calling ``set_output(transform="pandas")``
on a pipeline will propagate the configuration to all steps so that transform
methods produce pandas DataFrame outputs where supported.

Attributes created after fitting
--------------------------------

- named_steps : Bunch-like object mapping step names to estimator objects.
- classes_ : array of class labels (present if the final estimator is a
  classifier).
- n_features_in_ : number of features seen during fit (if available from the
  first estimator).
- feature_names_in_ : feature names seen during fit (if available from the
  first estimator).

Advanced notes
--------------

- A step can be assigned the special value 'passthrough' (or None) to skip
  that transform.
- Use ``clone`` (from sklearn.base) if you need a fresh unfitted copy of an
  estimator when building many pipelines programmatically.
- FeatureUnion / make_union can be used when parallel branches of transforms
  are needed (combine the outputs of several transformer pipelines).

Complete example
----------------

.. code-block:: python

    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import StandardScaler
    from sklearn.svm import SVC
    from sklearn.datasets import make_classification
    from sklearn.model_selection import train_test_split

    X, y = make_classification(random_state=0)
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

    pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])
    pipe.fit(X_train, y_train)
    acc = pipe.score(X_test, y_test)
    print(f"Test accuracy: {acc:.2f}")

References
----------

- User Guide: :ref:`pipeline`
- Examples: :ref:`sphx_glr_auto_examples_compose_plot_digits_pipe.py`,
  :ref:`sphx_glr_auto_examples_compose_plot_compare_reduction.py`
- Related helpers: :func:`make_pipeline`, :class:`FeatureUnion`, :func:`make_union`