Array API support
=================

Overview
--------
scikit-learn is implemented on top of NumPy and SciPy. The library primarily expects inputs to be NumPy ndarrays or SciPy sparse matrices. Many public estimators and utilities accept any "array-like" object that can be converted to a NumPy array via numpy.asarray or that implements the NumPy array interface. This document explains the practical behavior when passing Array API–compliant arrays or other third‑party array types to scikit-learn, current limitations, and recommended usage patterns.

Supported array types
---------------------
- NumPy ndarray: full support; this is the reference array type used throughout scikit-learn.
- SciPy sparse matrices: supported where explicitly documented (for example, many estimators accept CSR/CSC sparse matrices).
- Array-like objects implementing the NumPy array interface (e.g., objects exposing __array__ or the buffer protocol) will generally be accepted because they are converted to NumPy arrays internally.
- Third‑party array libraries that are not NumPy but provide an array-to-NumPy conversion (for example via __array__ or an explicit to_numpy()/get() call) can be used after conversion to NumPy.

How scikit-learn handles non-NumPy arrays
----------------------------------------
- Inputs are typically validated and normalized by utility functions (e.g., validation helpers in utils.validation) that call numpy.asarray or equivalent conversions. As a result, many third‑party arrays are converted to NumPy ndarrays before computations proceed.
- When a non‑NumPy array is converted, the resulting object is a host (CPU) NumPy array. Device arrays (GPU-backed arrays) will therefore normally be copied and transferred to host memory during conversion.
- In-place modifications to the original third‑party array are not guaranteed to be reflected in scikit-learn internals once conversion has occurred (a copy is commonly made). Do not rely on shared memory semantics unless the array type explicitly guarantees them and scikit-learn code path preserves them (which is not generally the case).

Dtype, memory layout and numeric expectations
---------------------------------------------
- Many scikit-learn algorithms expect floating-point inputs. The common default dtype is float64; some algorithms accept float32 but may perform computations in float64 internally or require promotion.
- Integer dtypes are accepted where meaningful (e.g., labels) but may be converted to floats when used as features.
- For best reproducibility and to avoid unexpected conversions, pass arrays with an appropriate dtype (float64 for most estimators).
- scikit-learn does not rely on a particular memory order (C/F), but contiguous arrays are typically faster. Conversions may yield contiguous NumPy arrays.

Sparse arrays
-------------
- SciPy sparse matrices (CSR, CSC, COO, etc.) are explicitly supported by many estimators that document sparse support. Sparse input handling is implemented using SciPy sparse types.
- The newer Array API sparse proposals or third‑party sparse array types are not guaranteed to be supported unless they are converted to SciPy sparse matrices or NumPy arrays prior to use.
- When passing sparse arrays, check the estimator’s documentation for explicit sparse support and any dtype requirements.

Device arrays and GPU backends
-----------------------------
- scikit-learn does not natively execute on GPUs. Passing GPU-backed arrays (for example, CuPy arrays or arrays from other GPU libraries) will typically result in conversion to a NumPy ndarray on the host (which transfers data from device to host).
- If you use a GPU library that exposes a NumPy-compatible __array__ interface or provides an explicit conversion to NumPy, use that conversion to create a NumPy array before calling scikit-learn to make the data movement explicit.
- Because of these conversions, using GPU arrays directly with scikit-learn does not generally deliver GPU acceleration of scikit-learn algorithms.

Metadata and array routing
--------------------------
- scikit-learn does not currently route metadata or non-array attributes through Array API backends. If you rely on array library–specific metadata or device information, convert data explicitly to the expected NumPy/SciPy types prior to calling scikit-learn functions.

Practical recommendations
-------------------------
- Prefer passing NumPy ndarrays or SciPy sparse matrices to scikit-learn APIs.
- If using a third‑party array library, convert explicitly to NumPy (for example, numpy.asarray(x) or a library-provided to_numpy()/get()) before calling scikit-learn to avoid implicit copies and hidden device transfers.
- Ensure feature arrays use a floating dtype appropriate for the estimator (float64 recommended unless you have a reason to use float32).
- For sparse data, use SciPy sparse formats supported by the estimator (CSR/CSC commonly supported).
- When using pipelines or meta-estimators (e.g., MultiOutputRegressor, ClassifierChain), ensure any custom transformers or estimators return NumPy arrays or SciPy sparse matrices compatible with downstream components.

Examples
--------
Basic usage with a third‑party array (explicit conversion):

.. code-block:: py

    import numpy as np
    # x is a third-party array providing a conversion to NumPy
    x_numpy = np.asarray(x)   # explicit conversion to host NumPy array
    model.fit(x_numpy, y)

Using SciPy sparse input (if estimator supports sparse):

.. code-block:: py

    from scipy import sparse
    X = sparse.csr_matrix(data)
    model.fit(X, y)  # works for estimators with documented sparse support

Limitations and incompatibilities
---------------------------------
- scikit-learn does not implement the Array API specification (NEP‑47) as a backend; instead, it relies on NumPy/SciPy types and conversions. Full, upstream Array API compatibility (zero-copy execution on non-NumPy backends, native device execution, or backend dispatching) is not provided.
- Estimators that internally rely on NumPy-specific routines or SciPy sparse operations may fail or be inefficient if given unfamiliar array types without prior conversion.
- Newer array types that do not expose a NumPy conversion mechanism are unlikely to be supported until explicit integration is provided.

Future directions
-----------------
The scientific Python community and the Array API initiative are evolving. Future versions of scikit-learn may expand interoperability with Array API–compliant libraries or introduce explicit backend support where appropriate. For now, the recommended and well-supported path is to use NumPy ndarrays and SciPy sparse matrices, converting third‑party arrays explicitly when needed.

See also
--------
- scikit-learn user guide sections on data representation and supported data types
- NumPy documentation on array interface and __array__ conversion behavior
- SciPy documentation for sparse matrix formats and their usage with machine learning estimators