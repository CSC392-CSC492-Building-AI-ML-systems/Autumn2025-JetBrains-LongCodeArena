sklearn.naive_bayes module
==========================

Overview
--------
The sklearn.naive_bayes module implements a family of Naive Bayes classifiers.
These are supervised learning methods based on applying Bayes' theorem with strong
(naive) independence assumptions between features. The implemented estimators
cover common cases such as continuous features (Gaussian), binary-valued
features (Bernoulli), count features (Multinomial / Complement), and
categorical features (CategoricalNB). Several estimators support incremental
learning via partial_fit.

Contents
--------
.. autosummary::
   :toctree: generated/

   BernoulliNB
   GaussianNB
   MultinomialNB
   ComplementNB
   CategoricalNB


Common base: _BaseNB
--------------------
_BaseNB is an abstract base class for the Naive Bayes estimators and defines
the common prediction API implemented by the concrete estimators.

Common public methods
- fit(X, y, sample_weight=None)
  Train the model given training data X and labels y.

- partial_fit(X, y, classes=None, sample_weight=None)
  Online update of model parameters (supported by estimators that implement it).
  When using partial_fit for the first time, the set of possible classes must be
  passed via the classes parameter.

- predict(X)
  Return predicted class labels for X.

- predict_proba(X)
  Return class membership probabilities for X.

- predict_log_proba(X)
  Return log probabilities for X (log of predict_proba).

- predict_joint_log_proba(X)
  Return joint log-probabilities log P(x, y) = log P(y) + log P(x|y).

Subclasses must implement:
- _joint_log_likelihood(X)
  Compute unnormalized posterior log probabilities for each sample and class.
- _check_X(X)
  Input validation used by predict* methods.


GaussianNB
----------
Gaussian Naive Bayes.

This estimator models each continuous feature with a Gaussian distribution
independently per class. It supports online updates via partial_fit using an
online algorithm to update means and variances.

Parameters
- priors : array-like of shape (n_classes,), default=None
  Prior probabilities of the classes. If specified, these priors are not
  adjusted according to the data.

- var_smoothing : float, default=1e-9
  Portion of the largest variance of all features added to variances for
  numerical stability.

Attributes
- class_count_ : ndarray of shape (n_classes,)
  Number of training samples observed in each class.

- class_prior_ : ndarray of shape (n_classes,)
  Estimated probability of each class.

- classes_ : ndarray of shape (n_classes,)
  Class labels known to the classifier.

- epsilon_ : float
  Absolute additive value to variances for numerical stability.

- n_features_in_ : int
  Number of features seen during fit.

- feature_names_in_ : ndarray of shape (n_features_in_,), optional
  Feature names seen during fit (when X has string feature names).

- var_ : ndarray of shape (n_classes, n_features)
  Variance of each feature per class.

- theta_ : ndarray of shape (n_classes, n_features)
  Mean of each feature per class.

Notes
See the :ref:`Gaussian Naive Bayes user guide <gaussian_naive_bayes>` for more
details on the algorithm and usage.

Example
- Train and predict with GaussianNB:
  clf = GaussianNB()
  clf.fit(X_train, y_train)
  preds = clf.predict(X_test)


BernoulliNB
-----------
Bernoulli Naive Bayes.

Appropriate for binary/boolean features (or for features that are first
binarized). Models feature presence/absence with per-class Bernoulli
distributions.

Typical parameters
- alpha : float, default=1.0
  Additive (Laplace/Lidstone) smoothing parameter.

- binarize : float or None, default=0.0
  Threshold for binarizing (mapping to booleans) of sample features. If None,
  input is expected to be already binary.

- fit_prior : bool, default=True
  Whether to learn class prior probabilities or use provided class_prior.

- class_prior : array-like, default=None
  Prior probabilities of the classes.

Attributes (typical)
- class_count_, class_log_prior_, classes_, feature_count_, theta_


MultinomialNB
-------------
Multinomial Naive Bayes.

Suited for discrete count features (e.g., word counts for text
classification). Models each class-conditional distribution as a multinomial
distribution over feature counts.

Typical parameters
- alpha : float, default=1.0
  Additive smoothing parameter.

- fit_prior : bool, default=True
  Whether to learn class prior probabilities or use provided class_prior.

- class_prior : array-like, default=None
  Prior probabilities of the classes.

Attributes (typical)
- class_count_, class_log_prior_, classes_, feature_count_


ComplementNB
------------
Complement Naive Bayes.

A variant of MultinomialNB designed to address imbalanced data between
classes, often yielding better performance on some text-classification tasks.

Typical parameters
- alpha : float, default=1.0
  Additive smoothing parameter.

- fit_prior : bool, default=True
  Whether to learn class prior probabilities.

- class_prior : array-like, default=None
  Prior probabilities of the classes.

- norm : bool, default=False
  Whether to apply L2 normalization to update weights (implementation detail).

Attributes (typical)
- class_count_, classes_, feature_count_, class_log_prior_


CategoricalNB
-------------
Categorical Naive Bayes.

Models discrete categorical features (with a finite set of categories) by
estimating a categorical distribution for each feature per class.

Typical parameters
- alpha : float, default=1.0
  Additive (Laplace) smoothing parameter.

- fit_prior : bool, default=True
  Whether to learn class prior probabilities or use provided class_prior.

- class_prior : array-like, default=None
  Prior probabilities of the classes.

Attributes (typical)
- class_count_, class_log_prior_, classes_, category_count_, category_log_prob_


Usage notes and tips
- All estimators expose the same prediction methods: predict, predict_proba,
  predict_log_proba, and predict_joint_log_proba (the latter returns unnormalized
  joint log-probabilities).

- When using partial_fit, supply the full set of classes in the first call:
  estimator.partial_fit(X_batch, y_batch, classes=all_classes)

- Many Naive Bayes implementations assume non-negative input (e.g., counts).
  Ensure input is preprocessed appropriately (e.g., binarize, count-vectorize,
  or scale) before fitting.

- Check estimator-specific attributes (e.g., feature_count_, theta_, var_) to
  inspect learned parameters.

See also
- Individual estimator user guides and examples for detailed guidance and
  parameter recommendations.