# General HDF5 file reader

This document describes the general HDF5 file reader facilities and the predefined transformation functions available for processing datasets in HDF5 files. The reader and its transformations are designed to handle three common input shapes robustly:

- h5py.Dataset (lazy HDF5 dataset)
- numpy.ndarray
- dict mapping names -> dataset/array (used when reading multiple child datasets at once)

Transformations accept any of the three forms above and either operate on the container as a whole or on each entry when given a dict.

## Key concepts

- HDF5 transformations are plain callables registered on the HDF5 reader and intended to post-process a dataset or group object returned by the reader.
- Registered transforms are stored in HDF5Reader._transforms (mapping name -> callable). Transforms that require a previously processed attribute (i.e., should only be applied to dataset entries) are recorded in HDF5Reader._attribute_transforms.
- All user-defined transform callables should raise clear exceptions; the decorator wraps exceptions into HDF5TransformationError to provide consistent error messages.

## Error type

- HDF5TransformationError: raised when a registered transformation fails. The original exception is preserved as the cause; the error message identifies the transform that failed.

## Registration decorator

Transforms are registered via a decorator that also marks whether the transform needs a previously processed attribute:

- hdf5_transformation(attribute_needed: bool)

Behavior:
- Decorates a function and registers it in HDF5Reader._transforms under the function name.
- If attribute_needed is True, also adds the function name to HDF5Reader._attribute_transforms.
- Wraps the function so that any exception raised inside is re-raised as an HDF5TransformationError with the transform name included.

## Common usage patterns

- Direct transformation: a transform can be invoked with a h5py.Dataset, numpy array, or dict of nameâ†’dataset to get a processed result.
- When given a dict, the transform is expected to be applied to each dict value and return a dict of the same keys with transformed values (this is the behavior implemented by the built-in transforms).
- Some transforms only make sense for pure h5py.Dataset inputs (e.g., retrieving the dataset name). In such cases, using them on arrays/lists will raise a ValueError.

## Built-in transformations

Below is a concise reference for the predefined transformations that are provided out of the box.

- get_first_element(dataset)
  - Returns the first element of dataset (index 0).
  - Accepts h5py.Dataset, numpy array, or dict -> applies indexing per-key for dict inputs.

- index_dataset(dataset, index)
  - Returns dataset[index].
  - Accepts h5py.Dataset, numpy array, or dict -> applies indexing per-key for dict inputs.

- slice_dataset(dataset, slice_arg)
  - Returns dataset[slice_arg].
  - Accepts h5py.Dataset, numpy array, or dict -> applies the slice per-key for dict inputs.

- get_shape(dataset)
  - Returns the shape attribute (dataset.shape) of the dataset.
  - For dict inputs returns a dict mapping keys -> shapes.

- get_name(dataset, full_path=False)
  - Returns the name of the dataset.
  - If full_path is False returns only the final path component (dataset.name.split('/')[-1]); if True returns the full path (dataset.name).
  - Requires an h5py.Dataset-like object for single-value usage; when given a dict it returns a dict mapping keys -> names.
  - Passing a list or numpy array raises ValueError.

- tile_array(dataset, n_repeats)
  - Applies numpy.tile to repeat the array n_repeats times.
  - For dict inputs, the operation is applied per key and returns a dict mapping keys -> tiled arrays.

- repeat_array(dataset, n_repeats)
  - Applies numpy.repeat to repeat each element n_repeats times.
  - For dict inputs, the operation is applied per key and returns a dict mapping keys -> repeated arrays.

- get_all_child_datasets(group, ignore=None, contains=None)
  - Scans the given group (mapping-like h5py group) and returns a dict mapping dataset-name -> h5py.Dataset for all direct child datasets.
  - ignore: a string or iterable of strings; any child key containing any of those phrases is skipped.
  - contains: a string or iterable of strings; if provided, only keys that include all phrases in contains are included.
  - Only direct children that are h5py.Dataset are returned (no recursion).

## Examples

- Get first element of a dataset:
  - result = HDF5Reader._transforms['get_first_element'](dataset)

- Get shapes for all child datasets in a group:
  - datasets = HDF5Reader._transforms['get_all_child_datasets'](group, ignore={'meta'}, contains=None)
  - shapes = HDF5Reader._transforms['get_shape'](datasets)

- Get dataset names (final name component) for a group:
  - datasets = HDF5Reader._transforms['get_all_child_datasets'](group)
  - names = HDF5Reader._transforms['get_name'](datasets, full_path=False)

Note: the transforms are registered under their function names and can be invoked via the HDF5Reader._transforms mapping. Transforms that require previously processed attributes are recorded in HDF5Reader._attribute_transforms and should be applied in contexts where such attributes are available.

## Notes and best practices

- Transforms should be resilient to the three supported input forms (h5py.Dataset, numpy array, dict). When a transform cannot meaningfully operate on a given input type it should raise a clear error.
- Any exceptions raised in a transform are converted to HDF5TransformationError to ease debugging and error reporting.
- When applying transforms to dict inputs, expect the return value to mirror the input dict structure (same keys).
- Use get_all_child_datasets to collect unknown child datasets of a group into a single dict and then apply other transforms to that dict to process all child datasets uniformly.