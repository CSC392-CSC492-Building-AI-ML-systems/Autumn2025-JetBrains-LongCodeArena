Feature Extraction for Model Inspection
======================================

Overview
--------
The feature extraction utilities provide a lightweight way to inspect intermediate
activations of a PyTorch model by symbolically tracing its forward graph with
torch.fx and returning a new nn.Module that yields the requested intermediate
tensors. The main entry points are:

- create_feature_extractor — build a module that returns intermediate features.
- get_graph_node_names — list the available node names in the traced graph.

These utilities use a custom tracer that records a readable, module-relative
qualified name for each traced node so you can refer to intermediate tensors by
stable, human-friendly names.

How node names work
-------------------
- Node names are "`.` separated" paths that walk the module hierarchy from the
  top-level module down to the leaf operation or leaf module. The top-level
  module name is not included.
- For module calls (call_module), the qualified name is the module path (e.g.
  "layer1.conv").
- For other ops (call_function, call_method, etc.) the tracer appends a
  representation of the node, producing names like "layer1.conv.relu" or
  "some_submodule.add_1".
- When the same local name appears multiple times under the same parent, a
  local index suffix _{i} is added (starting at _1) to disambiguate.
- You can treat certain module classes as "leaves" (not traced through) so that
  a single node represents the entire module call. This is useful for complex
  building-block modules you want to treat as atomic.

Finding available node names
----------------------------
Before building a feature extractor, list the available graph node names:

.. code-block:: python

    from torchvision.models.feature_extraction import get_graph_node_names
    model.eval()
    node_names = get_graph_node_names(model)
    for name in node_names:
        print(name)

This helps you choose which intermediate activations to extract.

Specifying return nodes
-----------------------
create_feature_extractor accepts a mapping of graph node names to user keys
that will be used in the output OrderedDict. For example, to extract two
intermediate activations:

.. code-block:: python

    from torchvision.models.feature_extraction import create_feature_extractor
    return_nodes = {
        "layer1.conv": "feat1",
        "layer3.block2.relu": "feat2",
    }
    feat_extractor = create_feature_extractor(model, return_nodes=return_nodes)
    outputs = feat_extractor(input_tensor)
    # outputs is an OrderedDict: {"feat1": tensor, "feat2": tensor}

The output is an OrderedDict that maps the user-provided keys to the
corresponding tensors.

Leaf modules and custom tracing
-------------------------------
The tracer supports specifying a set of leaf module classes (tuple of types)
that should not be traced into. When such modules are encountered, the tracer
creates a single node representing the module's forward call rather than
inlining its internal operations. This is useful to:

- Keep names shorter and focused on logical modules.
- Avoid exposing many internal ops from library building blocks.

You can pass leaf module types when creating the tracer or through utilities
that accept a leaf_modules argument.

Train vs. eval tracing differences
----------------------------------
The tracer records node names based on the code paths executed during tracing.
Some modules change behavior between train() and eval() (for example,
dropout, tracking statistics in batchnorm, or control-flow differences). As a
result, the set and ordering of nodes discovered in train mode may differ from
eval mode.

The utilities will attempt to detect such differences and warn you. If you
need to extract nodes that only exist (or are named differently) in a
particular mode, trace the model in that mode and supply the appropriate node
names to create_feature_extractor. The warning suggests specifying output nodes
separately for train and eval modes when necessary.

Practical tips
--------------
- Always call model.eval() (or model.train()) before listing node names so the
  tracer captures the graph for the intended mode.
- Use get_graph_node_names to discover candidate nodes and then map them to
  friendly output keys when calling create_feature_extractor.
- Use leaf modules to hide internal details of complex submodules and obtain
  cleaner node names.
- If you observe unexpected missing nodes or name differences between modes,
  trace both modes explicitly and select the appropriate node names for each.

Examples
--------
Basic example:

.. code-block:: python

    model.eval()
    nodes = get_graph_node_names(model)
    # choose nodes of interest from printed list
    return_nodes = {nodes[10]: "feat_a", nodes[25]: "feat_b"}
    feat_extractor = create_feature_extractor(model, return_nodes=return_nodes)
    features = feat_extractor(torch.randn(1, 3, 224, 224))
    print(features["feat_a"].shape, features["feat_b"].shape)

Using leaf modules:

.. code-block:: python

    from torchvision.models.feature_extraction import create_feature_extractor
    from torchvision.models.resnet import Bottleneck
    # treat Bottleneck blocks as leaves
    feat_extractor = create_feature_extractor(model, return_nodes={"layer3": "layer3_out"},
                                              leaf_modules=(Bottleneck,))
    out = feat_extractor(input)

Limitations
-----------
- Node names depend on the traced execution path; dynamic control flow or
  conditionally executed ops can lead to different graphs across runs or modes.
- The mapping between fx nodes and human-meaningful operations is best-effort;
  inspect printed node names to ensure you select the intended nodes.

See also
--------
- create_feature_extractor
- get_graph_node_names