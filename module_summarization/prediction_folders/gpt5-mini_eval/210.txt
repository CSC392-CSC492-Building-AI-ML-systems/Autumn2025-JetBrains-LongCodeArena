Empirical likelihood
====================

Overview
--------
This module implements empirical likelihood (EL) inference for descriptive
statistics: hypothesis testing and confidence interval construction for the
mean, variance, skewness, kurtosis, and correlation.  It supports both
univariate and multivariate data and can produce multivariate confidence
regions and mean–variance contour plots when matplotlib is available.

The implementation is based on the empirical likelihood profile likelihood
approach (Owen, 2001).  Constraints are expressed as moment/estimating
equations and EL is computed by profiling over a Lagrange multiplier that
enforces those constraints.  Optimization is performed using a modified
Newton solver with numerically stabilized transformations for small-probability
observations.

Requirements
------------
- numpy
- scipy
- statsmodels (for the Newton solver wrapper; optional plotting utilities)
- matplotlib (optional, for plotting routines)

Quick start
-----------
1. Construct a descriptive-statistics inference instance from your data:

    from emplike import DescStat
    ds = DescStat(endog)    # endog: 1-D array or 2-D array (nobs x k)

   - If endog is 1-D or has shape (nobs, 1) the returned object is the
     univariate-desc-stat instance (DescStatUV).
   - If endog has more than one column the returned object is the
     multivariate-desc-stat instance (DescStatMV).

2. Use the returned instance to perform EL hypothesis tests and to obtain
   confidence intervals/regions for parameters of interest (mean, variance,
   skewness, kurtosis, correlation).  When available the multivariate
   instance provides plotting helpers to draw confidence regions and
   mean–variance contours.

Module functionality (high level)
---------------------------------
- Hypothesis testing for descriptive parameters using empirical likelihood
  ratio statistics.
- Confidence intervals for:
  - Univariate: mean, variance, skewness, kurtosis.
  - Multivariate: vector means, pairwise correlations, and joint regions.
- Multivariate confidence region plotting and mean–variance contour plots
  (requires matplotlib).
- Weighting: supports observation weights in the EL formulation.
- Numerics: stabilized transformations for log-probabilities and a
  modified Newton solver for profiling over Lagrange multipliers.

Design and algorithms
---------------------
Estimating equations and constraints
- EL is built from estimating equations g(x_i, theta) so that the empirical
  probabilities p_i satisfy sum_i p_i g(x_i, theta) = 0 and sum_i p_i = 1.
- For descriptive statistics these estimating equations correspond to
  moment conditions (e.g., x - mu for the mean; functions of x for variance,
  skewness, kurtosis, correlations).

Profile likelihood via Lagrange multipliers
- The method profiles out the empirical probabilities by introducing a
  Lagrange multiplier vector eta.  The optimal p_i are expressed in closed
  form in terms of eta, and the profile (log-)likelihood is a function of eta.
- In the presence of nuisance parameters, the code profiles over these
  as well (internal optimizers over nuisance parameters call the EL solver
  repeatedly).

Numerical stabilization: log-star transform
- To avoid numerical issues when probabilities become very small, the
  implementation uses a stabilized transformation (log-star) on the
  arguments that would otherwise be inverted or logged.  This improves
  robustness for moderate sample sizes and extreme constraints.

Modified Newton solver
- The Lagrange multiplier is solved using a modified Newton method that
  requires the profile objective, its gradient, and its Hessian.  The
  implementation provides:
    - _log_star(eta, est_vect, weights, nobs): stabilized log representation
      of the observation contributions to the profile objective.
    - _grad(eta, est_vect, weights, nobs): gradient of the weighted EL
      profile w.r.t. eta.
    - _hess(eta, est_vect, weights, nobs): Hessian (matrix) of the weighted
      EL profile.
    - _modif_newton(eta, est_vect, weights): wrapper that calls a
      Newton-based optimizer to find the eta that maximizes the profile
      objective.  This uses the above functions and a numerical Newton
      routine from statsmodels for robust performance.

API summary
-----------
- DescStat(endog)
  - Factory that returns a descriptive-statistics inference object:
    - DescStatUV for univariate data (k = 1)
    - DescStatMV for multivariate data (k > 1)
  - Parameter
    - endog : ndarray
      - 1-D array of observations or 2-D array with shape (nobs, k).

- _OptFuncts (internal)
  - A helper class containing the optimization-relevant functions used by
    the EL solvers.  Key methods:
    - _log_star(eta, est_vect, weights, nobs)
      - Numerically stabilized transformation of the log-probabilities.
      - Returns the (weighted) log-star contributions per observation.
    - _grad(eta, est_vect, weights, nobs)
      - Returns the gradient (vector) of the profile objective w.r.t. eta.
    - _hess(eta, est_vect, weights, nobs)
      - Returns the Hessian (matrix) of the profile objective.
    - _modif_newton(eta, est_vect, weights)
      - Runs a modified Newton solver (via statsmodels._fit_newton) to find
        the eta that maximizes the stabilized profile objective.
    - (additional internal helpers prefixed with _opt_ and _ci_limits)
      - _opt_...: used to construct estimating-equation matrices for
        constrained/nuisance-parameter problems.
      - _ci_limits...: used to evaluate the profile log-likelihood ratio
        for fixed parameter values and to root-solve for confidence limits.

Notes on usage
--------------
- The package is designed to be used at a high level via the DescStat
  objects: obtain tests and confidence intervals/regions for parameters of
  interest.  Internally the estimators assemble estimating-equation vectors
  and call the EL profiling machinery.
- The EL ratio statistic is asymptotically chi-square distributed under
  standard regularity conditions (useful for hypothesis testing and for
  calibrating confidence regions).
- Numerical tolerance and maximum iterations are configurable in the
  optimizer wrappers; the default tolerances are selected to provide a
  balance of speed and accuracy for typical sample sizes.

Examples
--------
- Univariate data:
    ds = DescStat(x)          # x: 1-D array
    # ds provides EL-based hypothesis tests and confidence intervals for
    # mean, variance, skewness, kurtosis.

- Multivariate data:
    ds = DescStat(X)          # X: n x k array, k > 1
    # ds provides joint EL inference for multivariate mean vectors,
    # pairwise correlations, multivariate confidence regions, and plotting
    # utilities for visualizing confidence regions.

References
----------
Owen, A. (2001). Empirical Likelihood. Chapman & Hall.

Acknowledgements
----------------
The optimization wrapper leverages the Newton solver used in statsmodels
for stable root-finding and optimization in profiling the EL Lagrange
multipliers.