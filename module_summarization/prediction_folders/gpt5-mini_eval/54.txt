Working with Large Data Sets
===========================

Overview
--------
This module documents distributed estimation routines for large-scale regression problems where data are partitioned across machines or processes. The framework supports multiple distribution strategies and estimation methods and provides utilities for bias correction (debiasing) of regularized estimators so that averaged estimates across partitions can be used for inference.

Distribution methods
--------------------
- sequential: single-process execution, no extra dependencies.
- parallel: multi-process or cluster execution; supported backends via joblib include
  dask.distributed, yarn, ipyparallel and other joblib backends.

Estimation strategies
---------------------
- Naive coefficient averaging
  - Regularized (via model.fit_regularized)
  - Unregularized (via model.fit)
  - Simple average of partition-wise fitted coefficients, optionally thresholded to induce sparsity.
- Debiased regularized estimation (default)
  - Each partition fits a regularized estimator (LASSO/Ridge/more) and computes a gradient and a weighted design matrix.
  - Node-wise regressions (LASSO) on the weighted design construct an approximate inverse covariance.
  - An approximate inverse covariance is used to debias the averaged coefficients, improving asymptotic properties for sparse high-dimensional problems.
  - Follows methodology related to: Lee, Liu, Sun, Taylor (2015), "Communication-Efficient Sparse Regression: A One-Shot Approach." arXiv:1503.04337.

Key concepts and variables
--------------------------
- mod
  - A statsmodels model instance for a partition (provides .exog, .score, .hessian_factor, fit methods).
- partitions, pnum / mnum
  - Number of partitions and index of the current partition.
- fit_kwds, score_kwds, hess_kwds
  - Keyword argument dictionaries forwarded to the model's fit_regularized / fit, score, and hessian-related calls.
- alpha
  - Penalty weight (scalar or vector) used in regularized fits.
- L1_wt
  - Fraction of penalty allocated to the L1 term (0 → ridge, 1 → LASSO).
- wexog
  - Weighted design matrix created as sqrt(hessian_factor(params)) * X; used for node-wise regressions to estimate the inverse covariance.
- nodewise_row
  - Coefficients produced by node-wise LASSO regressions (one per variable) used to approximate the precision matrix.
- nodewise_weight
  - Weights derived from node-wise fits (gamma_hat) used to reweight node-wise coefficients when forming the approximate inverse covariance.
- approx_inv_cov
  - Estimated approximate inverse covariance matrix used to debias averaged coefficients. For OLS this approximates n * (X^T X)^{-1}.

Function reference
------------------

_est_regularized_naive(mod, pnum, partitions, fit_kwds=None)
  - Purpose: Fit a regularized model on a partition and return its fitted parameters.
  - Inputs: statsmodels model instance `mod`; partition index `pnum`; total `partitions`; non-empty dict `fit_kwds` forwarded to `mod.fit_regularized`.
  - Returns: array of fitted parameters.
  - Notes: Raises ValueError if `fit_kwds` is None.

_est_unregularized_naive(mod, pnum, partitions, fit_kwds=None)
  - Purpose: Fit an unregularized model on a partition (standard fit) and return parameters.
  - Inputs: same shape as above; `fit_kwds` forwarded to `mod.fit`.
  - Returns: array of fitted parameters.
  - Notes: Raises ValueError if `fit_kwds` is None.

_join_naive(params_l, threshold=0)
  - Purpose: Aggregate partition-wise parameter arrays by simple averaging.
  - Inputs: `params_l` (list of parameter arrays from partitions), `threshold` (values with absolute magnitude smaller than threshold are set to zero).
  - Returns: averaged parameter vector with optional thresholding applied.

_calc_grad(mod, params, alpha, L1_wt, score_kwds)
  - Purpose: Compute the (negative) log-likelihood gradient used in debiasing.
  - Formula: grad = - mod.score(params, **score_kwds) + alpha * (1 - L1_wt)
  - For OLS, mod.score corresponds to X^T (y - X beta) so that the returned gradient aligns with X^T(y - X beta) up to sign.
  - Returns: gradient array with the same dimension as `params`.

_calc_wdesign_mat(mod, params, hess_kwds)
  - Purpose: Build the weighted design matrix used for node-wise regressions.
  - Operation: rhess = sqrt(mod.hessian_factor(params, **hess_kwds)); returns rhess[:, None] * mod.exog
  - Returns: weighted design matrix (same shape as mod.exog).

_est_regularized_debiased(mod, mnum, partitions, fit_kwds=None, score_kwds=None, hess_kwds=None)
  - Purpose: Default partition-level routine for debiased regularized estimation.
  - Behavior: Fits a regularized estimator; computes gradient and weighted design; performs node-wise regressions to estimate an approximate inverse covariance; produces quantities necessary to form a debiased, communication-efficient aggregate estimator.
  - Inputs: model `mod`; partition index `mnum`; `partitions`; fit/score/hessian keyword dicts.
  - Typical outputs (tuple): fitted parameters and auxiliary objects used for debiasing such as gradient, weighted design (`wexog`), node-wise results (`nodewise_row`, `nodewise_weight`) and `approx_inv_cov`. These objects are used to form the final debiased aggregated estimator centrally.

Practical notes and behavior
----------------------------
- The naive approach is trivial and fast but does not correct bias introduced by regularization; debiasing is recommended when inference or reduced bias is required.
- Node-wise regressions for approximate inverse covariance typically use LASSO; tuning and implementation details live in the node-wise regression utilities.
- The approximate inverse covariance is an approximation; for OLS it targets n * (X^T X)^{-1} formed via node-wise regression rather than explicit matrix inversion — useful when p is large.
- Careful selection of penalty parameters, L1 weight, and node-wise tuning is required for reliable debiasing.
- Parallel execution via joblib requires appropriate backend configuration; sequential execution needs no extra dependencies.

Example workflow (high level)
-----------------------------
1. Partition your dataset across workers.
2. On each partition, call the debiased estimator routine to obtain fitted params and auxiliary debiasing objects (gradients, wexog, nodewise outputs).
3. Aggregate (average) parameters and combine auxiliary quantities centrally to form an approximate inverse covariance and compute the debiased aggregate estimator.
4. Optionally threshold small coefficients for sparsity and interpret results.

References
----------
- Lee, J. D., Liu, Q., Sun, Y., & Taylor, J. (2015). Communication-Efficient Sparse Regression: A One-Shot Approach. arXiv:1503.04337.