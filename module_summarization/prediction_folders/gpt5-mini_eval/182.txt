Developing scikit-learn estimators
==================================

Overview
--------
This document summarizes conventions, utilities and recommended practices for
implementing estimators compatible with scikit-learn. It focuses on the public
estimator API (fit / predict /transform /score /partial_fit), parameter handling,
composition (meta-estimators), multioutput support and common helper utilities
available in the codebase.

Requirements and dependencies
-----------------------------
When developing or testing estimators in the scikit-learn project, be mindful of
the project's minimum dependency constraints (NumPy, SciPy, joblib, threadpoolctl,
Cython, pytest, etc.). These are centrally defined for CI and packaging; tests
and local development should use versions at or above those minima.

Estimator API and surface
-------------------------
All estimators must implement the public methods appropriate to their task:

- Supervised estimators:
  - fit(X, y, **fit_params) — learn parameters from data.
  - predict(X) — return predictions for X (regressors and classifiers).
  - predict_proba(X) / decision_function(X) — where appropriate for classifiers.
  - score(X, y) — optional convenience method (mixins provide defaults).

- Online or incremental estimators:
  - partial_fit(X, y, classes=None, **params) — update model incrementally.

- Transformers:
  - fit(X, y=None, **fit_params)
  - transform(X)
  - fit_transform(X, y=None, **fit_params)

Conform to the following rules:
- fit must return self.
- Methods that require the estimator to be fitted should call check_is_fitted to raise a consistent error if not fitted.
- Support sample_weight in fit when relevant; detect via has_fit_parameter to ensure callers can pass sample weights safely.

Base classes and mixins
-----------------------
Use the base classes and mixins provided by the library to ensure consistent
behavior and metadata:

- BaseEstimator: provides get_params / set_params and parameter handling.
- RegressorMixin / ClassifierMixin: provide default score implementations and
  clarify estimator behavior.
- MetaEstimatorMixin: use for meta-estimators that wrap another estimator
  (stores wrapped estimator in an attribute named estimator).

These base classes also integrate parameter validation and cloning semantics.

Parameter validation
--------------------
Prefer the _parameter_constraints mechanism to declare accepted parameter types
and validation rules. Parameters should be documented and exposed via the
constructor with no side effects. The constructor should only set attributes
(e.g. self.param = param) and not perform any heavy computation.

Cloning and composition
-----------------------
Implementations that store sub-estimators should be compatible with clone
(see sklearn.clone). clone relies on get_params and set_params, so nested
estimators must be passed as constructor arguments and stored as attributes.

Use helpers:
- clone(estimator) to obtain an unfitted, independent copy before fitting.
- is_classifier(estimator) to detect classifier behavior when building composite
  logic (for example to set classes for partial_fit).

Meta-estimators and multioutput support
---------------------------------------
Meta-estimators adapt a base estimator to a different use case (e.g., extend
single-output estimators to multioutput). When implementing meta-estimators:

- Accept an estimator argument in the constructor and support n_jobs where
  parallelization of independent fits is possible.
- Use MetaEstimatorMixin to standardize behavior.
- Ensure compatibility with clone so that each fitted sub-estimator is a
  separate cloned instance.

The codebase includes common helpers for multioutput/meta-estimator
implementations:

- _fit_estimator(estimator, X, y, sample_weight=None, **fit_params)
  — clones and fits a single estimator (handles sample_weight when provided).

- _partial_fit_estimator(estimator, X, y, classes=None, partial_fit_params=None, first_time=True)
  — clones on first_time and calls partial_fit appropriately, passing classes
  when required.

- _available_if_estimator_has(attr)
  — builds an availability predicate to expose methods on the wrapper only if
  all wrapped sub-estimators implement a given method (used with available_if).

- _MultiOutputEstimator base class
  — abstract base class for multioutput meta-estimators; declares expected
  constructor signature and parameter constraints for estimator and n_jobs.

Parallelization
---------------
When fitting multiple independent sub-estimators (for different outputs or
folds), prefer joblib.Parallel and joblib.delayed to parallelize loops safely.
Respect n_jobs semantics and ensure deterministic behavior when a random state
is required (use check_random_state).

Metadata routing and advanced utilities
---------------------------------------
The project contains utilities to route metadata and method calls across
components (MetadataRouter, MethodMapping, process_routing, _routing_enabled,
_raise_for_params). Use these tools when building components that need to
propagate dataset-level metadata or map method names between wrappers and
wrapped estimators.

Use available_if to conditionally expose methods (e.g., predict_proba) on
wrappers only when the wrapped estimators implement them.

Validation and safety checks
----------------------------
- Validate input types and shapes using the shared validation utilities.
- Use check_classification_targets for classification targets.
- Use _check_method_params where applicable to validate fit-time parameters.
- call check_is_fitted at the start of predict/transform/score methods to
  provide consistent error messages to users.

Cross-validation utilities
--------------------------
When implementing methods that rely on cross-validated predictions internally,
use cross_val_predict from the model_selection module to maintain consistent
behavior with scikit-learn's CV semantics.

Testing and tooling
-------------------
- Write comprehensive unit tests for estimator behavior (fit/predict/partial_fit,
  persistence, cloning, parameter setting).
- Test multithreading/parallel behavior (n_jobs), reproducibility with random
  state, and sample_weight handling.
- Follow code style and static checks used in the project (formatters, linters,
  mypy types where used).

Example sketch (multioutput wrapper)
-----------------------------------
A typical multioutput wrapper will:
- accept estimator and n_jobs in __init__;
- clone and fit separate estimators per output in fit using _fit_estimator and joblib.Parallel;
- expose predict by delegating to the sequence of fitted estimators;
- implement available_if-based predicates to expose methods only when all
  sub-estimators support them.

Contributing
------------
Follow the project's contribution guidelines for PR structure, tests, CI and
changelog entries. Keep changes modest and well-tested; prefer reusing shared
utilities and helpers described above to ensure consistent behavior across the
codebase.