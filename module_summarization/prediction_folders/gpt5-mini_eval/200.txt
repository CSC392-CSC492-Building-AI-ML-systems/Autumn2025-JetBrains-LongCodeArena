Outlier detection and novelty detection
=====================================

Overview
--------
Outlier and novelty detection are concerned with finding observations that deviate
from the majority of the data. The two tasks are closely related but differ in
their assumptions and intended use:

- Novelty detection (also called semi-supervised anomaly detection) assumes the
  training data are "clean" (contain only or mostly normal/inlier examples).
  The learned model is used to detect novel or abnormal observations at test
  time.
- Outlier detection (unsupervised anomaly detection) assumes the training data
  may itself contain outliers. The goal is to identify the outliers in the
  provided dataset.

Many estimators in this area provide both hard labels (inlier vs outlier) and
continuous anomaly scores that can be thresholded.

Common estimators
-----------------
Typical algorithms used for novelty and outlier detection include:

- EllipticEnvelope
  - Fits a robust Gaussian (minimum covariance determinant) to the data.
  - Appropriate when the inliers follow an elliptical (Gaussian-like)
    distribution.
- OneClassSVM
  - A kernel-based method that estimates a decision boundary around the
    training data.
  - Useful for complex boundaries but can be slow on large datasets.
- IsolationForest
  - A treeâ€‘ensemble method that isolates anomalies using random partitions.
  - Scales well to medium/high dimensional data and large datasets.
- LocalOutlierFactor (LOF)
  - A density-based method comparing local density of a point to that of its
    neighbors.
  - Designed to detect local anomalies that differ from nearby points.

Key concepts and API
--------------------
- Labels: most estimators use label values of 1 for inliers (normal) and -1
  for outliers (anomalies).
- fit(X): train the model on data X.
- predict(X): return discrete labels (1 or -1) for samples X. For some
  estimators (e.g., LOF) predict is available only when the estimator is
  configured for novelty detection.
- fit_predict(X): fit on X and return labels for X (useful for unsupervised
  outlier detection when you want labels for the training set).
- decision_function(X) and score_samples(X): return continuous anomaly scores.
  Higher values typically indicate more normal (inlier) behavior for many
  estimators; check the estimator-specific documentation for the exact sign
  convention.
- contamination: a parameter (or other mechanism) used to set the expected
  proportion of outliers (used to derive a threshold for converting scores to
  labels). It can be used when you have an a priori estimate of outlier
  frequency.

Novelty vs outlier (practical differences)
------------------------------------------
- If you have a clean training set and will score new incoming samples, prefer
  novelty detection: train on known-normal data, then use predict/decision_function
  on new observations.
- If you must discover anomalies in a dataset that may itself contain outliers,
  use unsupervised outlier detection: call fit_predict on the dataset to obtain
  labels for the training points.
- Some estimators expose a novelty parameter (for example LOF in scikit-learn).
  When novelty=False the estimator is intended for outlier detection only and
  may not support predicting on new, unseen data. When novelty=True it is
  suitable for novelty detection and will provide predict/decision_function for
  new samples.

Practical guidance
------------------
- Preprocessing: scale features (standardization) and handle categorical
  variables appropriately. Many algorithms are sensitive to feature scales.
- Dimensionality: methods like IsolationForest and tree-based techniques tolerate
  higher dimensionality better than some density-based or kernel methods.
  Consider dimensionality reduction (PCA, autoencoders) when features are very
  high-dimensional.
- Runtime and memory: kernel methods (OneClassSVM) and exact nearest-neighbor
  computations (LOF) can be slow and memory heavy on large datasets.
  IsolationForest and approximate methods scale more favorably.
- Randomness: many ensemble-based methods (IsolationForest) use randomness;
  set random_state for reproducibility.
- Thresholding: if contamination is unknown, set a threshold on score_samples
  using domain knowledge, cross-validation on labeled examples, or by choosing
  a quantile of the score distribution.

Evaluation
----------
Evaluating outlier detection is challenging when labels are scarce. Common
approaches include:

- If labels are available: use ROC AUC, precision-recall curves, average
  precision, precision@k, and F1-score (with an appropriate threshold).
- If labels are not available: inspect top-ranked anomalies, perform manual
  validation, or use proxy tasks to estimate performance.
- When using contamination to set thresholds, be aware that an incorrect
  contamination estimate will bias precision/recall trade-offs.

Notes and caveats
-----------------
- The sign and scale of anomaly scores differ between estimators; consult the
  estimator documentation for details.
- Many algorithms assume continuous numerical features. Categorical or mixed
  data types may require specialized preprocessing or methods.
- Outlier and novelty detection are domain-sensitive tasks: algorithm choice,
  preprocessing, and threshold selection should be guided by domain knowledge
  and validation when possible.

References and further reading
------------------------------
For more details about each estimator and their specific options and methods,
see the estimator API reference and examples detailing usage patterns and
best practices.