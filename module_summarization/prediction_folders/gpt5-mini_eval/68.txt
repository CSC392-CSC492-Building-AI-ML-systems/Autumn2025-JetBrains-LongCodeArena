Gaussian process kernels
========================

This module provides kernel implementations and supporting utilities used for
Gaussian process regression and classification. The kernels are designed to
support kernel engineering (composition and arithmetic), analytic
gradient-based hyperparameter optimization, and both isotropic and
anisotropic length-scales.

Overview
--------

Kernels implemented here can be combined using Python operators:

- Sum: kernel_a + kernel_b
- Product: kernel_a * kernel_b
- Constant scaling / exponentiation with scalars: kernel ** scalar or scalar
  appearing in expressions (scalars are converted to constant kernels)

These composition operators yield kernel expressions that themselves behave
like kernels and expose their own hyperparameters for tuning. All kernels
support analytic gradients of kernel hyperparameters so they can be used with
gradient-based optimizers.

Key concepts
------------

- Hyperparameters. Each kernel exposes hyperparameters described by the
  Hyperparameter namedtuple with fields:
  - name: the attribute name used on the kernel (e.g., "length_scale")
  - value_type: currently "numeric"
  - bounds: lower and upper bounds (or the string "fixed")
  - n_elements: number of elements (1 for scalar, >1 for vector-valued)
  - fixed: whether the hyperparameter is fixed (cannot be optimized)

  The Hyperparameter type validates bounds (allows broadcasting for
  vector-valued parameters) and derives fixed from bounds when appropriate.

- Kernel base class. Kernel is the abstract base class for all kernels in
  this module. Kernels should implement the kernel function and, where
  appropriate, derivatives wrt hyperparameters. The base class provides a
  robust get_params method that introspects constructor arguments, exposing
  kernel configuration for integration with scikit-learn-style estimators and
  hyperparameter search.

Utilities
---------

- _check_length_scale(X, length_scale)
  Validates and normalizes length-scale values. Accepts scalar or 1-D array.
  Raises on dimension mismatch for anisotropic length-scales (the array
  length must equal the number of features in X) or on higher-dimensional
  length_scale inputs.

- Integration helpers and imports used by kernels:
  - pairwise_kernels: wrapper utilities for pairwise kernel computations
  - scipy.spatial.distance.cdist, pdist, squareform: distance computations
  - scipy.special.gamma, kv: special functions used by some covariance
    functions (e.g., Mat√©rn kernels)
  - numpy: array operations
  - clone: utility to deep copy kernels
  - ConvergenceWarning: warnings used during hyperparameter optimization

Examples
--------

Combining kernels and specifying hyperparameter bounds:

:: 
    from sklearn.gaussian_process.kernels import RBF, ConstantKernel
    # isotropic RBF with length scale bound between 1e-2 and 1e2
    k1 = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))
    # constant kernel with bounds
    k2 = ConstantKernel(constant_value=1.0, constant_value_bounds=(1e-3, 1e3))
    # composite kernel (product and sum)
    kernel = k2 * k1 + 0.5**2

Specifying anisotropic length-scales:

::
    # length_scale can be a 1-D array of length n_features
    anisotropic_rbf = RBF(length_scale=[1.0, 0.5, 2.0],
                          length_scale_bounds=(1e-2, 1e2))

Accessing hyperparameters:

::
    hp_list = kernel.hyperparameters
    for hp in hp_list:
        print(hp.name, hp.bounds, "fixed" if hp.fixed else "free")

Validation of length-scales:

::
    X = np.zeros((10, 3))
    _check_length_scale(X, 1.0)            # ok (isotropic)
    _check_length_scale(X, [1.0, 0.5, 2.0])  # ok (anisotropic)
    _check_length_scale(X, [1.0, 0.5])     # raises ValueError

Notes
-----

- Hyperparameter bounds may be a 2D array to specify per-element bounds for
  vector-valued hyperparameters. For convenience, a single row of bounds is
  broadcast to all elements.
- Passing the string "fixed" as bounds marks a hyperparameter as fixed.
- Kernel implementations are expected to follow scikit-learn estimator
  conventions: all constructor parameters should be explicit keyword
  arguments (no varargs) so that get_params works correctly.

See also
--------

- GaussianProcessRegressor and GaussianProcessClassifier for how kernels are
  used in Gaussian process models (examples above illustrate typical kernel
  construction patterns).