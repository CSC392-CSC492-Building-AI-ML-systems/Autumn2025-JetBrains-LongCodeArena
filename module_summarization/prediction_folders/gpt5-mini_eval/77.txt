Transforms utilities
====================

Overview
--------
This module provides a small collection of image transform utilities commonly used when preparing image data for models:
- InterpolationMode: enumeration of available interpolation modes.
- Utilities to query image dimensions (width/height/channels) independent of underlying representation (PIL Image or Tensor).
- Converters between PIL / numpy images and torch.Tensor (both a normalized float tensor and a tensor preserving the underlying dtype).

These functions accept PIL Images, numpy.ndarray, and torch.Tensor (where applicable) and unify behavior between PIL- and Tensor-backed images.

InterpolationMode
-----------------
Enumeration of supported interpolation modes. Use these names when selecting interpolation behavior in image resize/transform APIs.

Members
- NEAREST: "nearest"
- NEAREST_EXACT: "nearest-exact"
- BILINEAR: "bilinear"
- BICUBIC: "bicubic"
- BOX: "box" (PIL compatibility)
- HAMMING: "hamming"
- LANCZOS: "lanczos"

Utilities
- pil_modes_mapping: maps InterpolationMode -> PIL integer codes (useful when calling PIL resize directly).
- _interpolation_modes_from_int(i: int) -> InterpolationMode: convert a PIL integer code back into an InterpolationMode.

Image inspection helpers
------------------------
get_dimensions(img)
    Returns image dimensions as [channels, height, width].

    Args:
        img (PIL Image or torch.Tensor): input image.

    Returns:
        List[int]: [C, H, W]

get_image_size(img)
    Returns image size as [width, height].

    Args:
        img (PIL Image or torch.Tensor): input image.

    Returns:
        List[int]: [W, H]

get_image_num_channels(img)
    Returns number of channels in the image.

    Args:
        img (PIL Image or torch.Tensor): input image.

    Returns:
        int: number of channels.

Notes
- These helpers dispatch to appropriate backend implementations depending on whether img is a torch.Tensor or a PIL Image.
- They can be used without needing to know the underlying representation of the image.

Tensor conversion utilities
---------------------------

to_tensor(pic) -> torch.Tensor
    Convert a PIL Image or numpy.ndarray to a torch.Tensor. This function:
    - Accepts PIL Images and numpy.ndarray.
    - Converts HWC -> CHW.
    - For byte images (uint8 / PIL mode producing byte data), returns a floating-point tensor in the default torch dtype with values in [0.0, 1.0] (i.e., divided by 255.0).
    - For non-byte numpy / PIL types (e.g., np.float32, PIL "F", "I", "I;16"), returns a tensor of the corresponding dtype without automatic scaling.
    - Returns a contiguous tensor.

    Args:
        pic (PIL Image or numpy.ndarray): Input image.

    Returns:
        torch.Tensor: Image tensor in CHW format.

pil_to_tensor(pic) -> torch.Tensor
    Convert a PIL Image to a torch.Tensor preserving the underlying dtype (no normalization). A deep copy is performed.

    Args:
        pic (PIL Image): Input image.

    Returns:
        torch.Tensor: Tensor with shape [C, H, W] and dtype matching the image data representation.

Notes
- to_tensor is intended for standard input-to-model conversion (produces float tensors scaled to [0,1] for typical uint8 images).
- pil_to_tensor preserves numeric representation and is useful when you need exact dtype semantics from the PIL image.

Internal / helper predicates
----------------------------
- _is_numpy(img): True if the object is a numpy.ndarray.
- _is_numpy_image(img): True if a numpy array has 2 or 3 dimensions (grayscale or color image).
- _is_pil_image: wrapper used internally to detect PIL images.

Examples
--------
Basic usage with PIL:

:: 
    from PIL import Image
    import torch

    img = Image.open("path/to/image.jpg")  # PIL Image

    # Convert to tensor scaled to [0,1] float CHW
    t = to_tensor(img)  # torch.Tensor, dtype=torch.get_default_dtype()

    # Convert to tensor preserving dtype (deep copy)
    t_preserve = pil_to_tensor(img)

    # Query dimensions and size
    channels, height, width = get_dimensions(t)  # if t is a torch.Tensor
    width_h, height_h = get_image_size(img)      # if img is a PIL Image
    num_channels = get_image_num_channels(img)

Working with numpy arrays:

:: 
    import numpy as np

    arr = np.random.randint(0, 256, size=(224, 224, 3), dtype=np.uint8)  # HWC
    t = to_tensor(arr)  # converted to CHW, float in [0,1]

Interpolation mode mapping:

:: 
    from enum import Enum
    # Use InterpolationMode values in higher-level transforms APIs
    mode = InterpolationMode.BILINEAR

    # Convert to PIL integer code when directly calling PIL:
    pil_code = pil_modes_mapping[mode]

    # Convert from PIL integer code back to InterpolationMode:
    mode_back = _interpolation_modes_from_int(pil_code)

Compatibility and behavior
--------------------------
- The API logs usage for telemetry when not in torchscript scripting/tracing modes.
- to_tensor and pil_to_tensor are not intended for torch.jit scripting/tracing (they are regular Python utilities).
- The implementations attempt to preserve dtype semantics: byte images are commonly normalized by to_tensor, while pil_to_tensor preserves underlying integer/float types.

See also
--------
- Higher-level transform classes (e.g., torchvision.transforms.ToTensor, torchvision.transforms.PILToTensor) which wrap these functional utilities into callable transform objects suitable for use in transform pipelines.