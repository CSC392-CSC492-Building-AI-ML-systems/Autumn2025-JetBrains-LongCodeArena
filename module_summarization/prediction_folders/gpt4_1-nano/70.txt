Kernel Approximation Module
===========================

The `sklearn.kernel_approximation` module provides tools for approximating kernel functions using various feature map techniques. These methods enable scalable kernel computations by transforming data into a feature space where linear algorithms can be applied efficiently.

Overview
--------
This module implements several approximate kernel feature maps based on Fourier transforms, Count Sketches, and other randomized techniques. These approximations facilitate the use of kernel methods on large datasets by reducing computational complexity.

Main Classes
------------
### PolynomialCountSketch
Implements a polynomial kernel approximation via Tensor Sketch, which approximates the feature map of the polynomial kernel:

    K(X, Y) = (gamma * <X, Y> + coef0)^degree

using efficient Count Sketch computations with FFTs.

#### Parameters
- **gamma** (float, default=1.0): Parameter of the polynomial kernel.
- **degree** (int, default=2): Degree of the polynomial kernel.
- **coef0** (int, default=0): Constant term of the polynomial kernel.
- **n_components** (int, default=100): Dimensionality of the output feature space.
- **random_state** (int, RandomState instance, default=None): Controls randomness for reproducibility.

#### Attributes
- **indexHash_** (ndarray): Hash indices for Count Sketch.
- **bitHash_** (ndarray): Hash bits for Count Sketch.
- **n_features_in_** (int): Number of features seen during fit.
- **feature_names_in_** (ndarray): Names of features if available.

#### Methods
- **fit(X, y=None)**: Fits the transformer to the data, initializing hash functions.
- **transform(X)**: Transforms data into the approximate feature space.

Related Classes
---------------
- **AdditiveChi2Sampler**: Approximate feature map for the additive chi-squared kernel.
- **Nystroem**: Approximates a kernel map using a subset of training data.
- **RBFSampler**: Approximates the RBF kernel using random Fourier features.
- **SkewedChi2Sampler**: Approximate feature map for the skewed chi-squared kernel.

Usage Example
-------------
```python
from sklearn.kernel_approximation import PolynomialCountSketch
from sklearn.linear_model import SGDClassifier

X = [[0, 0], [1, 1], [1, 0], [0, 1]]
y = [0, 0, 1, 1]

ps = PolynomialCountSketch(degree=3, random_state=1)
X_features = ps.fit_transform(X)

clf = SGDClassifier(max_iter=10, tol=1e-3)
clf.fit(X_features, y)

score = clf.score(X_features, y)
print(f"Accuracy: {score}")
```

This module enables scalable kernel methods by providing efficient approximations of kernel feature maps, suitable for large-scale machine learning tasks.