Validation Curves
=================

Validation curves are a powerful tool for evaluating the performance of a machine learning model across a range of parameter values. By plotting scores for different parameter settings, validation curves help identify the optimal parameter value that balances bias and variance, leading to better generalization.

Overview
--------
A validation curve plots the model's score (such as accuracy, F1-score, etc.) against a specific hyperparameter. It typically displays both training and validation scores, along with measures of variability, to provide insights into the model's behavior and potential overfitting or underfitting.

Key Components
--------------
- **Score Data**: Arrays of scores obtained for different parameter values, often across multiple cross-validation folds.
- **Parameter Range**: The set of hyperparameter values tested.
- **Plot Styles**: Scores can be visualized using error bars, fill between regions, or simple lines to represent mean scores and variability.

Plotting Scores
--------------
The plotting function supports various styles to visualize the scores:

- **Fill Between**: Displays the mean score with a shaded region representing one standard deviation.
- **Error Bars**: Shows the mean score with error bars indicating variability.
- **Lines**: Plots the mean scores for training and validation sets.

Customization
-------------
Users can customize the appearance of validation curves by adjusting parameters such as:

- `score_name`: The label for the score axis.
- `std_display_style`: The style of variability display (`"errorbar"`, `"fill_between"`, or `None`).
- Plot aesthetics via `line_kw`, `fill_between_kw`, and `errorbar_kw`.

Usage Example
-------------
```python
from sklearn.model_selection import validation_curve
import matplotlib.pyplot as plt

# Assume `estimator` is a fitted model, `X` and `y` are data,
# and `param_name` is the hyperparameter to vary.

train_scores, test_scores, param_range = validation_curve(
    estimator, X, y, param_name="n_estimators", param_range=param_range, scoring="accuracy"
)

# Create validation curve display
from sklearn.model_selection import ValidationCurveDisplay

ValidationCurveDisplay(
    validation_curve=validation_curve,
    param_name="n_estimators",
    param_range=param_range,
    train_scores=train_scores,
    test_scores=test_scores,
    score_name="Accuracy"
).plot()
plt.show()
```

Interpretation
--------------
- **High training score with low validation score** suggests overfitting.
- **Both scores low** indicate underfitting.
- The optimal parameter value is where the validation score peaks, with a good balance between bias and variance.

References
----------
- scikit-learn documentation on [validation_curve](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html)
- Visualization API for model evaluation in scikit-learn

This documentation provides guidance on plotting validation curves to assess model performance across hyperparameters, aiding in model selection and tuning.