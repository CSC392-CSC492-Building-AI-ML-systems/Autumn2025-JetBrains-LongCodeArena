Nearest Neighbors
=================

Overview
--------
The Nearest Neighbors algorithms are a set of methods used to find the closest points in a dataset relative to a given query point. These methods are fundamental in various machine learning tasks such as classification, regression, and clustering. The implementation includes efficient data structures like Ball Trees to speed up neighbor searches, especially in high-dimensional spaces.

Data Structures
---------------
Ball Tree
---------
The Ball Tree is a binary tree data structure that partitions data points into nested hyperspheres (balls). Each node in the tree represents a subset of points enclosed within a ball, characterized by a centroid and a radius. This structure allows for efficient pruning during neighbor searches by quickly eliminating large portions of the dataset that are too far from the query point.

Implementation Details
----------------------
The implementation provides specialized classes for different data types, such as float64 and float32, named BallTree64 and BallTree32 respectively. These classes inherit from a common BinaryTree class and are optimized for their specific data types.

Key Functions
-------------
- Allocation and Initialization:
  - `allocate_data{{name_suffix}}`: Allocates memory for the tree nodes based on the number of points and features.
  - `init_node{{name_suffix}}`: Initializes each node with centroid and radius based on the dataset subset.

- Distance Computations:
  - `min_dist{{name_suffix}}`: Calculates the minimum possible distance between a point and a node, useful for pruning during search.
  - `max_dist{{name_suffix}}`: Calculates the maximum possible distance between a point and a node.
  - `min_max_dist{{name_suffix}}`: Computes both minimum and maximum distances for more advanced pruning strategies.

Distance Metrics
----------------
The implementation supports various distance metrics, including:
- Euclidean Distance
- Manhattan Distance
- Chebyshev Distance
- Canberra Distance
- Bray-Curtis Distance
- Hamming Distance
- Haversine Distance
- Jaccard Distance
- Mahalanobis Distance
- Minkowski Distance
- Sokal-Michener Distance
- Sokal-Sneath Distance
- Rogers-Tanimoto Distance
- Russell-Rao Distance
- Symmetric Euclidean Distance (SEuclidean)
- Weighted Minkowski Distance (WMinkowski)
- User-defined functions (PyFuncDistance)

Usage
-----
To perform neighbor searches, instantiate a BallTree object with your dataset and specify the desired metric. Use the `query` method to find the nearest neighbors for a given point or set of points. The tree structure significantly reduces the computational complexity compared to brute-force methods, especially for large datasets.

Example
-------
```python
from sklearn.neighbors import BallTree
import numpy as np

# Sample data
data = np.array([[0, 1], [1, 1], [2, 2], [3, 3]])

# Build the Ball Tree
tree = BallTree(data, metric='euclidean')

# Query the nearest neighbor for a point
dist, ind = tree.query([[1, 2]], k=1)
print("Nearest neighbor index:", ind)
print("Distance:", dist)
```

This documentation provides an overview of the internal implementation and usage of the Nearest Neighbors algorithms based on Ball Trees, highlighting the key components and functions for efficient neighbor searches.