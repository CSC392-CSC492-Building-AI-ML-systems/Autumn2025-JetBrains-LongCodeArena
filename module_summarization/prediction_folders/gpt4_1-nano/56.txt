Generate
========

This module provides tools for Bayesian inference in generalized linear mixed models (GLMMs). It supports models with binomial and Poisson families, assuming no additional scale or shape parameters. The primary focus is on estimating model parameters using Bayesian methods, specifically through the Laplace approximation (maximum a posteriori estimation) and variational Bayes (mean field approximation).

Key Features
------------
- Handles models with multiple random effects, modeled as mutually independent Gaussian variables.
- Supports sparse and dense design matrices for random effects (`exog_vc`), with flexible grouping of variance components via the `ident` parameter or formulas.
- Implements Bayesian priors for fixed effects and variance components, with configurable prior standard deviations.
- Provides a comprehensive modeling framework that integrates fixed effects, random effects, and their variance structures.

Model Specification
-------------------
The joint density of the data and parameters factorizes as:

.. math::

    p(y | vc, fep) \times p(vc | vcp) \times p(vcp) \times p(fe)

where:
- `fep` are fixed effect parameters,
- `vc` are random effect realizations,
- `vcp` are variance component parameters with log-normal priors.

The model assumes independent Gaussian distributions for random effects and Gaussian priors for fixed effects and variance components.

Usage
-----
The module's main class allows fitting models using either the Laplace approximation or variational Bayes, returning a `MixedGLMResults` object with estimated parameters and diagnostics.

References
----------
- Introduction to generalized linear mixed models:
  https://stats.idre.ucla.edu/other/mult-pkg/introduction-to-generalized-linear-mixed-models

- SAS documentation:
  https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_intromix_a0000000215.htm

- Assessment of estimation methods for binary outcomes:
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3866838/
