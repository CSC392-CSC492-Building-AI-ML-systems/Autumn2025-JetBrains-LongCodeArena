w_crawl
========

Synopsis
--------

w_crawl [OPTIONS] TASK_CALLABLE

Description
-----------

The `w_crawl` command is a tool for crawling through a weighted ensemble dataset, executing a specified function on each iteration. It is designed for postprocessing trajectories, cleaning up datasets, or performing any iteration-based task that can be expressed as "do X for iteration N, then do something with the result." 

This command parallelizes tasks by iteration, allowing for efficient processing of large datasets. Note that no guarantees are made about the order of evaluation; tasks are dispatched and processed asynchronously.

Features
--------

- Executes a user-defined callable on each iteration of the dataset.
- Supports optional initialization, finalization, and result processing through a custom crawler class.
- Parallel execution of iteration tasks for improved performance.
- Flexible argument parsing for dataset selection, iteration range, and task configuration.

Command-line Options
--------------------

- `-c`, `--crawler-instance`  
  Specify a module and instance (module.instance) of `WESTPACrawler` to coordinate the calculation. This is required if initialization, finalization, or result processing is needed.

- `TASK_CALLABLE`  
  The function to run on each iteration, specified as a module and function (module.function). This is a required argument.

- Additional options for dataset selection and iteration range are available through integrated argument groups.

Usage
-----

```bash
w_crawl [OPTIONS] TASK_CALLABLE
```

Example
-------

```bash
w_crawl -c mymodule.MyCrawler mymodule.my_task
```

This command runs `my_task` on each iteration, optionally using a custom crawler instance for advanced control over the crawling process.

Notes
-----

- The task callable should accept an iteration number and a data manager object.
- The command manages dataset opening and closing internally.
- Designed for use in high-performance computing environments with parallel execution capabilities.