Linear and Quadratic Discriminant Analysis
===========================================

Linear Discriminant Analysis (LDA) and Quadratic Discriminant Analysis (QDA) are classical methods used in statistics and machine learning for classification tasks. Both methods model the distribution of the predictors separately in each class and use Bayes’ theorem to estimate the posterior probabilities of the classes.

Linear Discriminant Analysis (LDA)
----------------------------------

LDA assumes that the different classes generate data based on Gaussian distributions with the same covariance matrix but different means. Under this assumption, the decision boundary between any two classes is linear, hence the name Linear Discriminant Analysis.

Key characteristics of LDA:

- Assumes multivariate normality of the predictors within each class.
- Assumes equal covariance matrices for all classes.
- Estimates class-specific means and a common covariance matrix.
- The decision boundary is linear.
- Can be used for dimensionality reduction as well as classification.

LDA is particularly effective when the class covariances are similar and the data is approximately normally distributed. It is computationally efficient and often performs well on small to medium-sized datasets.

Quadratic Discriminant Analysis (QDA)
-------------------------------------

QDA relaxes the assumption of equal covariance matrices across classes. It assumes that each class has its own covariance matrix, allowing for more flexible decision boundaries that are quadratic rather than linear.

Key characteristics of QDA:

- Assumes multivariate normality of the predictors within each class.
- Allows each class to have its own covariance matrix.
- Estimates class-specific means and covariance matrices.
- The decision boundary is quadratic.
- More flexible than LDA but requires more parameters to be estimated.

QDA can model more complex class distributions than LDA but may require more data to estimate the covariance matrices reliably. It is suitable when the assumption of equal covariance matrices is violated.

Comparison and Usage
-------------------

| Feature                  | LDA                          | QDA                          |
|--------------------------|------------------------------|------------------------------|
| Covariance matrices      | Assumed equal across classes | Estimated separately per class|
| Decision boundary        | Linear                       | Quadratic                    |
| Number of parameters     | Fewer                       | More                         |
| Flexibility             | Less flexible                | More flexible                |
| Data requirements       | Less data needed             | More data needed             |
| Suitable when           | Classes have similar covariances | Classes have different covariances |

Both LDA and QDA are generative models that provide probabilistic classification and can be used to understand the underlying data distribution. They are implemented in scikit-learn and can be easily applied to classification problems.

Example usage in scikit-learn
-----------------------------

```python
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis

# Create LDA and QDA classifiers
lda = LinearDiscriminantAnalysis()
qda = QuadraticDiscriminantAnalysis()

# Fit the models
lda.fit(X_train, y_train)
qda.fit(X_train, y_train)

# Predict class labels
y_pred_lda = lda.predict(X_test)
y_pred_qda = qda.predict(X_test)
```

References
----------

- Fisher, R. A. (1936). The use of multiple measurements in taxonomic problems. *Annals of Eugenics*, 7(2), 179–188.
- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning* (2nd ed.). Springer.
- McLachlan, G. J. (2004). *Discriminant Analysis and Statistical Pattern Recognition*. Wiley-Interscience.