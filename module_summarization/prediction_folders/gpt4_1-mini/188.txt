Kernel Approximation Functions
==============================

The `sklearn.kernel_approximation` module provides several functions and classes that approximate the feature mappings corresponding to certain kernels. These approximations enable efficient computation and scalability for kernel methods by transforming the input data into a finite-dimensional feature space that approximates the kernel function.

Overview
--------

Kernel methods often rely on computing pairwise similarities between samples using kernel functions. However, directly computing and storing kernel matrices can be computationally expensive for large datasets. Kernel approximation techniques address this by constructing explicit feature maps that approximate the kernel, allowing the use of linear methods in the transformed feature space.

The module implements approximate kernel feature maps based on techniques such as Fourier transforms and Count Sketches.

PolynomialCountSketch
---------------------

The `PolynomialCountSketch` class implements an approximation of the polynomial kernel feature map using the Tensor Sketch algorithm. This method efficiently approximates the polynomial kernel:

.. math::

    K(X, Y) = (\gamma \langle X, Y \rangle + \text{coef0})^{\text{degree}}

by computing a Count Sketch of the outer product of a vector with itself using Fast Fourier Transforms (FFT).

**Key Features:**

- Efficient approximation of polynomial kernels of arbitrary degree.
- Uses 2-wise independent hash functions for Count Sketch computation.
- Suitable for high-dimensional data where explicit polynomial feature expansion is computationally prohibitive.

**Parameters:**

- `gamma` (float, default=1.0): Parameter of the polynomial kernel.
- `degree` (int, default=2): Degree of the polynomial kernel.
- `coef0` (int, default=0): Independent term in the polynomial kernel.
- `n_components` (int, default=100): Dimensionality of the output feature space.
- `random_state` (int, RandomState instance, default=None): Controls randomness for hash function initialization.

**Attributes:**

- `indexHash_` (ndarray): Indexes used in the Count Sketch hash functions.
- `bitHash_` (ndarray): Random signs used in the Count Sketch hash functions.
- `n_features_in_` (int): Number of features seen during fitting.
- `feature_names_in_` (ndarray): Feature names seen during fitting (if available).

**Example Usage:**

```python
from sklearn.kernel_approximation import PolynomialCountSketch
from sklearn.linear_model import SGDClassifier

X = [[0, 0], [1, 1], [1, 0], [0, 1]]
y = [0, 0, 1, 1]

ps = PolynomialCountSketch(degree=3, random_state=1)
X_features = ps.fit_transform(X)

clf = SGDClassifier(max_iter=10, tol=1e-3)
clf.fit(X_features, y)
print(clf.score(X_features, y))  # Output: 1.0
```

Related Kernel Approximation Methods
------------------------------------

- **AdditiveChi2Sampler**: Approximates the additive chi-squared kernel feature map.
- **Nystroem**: Approximates kernel maps using a subset of the training data.
- **RBFSampler**: Approximates the Radial Basis Function (RBF) kernel feature map using random Fourier features.
- **SkewedChi2Sampler**: Approximates the "skewed chi-squared" kernel feature map.

For a comprehensive list of built-in kernels and their parameters, see `sklearn.metrics.pairwise.kernel_metrics`.

References
----------

- [Pham, N., & Pagh, R. (2013). Fast and scalable polynomial kernels via explicit feature maps. Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.](https://doi.org/10.1145/2487575.2487581)
- [Vedaldi, A., & Zisserman, A. (2012). Efficient additive kernels via explicit feature maps. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(3), 480-492.](https://doi.org/10.1109/TPAMI.2011.155)

See Also
--------

- `sklearn.kernel_approximation.AdditiveChi2Sampler`
- `sklearn.kernel_approximation.Nystroem`
- `sklearn.kernel_approximation.RBFSampler`
- `sklearn.kernel_approximation.SkewedChi2Sampler`
- `sklearn.metrics.pairwise.pairwise_kernels`

This module is part of scikit-learnâ€™s suite of tools for scalable kernel methods, enabling efficient learning with kernel approximations.