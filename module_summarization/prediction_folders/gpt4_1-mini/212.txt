Linear Mixed Effects Models
============================

Overview
--------

Linear mixed effects models are regression models designed for dependent data. They allow estimation of regression relationships involving both means and variances. These models are also known as multilevel linear models or hierarchical linear models.

The `MixedLM` class fits linear mixed effects models to data and supports common post-estimation tasks. This implementation is group-based and is most efficient when the data can be partitioned into independent groups. Some models with crossed effects can be handled by specifying a model with a single group.

Model Specification
-------------------

The data are partitioned into disjoint groups. For group *i*, the probability model is:

.. math::

   Y = X \\beta + Z \\gamma + \\epsilon

where:

- *n_i* is the number of observations in group *i*.
- *Y* is an *n_i*-dimensional response vector (called `endog` in `MixedLM`).
- *X* is an *n_i* Ã— *k_{fe}* design matrix for the fixed effects (called `exog` in `MixedLM`).
- *\\beta* is a *k_{fe}*-dimensional vector of fixed effects parameters (called `fe_params` in `MixedLM`).
- *Z* is a design matrix for the random effects with *n_i* rows (called `exog_re` in `MixedLM`). The number of columns in *Z* can vary by group.
- *\\gamma* is a random vector with mean zero. The covariance matrix for the first *k_{re}* elements of *\\gamma* (called `cov_re` in `MixedLM`) is common to all groups. The remaining elements of *\\gamma* are variance components. Each group receives its own independent realization of *\\gamma*.
- *\\epsilon* is an *n_i*-dimensional vector of independent and identically distributed normal errors with mean zero and variance *\\sigma^2*. The *\\epsilon* values are independent both within and between groups.

All of *Y*, *X*, and *Z* must be fully observed. The parameters *\\beta*, *\\Psi* (covariance matrix of random effects), and *\\sigma^2* are estimated using maximum likelihood (ML) or restricted maximum likelihood (REML). The vectors *\\gamma* and *\\epsilon* are random and define the probability model.

The marginal mean structure is:

.. math::

   E[Y | X, Z] = X \\beta

If only the mean structure is of interest, generalized estimating equations (GEE) provide an alternative to linear mixed models.

Random Effects
--------------

Two types of random effects are supported:

1. **Standard random effects**: These are correlated with each other in arbitrary ways. Every group has the same number (*k_{re}*) of standard random effects, with the same joint distribution but independent realizations across groups.

2. **Variance components**: These are uncorrelated with each other and with the standard random effects. Each variance component has mean zero, and all realizations of a given variance component share the same variance parameter. The number of realized variance components per variance parameter can differ across groups.

Parameterization and Estimation
-------------------------------

Three different parameterizations are used in different contexts:

- **User parameterization**: The covariance of the response is

  .. math::

     \\mathrm{cov}(Y) = \\sigma^2 I + Z \\Psi Z'

  This is the main parameterization visible to the user.

- **Profile parameterization**: The covariance is expressed as

  .. math::

     \\mathrm{cov}(Y) = I + Z \\Psi_1 Z'

  This parameterization is used in the profile likelihood maximization. The user covariance matrix *\\Psi* equals the profile covariance matrix *\\Psi_1* multiplied by the scale *\\sigma^2*.

- **Square root parameterization**: The Cholesky factor of *\\Psi_1* is used instead of *\\Psi* directly. This is hidden from the user.

The parameters can be packed into a vector by concatenating the fixed effects parameters (`fe_params`), the lower triangle or Cholesky square root of the random effects covariance matrix, and the variance parameters for the variance components. When unpacking, it is important to square or reflect the dependence structure depending on the parameterization.

Estimation uses generalized least squares (GLS) to avoid explicit optimization over fixed effects parameters. The likelihood is profiled over both the scale parameter and the fixed effects parameters. Because of this profiling, the Hessian of the profiled log-likelihood is not calculated, and optimization methods requiring the Hessian (e.g., Newton-Raphson) cannot be used.

Notation Summary
----------------

- `cov_re`: Random effects covariance matrix (denoted *\\Psi*).
- `scale`: Scalar error variance *\\sigma^2*.
- `vcomp`: Vector of variance parameters corresponding to variance components.
- `exog`: Fixed effects design matrix *X*.
- `exog_re`: Random effects design matrix *Z*.
- `endog`: Response vector *Y*.
- `fe_params`: Fixed effects parameters *\\beta*.
- `cov_re`: Covariance matrix of standard random effects *\\Psi*.
- `exog_vc` / `vc_formula`: Arguments specifying variance components.

References
----------

- Lindstrom, M. J., & Bates, D. M. (1988). Newton-Raphson and EM algorithms for linear mixed effects models for repeated measures data. *Journal of the American Statistical Association*, 83(404), 1014-1022.

- http://econ.ucsb.edu/~doug/245a/Papers/Mixed%20Effects%20Implement.pdf

Additional User-Oriented Resources
----------------------------------

- http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf

- http://lme4.r-forge.r-project.org/slides/2009-07-07-Rennes/3Longitudinal-4.pdf

Warnings and Notes
------------------

- The likelihood, gradient, and Hessian calculations closely follow Lindstrom and Bates (1988), adapted to support variance components.

- The model assumes that *Y*, *X*, and *Z* are fully observed without missing data.

- Optimization is performed without calculating the Hessian of the profiled log-likelihood, so methods requiring the Hessian cannot be used.

- Two score functions are implemented: one with respect to the random effects covariance matrix elements (used for inference), and one with respect to the Cholesky factor parameters (used for optimization).

- The implementation is most efficient for models where data can be partitioned into independent groups.

Summary
-------

Linear mixed effects models provide a flexible framework for modeling data with complex dependence structures, incorporating both fixed and random effects. The `MixedLM` class implements these models efficiently for grouped data, supporting estimation, inference, and variance component modeling.