Kernel Approximation Module
===========================

The :mod:`sklearn.kernel_approximation` module implements several approximate kernel feature maps based on Fourier transforms and Count Sketches. These feature maps provide efficient approximations to kernel functions, enabling scalable kernel methods for large datasets.

Overview
--------

Kernel methods often rely on computing the kernel matrix, which can be computationally expensive for large datasets. Kernel approximation techniques aim to approximate the kernel function by mapping the input data into a finite-dimensional feature space where linear methods can be applied efficiently.

This module provides implementations of various kernel approximation techniques, including:

- **PolynomialCountSketch**: Approximates the polynomial kernel feature map using Tensor Sketching and Fast Fourier Transforms (FFT).

PolynomialCountSketch
---------------------

The `PolynomialCountSketch` class implements an approximation of the polynomial kernel feature map via Tensor Sketching. The polynomial kernel is defined as:

.. math::

    K(X, Y) = (\gamma \langle X, Y \rangle + \text{coef0})^{\text{degree}}

where :math:`\gamma` is a scaling parameter, :math:`\text{coef0}` is a constant term, and :math:`\text{degree}` is the degree of the polynomial.

`PolynomialCountSketch` efficiently approximates this kernel by computing a Count Sketch of the outer product of a vector with itself using Fast Fourier Transforms (FFT). This approach reduces the computational complexity and memory requirements compared to explicit kernel computations.

.. versionadded:: 0.24

Parameters
~~~~~~~~~~

- **gamma** : float, default=1.0  
  Parameter of the polynomial kernel whose feature map will be approximated.

- **degree** : int, default=2  
  Degree of the polynomial kernel.

- **coef0** : int, default=0  
  Constant term in the polynomial kernel.

- **n_components** : int, default=100  
  Dimensionality of the output feature space. Typically, a larger number of components leads to better approximation quality.

- **random_state** : int, RandomState instance or None, default=None  
  Controls the randomness of the hash functions used in the Count Sketch. Pass an int for reproducible results.

Attributes
~~~~~~~~~~

- **indexHash_** : ndarray of shape (degree, n_features), dtype=int64  
  Indexes used in the 2-wise independent hash functions for Count Sketch computation.

- **bitHash_** : ndarray of shape (degree, n_features), dtype=float32  
  Random entries in {+1, -1} used in the 2-wise independent hash functions.

- **n_features_in_** : int  
  Number of features seen during fitting.

- **feature_names_in_** : ndarray of shape (n_features_in_,), optional  
  Names of features seen during fitting, if available.

Methods
~~~~~~~

- **fit(X, y=None)**  
  Initializes the internal hash functions based on the input data dimensionality. Does not require the target values.

- **transform(X)**  
  Transforms the input data into the approximate polynomial kernel feature space.

Example
~~~~~~~

>>> from sklearn.kernel_approximation import PolynomialCountSketch
>>> from sklearn.linear_model import SGDClassifier
>>> X = [[0, 0], [1, 1], [1, 0], [0, 1]]
>>> y = [0, 0, 1, 1]
>>> ps = PolynomialCountSketch(degree=3, random_state=1)
>>> X_features = ps.fit_transform(X)
>>> clf = SGDClassifier(max_iter=10, tol=1e-3)
>>> clf.fit(X_features, y)
SGDClassifier(max_iter=10)
>>> clf.score(X_features, y)
1.0

See Also
--------

- :class:`sklearn.kernel_approximation.AdditiveChi2Sampler`  
  Approximate feature map for the additive chi-squared kernel.

- :class:`sklearn.kernel_approximation.Nystroem`  
  Approximate a kernel map using a subset of the training data.

- :class:`sklearn.kernel_approximation.RBFSampler`  
  Approximate a RBF kernel feature map using random Fourier features.

- :class:`sklearn.kernel_approximation.SkewedChi2Sampler`  
  Approximate feature map for the skewed chi-squared kernel.

- :mod:`sklearn.metrics.pairwise.kernel_metrics`  
  List of built-in kernel functions.

Notes
-----

The approximation quality depends on the number of components (`n_components`) and the parameters of the polynomial kernel. Typically, increasing `n_components` improves the approximation but increases computational cost.

References
----------

- Daniel Lopez-Sanchez, et al. "Tensor Sketching for Polynomial Kernels."  
- A. MuÌˆller, et al. "Efficient Kernel Approximations for Large-Scale Learning."

License
-------

This module is released under the BSD 3-Clause License.

Authors
-------

- Andreas Mueller <amueller@ais.uni-bonn.de>  
- Daniel Lopez-Sanchez (TensorSketch) <lope@usal.es>