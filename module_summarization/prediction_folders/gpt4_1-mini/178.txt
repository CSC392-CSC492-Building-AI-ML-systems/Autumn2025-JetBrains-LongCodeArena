Computational Performance
=========================

The multioutput estimators implemented in this module are designed as meta-estimators that extend single-output estimators to handle multiple outputs. This design choice has implications for computational performance, which are important to consider when using these estimators in practice.

Parallelization and Efficiency
------------------------------

The multioutput estimators support parallel computation through the `n_jobs` parameter, which specifies the number of jobs to run in parallel. By leveraging parallelism, these estimators can fit or predict multiple output targets concurrently, potentially reducing the overall computation time significantly on multi-core systems.

Cloning and Independent Fitting
-------------------------------

Each output target is modeled by an independent clone of the base estimator. This means that the fitting and prediction for each output are performed separately. While this approach simplifies the implementation and ensures flexibility, it may lead to increased memory usage and computational overhead compared to specialized multioutput estimators that share computations across outputs.

Partial Fitting Support
----------------------

The estimators also support incremental learning via the `partial_fit` method when the base estimator provides it. This allows for efficient training on large datasets or streaming data by updating the model incrementally without retraining from scratch.

Considerations
--------------

- The computational cost scales linearly with the number of output targets since each target is handled by a separate estimator.
- The overhead of cloning and managing multiple estimators should be taken into account, especially for a large number of outputs.
- Utilizing the `n_jobs` parameter effectively can mitigate some of the computational costs by parallelizing operations.
- The performance depends heavily on the efficiency of the underlying base estimator used.

Summary
-------

The multioutput meta-estimators provide a flexible and parallelizable approach to handling multiple outputs by extending single-output estimators. While this design may introduce some computational overhead, it offers scalability and ease of use, especially when combined with parallel execution. Users should balance the number of outputs, available computational resources, and the choice of base estimator to optimize performance for their specific use case.