Pairwise Metrics, Affinities and Kernels
=========================================

This section provides an overview of the pairwise metrics, affinities, and kernels available for measuring similarity or dissimilarity between samples in a dataset. These functions are fundamental in many machine learning algorithms, including clustering, classification, and dimensionality reduction.

Pairwise Metrics
----------------

Pairwise metrics compute a distance or dissimilarity measure between pairs of samples. These metrics take two input arrays and return a matrix of distances between each pair of samples from the two arrays.

The inputs to pairwise metrics are typically two arrays `X` and `Y` of shape `(n_samples_X, n_features)` and `(n_samples_Y, n_features)`, respectively. If `Y` is not provided, the metric is computed between all pairs of samples in `X`.

Before computing pairwise metrics, the inputs are validated and converted to appropriate formats using utility functions such as `check_pairwise_arrays`. This function ensures that the inputs are arrays or sparse matrices of compatible shapes and appropriate data types, and it handles precomputed distance matrices as well.

Common pairwise metrics include Euclidean distance, Manhattan distance, cosine distance, and many others. These metrics can be used directly or as building blocks for more complex affinity or kernel computations.

Affinities
----------

Affinities measure the similarity between samples, often derived from pairwise distances. They are typically non-negative and symmetric, and higher values indicate greater similarity.

Affinity matrices are commonly used in clustering algorithms such as spectral clustering, where the affinity matrix represents the graph weights between samples.

Kernels
-------

Kernels are special functions that compute a similarity measure between samples in a way that corresponds to an inner product in some (possibly high-dimensional) feature space. Kernels enable algorithms to operate in implicit feature spaces without explicitly computing the coordinates in those spaces.

Common kernels include the linear kernel, polynomial kernel, radial basis function (RBF) kernel, and chi-squared kernel. Kernels are widely used in support vector machines, kernel PCA, and other kernel-based learning methods.

Utility Functions
-----------------

Several utility functions support the computation and validation of pairwise metrics, affinities, and kernels:

- `_return_float_dtype(X, Y)`: Determines the appropriate floating-point data type for inputs `X` and `Y`, returning `float32` if both inputs are of that type, otherwise `float64`.

- `check_pairwise_arrays(X, Y, precomputed=False, dtype=None, accept_sparse='csr', force_all_finite=True, copy=False)`: Validates and converts inputs `X` and `Y` to arrays or sparse matrices suitable for pairwise computations. It checks dimensionality, data types, and compatibility of shapes, and handles precomputed distance matrices.

- `check_paired_arrays(X, Y)`: Similar to `check_pairwise_arrays` but designed for paired distance computations where each sample in `X` corresponds to a sample in `Y`.

These functions ensure that the inputs to pairwise metrics, affinities, and kernels are consistent and safe to use, preventing common errors related to input formats and dimensions.

Examples
--------

Here is a simple example of computing pairwise Euclidean distances between samples in `X` and `Y`:

```python
from sklearn.metrics import pairwise_distances
X = [[0, 1], [1, 1]]
Y = [[1, 0], [2, 2]]
distances = pairwise_distances(X, Y, metric='euclidean')
```

Similarly, kernels can be computed using functions such as `rbf_kernel` or `chi2_kernel` to obtain similarity matrices.

Summary
-------

Pairwise metrics, affinities, and kernels form the backbone of many machine learning algorithms by providing measures of similarity or dissimilarity between samples. Proper validation and handling of input data ensure robust and efficient computation of these measures.