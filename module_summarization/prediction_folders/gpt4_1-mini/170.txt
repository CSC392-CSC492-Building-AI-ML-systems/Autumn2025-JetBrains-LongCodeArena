Handling Large Datasets
=======================

When working with large spectral data cubes, efficient handling and processing of data is crucial to balance memory usage and computational speed. The provided functions and classes implement several strategies to compute moment maps and manage multi-Stokes spectral cubes while accommodating large datasets.

Moment Map Computation Strategies
---------------------------------

Moment maps are statistical summaries of spectral cubes along a specified axis, commonly used in astrophysical data analysis. Computing these moments efficiently requires different approaches depending on the size of the data and available system resources.

The module provides three main strategies for moment computation:

1. **Cubewise Computation (`moment_cubewise`)**

   This method processes the entire data cube at once. It is straightforward and fast for small to moderately sized datasets that fit comfortably in memory.

   - Uses NumPy operations to compute moments by collapsing the cube along the specified axis.
   - Handles missing or invalid data by converting all-bad values to NaN and using `np.nansum`.
   - Suitable for orders 0 (integrated intensity), 1 (intensity-weighted mean), and higher moments.

2. **Raywise Computation (`moment_raywise`)**

   This approach computes moments one ray at a time (a ray is a 1D slice along the spectral axis at a fixed spatial position).

   - Iterates over spatial pixels, applying masks and weighting data accordingly.
   - Useful when the cube is too large to load entirely into memory but can be accessed ray-by-ray.
   - Balances memory usage and computational overhead.

3. **Slicewise Computation (`moment_slicewise`)**

   This method accumulates moment calculations one slice at a time along the axis of interest.

   - Processes 2D slices sequentially, accumulating results.
   - Offers a compromise between memory usage and speed.
   - Particularly effective when the cube is large but can be sliced efficiently.

Automatic Strategy Selection
----------------------------

The function `moment_auto` selects the most appropriate computation strategy based on the cube's size and structure, as well as the axis along which the moment is computed. This automatic selection helps optimize performance without requiring manual intervention.

Handling Missing Data
---------------------

The functions use robust handling of missing or invalid data points by:

- Filling missing data with NaN or zero as appropriate.
- Using masks to exclude invalid data from computations.
- Converting all-bad data to NaN to ensure accurate moment calculations.

Multi-Stokes Spectral Cubes
---------------------------

The `StokesSpectralCube` class manages spectral cubes containing multiple Stokes parameters (e.g., I, Q, U, V), which represent different polarization states.

- Supports shared masks across Stokes components as well as component-specific masks.
- Facilitates handling of complex datasets with multiple polarization measurements.
- Ensures consistent processing and masking across all Stokes cubes.

Best Practices for Large Dataset Handling
-----------------------------------------

- Use the automatic moment computation strategy (`moment_auto`) to let the system choose the optimal method.
- For very large datasets, prefer raywise or slicewise computations to reduce memory footprint.
- Apply masks early to exclude irrelevant or bad data, improving efficiency.
- When working with multi-Stokes data, leverage the `StokesSpectralCube` class to maintain consistency and manage masks effectively.

By employing these strategies and classes, users can efficiently process and analyze large spectral cubes, balancing memory constraints and computational speed to handle big data in astrophysical research.