Dataset Loading Utilities
=========================

The dataset loading utilities provide convenient functions to fetch and cache datasets from online repositories, with a focus on OpenML datasets. These utilities handle downloading, caching, retrying on network errors, and parsing dataset metadata and content.

Key Features
------------

- **Fetching datasets from OpenML**: The utilities allow downloading datasets from the OpenML repository via its REST API.
- **Caching**: Downloaded datasets are cached locally to avoid repeated downloads and improve efficiency.
- **Robust network handling**: Automatic retries on network errors with configurable retry counts and delays.
- **Cache validation and cleanup**: If a cached file is corrupted or invalid, it is automatically removed and re-downloaded.
- **Support for gzip compression**: Handles gzip-encoded responses transparently.
- **Error handling**: Specific handling for OpenML error codes, such as HTTP 412, which indicates a generic OpenML error.

Core Components
---------------

**fetch_openml**

The primary function to fetch datasets from OpenML. It downloads the dataset files and metadata, caches them locally, and returns the dataset in a usable format.

**Caching Mechanism**

Datasets are cached under a user-configurable data directory (defaulting to a standard data home). Cached files are stored under a subdirectory named `openml.org` with filenames corresponding to the OpenML resource path and a `.gz` extension.

**Network Retry Decorators**

- `_retry_on_network_error`: Decorator to retry a function call multiple times if network errors occur, with a delay between retries. It does not retry on HTTP 412 errors.
- `_retry_with_clean_cache`: Decorator that retries a function call once after deleting the cached file if the first call fails due to an exception (except specified exceptions).

**OpenML URL Access**

The function `_open_openml_url` handles downloading resources from OpenML, applying caching and retry logic. It transparently decompresses gzip-encoded responses and ensures atomic writes to the cache to avoid concurrency issues.

Usage Example
-------------

```python
from sklearn.datasets import fetch_openml

# Fetch the "mnist_784" dataset from OpenML
mnist = fetch_openml(name="mnist_784", version=1, as_frame=False)

# Access data and target
X, y = mnist.data, mnist.target
```

Parameters such as `data_home` can be specified to control the cache location, and retry parameters can be adjusted for network robustness.

Error Handling
--------------

- `OpenMLError`: Raised when OpenML returns a generic error (HTTP 412).
- Network errors trigger retries up to a configurable number of attempts.
- Cache corruption triggers automatic cache cleanup and re-download.

Summary
-------

The dataset loading utilities provide a reliable and efficient way to access datasets from OpenML, with built-in caching, error handling, and network robustness. They simplify the process of obtaining datasets for machine learning experiments and ensure consistent access to up-to-date data.