Gaussian Process Kernels
========================

This module provides a collection of kernels for Gaussian process regression and classification. The kernels are designed to support kernel engineering, allowing users to combine kernels using the "+" and "*" operators or exponentiate them with a scalar using the "**" operator. These operations enable the construction of complex kernels from simpler base kernels. Additionally, scalar values can be automatically converted to constant kernels when used in kernel expressions.

Key Features
------------

- **Kernel Composability**: Kernels can be combined through addition and multiplication, and can be exponentiated by scalars, facilitating flexible kernel design.
- **Hyperparameter Optimization**: All kernels support analytic gradient-based optimization of hyperparameters. Users can specify the search space for hyperparameters by defining lower and upper bounds or by fixing certain hyperparameters to exclude them from optimization.
- **Support for Anisotropic Kernels**: Kernels can handle anisotropic length scales, allowing different length scales for each input dimension.
- **Integration with Scikit-learn**: The kernels follow scikit-learn conventions, making them compatible with Gaussian process models in the scikit-learn ecosystem.

Core Components
---------------

### Hyperparameter

The `Hyperparameter` class encapsulates the specification of a kernel hyperparameter. It includes the hyperparameter's name, type, bounds, number of elements (for vector-valued parameters), and whether it is fixed during optimization.

Attributes:

- `name` (str): Name of the hyperparameter.
- `value_type` (str): Type of the hyperparameter (currently only "numeric" is supported).
- `bounds` (pair of floats or "fixed"): Lower and upper bounds for the hyperparameter or "fixed" if the parameter is not to be optimized.
- `n_elements` (int): Number of elements in the hyperparameter value (default is 1 for scalar parameters).
- `fixed` (bool): Indicates if the hyperparameter is fixed during optimization.

Example usage:

```python
from sklearn.gaussian_process.kernels import ConstantKernel, Hyperparameter

kernel = ConstantKernel(constant_value=1.0, constant_value_bounds=(0.0, 10.0))

for hyperparameter in kernel.hyperparameters:
    print(hyperparameter)
```

### Kernel Base Class

The `Kernel` class is the abstract base class for all kernels in this module. It defines the interface and common functionality for kernel implementations, including parameter management and hyperparameter handling.

Key methods include:

- `get_params(deep=True)`: Returns the parameters of the kernel, supporting deep retrieval of parameters from nested kernels.

Usage and Examples
------------------

Kernels in this module can be used directly with Gaussian process models for regression and classification tasks. They can be combined to create custom kernels tailored to specific problems.

Example of combining kernels:

```python
from sklearn.gaussian_process.kernels import RBF, ConstantKernel

kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)
```

This creates a kernel that is the product of a constant kernel and a radial basis function (RBF) kernel.

Notes
-----

- The module is inspired by the kernel module of the george package.
- Hyperparameters can be fixed or bounded to control the optimization process.
- The module supports analytic gradients for efficient hyperparameter tuning.

References
----------

- Rasmussen, C. E., & Williams, C. K. I. (2006). Gaussian Processes for Machine Learning. MIT Press.
- scikit-learn Gaussian Process documentation: https://scikit-learn.org/stable/modules/gaussian_process.html