Empirical Likelihood Inference on Descriptive Statistics
==========================================================

Overview
--------
This module provides tools for conducting empirical likelihood inference on descriptive statistics such as the mean, variance, skewness, kurtosis, and correlation. Empirical likelihood is a nonparametric method of statistical inference that combines the flexibility of nonparametric methods with the likelihood-based inference framework.

Key Features
------------
- Hypothesis testing and confidence interval construction for various descriptive statistics.
- Support for both univariate and multivariate data.
- Generation of multivariate confidence region plots and mean-variance contour plots when matplotlib is installed.
- Optimization routines tailored for empirical likelihood problems.

References
----------
Owen, A. (2001). *Empirical Likelihood*. Chapman and Hall.

Usage
-----
The primary interface to the module is through the `DescStat` function, which returns an instance for conducting inference on descriptive statistics via empirical likelihood.

```python
DescStat(endog)
```

Parameters
----------
- `endog` : ndarray  
  The input data array. If the data is univariate (one-dimensional), a univariate inference instance is returned. For multivariate data (two-dimensional with more than one column), a multivariate inference instance is returned.

Returns
-------
- An instance of `DescStatUV` for univariate data or `DescStatMV` for multivariate data. These instances provide methods for hypothesis testing and confidence interval construction.

Core Components
---------------
### _OptFuncts Class
This internal class encapsulates functions that are optimized or solved during empirical likelihood inference. It handles the construction of estimating equations, the calculation of gradients and Hessians, and the maximization of the empirical likelihood function.

Key methods include:

- `_log_star(eta, est_vect, weights, nobs)`  
  Computes a transformed log-likelihood function in terms of the Lagrange multiplier `eta`. This transformation facilitates numerical optimization.

- `_grad(eta, est_vect, weights, nobs)`  
  Calculates the gradient of the weighted empirical likelihood function with respect to the Lagrange multiplier.

- `_hess(eta, est_vect, weights, nobs)`  
  Computes the Hessian matrix (second derivatives) of the weighted empirical likelihood function.

- `_modif_newton(eta, est_vect, weights)`  
  Implements a modified Newton's method to find the Lagrange multiplier that maximizes the empirical likelihood. This method uses the gradient and Hessian computations to efficiently solve the optimization problem.

Methodology
-----------
Empirical likelihood inference is based on constructing a nonparametric likelihood function that assigns weights to observations such that certain estimating equations (e.g., moment conditions) are satisfied. The Lagrange multipliers associated with these constraints are found by solving a system of nonlinear equations, typically via Newton-type optimization methods.

The module profiles out nuisance parameters when present, focusing inference on parameters of interest. Confidence intervals and hypothesis tests are constructed by evaluating the empirical likelihood ratio statistic and comparing it to critical values from chi-squared distributions.

Visualization
-------------
If matplotlib is available, the module can generate:

- Multivariate confidence region plots, illustrating joint confidence regions for multiple parameters.
- Mean-variance contour plots, useful for visualizing the trade-off between mean and variance in multivariate data.

These visualizations aid in interpreting the results of empirical likelihood inference.

Conclusion
----------
This module offers a comprehensive framework for empirical likelihood inference on descriptive statistics, combining rigorous statistical methodology with practical tools for analysis and visualization. It is suitable for researchers and practitioners seeking flexible, likelihood-based inference without relying on parametric assumptions.