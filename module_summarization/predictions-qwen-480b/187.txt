Isotonic Regression
==================

.. currentmodule:: sklearn.isotonic

Isotonic regression is a non-parametric regression technique that fits a 
free-form line to a set of data points under the condition that the fitted 
values are monotonically increasing or decreasing. It is particularly useful 
when you expect a monotonic relationship between the independent and dependent 
variables but do not want to assume a specific functional form.

The isotonic regression model finds the best fit to the data while preserving 
the monotonicity constraint. This is achieved by solving a convex optimization 
problem that minimizes the squared error between the observed and predicted 
values, subject to the isotonic constraints.

.. figure:: ../auto_examples/images/sphx_glr_plot_isotonic_regression_001.png
   :target: ../auto_examples/plot_isotonic_regression.html
   :align: center
   :scale: 75%

   Example of isotonic regression on synthetic data.

Definition
----------

Given a sequence of real numbers :math:`y_1, y_2, \ldots, y_n`, isotonic 
regression finds a sequence :math:`\hat{y}_1, \hat{y}_2, \ldots, \hat{y}_n` 
that minimizes the sum of squared errors:

.. math::

    \sum_{i=1}^{n} (y_i - \hat{y}_i)^2

subject to the monotonicity constraint:

.. math::

    \hat{y}_1 \leq \hat{y}_2 \leq \cdots \leq \hat{y}_n \quad \text{(increasing case)}

or

.. math::

    \hat{y}_1 \geq \hat{y}_2 \geq \cdots \geq \hat{y}_n \quad \text{(decreasing case)}

The algorithm used to solve this problem is based on the pool adjacent violators 
algorithm (PAVA), which is an efficient method for computing the isotonic fit.

Applications
------------

Isotonic regression is commonly used in:

- **Calibration of classifiers**: Adjusting predicted probabilities to be 
  monotonically related to the true class probabilities.
- **Dose-response modeling**: Where the response is expected to increase or 
  decrease with the dose.
- **Economics and finance**: Modeling relationships where monotonicity is 
  economically meaningful.
- **Bioinformatics**: Analyzing gene expression data where monotonic trends 
  are expected.

Examples
--------

- :ref:`sphx_glr_auto_examples_plot_isotonic_regression.py`

Functions
---------

.. autosummary::
   :toctree: generated/
   :template: function.rst

   isotonic_regression
   check_increasing

Classes
-------

.. autosummary::
   :toctree: generated/
   :template: class.rst

   IsotonicRegression

Implementation Details
----------------------

The implementation in scikit-learn uses the pool adjacent violators algorithm 
(PAVA) to solve the isotonic regression problem efficiently. The algorithm 
works by iteratively adjusting the values to satisfy the monotonicity 
constraints while minimizing the squared error.

The implementation also supports:

- **Sample weights**: Allowing for weighted least squares fitting.
- **Bounds on predictions**: Constraining the predicted values to lie within 
  specified bounds.
- **Handling of out-of-bounds predictions**: Specifying how to handle input 
  values outside the training domain during prediction.

For more details on the algorithm and its implementation, see the references 
below.

References
----------

- Best, M. J., & Chakravarti, N. (1990). Active set algorithms for isotonic 
  regression; A unifying framework. *Mathematical Programming*, 47(1-3), 425-439.
- Barlow, R. E., Bartholomew, D. J., Bremner, J. M., & Brunk, H. D. (1972). 
  *Statistical inference under order restrictions*. Wiley.
- Wikipedia contributors. (2021). Isotonic regression. In *Wikipedia, The Free 
  Encyclopedia*. Retrieved from 
  https://en.wikipedia.org/wiki/Isotonic_regression