.. _gaussian_process:

===================
Gaussian Process
===================

.. currentmodule:: sklearn.gaussian_process

The :mod:`sklearn.gaussian_process` module implements a variety of Gaussian Process (GP) models for regression and classification tasks. Gaussian Processes are powerful non-parametric models that provide a principled approach to learning distributions over functions, offering both predictions and uncertainty estimates.

This module includes:

- :class:`GaussianProcessRegressor`: A Gaussian Process regressor for regression tasks.
- :class:`GaussianProcessClassifier`: A Gaussian Process classifier for classification tasks.
- A rich set of kernels for kernel engineering, allowing flexible modeling of data relationships.

.. toctree::
   :maxdepth: 2
   :hidden:

   kernels

Kernels
-------

Kernels play a central role in Gaussian Processes, defining the covariance structure between data points. The kernels in this module support:

- **Kernel Composition**: Kernels can be combined using the ``+`` (sum) and ``*`` (product) operators.
- **Scalar Exponentiation**: Kernels can be exponentiated with a scalar using the ``**`` operator.
- **Automatic Constant Conversion**: Scalar values in expressions are automatically converted to :class:`ConstantKernel`.
- **Hyperparameter Optimization**: All kernels support analytic gradient-based optimization of hyperparameters.
- **Flexible Hyperparameter Bounds**: Hyperparameters can be bounded or fixed during optimization.

Each kernel is defined by its hyperparameters, which can be scalar or vector-valued (e.g., anisotropic length scales). The :class:`Hyperparameter` class provides a structured way to define and manage these parameters.

For more details on available kernels and their usage, see the :ref:`kernel documentation <kernels>`.

Examples
--------

- :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy_targets.py`
- :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpc_iris.py`
- :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_prior_posterior.py`

.. _kernel_engineering:

Kernel Engineering
------------------

Kernel engineering allows users to design custom kernels tailored to specific data properties. By combining base kernels (e.g., RBF, Mat√©rn, WhiteKernel), complex covariance structures can be modeled.

Example:

.. code-block:: python

    from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C

    # Define a composite kernel
    kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))

This kernel combines a constant term with an RBF (Radial Basis Function) kernel, allowing joint optimization of both components' hyperparameters.

Hyperparameter Handling
-----------------------

Each kernel exposes its hyperparameters through the :attr:`hyperparameters` attribute. These can be optimized during model fitting or fixed to specific values.

Bounds on hyperparameters define the search space during optimization. If a hyperparameter is declared as "fixed", it will not be optimized.

Example:

.. code-block:: python

    from sklearn.gaussian_process.kernels import ConstantKernel

    # Define a kernel with bounded hyperparameter
    kernel = ConstantKernel(constant_value=1.0, constant_value_bounds=(1e-3, 1e3))

    # Access hyperparameters
    for param in kernel.hyperparameters:
        print(param)

This flexibility allows fine-grained control over model complexity and behavior.

See Also
--------

- :ref:`GaussianProcessRegressor <gaussian_process_regressor>`
- :ref:`GaussianProcessClassifier <gaussian_process_classifier>`
- :ref:`Kernels <kernels>`