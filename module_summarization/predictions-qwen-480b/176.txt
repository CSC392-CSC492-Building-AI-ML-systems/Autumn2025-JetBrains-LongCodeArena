Probability Calibration
=======================

.. currentmodule:: sklearn.calibration

When performing classification, one often wants not only to predict the class label, but also to obtain a probability of the prediction. Some models can naturally output probabilities, but these probabilities can be poorly calibrated. Probability calibration is a technique that transforms the output of a classifier into a calibrated probability distribution.

The :class:`CalibratedClassifierCV` class provides a way to calibrate the output probabilities of a classifier using cross-validation. It supports two calibration methods: Platt scaling (sigmoid) and isotonic regression.

Calibration Methods
-------------------

Two methods are available for calibration:

- **Sigmoid (Platt scaling)**: This method fits a logistic regression model to the classifier's scores. It is suitable for small datasets and assumes a sigmoid-shaped calibration curve.

- **Isotonic regression**: This is a non-parametric approach that fits a non-decreasing function to the data. It is more flexible than sigmoid calibration but requires more data to avoid overfitting.

Cross-Validation Strategies
---------------------------

The calibration process uses cross-validation to avoid overfitting. The following strategies are supported:

- **Ensemble**: For each cross-validation fold, a copy of the base estimator is fitted on the training subset and calibrated using the testing subset. Predictions are averaged across all calibrated classifiers.

- **Non-ensemble**: Cross-validation is used to obtain unbiased predictions via `cross_val_predict`, which are then used for calibration. The final classifier is trained on all the data.

Pre-fitted Models
-----------------

If the classifier is already fitted, the `cv="prefit"` option can be used. In this case, all provided data is used for calibration, and the user must ensure that the data used for fitting and calibration are disjoint.

Parameters
----------

The main parameters of :class:`CalibratedClassifierCV` are:

- `estimator`: The classifier to be calibrated.
- `method`: The calibration method ('sigmoid' or 'isotonic').
- `cv`: The cross-validation strategy.
- `n_jobs`: The number of jobs to run in parallel.
- `ensemble`: Whether to use the ensemble approach.

Attributes
----------

After fitting, the following attributes are available:

- `classes_`: The class labels.
- `n_features_in_`: The number of features seen during fitting.
- `feature_names_in_`: The names of features seen during fitting.
- `calibrated_classifiers_`: The list of calibrated classifiers.

Examples
--------

>>> from sklearn.datasets import make_classification
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.svm import LinearSVC
>>> from sklearn.calibration import CalibratedClassifierCV
>>> X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)
>>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
>>> svc = LinearSVC()
>>> calibrated_svc = CalibratedClassifierCV(svc, method='sigmoid', cv=3)
>>> calibrated_svc.fit(X_train, y_train)
>>> calibrated_svc.predict_proba(X_test)
array([[0.8, 0.2],
       [0.3, 0.7],
       ...])

See Also
--------

- :ref:`User Guide <calibration>` for more details on probability calibration.
- :func:`~sklearn.model_selection.cross_val_predict` for computing unbiased predictions.
- :class:`~sklearn.isotonic.IsotonicRegression` for isotonic calibration.
- :class:`~sklearn.svm.LinearSVC` for SVM classifiers with probability outputs.