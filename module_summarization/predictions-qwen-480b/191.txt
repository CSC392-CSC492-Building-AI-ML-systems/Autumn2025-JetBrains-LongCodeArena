Validation curves: plotting scores to evaluate models
=====================================================

.. currentmodule:: sklearn.model_selection

Validation curves are a useful tool for evaluating the performance of a model
as a function of a specific hyperparameter. They help diagnose whether a model
is overfitting or underfitting by visualizing the training and validation scores
across different values of the hyperparameter.

The :func:`validation_curve` function computes the training and validation scores
for a given estimator and a range of hyperparameter values. The resulting scores
can be visualized using the :class:`ValidationCurveDisplay` class, which provides
a convenient interface for plotting the curves.

Usage
-----

To generate a validation curve, you need to specify the estimator, the
hyperparameter to vary, and the range of values for that hyperparameter. The
function will then compute the training and validation scores for each value
using cross-validation.

Example
-------

The following example demonstrates how to plot a validation curve for a
:class:`~sklearn.svm.SVC` classifier with respect to the `gamma` parameter:

    >>> import matplotlib.pyplot as plt
    >>> from sklearn.datasets import load_digits
    >>> from sklearn.model_selection import validation_curve
    >>> from sklearn.svm import SVC

    >>> X, y = load_digits(return_X_y=True)
    >>> param_range = [0.001, 0.01, 0.1, 1.0]
    >>> train_scores, test_scores = validation_curve(
    ...     SVC(), X, y, param_name="gamma", param_range=param_range,
    ...     cv=5, scoring="accuracy"
    ... )

    >>> plt.figure()
    >>> plt.plot(param_range, train_scores.mean(axis=1), label="Training score")
    >>> plt.plot(param_range, test_scores.mean(axis=1), label="Cross-validation score")
    >>> plt.xlabel("Gamma")
    >>> plt.ylabel("Score")
    >>> plt.legend()
    >>> plt.show()

Interpretation
--------------

- **High training score and low validation score**: The model is overfitting.
  It learns the training data too well but fails to generalize to unseen data.

- **Low training and validation scores**: The model is underfitting. It is
  too simple to capture the underlying pattern of the data.

- **Training and validation scores are close and high**: The model is performing
  well and generalizing effectively.

By analyzing the validation curves, you can choose the optimal value of the
hyperparameter that balances bias and variance, leading to better model performance.