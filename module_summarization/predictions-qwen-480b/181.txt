Dataset loading utilities
=========================

.. currentmodule:: sklearn.datasets

The :mod:`sklearn.datasets` module includes various utilities to load and fetch datasets, both small toy datasets and larger datasets from external repositories such as OpenML. These utilities are useful for quickly accessing data for experimentation, testing, and educational purposes.

OpenML dataset fetching
-----------------------

The following function allows loading datasets from the `OpenML <https://www.openml.org>`_ repository:

.. autofunction:: fetch_openml

This function provides access to a wide range of datasets hosted on OpenML. It handles downloading, caching, and parsing of datasets, returning them in a convenient format for use with scikit-learn.

Internally, the function communicates with the OpenML API to retrieve dataset metadata and content. It supports automatic retries on network errors and handles compressed data transparently.

Caching
~~~~~~~

To avoid repeated downloads, datasets fetched from OpenML are cached locally. The cache location is determined by the ``data_home`` parameter or the default scikit-learn data directory. If a cached version is found, it is used; otherwise, the dataset is downloaded and stored for future use.

Error handling
~~~~~~~~~~~~~~

The fetching mechanism includes robust error handling for network issues and corrupted cache files. In case of a recoverable error (e.g., network timeout), the function will retry the operation. If the local cache is found to be invalid, it is automatically cleared and the dataset is redownloaded.

Examples
~~~~~~~~

Basic usage:

    >>> from sklearn.datasets import fetch_openml
    >>> mnist = fetch_openml('mnist_784', version=1, cache=True)
    >>> mnist.data.shape
    (70000, 784)

Fetching with specific parameters:

    >>> iris = fetch_openml(name='iris', return_X_y=True)
    >>> iris[0].shape
    (150, 4)

For more information on available datasets, visit the `OpenML website <https://www.openml.org>`_.