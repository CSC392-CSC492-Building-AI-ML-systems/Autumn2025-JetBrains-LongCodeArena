`mixed_glm` Module
==================

The `mixed_glm` module provides Bayesian inference for generalized linear mixed models (GLMMs). It supports families without additional scale or shape parameters, such as binomial and Poisson. Two estimation approaches are implemented: Laplace approximation (maximum a posteriori) and variational Bayes (mean field approximation to the posterior distribution). All random effects are modeled as mutually independent.

Model and Parameterization
--------------------------
The joint density of data and parameters factors as:

.. math::

    p(y | vc, fep) p(vc | vcp) p(vcp) p(fe)

Here, :math:`p(vcp)` and :math:`p(fe)` are Gaussian prior distributions (with :math:`vcp` parameters as log standard deviations, so standard deviations follow log-normal distributions). The random effects distribution :math:`p(vc | vcp)` is independent Gaussian, and :math:`p(y | vc, fep)` depends on the specific GLM being fitted.

Key Components
--------------
- **`exog_vc`**: Design matrix for random effects. Each column corresponds to an independent realization of a random effect with mean zero and an unknown standard deviation. Standard deviation parameters are constrained to be equal within subsets of columns, specified via the `ident` parameter (or derived from formulas).
- **`ident`**: Array of integer labels indicating which columns of `exog_vc` share the same standard deviation.
- **Sparse Matrix Support**: `exog_vc` can be provided as a sparse matrix (or will be converted internally). Note: using formulas may temporarily create a dense version.

Usage
-----
The module includes the `MixedGLM` class for model fitting. Key methods are:
- `fit_map()`: Laplace approximation to the posterior.
- `fit_vb()`: Variational Bayes approximation.

Priors:
- Random effect standard deviation parameters (`vcp`) have log-normal priors with mean 0 and standard deviation `vcp_p`.
- Fixed effects parameters have Gaussian priors with mean 0 and standard deviation `fe_p`.

Example
-------
Below is a basic example using a binomial family model:

.. code-block:: python

    import numpy as np
    import statsmodels.api as sm
    from statsmodels.genmod.families import Binomial

    # Simulate some data
    np.random.seed(4321)
    n = 200
    exog = np.random.normal(size=(n, 2))
    exog_vc = np.random.normal(size=(n, 5))
    ident = np.array([0] * 2 + [1] * 3)  # Two groups for random effects
    lin_pred = exog[:, 0] + exog[:, 1] + 0.5 * exog_vc[:, 0] - 0.3 * exog_vc[:, 3]
    prob = 1 / (1 + np.exp(-lin_pred))
    endog = np.random.binomial(1, prob, n)

    # Fit the model
    model = sm.MixedGLM(endog, exog, exog_vc, ident, family=Binomial())
    result = model.fit_map()
    print(result.summary())

Notes
-----
- For families like binomial, setting `vcp_p` too large may cause numerical issues; a value like 0.5 is often effective.
- The module is suited for applications where random effects are independent and the design matrix may be sparse.

References
----------
- Introduction to GLMMs: https://stats.idre.ucla.edu/other/mult-pkg/introduction-to-generalized-linear-mixed-models
- SAS documentation on mixed models: https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_intromix_a0000000215.htm
- Evaluation of estimation methods for binary outcomes: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3866838/