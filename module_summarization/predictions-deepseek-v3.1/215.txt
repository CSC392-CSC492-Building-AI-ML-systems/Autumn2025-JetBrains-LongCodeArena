.. _queues:

Queues
======

Asynchronous queues for coroutines. These classes are very similar
to those provided in the standard library's `asyncio package
<https://docs.python.org/3/library/asyncio-queue.html>`_.

.. warning::

   Unlike the standard library's `queue` module, the classes defined here
   are *not* thread-safe. To use these queues from another thread,
   use `.IOLoop.add_callback` to transfer control to the `.IOLoop` thread
   before calling any queue methods.

Classes
-------

.. autoclass:: Queue
   :members:
   :show-inheritance:

.. autoclass:: PriorityQueue
   :members:
   :show-inheritance:

.. autoclass:: LifoQueue
   :members:
   :show-inheritance:

Exceptions
----------

.. autoexception:: QueueEmpty

.. autoexception:: QueueFull

Example
-------

The Queue class implements an asynchronous producer/consumer pattern for coroutines:

.. testcode::

    import asyncio
    from tornado.ioloop import IOLoop
    from tornado.queues import Queue

    q = Queue(maxsize=2)

    async def consumer():
        async for item in q:
            try:
                print('Doing work on %s' % item)
                await asyncio.sleep(0.01)
            finally:
                q.task_done()

    async def producer():
        for item in range(5):
            await q.put(item)
            print('Put %s' % item)

    async def main():
        # Start consumer without waiting (since it never finishes).
        IOLoop.current().spawn_callback(consumer)
        await producer()     # Wait for producer to put all tasks.
        await q.join()       # Wait for consumer to finish all tasks.
        print('Done')

    asyncio.run(main())

.. testoutput::

    Put 0
    Put 1
    Doing work on 0
    Put 2
    Doing work on 1
    Put 3
    Doing work on 2
    Put 4
    Doing work on 3
    Doing work on 4
    Done

In this pattern:

- The producer coroutine puts items into the queue using ``await q.put(item)``
- The consumer coroutine retrieves items using ``async for item in q:``
- ``q.join()`` waits until all items have been processed (after calling ``q.task_done()`` for each item)
- The queue size is limited to help balance producer and consumer speeds

For Python versions before 3.5 (without native coroutines), the consumer can be written as:

.. testcode::

    @gen.coroutine
    def consumer():
        while True:
            item = yield q.get()
            try:
                print('Doing work on %s' % item)
                yield gen.sleep(0.01)
            finally:
                q.task_done()