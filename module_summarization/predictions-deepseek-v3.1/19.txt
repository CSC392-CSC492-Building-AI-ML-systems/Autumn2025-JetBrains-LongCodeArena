w_crawl
=======

The ``w_crawl`` command provides a framework for executing custom functions across iterations of a weighted ensemble dataset. It enables parallel processing of iteration-based tasks for postprocessing, data analysis, cleanup operations, or any other operation that can be applied per iteration.

Synopsis
--------

.. code-block:: bash

   w_crawl [options] TASK_CALLABLE

Description
-----------

The ``w_crawl`` tool processes a WESTPA dataset by applying a user-defined function to each iteration within a specified range. The tool handles parallel execution of tasks across iterations without guaranteeing order of evaluation, making it suitable for independent per-iteration operations.

Key features include:
- Parallel execution of tasks by iteration
- Support for custom initialization and finalization procedures
- Flexible result processing through a crawler interface
- Integration with WESTPA's data management system

Options
-------

Standard Options
~~~~~~~~~~~~~~~~

.. program:: w_crawl

.. option:: -h, --help

   Show help message and exit.

.. option:: --version

   Show program version and exit.

Data Selection Options
~~~~~~~~~~~~~~~~~~~~~~

These options control which iterations are processed:

.. option:: -s ITER_START, --start=ITER_START

   Start at iteration ITER_START (default: first available iteration).

.. option:: -e ITER_STOP, --stop=ITER_STOP

   Stop at iteration ITER_STOP (default: last available iteration).

Task Options
~~~~~~~~~~~~

.. option:: -c CRAWLER_INSTANCE, --crawler-instance=CRAWLER_INSTANCE

   Use CRAWLER_INSTANCE (specified as ``module.instance``) as an instance of WESTPACrawler to coordinate the calculation. Required only if initialization, finalization, or task result processing is needed.

.. option:: TASK_CALLABLE

   **Required.** Run TASK_CALLABLE (specified as ``module.function``) on each iteration.

Progress Indicator Options
~~~~~~~~~~~~~~~~~~~~~~~~~~

.. option:: --progress

   Show progress during operation.

.. option:: --no-progress

   Do not show progress during operation.

Arguments
---------

The tool requires one positional argument:

:TASK_CALLABLE: A Python callable specified in module.function format that will be executed for each iteration.

Usage Examples
--------------

Basic usage with a simple task function:

.. code-block:: bash

   w_crawl mymodule.process_iteration

Using a crawler for coordinated processing:

.. code-block:: bash

   w_crawl -c mypackage.mycrawler mymodule.analysis_task

Processing a specific iteration range:

.. code-block:: bash

   w_crawl -s 100 -e 200 mymodule.cleanup_task

Implementation Details
----------------------

The tool uses WESTPA's parallel processing framework to distribute tasks across available workers. Each iteration is processed independently, with the specified task function receiving the iteration number and corresponding data.

The crawler interface (WESTPACrawler) provides hooks for:
- ``initialize()``: Pre-processing setup
- ``process_iter_result()``: Handling results from each iteration
- ``finalize()``: Post-processing cleanup

The task function should accept two parameters: iteration number and the corresponding iteration data group, and return a result that can be processed by the crawler's ``process_iter_result()`` method.

See Also
--------

- :doc:`w_ipa`
- :doc:`w_assign`
- :doc:`w_truncate`

Note
----

The data manager is opened in read-only mode during task execution. For operations requiring write access, appropriate data management should be handled within the task function or crawler implementation.