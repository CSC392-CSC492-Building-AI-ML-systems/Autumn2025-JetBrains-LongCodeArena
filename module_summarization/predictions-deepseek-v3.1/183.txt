.. _feature_selection:

Feature Selection and Dimensionality Reduction
=============================================

.. currentmodule:: sklearn.feature_selection

Feature selection, also known as variable selection or attribute selection, is the process of selecting a subset of relevant features (variables, predictors) for use in model construction. Dimensionality reduction techniques transform the data from a high-dimensional space into a low-dimensional space while preserving as much of the relevant information as possible.

Why Feature Selection?
----------------------

- **Reduces overfitting**: Less redundant data means less opportunity to make decisions based on noise
- **Improves accuracy**: Less misleading data improves model accuracy
- **Reduces training time**: Fewer data points reduce algorithm training time
- **Improves interpretability**: Simpler models are easier to understand and explain

Types of Feature Selection Methods
----------------------------------

Univariate Feature Selection
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Univariate feature selection works by selecting the best features based on univariate statistical tests.

.. autosummary::
   :toctree: generated/
   :template: function.rst
   
   SelectKBest
   SelectPercentile
   SelectFpr
   SelectFdr
   SelectFwe
   GenericUnivariateSelect

Recursive Feature Elimination
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

RFE works by recursively removing features and building a model on the remaining features.

.. autosummary::
   :toctree: generated/
   :template: function.rst
   
   RFE
   RFECV

Feature Selection Using Model Weights
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Select features based on importance weights from machine learning models.

.. autosummary::
   :toctree: generated/
   :template: function.rst
   
   SelectFromModel

Sequential Feature Selection
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Sequential feature selection algorithms are a family of greedy search algorithms.

.. autosummary::
   :toctree: generated/
   :template: function.rst
   
   SequentialFeatureSelector

Dimensionality Reduction Techniques
-----------------------------------

While not strictly feature selection (since they create new features), dimensionality reduction methods are often used for similar purposes:

.. autosummary::
   :toctree: generated/
   :template: function.rst
   
   PCA
   KernelPCA
   SparsePCA
   TruncatedSVD
   DictionaryLearning
   FactorAnalysis
   FastICA
   NMF
   LatentDirichletAllocation

Utility Functions
-----------------

.. autosummary::
   :toctree: generated/
   :template: function.rst
   
   mutual_info_classif
   mutual_info_regression
   chi2
   f_classif
   f_regression
   r_regression

Examples
--------

See :ref:`sphx_glr_auto_examples_feature_selection` for examples of feature selection and dimensionality reduction techniques.

.. note::
   Feature selection is an important step in the machine learning pipeline that can significantly improve model performance, reduce computational costs, and enhance model interpretability.

.. seealso::
   :ref:`decomposition` - Additional dimensionality reduction techniques
   :ref:`preprocessing` - Data preprocessing and normalization methods