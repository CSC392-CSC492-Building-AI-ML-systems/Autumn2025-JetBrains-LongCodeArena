Linear Mixed Effects Models
=============================

Linear mixed effects models are regression models for dependent data.
They can be used to estimate regression relationships involving both
means and variances.

These models are also known as multilevel linear models, and
hierarchical linear models.

The MixedLM class fits linear mixed effects models to data, and
provides support for some common post-estimation tasks.  This is a
group-based implementation that is most efficient for models in which
the data can be partitioned into independent groups.  Some models with
crossed effects can be handled by specifying a model with a single
group.

Model Specification
-------------------

The data are partitioned into disjoint groups.  The probability model
for group i is:

Y = X*beta + Z*gamma + epsilon

where

* n_i is the number of observations in group i
* Y is a n_i dimensional response vector (called endog in MixedLM)
* X is a n_i x k_fe dimensional design matrix for the fixed effects (called exog in MixedLM)
* beta is a k_fe-dimensional vector of fixed effects parameters (called fe_params in MixedLM)
* Z is a design matrix for the random effects with n_i rows (called exog_re in MixedLM)
* gamma is a random vector with mean 0
* epsilon is a n_i dimensional vector of iid normal errors with mean 0 and variance sigma^2

Random Effects Types
--------------------

Two types of random effects are supported:

1. **Standard random effects**: Correlated with each other in arbitrary ways. Every group has the same number (k_re) of standard random effects, with the same joint distribution (but with independent realizations across groups)

2. **Variance components**: Uncorrelated with each other, and with the standard random effects. Each variance component has mean zero, and all realizations of a given variance component have the same variance parameter

Estimation
----------

Parameters beta, Psi (cov_re), and sigma^2 (scale) are estimated using ML or REML estimation. The marginal mean structure is E[Y | X, Z] = X*beta.

Parameterizations
-----------------

Three different parameterizations are used:

1. **User parameterization**: cov(endog) = scale*I + Z * cov_re * Z'
2. **Profile parameterization**: cov(endog) = I + Z * cov_re1 * Z'
3. **Square root parameterization**: Uses Cholesky factor of cov_re1

References
----------

Primary implementation reference:
- MJ Lindstrom, DM Bates (1988). "Newton Raphson and EM algorithms for linear mixed effects models for repeated measures data". Journal of the American Statistical Association. Volume 83, Issue 404, pages 1014-1022.

Additional references:
- http://econ.ucsb.edu/~doug/245a/Papers/Mixed%20Effects%20Implement.pdf
- http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf
- http://lme4.r-forge.r-project.org/slides/2009-07-07-Rennes/3Longitudinal-4.pdf

Implementation Notes
--------------------

- Y, X and Z must be entirely observed
- The numerical optimization uses GLS to avoid explicitly optimizing over fixed effects parameters
- The likelihood is profiled over both the scale parameter and fixed effects parameters
- Optimization methods requiring Hessian matrix (e.g., Newton-Raphson) cannot be used due to profiling
- Two score methods are implemented for different parameterizations

Notation
--------

- `cov_re`: Random effects covariance matrix (Psi)
- `scale`: Scalar error variance (sigma^2)
- `vcomp`: Vector of variance parameters for variance components