.. _preprocessing_targets:

===============================
Transforming the prediction target
===============================

The :mod:`sklearn.preprocessing` module provides functionality to transform
prediction targets for use in supervised learning tasks. While the primary
encoders like :class:`~sklearn.preprocessing.OneHotEncoder` and
:class:`~sklearn.preprocessing.OrdinalEncoder` are designed for feature
transformation, similar principles can be applied to target variables when
needed.

.. _label_encoding:

Label Encoding
==============

For classification tasks, target labels often need to be converted from
strings or other formats into integer representations that can be processed
by estimators. The :class:`~sklearn.preprocessing.LabelEncoder` provides
this functionality, converting class labels into integer values ranging from
0 to n_classes-1.

Example::

    from sklearn.preprocessing import LabelEncoder
    
    le = LabelEncoder()
    y = ['class_a', 'class_b', 'class_c', 'class_a']
    y_encoded = le.fit_transform(y)
    # y_encoded: array([0, 1, 2, 0])

The encoder stores the mapping between original labels and encoded values
in its ``classes_`` attribute.

.. _target_binarization:

Target Binarization
===================

For multiclass classification problems, it can be useful to transform
the target into a binary matrix representation. The
:class:`~sklearn.preprocessing.LabelBinarizer` converts multiclass labels
into a binary label matrix where each class gets its own column.

Example::

    from sklearn.preprocessing import LabelBinarizer
    
    lb = LabelBinarizer()
    y = ['class_a', 'class_b', 'class_c', 'class_a']
    y_binary = lb.fit_transform(y)
    # y_binary: array([[1, 0, 0],
    #                  [0, 1, 0],
    #                  [0, 0, 1],
    #                  [1, 0, 0]])

.. _regression_target_transformation:

Regression Target Transformation
================================

For regression tasks, target variables may benefit from transformation to
meet modeling assumptions. Common transformations include:

- **Log transformation**: Applied when the target exhibits exponential growth
- **Power transformations**: Using :class:`~sklearn.preprocessing.PowerTransformer`
  or :class:`~sklearn.preprocessing.QuantileTransformer`
- **Standardization**: Using :class:`~sklearn.preprocessing.StandardScaler`

These transformations can help stabilize variance and make the target
distribution more Gaussian-like, which can improve model performance.

Example of target standardization::

    from sklearn.preprocessing import StandardScaler
    
    scaler = StandardScaler()
    y = [[1000], [2000], [3000], [4000]]
    y_scaled = scaler.fit_transform(y)

.. note::
   When transforming targets for regression, remember to apply the inverse
   transformation to model predictions to bring them back to the original
   scale for interpretation and evaluation.

Handling Missing Values in Targets
==================================

For targets with missing values, consider:

- **Imputation**: Using simple strategies like mean/median imputation or
  more sophisticated methods like :class:`~sklearn.impute.KNNImputer`
- **Indicator variables**: Adding indicators for missingness when appropriate
- **Removal**: Removing samples with missing targets if the dataset is
  sufficiently large

.. warning::
   The appropriate handling of missing targets depends on the nature of the
   missingness (MCAR, MAR, MNAR) and the specific learning task.

Custom Target Transformation
============================

For specialized requirements, custom target transformations can be implemented
by creating classes that inherit from :class:`~sklearn.base.BaseEstimator` and
:class:`~sklearn.base.TransformerMixin`, implementing ``fit``, ``transform``,
and optionally ``inverse_transform`` methods.

See Also
========

- :ref:`preprocessing` for feature transformation techniques
- :ref:`impute` for missing value imputation
- :ref:`decomposition` for dimensionality reduction techniques that can
  be applied to transformed targets