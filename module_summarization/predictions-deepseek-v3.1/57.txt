mixed_linear
============

.. currentmodule:: statsmodels.regression.mixed_linear_model

.. autoclass:: MixedLM
   :members:
   :inherited-members:

Overview
--------
Linear mixed effects models are regression models for dependent data. They can be used to estimate regression relationships involving both means and variances. These models are also known as multilevel linear models and hierarchical linear models.

The MixedLM class fits linear mixed effects models to data and provides support for common post-estimation tasks. This implementation is group-based and most efficient for models where data can be partitioned into independent groups. Some models with crossed effects can be handled by specifying a model with a single group.

Model Specification
-------------------
The data are partitioned into disjoint groups. The probability model for group *i* is:

Y = X*β + Z*γ + ε

where:

- *n_i*: number of observations in group *i*
- *Y*: *n_i* dimensional response vector (endog)
- *X*: *n_i* × *k_fe* design matrix for fixed effects (exog)
- *β*: *k_fe*-dimensional vector of fixed effects parameters (fe_params)
- *Z*: design matrix for random effects with *n_i* rows (exog_re)
- *γ*: random vector with mean 0
- *ε*: *n_i* dimensional vector of iid normal errors with mean 0 and variance σ²

Y, X, and Z must be entirely observed. β, Psi, and σ² are estimated using ML or REML estimation.

Random Effects Types
--------------------
Two types of random effects are supported:

1. **Standard random effects**: Correlated with each other arbitrarily. Every group has the same number (*k_re*) of standard random effects with the same joint distribution (independent realizations across groups).

2. **Variance components**: Uncorrelated with each other and with standard random effects. Each variance component has mean zero, and all realizations share the same variance parameter. The number of realized variance components per variance parameter can differ across groups.

Parameterizations
-----------------
Three different parameterizations are used:

1. **User parameterization**: cov(endog) = scale*I + Z * cov_re * Z'
2. **Profile parameterization**: cov(endog) = I + Z * cov_re1 * Z'
3. **Square root parameterization**: Uses Cholesky factor of cov_re1

The regression slopes (fe_params) are identical in all parameterizations, but variance parameters differ.

Estimation References
---------------------
Primary implementation details based on:

- Lindstrom, M.J. & Bates, D.M. (1988). "Newton Raphson and EM algorithms for linear mixed effects models for repeated measures data". Journal of the American Statistical Association, 83(404), 1014-1022.

See also:

- http://econ.ucsb.edu/~doug/245a/Papers/Mixed%20Effects%20Implement.pdf
- http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf
- http://lme4.r-forge.r-project.org/slides/2009-07-07-Rennes/3Longitudinal-4.pdf

Implementation Notes
--------------------
- Numerical optimization uses GLS to avoid explicit optimization over fixed effects parameters
- Likelihood is profiled over both scale parameter and fixed effects parameters
- Hessian calculation for profiled log likelihood is not implemented
- Optimization methods requiring Hessian matrix (e.g., Newton-Raphson) cannot be used

Notation
--------
- `cov_re`: Random effects covariance matrix (Psi)
- `scale`: Scalar error variance
- `vcomp`: Vector of variance parameters

See Also
--------
:class:`statsmodels.genmod.generalized_estimating_equations.GEE` : Alternative approach when only mean structure is of interest