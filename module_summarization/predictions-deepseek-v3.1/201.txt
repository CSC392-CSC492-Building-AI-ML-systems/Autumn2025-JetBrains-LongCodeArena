.. _partial_dependence:

Partial Dependence Plots
========================

Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) plots are model-agnostic tools for interpreting and visualizing the relationship between input features and predictions from machine learning models.

Partial Dependence Plots
------------------------

Partial Dependence Plots show the marginal effect of one or two features on the predicted outcome of a machine learning model. A PDP averages the predictions across all instances while varying the target feature(s), holding all other features constant at their observed values.

The partial dependence function for a single feature is calculated as:

.. math::
   PD(x_s) = \frac{1}{n} \sum_{i=1}^{n} f(x_s, x_{c_i})

where:
- :math:`x_s` is the target feature being varied
- :math:`x_{c_i}` are the other features from the i-th observation
- :math:`f` is the trained model
- :math:`n` is the number of observations

Individual Conditional Expectation Plots
----------------------------------------

ICE plots display the dependence of the prediction on a feature for each individual instance separately. Unlike PDPs that show the average effect, ICE plots reveal heterogeneity in the relationship and can uncover interactions or unusual patterns that might be hidden in the averaged plot.

Each ICE line represents:

.. math::
   ICE_i(x_s) = f(x_s, x_{c_i})

where each line corresponds to one observation :math:`i` with its specific values for the other features :math:`x_{c_i}`.

Interpretation Guidelines
-------------------------

- **PDPs** show the average relationship between the target feature and prediction
- **ICE plots** reveal instance-level variations and potential interactions
- Flat lines indicate the feature has little effect on predictions
- Steep slopes suggest strong feature importance
- Nonlinear patterns reveal complex relationships captured by the model
- Diverging ICE lines indicate feature interactions

Common Use Cases
----------------

- Model debugging and validation
- Feature importance analysis
- Understanding complex model behavior
- Communicating model insights to stakeholders
- Detecting bias or unexpected model behavior

Implementation Notes
--------------------

The implementation handles both numerical and categorical features, supports various model types, and provides options for grid resolution, parallel computation, and visualization customization.

Related Functions
-----------------

- :func:`sklearn.inspection.partial_dependence`
- :func:`sklearn.inspection.PartialDependenceDisplay`
- :func:`sklearn.inspection.permutation_importance`

See Also
--------

- :ref:`permutation_importance`
- :ref:`plot_partial_dependence`

References
----------

.. [1] Friedman, J. H. (2001). Greedy function approximation: A gradient boosting machine. 
       Annals of Statistics, 29(5), 1189â€“1232.

.. [2] Goldstein, A., Kapelner, A., Bleich, J., & Pitkin, E. (2015). 
       Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation. 
       Journal of Computational and Graphical Statistics, 24(1), 44-65.