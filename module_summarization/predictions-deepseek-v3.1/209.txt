Analyzing a Collection of Text Documents
=========================================

The :mod:`sklearn.feature_extraction.text` submodule provides utilities for
converting collections of text documents into numerical feature vectors, which
is a crucial step in many machine learning applications involving text data.

Preprocessing Functions
-----------------------

The module includes several text preprocessing utilities:

.. autofunction:: strip_accents_unicode
.. autofunction:: strip_accents_ascii
.. autofunction:: strip_tags

These functions help normalize text by:
- Removing accents and diacritical marks from Unicode characters
- Stripping HTML/XML tags from text (basic implementation)
- Handling character encoding issues

Text Analysis Pipeline
----------------------

The module provides a flexible text analysis pipeline through:

.. autofunction:: _preprocess
.. autofunction:: _analyze

These functions support chaining together various text processing steps including:
- Lowercasing
- Accent removal
- Tokenization
- N-gram generation
- Stop word removal
- Custom preprocessing and decoding

The analysis can be configured to use either a custom analyzer function or
a combination of preprocessor, tokenizer, and n-gram generator.

Vectorizer Classes
------------------

The module provides several vectorizer classes that implement the text-to-feature
transformation:

- :class:`CountVectorizer`: Convert a collection of text documents to a matrix of token counts
- :class:`TfidfVectorizer`: Convert a collection of text documents to a matrix of TF-IDF features
- :class:`HashingVectorizer`: Convert a collection of text documents to a matrix of token occurrences using feature hashing

These vectorizers support:
- Multiple input types (raw text, filenames, file objects)
- Custom token patterns and tokenization
- N-gram extraction (unigrams, bigrams, etc.)
- Stop word filtering
- Term frequency-inverse document frequency (TF-IDF) weighting
- Unicode handling and encoding/decoding

Stop Words
----------

The module includes:

.. autodata:: ENGLISH_STOP_WORDS

A built-in set of English stop words that can be used for filtering common words
that typically don't contribute to the meaning of text in machine learning
applications.

Usage Example
-------------

Typical workflow involves:

1. Preprocessing text using the provided utilities
2. Creating a vectorizer instance with desired parameters
3. Fitting the vectorizer to the text corpus
4. Transforming documents into feature vectors
5. Using the feature vectors in machine learning models

The vectorizers are designed to work seamlessly with scikit-learn's pipeline
and cross-validation infrastructure, making it easy to incorporate text
processing into machine learning workflows.