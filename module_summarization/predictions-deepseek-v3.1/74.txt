random_projection
================

.. currentmodule:: sklearn.random_projection

Random Projection transformers implement dimensionality reduction through random projection techniques, which provide a computationally efficient way to reduce data dimensionality while approximately preserving pairwise distances between samples.

.. _random_projection:

Overview
--------

Random Projections are a simple and computationally efficient method for dimensionality reduction that trades a controlled amount of accuracy (as additional variance) for faster processing times and smaller model sizes. The technique preserves pairwise distances between samples through carefully controlled random projection matrices.

The theoretical foundation for random projection efficiency is based on the Johnson-Lindenstrauss lemma, which states that a small set of points in a high-dimensional space can be embedded into a much lower-dimensional space while nearly preserving distances between points.

Functions
---------

.. autofunction:: johnson_lindenstrauss_min_dim

.. autofunction:: _check_density

.. autofunction:: _check_input_size

.. autofunction:: _gaussian_random_matrix

Classes
-------

.. autoclass:: BaseRandomProjection
   :members:
   :inherited-members:

.. autoclass:: GaussianRandomProjection
   :members:
   :inherited-members:

.. autoclass:: SparseRandomProjection
   :members:
   :inherited-members:

The module provides both Gaussian and sparse random projection implementations, with the sparse variant offering additional computational efficiency for high-dimensional data.

References
----------

- Johnson-Lindenstrauss lemma: https://en.wikipedia.org/wiki/Johnson-Lindenstrauss_lemma
- Dasgupta, S., & Gupta, A. (1999). "An elementary proof of the Johnson-Lindenstrauss Lemma"

Examples
--------

>>> from sklearn.random_projection import johnson_lindenstrauss_min_dim
>>> johnson_lindenstrauss_min_dim(1e6, eps=0.5)
663

>>> from sklearn.random_projection import GaussianRandomProjection
>>> transformer = GaussianRandomProjection(n_components=100)
>>> X_transformed = transformer.fit_transform(X)

Note: This module is particularly useful for large datasets where traditional dimensionality reduction methods would be computationally expensive.