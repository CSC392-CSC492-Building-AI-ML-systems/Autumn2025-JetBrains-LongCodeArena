.. _calibration:

Probability calibration
======================

Calibration of predicted probabilities is a technique to adjust the output of a classifier to provide more accurate probability estimates. This is particularly useful for models like Support Vector Machines or boosted trees, which may not naturally produce well-calibrated probabilities.

Overview
--------

The :class:`~sklearn.calibration.CalibratedClassifierCV` class provides two main methods for probability calibration:

- **Sigmoid calibration (Platt's method)**: Uses logistic regression to map the classifier outputs to calibrated probabilities
- **Isotonic calibration**: A non-parametric approach that fits a piecewise constant, non-decreasing function

The calibration can be performed using cross-validation to avoid overfitting, or using a prefit estimator when you already have a trained classifier.

Key Features
------------

- Supports both binary and multiclass classification
- Works with any classifier that has either `decision_function` or `predict_proba` method
- Provides ensemble averaging for more robust probability estimates
- Parallel computation support for faster calibration
- Compatible with scikit-learn's model selection and evaluation tools

Basic Usage
-----------

.. code-block:: python

    from sklearn.calibration import CalibratedClassifierCV
    from sklearn.svm import LinearSVC
    
    # Calibrate a LinearSVC using default 5-fold cross-validation
    base_clf = LinearSVC()
    calibrated_clf = CalibratedClassifierCV(base_clf, method='sigmoid')
    calibrated_clf.fit(X_train, y_train)
    
    # Get calibrated probabilities
    probabilities = calibrated_clf.predict_proba(X_test)

Parameters
----------

The main parameters of `CalibratedClassifierCV` include:

- `estimator`: The base classifier to calibrate (default: LinearSVC)
- `method`: Calibration method ('sigmoid' or 'isotonic')
- `cv`: Cross-validation strategy (integer, CV splitter, or "prefit")
- `ensemble`: Whether to use ensemble averaging (default: True)
- `n_jobs`: Number of parallel jobs

Methods
-------

The class provides standard classifier methods:

- `fit(X, y[, sample_weight])`: Fit the calibrated model
- `predict(X)`: Predict class labels
- `predict_proba(X)`: Predict calibrated probabilities
- `score(X, y[, sample_weight])`: Return the mean accuracy

Attributes
----------

After fitting, the model provides:

- `classes_`: Array of class labels
- `calibrated_classifiers_`: List of fitted classifier-calibrator pairs
- `n_features_in_`: Number of features seen during fit

Examples
--------

See the :ref:`example gallery <calibration_examples>` for detailed examples of probability calibration with different classifiers and datasets.

Notes
-----

- Isotonic calibration requires more data than sigmoid calibration to avoid overfitting
- The quality of calibration depends on the reliability of the base classifier's outputs
- For best results, use separate data for classifier training and calibration

References
----------

- Platt, J. (1999). Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods.
- Zadrozny, B. & Elkan, C. (2002). Transforming classifier scores into accurate multiclass probability estimates.

See Also
--------

- :class:`~sklearn.isotonic.IsotonicRegression`: The isotonic regression model used for calibration
- :func:`~sklearn.model_selection.cross_val_predict`: Used when ensemble=False
- :class:`~sklearn.linear_model.LogisticRegression`: Related to sigmoid calibration method