Validation Curves: Plotting Scores to Evaluate Models
=====================================================

Validation curves are a useful diagnostic tool to understand the influence of a single hyperparameter on the training and validation scores of a model. They help in finding the optimal value for a hyperparameter by showing how the model's performance varies as the hyperparameter is adjusted.

The :class:`~sklearn.model_selection.ValidationCurveDisplay` class provides a convenient way to visualize validation curves. It is recommended to use the :meth:`~sklearn.model_selection.ValidationCurveDisplay.from_estimator` method to create a display instance.

Basic Usage
-----------

Here is a basic example of how to plot a validation curve:

.. code-block:: python

    from sklearn.datasets import make_classification
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import ValidationCurveDisplay

    X, y = make_classification(n_samples=1000, random_state=0)
    estimator = LogisticRegression()

    param_name = "C"
    param_range = np.logspace(-6, 6, 7)

    display = ValidationCurveDisplay.from_estimator(
        estimator,
        X,
        y,
        param_name=param_name,
        param_range=param_range,
        cv=5,
    )

Customizing the Display
-----------------------

The display can be customized in several ways:

.. code-block:: python

    display = ValidationCurveDisplay.from_estimator(
        estimator,
        X,
        y,
        param_name=param_name,
        param_range=param_range,
        cv=5,
        scoring="accuracy",
        n_jobs=2,
        negate_score=True,
        score_name="Negative Accuracy",
        std_display_style="fill_between",
        line_kw={"marker": "o"},
        fill_between_kw={"alpha": 0.3},
    )

Parameters
----------
estimator : estimator instance
    An estimator object implementing `fit` and `predict` methods.

X : array-like of shape (n_samples, n_features)
    Training data.

y : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Target values.

param_name : str
    Name of the parameter that will be varied.

param_range : array-like of shape (n_values,)
    The values of the parameter that will be evaluated.

cv : int, cross-validation generator or an iterable, default=None
    Determines the cross-validation splitting strategy.

scoring : str or callable, default=None
    A string (see model evaluation documentation) or a scorer callable object.

n_jobs : int, default=None
    Number of jobs to run in parallel.

pre_dispatch : int or str, default='all'
    Controls the number of jobs that get dispatched during parallel execution.

verbose : int, default=0
    Controls the verbosity: the higher, the more messages.

Attributes
----------
train_scores : array of shape (n_ticks, n_cv_folds)
    Scores on training sets.

test_scores : array of shape (n_ticks, n_cv_folds)
    Scores on test set.

score_name : str
    The name of the score used to decorate the y-axis.

Notes
-----
All parameters are stored as attributes. The visualization includes:

- Mean training score and standard deviation
- Mean validation score and standard deviation
- Automatic scaling of the x-axis (linear or log based on parameter spacing)
- Legend identifying training and validation scores

See Also
--------
learning_curve : Compute learning curve.
LearningCurveDisplay : Learning curve visualization.

Examples
--------
See :ref:`sphx_glr_auto_examples_model_selection_plot_validation_curve.py`
for an example of validation curve usage.