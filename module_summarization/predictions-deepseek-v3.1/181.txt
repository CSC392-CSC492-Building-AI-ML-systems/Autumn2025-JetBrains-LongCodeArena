.. _openml_datasets:

OpenML Dataset Loading Utilities
================================

The :mod:`sklearn.datasets` module provides utilities to load datasets from OpenML, a public repository for machine learning data and experiments.

Main Function
-------------

.. autofunction:: fetch_openml

This function fetches a dataset by name or ID from OpenML, returning the data and metadata as a :class:`~sklearn.utils.Bunch` object.

Parameters
----------
- `name` (str or None): The name of the dataset to fetch. Mutually exclusive with `data_id`.
- `data_id` (int or None): OpenML ID of the dataset. Mutually exclusive with `name`.
- `version` (int or str, default='active'): Version of the dataset. Can be 'active' or a specific version number.
- `data_home` (str or None): Directory to cache downloaded datasets. If None, no caching is applied.
- `target_column` (str, 'default-target', or None; default='default-target'): Specify the target column in the dataset.
- `cache` (bool, default=True): Whether to cache downloaded datasets using joblib.
- `return_X_y` (bool, default=False): If True, returns `(data, target)` instead of a Bunch object.
- `as_frame` (bool or 'auto', default='auto'): Whether to return pandas DataFrames.

Returns
-------
- `data` : :class:`~sklearn.utils.Bunch`
    Dictionary-like object with the following attributes:
    - `data` (np.ndarray or scipy.sparse.csr_matrix): The feature matrix
    - `target` (np.ndarray): The target vector
    - `frame` (pandas.DataFrame): Only present when `as_frame=True`
    - `DESCR` (str): Full description of the dataset
    - `details` (dict): Additional metadata from OpenML
    - `categories` (dict): Mapping of categorical feature names to categories
    - `feature_names` (list): Names of the features

Network Handling
----------------
The download utilities include automatic retry mechanisms for network errors:
- Up to 3 retries by default with 1-second delays between attempts
- HTTP 412 errors (OpenML-specific errors) are not retried
- Automatic cache invalidation and redownload on corrupted cache files

Caching
-------
Datasets are cached locally in `data_home/openml.org/` directory structure:
- Files are stored in gzip-compressed format
- Atomic download operations ensure cache consistency
- Cache directory can be customized via `data_home` parameter

Examples
--------
>>> from sklearn.datasets import fetch_openml
>>> iris = fetch_openml(name='iris', version=1)
>>> X, y = iris.data, iris.target

>>> housing = fetch_openml(name='house_prices', as_frame=True)
>>> X_frame = housing.frame

Note: This implementation requires an active internet connection for downloading datasets from OpenML.org.