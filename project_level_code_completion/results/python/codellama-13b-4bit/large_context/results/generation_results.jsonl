{"original_prediction": "    file = next(raw_path.glob(f'_iblrig_{label}Camera.GPIO*.bin'), None)", "prediction_line": "    file = next(raw_path.glob(f'_iblrig_{label}Camera.GPIO*.bin'), None)", "ground_truth": "    label = assert_valid_label(label)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        settings = json.load(f)", "prediction_line": "        settings = json.load(f)", "ground_truth": "        settings = json.load(f)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1Low\", [np.nan])", "prediction_line": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1Low\", [np.nan])", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1Low\", [np.nan])", "line_class": "common", "zero_context": true}
{"original_prediction": "        data.drop(data.index[0], inplace=True)", "prediction_line": "        data.drop(data.index[0], inplace=True)", "ground_truth": "        data.drop(data.loc[:drop_first].index, inplace=True)", "line_class": "common", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Save a boolean value to the database", "prediction_line": "    \"\"\"", "ground_truth": "    if isinstance(save, bool):", "line_class": "common", "zero_context": true}
{"original_prediction": "        return save\n    if isinstance(save, str):", "prediction_line": "        return save", "ground_truth": "        out = save", "line_class": "common", "zero_context": true}
{"original_prediction": "    elif isinstance(save, str):", "prediction_line": "    elif isinstance(save, str):", "ground_truth": "    elif isinstance(save, list):", "line_class": "common", "zero_context": true}
{"original_prediction": "        out = save == dataset_type", "prediction_line": "        out = save == dataset_type", "ground_truth": "        out = (dataset_type in save) or (Path(dataset_type).stem in save)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2High\", [np.nan])", "prediction_line": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2High\", [np.nan])", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2High\", [np.nan])", "line_class": "common", "zero_context": true}
{"original_prediction": "    # check that the wheel position is within the expected range", "prediction_line": "    # check that the wheel position is within the expected range", "ground_truth": "    data.drop(data.loc[data.bns_ts.apply(len) != 33].index, inplace=True)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2Low\", [np.nan])", "prediction_line": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2Low\", [np.nan])", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2Low\", [np.nan])", "line_class": "common", "zero_context": true}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"BNC1\"][\"times\"]", "prediction_line": "                    for x in tr[\"behavior_data\"][\"BNC1\"][\"times\"]", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1High\", [np.nan])", "line_class": "common", "zero_context": true}
{"original_prediction": "        return _load_encoder_positions_file_lt5(path)", "prediction_line": "        return _load_encoder_positions_file_lt5(path)", "ground_truth": "        return _load_encoder_positions_file_lt5(path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data = [trial_times_to_times(d) for d in data]", "prediction_line": "        data = [trial_times_to_times(d) for d in data]", "ground_truth": "        data = [trial_times_to_times(t) for t in data]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        df = load_camera_frame_data(session_path, camera=label)", "prediction_line": "        df = load_camera_frame_data(session_path, camera=label)", "ground_truth": "        df = load_camera_frame_data(session_path, camera=label)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "prediction_line": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "ground_truth": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return _load_encoder_events_file_lt5(path)", "prediction_line": "        return _load_encoder_events_file_lt5(path)", "ground_truth": "        return _load_encoder_events_file_lt5(path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return load_camera_frame_data(session_path, camera, raw=True)", "prediction_line": "        return load_camera_frame_data(session_path, camera, raw=True)", "ground_truth": "        df = load_camera_frame_data(session_path, camera=camera)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        df = load_camera_frame_data(session_path, camera=label)", "prediction_line": "        df = load_camera_frame_data(session_path, camera=label)", "ground_truth": "        df = load_camera_frame_data(session_path, camera=label, raw=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        settings = load_settings(session_path)", "prediction_line": "        settings = load_settings(session_path)", "ground_truth": "        settings = load_settings(session_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    data['re_ts'] = data['re_ts'].astype(int)", "prediction_line": "    data['re_ts'] = data['re_ts'].astype(int)", "ground_truth": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    gpio = load_camera_gpio(session_path, label, raw=raw)", "prediction_line": "    gpio = load_camera_gpio(session_path, label, raw=raw)", "ground_truth": "    gpio = load_camera_gpio(session_path, label, as_dicts=not raw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "prediction_line": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "ground_truth": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        converted_events[k] = convert(v)", "prediction_line": "        converted_events[k] = convert(v)", "ground_truth": "        converted_events.update({k: [convert(i) for i in v]})", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data = load_data(session_path)", "prediction_line": "        data = load_data(session_path)", "ground_truth": "        data = load_data(session_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        converted_states.update({k: [convert(i) for i in v]})", "prediction_line": "        converted_states.update({k: [convert(i) for i in v]})", "ground_truth": "        converted_states.update({k: [[convert(i) for i in x] for x in v]})", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data = pd.read_csv(path, sep=' ', header=None, error_bad_lines=False)", "prediction_line": "        data = pd.read_csv(path, sep=' ', header=None, error_bad_lines=False)", "ground_truth": "        return _load_encoder_events_file_ge5(path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "prediction_line": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "ground_truth": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return _load_encoder_positions_file_ge5(path)", "prediction_line": "        return _load_encoder_positions_file_ge5(path)", "ground_truth": "        return _load_encoder_positions_file_ge5(path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    :param session_path: Absolute path of session folder", "prediction_line": "    :param session_path: Absolute path of session folder", "ground_truth": "    Assumes that a folder called \"raw_behavior_data\" exists in folder.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "_ibl_trials.relativeHumidity", "prediction_line": "_ibl_trials.relativeHumidity", "ground_truth": "    _ibl_trials.relativeHumidity", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   Convert timestamps to absolute time.", "prediction_line": "   Convert timestamps to absolute time.", "ground_truth": "    Bpod timestamps are in microseconds (µs)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    data = _clean_wheel_dataframe(data, label, path)", "prediction_line": "    data = _clean_wheel_dataframe(data, label, path)", "ground_truth": "    data = _clean_wheel_dataframe(data, label, path)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   :param session_path: Absolute path of session folder", "prediction_line": "   :param session_path: Absolute path of session folder", "ground_truth": "    The raw binary file contains uint32 values (saved as doubles) where the first 4 bits", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # find the one that matches the derivative of the current event", "prediction_line": "        # find the one that matches the derivative of the current event", "ground_truth": "        dec = np.abs(dt0[i0] - dt1[isearch]) < diff_threshold", "line_class": "random", "zero_context": true}
{"original_prediction": "            return\n        if as_dicts:", "prediction_line": "            return", "ground_truth": "            return [None] * 4 if as_dicts else None", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Synchronize two time series using robust methods.", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "random", "zero_context": true}
{"original_prediction": "    BNC1_fronts = BNC1_fronts[1:]", "prediction_line": "    BNC1_fronts = BNC1_fronts[1:]", "ground_truth": "    BNC1_fronts = BNC1_fronts[1:, :]", "line_class": "random", "zero_context": true}
{"original_prediction": "    file = next(raw_path.glob(f'_iblrig_{label}Camera.GPIO*.bin'), None)", "prediction_line": "    file = next(raw_path.glob(f'_iblrig_{label}Camera.GPIO*.bin'), None)", "ground_truth": "    label = assert_valid_label(label)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        settings = json.load(f)", "prediction_line": "        settings = json.load(f)", "ground_truth": "        settings = json.load(f)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1Low\", [np.nan])", "prediction_line": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1Low\", [np.nan])", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1Low\", [np.nan])", "line_class": "common", "zero_context": true}
{"original_prediction": "        data.drop(data.index[0], inplace=True)", "prediction_line": "        data.drop(data.index[0], inplace=True)", "ground_truth": "        data.drop(data.loc[:drop_first].index, inplace=True)", "line_class": "common", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Save a boolean value to the database", "prediction_line": "    \"\"\"", "ground_truth": "    if isinstance(save, bool):", "line_class": "common", "zero_context": true}
{"original_prediction": "        return save\n    if isinstance(save, str):", "prediction_line": "        return save", "ground_truth": "        out = save", "line_class": "common", "zero_context": true}
{"original_prediction": "    elif isinstance(save, str):", "prediction_line": "    elif isinstance(save, str):", "ground_truth": "    elif isinstance(save, list):", "line_class": "common", "zero_context": true}
{"original_prediction": "        out = save == dataset_type", "prediction_line": "        out = save == dataset_type", "ground_truth": "        out = (dataset_type in save) or (Path(dataset_type).stem in save)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2High\", [np.nan])", "prediction_line": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2High\", [np.nan])", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2High\", [np.nan])", "line_class": "common", "zero_context": true}
{"original_prediction": "    # check that the wheel position is within the expected range", "prediction_line": "    # check that the wheel position is within the expected range", "ground_truth": "    data.drop(data.loc[data.bns_ts.apply(len) != 33].index, inplace=True)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2Low\", [np.nan])", "prediction_line": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2Low\", [np.nan])", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2Low\", [np.nan])", "line_class": "common", "zero_context": true}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"BNC1\"][\"times\"]", "prediction_line": "                    for x in tr[\"behavior_data\"][\"BNC1\"][\"times\"]", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1High\", [np.nan])", "line_class": "common", "zero_context": true}
{"original_prediction": "        return _load_encoder_positions_file_lt5(path)", "prediction_line": "        return _load_encoder_positions_file_lt5(path)", "ground_truth": "        return _load_encoder_positions_file_lt5(path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data = [trial_times_to_times(d) for d in data]", "prediction_line": "        data = [trial_times_to_times(d) for d in data]", "ground_truth": "        data = [trial_times_to_times(t) for t in data]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        df = load_camera_frame_data(session_path, camera=label)", "prediction_line": "        df = load_camera_frame_data(session_path, camera=label)", "ground_truth": "        df = load_camera_frame_data(session_path, camera=label)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "prediction_line": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "ground_truth": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return _load_encoder_events_file_lt5(path)", "prediction_line": "        return _load_encoder_events_file_lt5(path)", "ground_truth": "        return _load_encoder_events_file_lt5(path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return load_camera_frame_data(session_path, camera, raw=True)", "prediction_line": "        return load_camera_frame_data(session_path, camera, raw=True)", "ground_truth": "        df = load_camera_frame_data(session_path, camera=camera)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        df = load_camera_frame_data(session_path, camera=label)", "prediction_line": "        df = load_camera_frame_data(session_path, camera=label)", "ground_truth": "        df = load_camera_frame_data(session_path, camera=label, raw=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        settings = load_settings(session_path)", "prediction_line": "        settings = load_settings(session_path)", "ground_truth": "        settings = load_settings(session_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    data['re_ts'] = data['re_ts'].astype(int)", "prediction_line": "    data['re_ts'] = data['re_ts'].astype(int)", "ground_truth": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    gpio = load_camera_gpio(session_path, label, raw=raw)", "prediction_line": "    gpio = load_camera_gpio(session_path, label, raw=raw)", "ground_truth": "    gpio = load_camera_gpio(session_path, label, as_dicts=not raw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "prediction_line": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "ground_truth": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        converted_events[k] = convert(v)", "prediction_line": "        converted_events[k] = convert(v)", "ground_truth": "        converted_events.update({k: [convert(i) for i in v]})", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data = load_data(session_path)", "prediction_line": "        data = load_data(session_path)", "ground_truth": "        data = load_data(session_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        converted_states.update({k: [convert(i) for i in v]})", "prediction_line": "        converted_states.update({k: [convert(i) for i in v]})", "ground_truth": "        converted_states.update({k: [[convert(i) for i in x] for x in v]})", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data = pd.read_csv(path, sep=' ', header=None, error_bad_lines=False)", "prediction_line": "        data = pd.read_csv(path, sep=' ', header=None, error_bad_lines=False)", "ground_truth": "        return _load_encoder_events_file_ge5(path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "prediction_line": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "ground_truth": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return _load_encoder_positions_file_ge5(path)", "prediction_line": "        return _load_encoder_positions_file_ge5(path)", "ground_truth": "        return _load_encoder_positions_file_ge5(path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    :param session_path: Absolute path of session folder", "prediction_line": "    :param session_path: Absolute path of session folder", "ground_truth": "    Assumes that a folder called \"raw_behavior_data\" exists in folder.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "_ibl_trials.relativeHumidity", "prediction_line": "_ibl_trials.relativeHumidity", "ground_truth": "    _ibl_trials.relativeHumidity", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   Convert timestamps to absolute time.", "prediction_line": "   Convert timestamps to absolute time.", "ground_truth": "    Bpod timestamps are in microseconds (µs)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    data = _clean_wheel_dataframe(data, label, path)", "prediction_line": "    data = _clean_wheel_dataframe(data, label, path)", "ground_truth": "    data = _clean_wheel_dataframe(data, label, path)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   :param session_path: Absolute path of session folder", "prediction_line": "   :param session_path: Absolute path of session folder", "ground_truth": "    The raw binary file contains uint32 values (saved as doubles) where the first 4 bits", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # find the one that matches the derivative of the current event", "prediction_line": "        # find the one that matches the derivative of the current event", "ground_truth": "        dec = np.abs(dt0[i0] - dt1[isearch]) < diff_threshold", "line_class": "random", "zero_context": true}
{"original_prediction": "            return\n        if as_dicts:", "prediction_line": "            return", "ground_truth": "            return [None] * 4 if as_dicts else None", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Synchronize two time series using robust methods.", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "random", "zero_context": true}
{"original_prediction": "    BNC1_fronts = BNC1_fronts[1:]", "prediction_line": "    BNC1_fronts = BNC1_fronts[1:]", "ground_truth": "    BNC1_fronts = BNC1_fronts[1:, :]", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.__dict__.update(us)", "prediction_line": "        self.__dict__.update(us)", "ground_truth": "        self.__dict__.update(us)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.__dict__.update(spc.__dict__)", "prediction_line": "        self.__dict__.update(spc.__dict__)", "ground_truth": "        self.__dict__.update(spc.__dict__)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.task_settings = ts", "prediction_line": "        self.task_settings = ts", "ground_truth": "        self.__dict__.update(ts)", "line_class": "common", "zero_context": true}
{"original_prediction": "            log.info(\"Cameras launched\")", "prediction_line": "            log.info(\"Cameras launched\")", "ground_truth": "            return bonsai.start_camera_recording(self)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       _task_settings.USE_SOUND_STIMULUS = False", "prediction_line": "       _task_settings.USE_SOUND_STIMULUS = False", "ground_truth": "    sph = SessionParamHandler(_task_settings, _user_settings, debug=True, fmake=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        :param events: list of events", "prediction_line": "        \"\"\"", "ground_truth": "        return misc.get_port_events(events, name=name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "prediction_line": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "ground_truth": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "            self.bpod_lights(0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            iotasks.save_task_code(self)", "prediction_line": "            iotasks.save_task_code(self)", "ground_truth": "            iotasks.copy_task_code(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.CALIB_FUNC_RANGE_X = adaptive.init_calib_func_range_x()", "prediction_line": "        self.CALIB_FUNC_RANGE_X = adaptive.init_calib_func_range_x()", "ground_truth": "        self.REWARD_VALVE_TIME = adaptive.init_reward_valve_time(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.SOUND_SAMPLE_FREQ = None if \"ephys\" in self.PYBPOD_BOARD else self.SOUND_SAMPLE_FREQ", "prediction_line": "        self.SOUND_SAMPLE_FREQ = None if \"ephys\" in self.PYBPOD_BOARD else self.SOUND_SAMPLE_FREQ", "ground_truth": "        self.SOUND_SAMPLE_FREQ = sound.sound_sample_freq(self.SOFT_SOUND)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "        self.OUT_TONE = (\"SoftCode\", 1) if self.SOFT_SOUND else (\"Serial3\", 5)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.save_settings_file()", "prediction_line": "            self.save_settings_file()", "ground_truth": "            iotasks.save_session_settings(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return False", "prediction_line": "            return False", "ground_truth": "            return bonsai.start_mic_recording(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       self.SOUND_BOARD_BPOD_PORT = self.SOUND_BOARD_BPOD_PORT", "prediction_line": "       self.SOUND_BOARD_BPOD_PORT = self.SOUND_BOARD_BPOD_PORT", "ground_truth": "        self.SD = sound.configure_sounddevice(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.ALL_THRESHOLDS.extend(self.F2TTL_GET_AND_SET_THRESHOLDS)", "prediction_line": "        self.ALL_THRESHOLDS.extend(self.F2TTL_GET_AND_SET_THRESHOLDS)", "ground_truth": "        self.ROTARY_ENCODER = MyRotaryEncoder(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.CALIB_FUNC = adaptive.get_calibration_function(self.SCREEN_SIZE_PIX, self.SCREEN_DIST)", "prediction_line": "            self.CALIB_FUNC = adaptive.get_calibration_function(self.SCREEN_SIZE_PIX, self.SCREEN_DIST)", "ground_truth": "            self.CALIB_FUNC = adaptive.init_calib_func()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.SD.stop()", "prediction_line": "        self.SD.stop()", "ground_truth": "        self.SD.stop()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "        self.CALIB_FUNC_RANGE = adaptive.init_calib_func_range()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.task_settings = task_settings", "prediction_line": "        self.task_settings = task_settings", "ground_truth": "        self = iotasks.deserialize_pybpod_user_settings(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Saves ambient sensor reading to file", "prediction_line": "        \"\"\"", "ground_truth": "        return ambient_sensor.get_reading(bpod_instance, save_to=self.SESSION_RAW_DATA_FOLDER)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "            iotasks.save_task_code(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.SOUND_BOARD_BPOD_PORT = \"Serial4\"", "prediction_line": "            self.SOUND_BOARD_BPOD_PORT = \"Serial4\"", "ground_truth": "            sound.configure_sound_card(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def stop_tone(self):", "prediction_line": "    def stop_tone(self):", "ground_truth": "    def stop_sound(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import iblrig.user_input as user_input", "prediction_line": "import iblrig.user_input as user_input", "ground_truth": "import iblrig.user_input as user", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import numpy as np", "prediction_line": "import numpy as np", "ground_truth": "from sys import platform", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def reprJSON(self):", "prediction_line": "    def reprJSON(self):", "ground_truth": "    def reprJSON(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import numpy as np", "prediction_line": "import numpy as np", "ground_truth": "from pythonosc import udp_client", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.OSC_CLIENT_IP = \"127.0.0.1\"", "prediction_line": "        self.OSC_CLIENT_IP = \"127.0.0.1\"", "ground_truth": "        self.OSC_CLIENT_IP = \"127.0.0.1\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "        if self.SOFT_SOUND is None:", "line_class": "random", "zero_context": true}
{"original_prediction": "        else:\n            make = True  # True makes raw_behavior_data and processed_data folders", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "                sx[\"water_administration\"] = None", "prediction_line": "                sx[\"water_administration\"] = None", "ground_truth": "                sx[\"water_administration\"] = None", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.CALIB_FUNC_RANGE = None", "prediction_line": "        self.CALIB_FUNC_RANGE = None", "ground_truth": "        if self.AUTOMATIC_CALIBRATION:", "line_class": "random", "zero_context": true}
{"original_prediction": "   ax_bars.clear()", "prediction_line": "   ax_bars.clear()", "ground_truth": "    bar_data = get_barplot_data(tph)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ax_bars.clear()", "prediction_line": "    ax_bars.clear()", "ground_truth": "    psych_data = get_psych_data(tph)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    chron_data = get_chron_data(tph)", "prediction_line": "    chron_data = get_chron_data(tph)", "ground_truth": "    chron_data = get_chron_data(tph)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    vars_data = get_vars_data(tph)", "prediction_line": "    vars_data = get_vars_data(tph)", "ground_truth": "    vars_data = get_vars_data(tph)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    prop_resp_ccw08 = get_prop_ccw_resp(0.8)", "prediction_line": "    prop_resp_ccw08 = get_prop_ccw_resp(0.8)", "ground_truth": "    prop_resp_ccw08 = get_prop_ccw_resp(0.8)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ax_bars.clear()", "prediction_line": "    ax_bars.clear()", "ground_truth": "    plot_bars(bar_data, ax=ax_bars)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    plot_psych(psych_data, ax=ax_psych)", "prediction_line": "    plot_psych(psych_data, ax=ax_psych)", "ground_truth": "    plot_psych(psych_data, ax=ax_psych)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    plot_chron(chron_data, ax=ax_chron)", "prediction_line": "    plot_chron(chron_data, ax=ax_chron)", "ground_truth": "    plot_chron(chron_data, ax=ax_chron)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    plot_vars(vars_data, ax=ax_vars)", "prediction_line": "    plot_vars(vars_data, ax=ax_vars)", "ground_truth": "    plot_vars(vars_data, ax=ax_vars, ax2=ax_vars2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rts02 = get_rts(0.2)", "prediction_line": "    rts02 = get_rts(0.2)", "ground_truth": "    rts02, rts05, rts08 = get_rts(0.2), get_rts(0.5), get_rts(0.8)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    prop_resp_ccw_0 = get_prop_ccw_resp(0)", "prediction_line": "    prop_resp_ccw_0 = get_prop_ccw_resp(0)", "ground_truth": "    prop_resp_ccw02 = get_prop_ccw_resp(0.2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    prop_resp_ccw05 = get_prop_ccw_resp(0.5)", "prediction_line": "    prop_resp_ccw05 = get_prop_ccw_resp(0.5)", "ground_truth": "    prop_resp_ccw05 = get_prop_ccw_resp(0.5)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    sig_contrasts_all = sig_contrasts_all[sig_contrasts_all != 0]", "prediction_line": "    sig_contrasts_all = sig_contrasts_all[sig_contrasts_all != 0]", "ground_truth": "    sig_contrasts_all = np.append(sig_contrasts_all, [-x for x in sig_contrasts_all if x != 0])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "import numpy as np", "prediction_line": "import numpy as np", "ground_truth": "import numpy as np", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    ax.text(", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import os\nimport sys", "prediction_line": "import os", "ground_truth": "# @Author: Niccolò Bonacchi", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    ax2.bar(x[4], prop_correct, width, color=\"orange\", label=\"Proportion correct\")", "prediction_line": "    ax2.bar(x[4], prop_correct, width, color=\"orange\", label=\"Proportion correct\")", "ground_truth": "    ax2.bar(x[4], prop_correct, width, color=\"black\", label=\"Proportion correct\")", "line_class": "random", "zero_context": true}
{"original_prediction": "    return", "prediction_line": "    return", "ground_truth": "    ax2.figure.canvas.draw_idle()", "line_class": "random", "zero_context": true}
{"original_prediction": "        ax2 = ax.twinx()", "prediction_line": "        ax2 = ax.twinx()", "ground_truth": "        ax2 = ax.twinx()", "line_class": "random", "zero_context": true}
{"original_prediction": "        label=\"Current Block\",", "prediction_line": "        label=\"Current Block\",", "ground_truth": "        label=\"Block number\",", "line_class": "random", "zero_context": true}
{"original_prediction": "00\n    prop_correct = vars_data[\"prop_correct\"]", "prediction_line": "00", "ground_truth": "    prop_correct = vars_data[\"prop_correct\"]", "line_class": "random", "zero_context": true}
{"original_prediction": "        us = {", "prediction_line": "        us = {", "ground_truth": "        self.__dict__.update(ts)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.__dict__.update(us)", "prediction_line": "        self.__dict__.update(us)", "ground_truth": "        self.__dict__.update(us)", "line_class": "common", "zero_context": true}
{"original_prediction": "        pregenerated_session_folder = passive_session_folder.joinpath(str(pregenerated_session_num))", "prediction_line": "        pregenerated_session_folder = passive_session_folder.joinpath(str(pregenerated_session_num))", "ground_truth": "        stimDelays = np.load(", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.__dict__.update(spc.__dict__)", "prediction_line": "        self.__dict__.update(spc.__dict__)", "ground_truth": "        self.__dict__.update(spc.__dict__)", "line_class": "common", "zero_context": true}
{"original_prediction": "        stimIDs = np.load(", "prediction_line": "        stimIDs = np.load(", "ground_truth": "        stimIDs = np.load(", "line_class": "common", "zero_context": true}
{"original_prediction": "        positions = np.load(", "prediction_line": "        positions = np.load(", "ground_truth": "        pcs = np.load(", "line_class": "common", "zero_context": true}
{"original_prediction": "        \"\"\"Patches the settings file with the given dictionary\"\"\"", "prediction_line": "        \"\"\"Patches the settings file with the given dictionary\"\"\"", "ground_truth": "        self.__dict__.update(patch)", "line_class": "common", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "            self.bpod_lights(0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        iotasks.save_session_settings(self)", "prediction_line": "        iotasks.save_session_settings(self)", "ground_truth": "        misc.patch_settings_file(self.SETTINGS_FILE_PATH, patch)", "line_class": "infile", "zero_context": true}
{"original_prediction": "           self.bpod_lights(1)", "prediction_line": "           self.bpod_lights(1)", "ground_truth": "        self.display_logs()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "prediction_line": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "ground_truth": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.STIM_DURATION,", "prediction_line": "            self.STIM_DURATION,", "ground_truth": "        ) = self.load_passive_session_pcs()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        :param events: list of events", "prediction_line": "        \"\"\"", "ground_truth": "        return misc.get_port_events(events, name=name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       _task_settings.BONSAI_EDITOR = False", "prediction_line": "       _task_settings.BONSAI_EDITOR = False", "ground_truth": "    sph = SessionParamHandler(_task_settings, _user_settings, debug=False, fmake=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.STIM_FRAMES,", "prediction_line": "            self.STIM_FRAMES,", "ground_truth": "        ) = self.load_passive_session_delays_ids()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.SD.stop()", "prediction_line": "        self.SD.stop()", "ground_truth": "        self.SD.stop()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.save_session_settings()", "prediction_line": "            self.save_session_settings()", "ground_truth": "            iotasks.save_session_settings(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            iotasks.save_task_code(self)", "prediction_line": "            iotasks.save_task_code(self)", "ground_truth": "            iotasks.copy_task_code(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       self.SessionPathCreator = ph.SessionPathCreator(**self.__dict__)", "prediction_line": "       self.SessionPathCreator = ph.SessionPathCreator(**self.__dict__)", "ground_truth": "        spc = ph.SessionPathCreator(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       self.ERROR_TONE_DURATION = float(0.1)", "prediction_line": "       self.ERROR_TONE_DURATION = float(0.1)", "ground_truth": "        self.SD = sound.configure_sounddevice(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            log.info(msg)", "prediction_line": "            log.info(msg)", "ground_truth": "            log.info(msg)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.WHITE_NOISE = sound.make_sound(", "prediction_line": "        self.WHITE_NOISE = sound.make_sound(", "ground_truth": "        self.WHITE_NOISE = sound.make_sound(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.SOUND_ACTIONS = [", "prediction_line": "        self.SOUND_ACTIONS = [", "ground_truth": "        sound.configure_sound_card(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.SOUND_SAMPLES = sound.create_sound_samples(self)", "prediction_line": "        self.SOUND_SAMPLES = sound.create_sound_samples(self)", "ground_truth": "        self.GO_TONE = sound.make_sound(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "        self.IS_MOCK = user_input.ask_is_mock(self.SETTINGS_FILE_PATH)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "            iotasks.save_task_code(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.SOUND_SAMPLE_RATE = 48000", "prediction_line": "        self.SOUND_SAMPLE_RATE = 48000", "ground_truth": "        self.SOUND_SAMPLE_FREQ = sound.sound_sample_freq(self.SOFT_SOUND)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        pregenerated_session_path = Path(", "prediction_line": "        pregenerated_session_path = Path(", "ground_truth": "        base = Path(ph.get_iblrig_params_folder())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.CALIB_FUNC = adaptive.get_calibration_function(", "prediction_line": "            self.CALIB_FUNC = adaptive.get_calibration_function(", "ground_truth": "            self.CALIB_FUNC = adaptive.init_calib_func()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                sub.append(remove_from_dict(sx))", "prediction_line": "                sub.append(remove_from_dict(sx))", "ground_truth": "                sub.append(remove_from_dict(sx))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.STIM_SIZE = 100  # (pixels) Size of the square around the Gabor patch", "prediction_line": "        self.STIM_SIZE = 100  # (pixels) Size of the square around the Gabor patch", "ground_truth": "        self.STIM_GAIN = 4.0  # (azimuth_degree/mm) Gain of the RE", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def display_logs(self):", "prediction_line": "    def display_logs(self):", "ground_truth": "    def get_port_events(self, events, name=\"\"):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import iblrig.bonsai as bonsai", "prediction_line": "import iblrig.bonsai as bonsai", "ground_truth": "import iblrig.iotasks as iotasks", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # =========================================================================", "prediction_line": "    # =========================================================================", "ground_truth": "    # =========================================================================", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # SOUND", "prediction_line": "        # SOUND", "ground_truth": "        # SOUNDS", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # self.SUBJECT_GENDER = self.ask_subject_gender()", "prediction_line": "        # self.SUBJECT_GENDER = self.ask_subject_gender()", "ground_truth": "        self.POOP_COUNT = True", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.N_LEARNING_BLOCKS = 1  # Number of learning blocks for the current session", "prediction_line": "        self.N_LEARNING_BLOCKS = 1  # Number of learning blocks for the current session", "ground_truth": "        self.USE_AUTOMATIC_STOPPING_CRITERIONS = (", "line_class": "random", "zero_context": true}
{"original_prediction": "            if \"__\" in sx:", "prediction_line": "            if \"__\" in sx:", "ground_truth": "            if \"weighings\" in sx.keys():", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.SUBJECT_DISENGAGED_TRIGGERED_TIME = None", "prediction_line": "        self.SUBJECT_DISENGAGED_TRIGGERED_TIME = None", "ground_truth": "        self.SUBJECT_DISENGAGED_TRIALNUM = None", "line_class": "random", "zero_context": true}
{"original_prediction": "passive_session_folder.joinpath(f\"stimDelays_{pregenerated_session_num}.npy\"))", "prediction_line": "passive_session_folder.joinpath(f\"stimDelays_{pregenerated_session_num}.npy\"))", "ground_truth": "            passive_session_folder / f\"session_{pregenerated_session_num}_passive_stimDelays.npy\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.__dict__.update(us)", "prediction_line": "        self.__dict__.update(us)", "ground_truth": "        self.__dict__.update(us)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.__dict__.update(spc.__dict__)", "prediction_line": "        self.__dict__.update(spc.__dict__)", "ground_truth": "        self.__dict__.update(spc.__dict__)", "line_class": "common", "zero_context": true}
{"original_prediction": "        \"\"\"Patches the settings file with a dictionary\"\"\"", "prediction_line": "        \"\"\"Patches the settings file with a dictionary\"\"\"", "ground_truth": "        self.__dict__.update(patch)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.task_settings = ts", "prediction_line": "        self.task_settings = ts", "ground_truth": "        self.__dict__.update(ts)", "line_class": "common", "zero_context": true}
{"original_prediction": "            log.info(\"Cameras launched\")", "prediction_line": "            log.info(\"Cameras launched\")", "ground_truth": "            return bonsai.start_camera_recording(self)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        :param events: list of events", "prediction_line": "        \"\"\"", "ground_truth": "        return misc.get_port_events(events, name=name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "   _task_settings.SCREEN_FULLSCREEN = True", "prediction_line": "   _task_settings.SCREEN_FULLSCREEN = True", "ground_truth": "    sph = SessionParamHandler(_task_settings, _user_settings, debug=False, fmake=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "            self.bpod_lights(0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def bpod_lights(self, command):", "prediction_line": "    def bpod_lights(self, command):", "ground_truth": "        self.display_logs()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "prediction_line": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "ground_truth": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        iotasks.save_session_settings(self)", "prediction_line": "        iotasks.save_session_settings(self)", "ground_truth": "        misc.patch_settings_file(self.SETTINGS_FILE_PATH, patch)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       self.ERROR_TONE_DURATION = float(self.ERROR_TONE_DURATION)", "prediction_line": "       self.ERROR_TONE_DURATION = float(self.ERROR_TONE_DURATION)", "ground_truth": "        self.SD = sound.configure_sounddevice(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            iotasks.save_task_code(self)", "prediction_line": "            iotasks.save_task_code(self)", "ground_truth": "            iotasks.copy_task_code(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "                iotasks.save_video_code(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.ADAPTIVE_SCALE_FACTOR = 1.0", "prediction_line": "        self.ADAPTIVE_SCALE_FACTOR = 1.0", "ground_truth": "        self.CALIB_FUNC_RANGE = adaptive.init_calib_func_range()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.ALL_THRESHOLDS = [x for x in self.ALL_THRESHOLDS if x is not None]", "prediction_line": "        self.ALL_THRESHOLDS = [x for x in self.ALL_THRESHOLDS if x is not None]", "ground_truth": "        self.ROTARY_ENCODER = MyRotaryEncoder(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.task_settings = task_settings", "prediction_line": "        self.task_settings = task_settings", "ground_truth": "        self = iotasks.deserialize_pybpod_user_settings(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            log.info(msg)", "prediction_line": "            log.info(msg)", "ground_truth": "            log.info(msg)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if self.CAMERA_ON:", "prediction_line": "        if self.CAMERA_ON:", "ground_truth": "        if bonsai.launch_cameras():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def get_session_path(self):", "prediction_line": "    def get_session_path(self):", "ground_truth": "            iotasks.save_task_code(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            iotasks.save_session_settings(self)", "prediction_line": "            iotasks.save_session_settings(self)", "ground_truth": "            iotasks.save_session_settings(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       # =====================================================================", "prediction_line": "       # =====================================================================", "ground_truth": "        self.OUT_TONE = (\"SoftCode\", 1) if self.SOFT_SOUND else (\"Serial3\", 6)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.ADAPTIVE_SPEED = adaptive.init_adaptive_speed()", "prediction_line": "        self.ADAPTIVE_SPEED = adaptive.init_adaptive_speed()", "ground_truth": "        self.REWARD_VALVE_TIME = adaptive.init_reward_valve_time(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "        bonsai.start_visual_stim(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.SOUND_SAMPLE_FREQ = None if \"ephys\" in self.PYBPOD_BOARD else self.SOUND_SAMPLE_FREQ", "prediction_line": "        self.SOUND_SAMPLE_FREQ = None if \"ephys\" in self.PYBPOD_BOARD else self.SOUND_SAMPLE_FREQ", "ground_truth": "        self.SOUND_SAMPLE_FREQ = sound.sound_sample_freq(self.SOFT_SOUND)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.SOUND_BOARD_BPOD_PORT = \"Serial4\"", "prediction_line": "            self.SOUND_BOARD_BPOD_PORT = \"Serial4\"", "ground_truth": "            sound.configure_sound_card(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "class SessionParamHandler(object):", "prediction_line": "class SessionParamHandler(object):", "ground_truth": "class SessionParamHandler(object):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # SOUND", "prediction_line": "        # SOUND", "ground_truth": "        # SOUNDS", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "        # =====================================================================", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # =========================================================================", "prediction_line": "    # =========================================================================", "ground_truth": "    # =========================================================================", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def reprJSON(self):", "prediction_line": "    def reprJSON(self):", "ground_truth": "    def reprJSON(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        :param command: 0: all lights off, 1: green on, 2: red on, 3: green and red on", "prediction_line": "        \"\"\"", "ground_truth": "        fpath = Path(self.IBLRIG_FOLDER) / \"scripts\" / \"bpod_lights.py\"", "line_class": "random", "zero_context": true}
{"original_prediction": "PREVIOUS WEIGHT:               {self.LAST_TRIAL_DATA['subject_weight']}", "prediction_line": "PREVIOUS WEIGHT:               {self.LAST_TRIAL_DATA['subject_weight']}", "ground_truth": "LAST REWARD:                   {self.LAST_TRIAL_DATA[\"reward_amount\"]}", "line_class": "random", "zero_context": true}
{"original_prediction": "        else:\n            make = True  # True makes raw_behavior_data and processed_data folders", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "        if self.DEBUG:", "prediction_line": "        if self.DEBUG:", "ground_truth": "        if self.PREVIOUS_DATA_FILE:", "line_class": "random", "zero_context": true}
{"original_prediction": "    dt = \"_\".join(dt)", "prediction_line": "    dt = \"_\".join(dt)", "ground_truth": "    dt = [x if int(x) >= 10 else \"0\" + x for x in dt]", "line_class": "random", "zero_context": true}
{"original_prediction": "    fig1 = m.plot_parameters(plotting_backend=\"plotly\")", "prediction_line": "    fig1 = m.plot_parameters(plotting_backend=\"plotly\")", "ground_truth": "    fig1 = m.plot_components(forecast, plotting_backend=\"plotly\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    fig2 = m.plot(forecast, plotting_backend=\"plotly\")", "prediction_line": "    fig2 = m.plot(forecast, plotting_backend=\"plotly\")", "ground_truth": "    fig2 = m.plot(forecast, plotting_backend=\"plotly\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    fig3 = m.plot_parameters(plotting_backend=\"plotly\")", "prediction_line": "    fig3 = m.plot_parameters(plotting_backend=\"plotly\")", "ground_truth": "    fig3 = m.plot_parameters(plotting_backend=\"plotly\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    fig4 = m.plot(forecast, plotting_backend=\"plotly\")", "prediction_line": "    fig4 = m.plot(forecast, plotting_backend=\"plotly\")", "ground_truth": "    fig4 = m.plot_components(forecast, forecast_in_focus=2, plotting_backend=\"plotly\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    fig5 = m.plot(forecast, forecast_in_focus=2, plotting_backend=\"plotly\")", "prediction_line": "    fig5 = m.plot(forecast, forecast_in_focus=2, plotting_backend=\"plotly\")", "ground_truth": "    fig5 = m.plot_components(forecast, forecast_in_focus=2, residuals=True, plotting_backend=\"plotly\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    fig1 = m.plot_components(forecast, plotting_backend=\"plotly\")", "prediction_line": "    fig1 = m.plot_components(forecast, plotting_backend=\"plotly\")", "ground_truth": "    fig1 = m.plot(forecast, plotting_backend=\"plotly\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    fig1 = m.plot_parameters(forecast, plotting_backend=\"plotly\")", "prediction_line": "    fig1 = m.plot_parameters(forecast, plotting_backend=\"plotly\")", "ground_truth": "    fig1 = m.plot_parameters(plotting_backend=\"plotly\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    fig3 = m.plot_components(forecast, plotting_backend=\"plotly\")", "prediction_line": "    fig3 = m.plot_components(forecast, plotting_backend=\"plotly\")", "ground_truth": "    fig3 = m.plot_components(forecast, plotting_backend=\"plotly\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    fig2 = m.plot_components(forecast, plotting_backend=\"plotly\")", "prediction_line": "    fig2 = m.plot_components(forecast, plotting_backend=\"plotly\")", "ground_truth": "    fig2 = m.plot_components(forecast, plotting_backend=\"plotly\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    fig2 = m.plot_parameters(plotting_backend=\"plotly\")", "prediction_line": "    fig2 = m.plot_parameters(plotting_backend=\"plotly\")", "ground_truth": "    fig2 = m.plot_parameters(plotting_backend=\"plotly\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    fig4 = m.plot_components(forecast, plotting_backend=\"plotly\")", "prediction_line": "    fig4 = m.plot_components(forecast, plotting_backend=\"plotly\")", "ground_truth": "    fig4 = m.plot_parameters(plotting_backend=\"plotly\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    m.highlight_nth_step_ahead_of_each_forecast(7)", "prediction_line": "    m.highlight_nth_step_ahead_of_each_forecast(7)", "ground_truth": "    m.highlight_nth_step_ahead_of_each_forecast(7)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if other_seasons:", "prediction_line": "    if other_seasons:", "ground_truth": "    m = NeuralProphet(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    future = m.make_future_dataframe(df, n_historic_predictions=10)", "prediction_line": "    future = m.make_future_dataframe(df, n_historic_predictions=10)", "ground_truth": "    future = m.make_future_dataframe(df=history_df, events_df=events_df, periods=30, n_historic_predictions=90)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    m = m.add_country_holidays(country_code=\"US\")", "prediction_line": "    m = m.add_country_holidays(country_code=\"US\")", "ground_truth": "    m = m.add_country_holidays(\"US\", mode=\"additive\", regularization=0.5)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    m.add_country_holidays(\"China\")", "prediction_line": "    m.add_country_holidays(\"China\")", "ground_truth": "    m.add_country_holidays(\"Thailand\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    metrics_df = m.fit(df, freq=\"MS\")", "prediction_line": "    metrics_df = m.fit(df, freq=\"MS\")", "ground_truth": "    metrics = m.fit(df, freq=\"MS\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    metrics_df = m.fit(df, freq=\"D\")", "prediction_line": "    metrics_df = m.fit(df, freq=\"D\")", "ground_truth": "    metrics_df = m.fit(df, freq=\"D\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    metrics_df = m.fit(history_df, freq=\"D\")", "prediction_line": "    metrics_df = m.fit(history_df, freq=\"D\")", "ground_truth": "    metrics_df = m.fit(history_df, freq=\"D\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    future = m.make_future_dataframe(df, n_historic_predictions=10)", "prediction_line": "    future = m.make_future_dataframe(df, n_historic_predictions=10)", "ground_truth": "    future = m.make_future_dataframe(df, n_historic_predictions=10)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   metrics_df = m.fit(df, freq=\"D\")", "prediction_line": "   metrics_df = m.fit(df, freq=\"D\")", "ground_truth": "    metrics = m.fit(df, freq=\"5min\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    metrics_df = m.fit(df, freq=\"D\")", "prediction_line": "    metrics_df = m.fit(df, freq=\"D\")", "ground_truth": "    m = m.add_seasonality(name=\"quarterly\", period=90, fourier_order=5)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "to be 10 days", "prediction_line": "to be 10 days", "ground_truth": "    m = m.add_events(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    forecast = m.predict(future)", "prediction_line": "    forecast = m.predict(future)", "ground_truth": "    forecast = m.predict(df=future)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    future = m.make_future_dataframe(df, n_historic_predictions=10)", "prediction_line": "    future = m.make_future_dataframe(df, n_historic_predictions=10)", "ground_truth": "    future = m.make_future_dataframe(df=df, regressors_df=regressors_df_future, n_historic_predictions=10, periods=50)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    future = m.make_future_dataframe(df, n_historic_predictions=365, periods=365)", "prediction_line": "    future = m.make_future_dataframe(df, n_historic_predictions=365, periods=365)", "ground_truth": "    future = m.make_future_dataframe(df, n_historic_predictions=365, periods=365)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    )\n    metrics_df = m.fit(df, events_df=events_df, freq=\"D\")", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_forecast_horizon():", "prediction_line": "def test_forecast_horizon():", "ground_truth": "def test_plotly():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    df[\"B\"] = df[\"y\"].rolling(30, min_periods=1).mean()", "prediction_line": "    df[\"B\"] = df[\"y\"].rolling(30, min_periods=1).mean()", "ground_truth": "    df[\"B\"] = df[\"y\"].rolling(30, min_periods=1).mean()", "line_class": "random", "zero_context": true}
{"original_prediction": "        fig1.show()", "prediction_line": "        fig1.show()", "ground_truth": "        fig1.show()", "line_class": "random", "zero_context": true}
{"original_prediction": "        n_lags=0,", "prediction_line": "        n_lags=0,", "ground_truth": "        yearly_seasonality=2,", "line_class": "random", "zero_context": true}
{"original_prediction": "        batch_size=BATCH_SIZE,", "prediction_line": "        batch_size=BATCH_SIZE,", "ground_truth": "        batch_size=BATCH_SIZE,", "line_class": "random", "zero_context": true}
{"original_prediction": "        n_forecasts=7,", "prediction_line": "        n_forecasts=7,", "ground_truth": "        n_lags=2,", "line_class": "random", "zero_context": true}
{"original_prediction": "    padded_range = get_dynamic_axis_range(list(fcst[\"ds\"]), type=\"dt\")", "prediction_line": "    padded_range = get_dynamic_axis_range(list(fcst[\"ds\"]), type=\"dt\")", "ground_truth": "    padded_range = get_dynamic_axis_range(list(fcst[\"ds\"]), type=\"dt\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    padded_range = get_dynamic_axis_range(list(df_y[\"ds\"]), type=\"dt\")", "prediction_line": "    padded_range = get_dynamic_axis_range(list(df_y[\"ds\"]), type=\"dt\")", "ground_truth": "    padded_range = get_dynamic_axis_range(list(df_y[\"ds\"]), type=\"dt\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "   if quick:\n        seasonality = m.model.get_seasonality(", "prediction_line": "   if quick:", "ground_truth": "    end = start + pd.Timedelta(days=period)", "line_class": "common", "zero_context": true}
{"original_prediction": "        yaxis.update(tickformat=\".1%\", hoverformat=\".4%\")", "prediction_line": "        yaxis.update(tickformat=\".1%\", hoverformat=\".4%\")", "ground_truth": "        yaxis.update(tickformat=\".1%\", hoverformat=\".4%\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        if trace_object is not None:", "prediction_line": "        if trace_object is not None:", "ground_truth": "        xaxis.update(trace_object[\"xaxis\"])", "line_class": "common", "zero_context": true}
{"original_prediction": "        yaxis.update(trace_object[\"yaxis\"])", "prediction_line": "        yaxis.update(trace_object[\"yaxis\"])", "ground_truth": "        xaxis.update(**xaxis_args)", "line_class": "common", "zero_context": true}
{"original_prediction": "        yaxis.update(trace_object[\"yaxis\"])", "prediction_line": "        yaxis.update(trace_object[\"yaxis\"])", "ground_truth": "        yaxis.update(trace_object[\"yaxis\"])", "line_class": "common", "zero_context": true}
{"original_prediction": "        yaxis.update(**yaxis_args)", "prediction_line": "        yaxis.update(**yaxis_args)", "ground_truth": "        yaxis.update(**yaxis_args)", "line_class": "common", "zero_context": true}
{"original_prediction": "    if quick:", "prediction_line": "    if quick:", "ground_truth": "    days = pd.to_datetime(np.linspace(start.value, end.value, plot_points, endpoint=False))", "line_class": "common", "zero_context": true}
{"original_prediction": "                multiplicative_axes.append(i)", "prediction_line": "                multiplicative_axes.append(i)", "ground_truth": "                comp.update({\"multiplicative\": True})", "line_class": "common", "zero_context": true}
{"original_prediction": "    # This is the period that is plotted.", "prediction_line": "    # This is the period that is plotted.", "ground_truth": "    start = pd.to_datetime(\"2017-01-01 0000\")", "line_class": "common", "zero_context": true}
{"original_prediction": "            trace_object = get_event_component_props(fcst=fcst, **comp)", "prediction_line": "            trace_object = get_event_component_props(fcst=fcst, **comp)", "ground_truth": "            trace_object = get_forecast_component_props(fcst=fcst, **comp)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                comp[\"comp_name\"] = f\"{comp_name}_1\"", "prediction_line": "                comp[\"comp_name\"] = f\"{comp_name}_1\"", "ground_truth": "                trace_object = get_seasonality_props(m, fcst, **comp)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                trace_object = get_seasonality_props(m, fcst, **comp)", "prediction_line": "                trace_object = get_seasonality_props(m, fcst, **comp)", "ground_truth": "                trace_object = get_forecast_component_props(fcst=fcst, comp_name=comp_name, plot_name=comp[\"plot_name\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            trace_object = get_forecast_component_props(fcst=fcst, **comp)", "prediction_line": "            trace_object = get_forecast_component_props(fcst=fcst, **comp)", "ground_truth": "            trace_object = get_multiforecast_component_props(fcst=fcst, **comp)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        components.append(", "prediction_line": "        components.append(", "ground_truth": "        components.append(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        df_y = m.model.predict_seasonal_quick(df_y, comp_name)", "prediction_line": "        df_y = m.model.predict_seasonal_quick(df_y, comp_name)", "ground_truth": "        predicted = m.predict_season_from_dates(m, dates=df_y[\"ds\"], name=comp_name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        predicted = m.predict_season(m, df_y, name=comp_name)", "prediction_line": "        predicted = m.predict_season(m, df_y, name=comp_name)", "ground_truth": "        predicted = m.predict_seasonal_components(df_y)[comp_name]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if multiplicative:", "prediction_line": "    if multiplicative:", "ground_truth": "    traces.append(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if m.n_changepoints > 0:", "prediction_line": "    if m.n_changepoints > 0:", "ground_truth": "    components.append({\"plot_name\": \"Trend\", \"comp_name\": \"trend\"})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            yhat = fcst[yhat_col_name]", "prediction_line": "            yhat = fcst[yhat_col_name]", "ground_truth": "            data.append(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ax.update(tickformat=\"%\")", "prediction_line": "        ax.update(tickformat=\"%\")", "ground_truth": "        ax = set_y_as_percent(ax)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Flag whether to add the x-axis to the plot", "prediction_line": "            Flag whether to add the x-axis to the plot", "ground_truth": "            Flag whether to add x-symbols to the plotted points", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        bar : bool", "prediction_line": "        bar : bool", "ground_truth": "        bar : bool", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        multiplicative : bool", "prediction_line": "        multiplicative : bool", "ground_truth": "        multiplicative : bool", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            Name of the component to plot", "prediction_line": "            Name of the component to plot", "ground_truth": "            Name of the component to plot", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            Output of m.predict", "prediction_line": "            Output of m.predict", "ground_truth": "            Output of m.predict", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            )\n        else:", "prediction_line": "            )", "ground_truth": "            )", "line_class": "random", "zero_context": true}
{"original_prediction": "                        dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),", "prediction_line": "                        dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),", "ground_truth": "                        dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"comp_name\": \"events_multiplicative\",", "prediction_line": "                \"comp_name\": \"events_multiplicative\",", "ground_truth": "                \"comp_name\": \"events_multiplicative\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    yaxis = go.layout.YAxis(title=plot_name, range=get_dynamic_axis_range(y, type=\"y\"))", "prediction_line": "    yaxis = go.layout.YAxis(title=plot_name, range=get_dynamic_axis_range(y, type=\"y\"))", "ground_truth": "    yaxis = go.layout.YAxis(", "line_class": "random", "zero_context": true}
{"original_prediction": "            for i, yhat_col_name in enumerate(yhat_col_names):", "prediction_line": "            for i, yhat_col_name in enumerate(yhat_col_names):", "ground_truth": "            num_forecast_steps = sum(fcst[\"yhat1\"].notna())", "line_class": "random", "zero_context": true}
{"original_prediction": "        m.plot_components(forecast)", "prediction_line": "        m.plot_components(forecast)", "ground_truth": "        m.plot_components(forecast)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        m = m.add_lagged_regressor(name=\"B\", lag=30)", "prediction_line": "        m = m.add_lagged_regressor(name=\"B\", lag=30)", "ground_truth": "        m = m.add_lagged_regressor(name=\"B\", only_last_value=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    m.fit(df, freq=\"D\")", "prediction_line": "    m.fit(df, freq=\"D\")", "ground_truth": "    metrics_df = m.fit(df, freq=\"D\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    forecast = m.predict(future_df)", "prediction_line": "    forecast = m.predict(future_df)", "ground_truth": "    forecast = m.predict(df=future_df)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with pytest.raises(Exception):", "prediction_line": "    with pytest.raises(Exception):", "ground_truth": "    forecast = m.predict(df_global)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    metrics_df = m.fit(df_global, freq=\"D\")", "prediction_line": "    metrics_df = m.fit(df_global, freq=\"D\")", "ground_truth": "    metrics_df = m.fit(df_global, freq=\"D\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    future = m.make_future_dataframe(df_global, periods=m.n_forecasts, n_historic_predictions=10)", "prediction_line": "    future = m.make_future_dataframe(df_global, periods=m.n_forecasts, n_historic_predictions=10)", "ground_truth": "    future = m.make_future_dataframe(df_global, periods=m.n_forecasts, n_historic_predictions=10)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    m = m.add_future_regressor(name=\"D\", only_last_value=True, regularization=0.1)", "prediction_line": "    m = m.add_future_regressor(name=\"D\", only_last_value=True, regularization=0.1)", "ground_truth": "    m = m.add_future_regressor(name=\"D\", regularization=0.1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    metrics = m.fit(df, freq=\"MS\")", "prediction_line": "    metrics = m.fit(df, freq=\"MS\")", "ground_truth": "    metrics = m.fit(df, freq=\"MS\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   metrics_df = m.fit(history_df, freq=\"D\")", "prediction_line": "   metrics_df = m.fit(history_df, freq=\"D\")", "ground_truth": "    m.fit(history_df, freq=\"D\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   m = m.add_lagged_regressor(name=\"C\")", "prediction_line": "   m = m.add_lagged_regressor(name=\"C\")", "ground_truth": "    m = m.add_future_regressor(name=\"C\", regularization=0.1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    metrics_df = m.fit(df, freq=\"D\")", "prediction_line": "    metrics_df = m.fit(df, freq=\"D\")", "ground_truth": "    history_df = m.create_df_with_events(df, events_df)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # add seasonality", "prediction_line": "    # add seasonality", "ground_truth": "    m = m.add_country_holidays(\"US\", mode=\"additive\", regularization=0.1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        m.plot(forecast)", "prediction_line": "        m.plot(forecast)", "ground_truth": "        m.plot(forecast)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    future = m.make_future_dataframe(df, periods=m.n_forecasts, n_historic_predictions=10)", "prediction_line": "    future = m.make_future_dataframe(df, periods=m.n_forecasts, n_historic_predictions=10)", "ground_truth": "    future = m.make_future_dataframe(df, periods=6, n_historic_predictions=3 * 24 * 12)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    m = NeuralProphet()", "prediction_line": "    m = NeuralProphet()", "ground_truth": "    # Without auto-regression enabled", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    m.plot_components(forecast)", "prediction_line": "    m.plot_components(forecast)", "ground_truth": "    # m.plot_last_forecast(forecast, include_previous_forecasts=10)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    \"2011-01-23\",", "prediction_line": "                    \"2011-01-23\",", "ground_truth": "                    \"2013-01-12\",", "line_class": "random", "zero_context": true}
{"original_prediction": "[\"2005-01-01\", \"2006-01-01\", \"2007-01-01\", \"2008-01-01\", \"2009-01-01\"]),", "prediction_line": "[\"2005-01-01\", \"2006-01-01\", \"2007-01-01\", \"2008-01-01\", \"2009-01-01\"]),", "ground_truth": "                [", "line_class": "random", "zero_context": true}
{"original_prediction": "    m.add_lagged_regressor(\"L1\", 1)", "prediction_line": "    m.add_lagged_regressor(\"L1\", 1)", "ground_truth": "    if m.n_lags > 0:", "line_class": "random", "zero_context": true}
{"original_prediction": "        uncertainty_samples=10,", "prediction_line": "        uncertainty_samples=10,", "ground_truth": "        epochs=EPOCHS,", "line_class": "random", "zero_context": true}
{"original_prediction": "        n_lags=12,", "prediction_line": "        n_lags=12,", "ground_truth": "        loss_func=\"MSE\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    results_train, results_test = benchmark.run()", "prediction_line": "    results_train, results_test = benchmark.run()", "ground_truth": "    results_train, results_test = benchmark.run()", "line_class": "common", "zero_context": true}
{"original_prediction": "    results_train, results_test = exp.run()", "prediction_line": "    results_train, results_test = exp.run()", "ground_truth": "    result_train, result_val = exp.run()", "line_class": "common", "zero_context": true}
{"original_prediction": "    results_summary, results_train, results_test = benchmark_cv.run()", "prediction_line": "    results_summary, results_train, results_test = benchmark_cv.run()", "ground_truth": "    results_summary, results_train, results_test = benchmark_cv.run()", "line_class": "common", "zero_context": true}
{"original_prediction": "    result_summary, result_train, result_test = exp_cv.run()", "prediction_line": "    result_summary, result_train, result_test = exp_cv.run()", "ground_truth": "    result_train, result_val = exp_cv.run()", "line_class": "common", "zero_context": true}
{"original_prediction": "    exp = CrossValidationExperiment(", "prediction_line": "    exp = CrossValidationExperiment(", "ground_truth": "    exp_cv = CrossValidationExperiment(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        experiments.append(", "prediction_line": "        experiments.append(", "ground_truth": "        experiments.append(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    experiment = SimpleExperiment(", "prediction_line": "    experiment = SimpleExperiment(", "ground_truth": "    exp = SimpleExperiment(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    benchmark = ManualBenchmark(experiments=experiments)", "prediction_line": "    benchmark = ManualBenchmark(experiments=experiments)", "ground_truth": "    benchmark = ManualBenchmark(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                model_class=ProphetModel,", "prediction_line": "                model_class=ProphetModel,", "ground_truth": "                model_class=ProphetModel,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (NeuralProphetModel, {\"n_lags\": 10, \"n_forecasts\": 10}),", "prediction_line": "        (NeuralProphetModel, {\"n_lags\": 10, \"n_forecasts\": 10}),", "ground_truth": "        (NeuralProphetModel, {\"n_lags\": 5, \"n_forecasts\": 3, \"epochs\": EPOCHS}),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Dataset(df=peyton_manning_df, name=\"peyton_manning\", freq=\"D\"),", "prediction_line": "        Dataset(df=peyton_manning_df, name=\"peyton_manning\", freq=\"D\"),", "ground_truth": "        Dataset(df=peyton_manning_df, name=\"peyton_manning\", freq=\"D\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    benchmark = ManualCVBenchmark(", "prediction_line": "    benchmark = ManualCVBenchmark(", "ground_truth": "    benchmark_cv = ManualCVBenchmark(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        SimpleExperiment(", "prediction_line": "        SimpleExperiment(", "ground_truth": "        SimpleExperiment(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            model_class=NeuralProphetModel,", "prediction_line": "            model_class=NeuralProphetModel,", "ground_truth": "            model_class=NeuralProphetModel,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            data=Dataset(df=air_passengers_df, name=\"air_passengers\", freq=\"MS\"),", "prediction_line": "            data=Dataset(df=air_passengers_df, name=\"air_passengers\", freq=\"MS\"),", "ground_truth": "            data=Dataset(df=air_passengers_df, name=\"air_passengers\", freq=\"MS\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   log.info(\"SimpleBenchmark\")", "prediction_line": "   log.info(\"SimpleBenchmark\")", "ground_truth": "    benchmark = SimpleBenchmark(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            data=Dataset(df=peyton_manning_df, name=\"peyton_manning\", freq=\"D\"),", "prediction_line": "            data=Dataset(df=peyton_manning_df, name=\"peyton_manning\", freq=\"D\"),", "ground_truth": "            data=Dataset(df=peyton_manning_df, name=\"peyton_manning\", freq=\"D\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (NeuralProphetModel, {\"epochs\": EPOCHS, \"seasonality_mode\": \"multiplicative\", \"learning_rate\": 0.1}),", "prediction_line": "        (NeuralProphetModel, {\"epochs\": EPOCHS, \"seasonality_mode\": \"multiplicative\", \"learning_rate\": 0.1}),", "ground_truth": "        (NeuralProphetModel, {\"epochs\": EPOCHS, \"learning_rate\": 0.1}),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (NeuralProphetModel, {\"epochs\": EPOCHS, \"seasonality_mode\": \"multiplicative\", \"learning_rate\": 0.1}),", "prediction_line": "        (NeuralProphetModel, {\"epochs\": EPOCHS, \"seasonality_mode\": \"multiplicative\", \"learning_rate\": 0.1}),", "ground_truth": "        (NeuralProphetModel, {\"epochs\": EPOCHS, \"learning_rate\": 0.1, \"seasonality_mode\": \"multiplicative\"}),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_2_benchmark_manual_CV():", "prediction_line": "def test_2_benchmark_manual_CV():", "ground_truth": "def test_2_benchmark_manualCV():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import numpy as np", "prediction_line": "import numpy as np", "ground_truth": "import logging", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    ]\n    error_functions = [", "prediction_line": "    ]", "ground_truth": "    ]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # peyton_manning = results_summary[results_summary['data'] == 'peyton_manning']", "prediction_line": "        # peyton_manning = results_summary[results_summary['data'] == 'peyton_manning']", "ground_truth": "        # air_passengers = air_passengers[air_passengers['split'] == 'test']", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "#!/usr/bin/env python3", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    log.debug(\"{}\".format(results_test))", "prediction_line": "    log.debug(\"{}\".format(results_test))", "ground_truth": "    log.debug(\"{}\".format(results_test))", "line_class": "random", "zero_context": true}
{"original_prediction": "    log.info(\"test_cv_experiment\")", "prediction_line": "    log.info(\"test_cv_experiment\")", "ground_truth": "    log.info(\"test_cv_experiment\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        test_percentage=10,", "prediction_line": "        test_percentage=10,", "ground_truth": "        test_percentage=10,", "line_class": "random", "zero_context": true}
{"original_prediction": "    model_classes_and_params = [", "prediction_line": "    model_classes_and_params = [", "ground_truth": "    experiments = [", "line_class": "random", "zero_context": true}
{"original_prediction": "    air_passengers_df = pd.read_csv(AIR_FILE, nrows=NROWS)", "prediction_line": "    air_passengers_df = pd.read_csv(AIR_FILE, nrows=NROWS)", "ground_truth": "    air_passengers_df = pd.read_csv(AIR_FILE, nrows=NROWS)", "line_class": "random", "zero_context": true}
{"original_prediction": "            if m.config_normalization.unknown_data_params:", "prediction_line": "            if m.config_normalization.unknown_data_params:", "ground_truth": "            if df_name is None and m.id_list.__len__() == 1:", "line_class": "common", "zero_context": true}
{"original_prediction": "            else:\n                df_name = m.id_list[0]", "prediction_line": "            else:", "ground_truth": "            elif df_name is None and m.id_list.__len__() > 1:", "line_class": "common", "zero_context": true}
{"original_prediction": "    quantile_index = m.model.quantiles.index(quantile)", "prediction_line": "    quantile_index = m.model.quantiles.index(quantile)", "ground_truth": "    quantile_index = m.model.quantiles.index(quantile)", "line_class": "common", "zero_context": true}
{"original_prediction": "                df_name = \"__df__\"", "prediction_line": "                df_name = \"__df__\"", "ground_truth": "                if m.id_list.__len__() > 1:", "line_class": "common", "zero_context": true}
{"original_prediction": "    else:\n        components = check_if_configured(m, components)", "prediction_line": "    else:", "ground_truth": "        components = check_if_configured(m=m, components=components)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    valid_configuration = OrderedDict()", "prediction_line": "    valid_configuration = OrderedDict()", "ground_truth": "        components = check_if_configured(m=m, components=components, error_flag=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    t_i = np.arange(dates.shape[0])", "prediction_line": "    t_i = np.arange(dates.shape[0])", "ground_truth": "    features = time_dataset.fourier_series(dates=dates, period=config.period, series_order=config.resolution)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"plot_components\": plot_components,", "prediction_line": "            \"plot_components\": plot_components,", "ground_truth": "            \"components_list\": plot_components,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if m.config_trend.changepoints is None:", "prediction_line": "        if m.config_trend.changepoints is None:", "ground_truth": "        plot_components.append({\"plot_name\": \"Trend\", \"comp_name\": \"trend\"})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            \"weights\": m.model.get_covar_weights(name).detach().numpy(),", "prediction_line": "                            \"weights\": m.model.get_covar_weights(name).detach().numpy(),", "ground_truth": "                            \"weights\": m.model.get_covar_weights(name).detach().numpy(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    lagged_scalar_regressors.append(name)", "prediction_line": "                    lagged_scalar_regressors.append(name)", "ground_truth": "                    lagged_scalar_regressors.append((name, m.model.get_covar_weights(name).detach().numpy()))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                plot_components.append(", "prediction_line": "                plot_components.append(", "ground_truth": "                plot_components.append({\"plot_name\": \"seasonality\", \"comp_name\": name})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    valid_configuration = OrderedDict()", "prediction_line": "    valid_configuration = OrderedDict()", "ground_truth": "    plot_components = []", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        invalid_components.append(\"trend_rate_change\")", "prediction_line": "        invalid_components.append(\"trend_rate_change\")", "ground_truth": "        invalid_components.append(\"trend_rate_change\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        invalid_components.append(\"lagged_regressors\")", "prediction_line": "        invalid_components.append(\"lagged_regressors\")", "ground_truth": "        invalid_components.append(\"lagged_regressors\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            plot_components.append(", "prediction_line": "            plot_components.append(", "ground_truth": "            plot_components.append({\"plot_name\": \"Additive future regressor\"})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        invalid_components.append(\"future_regressors\")", "prediction_line": "        invalid_components.append(\"future_regressors\")", "ground_truth": "        invalid_components.append(\"future_regressors\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                event_params = m.model.get_event_weights(country_holiday)", "prediction_line": "                event_params = m.model.get_event_weights(country_holiday)", "ground_truth": "                event_params = m.model.get_event_weights(country_holiday)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            plot_components.append({\"plot_name\": \"Multiplicative future regressor\"})", "prediction_line": "            plot_components.append({\"plot_name\": \"Multiplicative future regressor\"})", "ground_truth": "            plot_components.append({\"plot_name\": \"Multiplicative future regressor\"})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        plot_components.append({\"plot_name\": \"Trend Rate Change\", \"comp_name\": \"trend_rate_change\"})", "prediction_line": "        plot_components.append({\"plot_name\": \"Trend Rate Change\", \"comp_name\": \"trend_rate_change\"})", "ground_truth": "        plot_components.append({\"plot_name\": \"Trend Rate Change\"})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    \"quantile_index\": quantile_index,", "prediction_line": "                    \"quantile_index\": quantile_index,", "ground_truth": "                    \"weights\": m.model.ar_weights.detach().numpy(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        m : NeuralProphet", "prediction_line": "        m : NeuralProphet", "ground_truth": "        m : NeuralProphet", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    if config.mode == \"multiplicative\":", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "         n_steps: int", "prediction_line": "         n_steps: int", "ground_truth": "         n_steps: int", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "             Name of the season", "prediction_line": "             Name of the season", "ground_truth": "             Name of seasonality component", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       error_flag : bool, optional", "prediction_line": "       error_flag : bool, optional", "ground_truth": "            Options", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    return predicted", "prediction_line": "    return predicted", "ground_truth": "    predicted = {name: predicted}", "line_class": "random", "zero_context": true}
{"original_prediction": "                        \"comp_name\": \"autoregression\",", "prediction_line": "                        \"comp_name\": \"autoregression\",", "ground_truth": "                        \"comp_name\": \"ar\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                    {\n                        \"plot_name\": f'Future Regressor \"{regressor}\"',", "prediction_line": "                    {", "ground_truth": "                    {", "line_class": "random", "zero_context": true}
{"original_prediction": "            elif validator == \"plot_parameters\":", "prediction_line": "            elif validator == \"plot_parameters\":", "ground_truth": "            elif validator == \"plot_parameters\":", "line_class": "random", "zero_context": true}
{"original_prediction": "    features = torch.from_numpy(np.expand_dims(features, 1))", "prediction_line": "    features = torch.from_numpy(np.expand_dims(features, 1))", "ground_truth": "    features = torch.from_numpy(np.expand_dims(features, 1))", "line_class": "random", "zero_context": true}
{"original_prediction": "        super(BaseArch, self).__init__()", "prediction_line": "        super(BaseArch, self).__init__()", "ground_truth": "        super(BaseArch, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(TopDownHRNet, self).__init__()", "prediction_line": "        super(TopDownHRNet, self).__init__()", "ground_truth": "        super(TopDownHRNet, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "                dr[border:-border, border:-border] = heatmap[i, j].copy()", "prediction_line": "                dr[border:-border, border:-border] = heatmap[i, j].copy()", "ground_truth": "                dr[border:-border, border:-border] = heatmap[i, j].copy()", "line_class": "commited", "zero_context": true}
{"original_prediction": "                dr = dr[border:-border, border:-border].copy()", "prediction_line": "                dr = dr[border:-border, border:-border].copy()", "ground_truth": "                heatmap[i, j] = dr[border:-border, border:-border].copy()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        hm = np.log(hm)", "prediction_line": "        hm = np.log(hm)", "ground_truth": "        hm = np.log(hm)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            tmp = output_flipped[:, pair[0], :, :].copy()", "prediction_line": "            tmp = output_flipped[:, pair[0], :, :].copy()", "ground_truth": "            tmp = output_flipped[:, pair[0], :, :].copy()", "line_class": "commited", "zero_context": true}
{"original_prediction": "def ConvTranspose2d(in_channels,", "prediction_line": "def ConvTranspose2d(in_channels,", "ground_truth": "@register", "line_class": "commited", "zero_context": true}
{"original_prediction": "        preds = coords.copy()", "prediction_line": "        preds = coords.copy()", "ground_truth": "        preds = coords.copy()", "line_class": "commited", "zero_context": true}
{"original_prediction": "                output_flipped = paddle.to_tensor(output_flipped)", "prediction_line": "                output_flipped = paddle.to_tensor(output_flipped)", "ground_truth": "                output_flipped = paddle.to_tensor(output_flipped.copy())", "line_class": "commited", "zero_context": true}
{"original_prediction": "        backbone = create(cfg['backbone'])", "prediction_line": "        backbone = create(cfg['backbone'])", "ground_truth": "        backbone = create(cfg['backbone'])", "line_class": "commited", "zero_context": true}
{"original_prediction": "            preds[i] = transform_preds(coords[i], center[i], scale[i],", "prediction_line": "            preds[i] = transform_preds(coords[i], center[i], scale[i],", "ground_truth": "            preds[i] = transform_preds(coords[i], center[i], scale[i],", "line_class": "commited", "zero_context": true}
{"original_prediction": "                self.scale = item['NormalizeImage']['scale']", "prediction_line": "                self.scale = item['NormalizeImage']['scale']", "ground_truth": "                if item['NormalizeImage'].get('is_scale', True):", "line_class": "common", "zero_context": true}
{"original_prediction": "            self.model_loss()", "prediction_line": "            self.model_loss()", "ground_truth": "            out = self.get_loss()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            out = self.get_pred()", "prediction_line": "            out = self.get_pred()", "ground_truth": "            out = self.get_pred()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self._forward()['loss']", "prediction_line": "        return self._forward()['loss']", "ground_truth": "        return self._forward()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self._forward()", "prediction_line": "        return self._forward()", "ground_truth": "        res_lst = self._forward()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            coords = self.dark_postprocess(heatmaps, coords, kernelsize)", "prediction_line": "            coords = self.dark_postprocess(heatmaps, coords, kernelsize)", "ground_truth": "            coords = self.dark_postprocess(heatmaps, coords, kernelsize)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       heatmap_height = hm.shape[0]", "prediction_line": "       heatmap_height = hm.shape[0]", "ground_truth": "        hm = self.gaussian_blur(hm, kernelsize)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.loss = loss", "prediction_line": "        self.loss = loss", "ground_truth": "        self.post_process = HRNetPostProcess(use_dark)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                coords[n][p] = self.dark_parse(hm[n][p], coords[n][p])", "prediction_line": "                coords[n][p] = self.dark_parse(hm[n][p], coords[n][p])", "ground_truth": "                coords[n, p] = self.dark_parse(hm[n][p], coords[n][p])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.shift_heatmap = shift_heatmap", "prediction_line": "        self.shift_heatmap = shift_heatmap", "ground_truth": "        self.final_conv = Conv2d(width, num_joints, 1, 1, 0, bias=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                output_flipped = flip_back(output_flipped.numpy(),", "prediction_line": "                output_flipped = flip_back(output_flipped.numpy(),", "ground_truth": "                output_flipped = self.flip_back(output_flipped.numpy(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "       return self.get_outputs()", "prediction_line": "       return self.get_outputs()", "ground_truth": "        self.model_arch()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert isinstance(heatmaps,", "prediction_line": "        assert isinstance(heatmaps,", "ground_truth": "        coords, maxvals = self.get_max_preds(heatmaps)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.mean = np.array(cfg_transform.mean, dtype=np.float32)", "prediction_line": "        self.mean = np.array(cfg_transform.mean, dtype=np.float32)", "ground_truth": "        self.scale = 1.", "line_class": "inproject", "zero_context": true}
{"original_prediction": "0 / 255.0", "prediction_line": "0 / 255.0", "ground_truth": "        self.mean = paddle.to_tensor([0.485, 0.456, 0.406]).reshape(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                origin_heatmap = heatmap[i, j, :, :]", "prediction_line": "                origin_heatmap = heatmap[i, j, :, :]", "ground_truth": "                origin_max = np.max(heatmap[i, j])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.std = paddle.to_tensor([0.229, 0.224, 0.225]).reshape(", "prediction_line": "        self.std = paddle.to_tensor([0.229, 0.224, 0.225]).reshape(", "ground_truth": "        self.std = paddle.to_tensor([0.229, 0.224, 0.225]).reshape(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                dr = cv2.GaussianBlur(dr, (kernel, kernel), 0)", "prediction_line": "                dr = cv2.GaussianBlur(dr, (kernel, kernel), 0)", "ground_truth": "                dr = cv2.GaussianBlur(dr, (kernel, kernel), 0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.scale = item['scale']", "prediction_line": "                self.scale = item['scale']", "ground_truth": "                self.mean = paddle.to_tensor(item['NormalizeImage'][", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                heatmap[i, j] *= origin_max / np.max(heatmap[i, j])", "prediction_line": "                heatmap[i, j] *= origin_max / np.max(heatmap[i, j])", "ground_truth": "                heatmap[i, j] *= origin_max / np.max(heatmap[i, j])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.std = paddle.to_tensor(item['NormalizeImage'][", "prediction_line": "                self.std = paddle.to_tensor(item['NormalizeImage'][", "ground_truth": "                self.std = paddle.to_tensor(item['NormalizeImage'][", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    self.scale = 255.", "prediction_line": "                    self.scale = 255.", "ground_truth": "                    self.scale = 1. / 255.", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            scale = self.inputs['scale'].numpy(", "prediction_line": "            scale = self.inputs['scale'].numpy(", "ground_truth": "            scale = self.inputs['scale'].numpy(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            image = image / 255.", "prediction_line": "            image = image / 255.", "ground_truth": "            self.inputs['image'] = (image * self.scale - self.mean) / self.std", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        coords, maxvals = self.get_final_preds(output, center, scale)", "prediction_line": "        coords, maxvals = self.get_final_preds(output, center, scale)", "ground_truth": "        preds, maxvals = self.get_final_preds(output.numpy(), center, scale)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            preds, maxvals = self.post_process(", "prediction_line": "            preds, maxvals = self.post_process(", "ground_truth": "            outputs = self.post_process(hrnet_outputs, center, scale)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            loss (str): loss name", "prediction_line": "            loss (str): loss name", "ground_truth": "            post_process (object): `HRNetPostProcess` instance", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       \"\"\"\n        coords, maxvals = self.get_max_preds(heatmaps)", "prediction_line": "       \"\"\"", "ground_truth": "        Args:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from ppocr.modeling.backbones.det_mobilenet_v3 import DetMobileNetV3", "prediction_line": "from ppocr.modeling.backbones.det_mobilenet_v3 import DetMobileNetV3", "ground_truth": "import numpy as np", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Returns:\n            preds: numpy.ndarray([batch_size, num_joints, 3])", "prediction_line": "        Returns:", "ground_truth": "        Returns:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def from_config(cls, cfg, *args, **kwargs):", "prediction_line": "    def from_config(cls, cfg, *args, **kwargs):", "ground_truth": "    def from_config(cls, cfg, *args, **kwargs):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                        ])\n                        coords[n][p] += np.sign(diff) * .25", "prediction_line": "                        ])", "ground_truth": "                        ])", "line_class": "random", "zero_context": true}
{"original_prediction": "                 backbone_cfg=None,", "prediction_line": "                 backbone_cfg=None,", "ground_truth": "                 loss='KeyPointMSELoss',", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.loss = loss", "prediction_line": "        self.loss = loss", "ground_truth": "        self.loss = loss", "line_class": "random", "zero_context": true}
{"original_prediction": "    def model_arch(self, ):", "prediction_line": "    def model_arch(self, ):", "ground_truth": "    @classmethod", "line_class": "random", "zero_context": true}
{"original_prediction": "        return outputs", "prediction_line": "        return outputs", "ground_truth": "        return outputs", "line_class": "random", "zero_context": true}
{"original_prediction": "            df_info = df_info.strip().split()", "prediction_line": "            df_info = df_info.strip().split()", "ground_truth": "            info = df_info.strip()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if info.startswith(SHM_KEY):", "prediction_line": "            if info.startswith(SHM_KEY):", "ground_truth": "            if info.find(SHM_KEY) >= 0:", "line_class": "commited", "zero_context": true}
{"original_prediction": "                shm_infos.append(info)", "prediction_line": "                shm_infos.append(info)", "ground_truth": "                shm_infos.append(info.split())", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(EvalReader, self).__init__(sample_transforms, batch_transforms,", "prediction_line": "        super(EvalReader, self).__init__(sample_transforms, batch_transforms,", "ground_truth": "        super(EvalReader, self).__init__(sample_transforms, batch_transforms,", "line_class": "commited", "zero_context": true}
{"original_prediction": "@register\nclass TestReader(BaseDataLoader):", "prediction_line": "@register", "ground_truth": "@register", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(BatchCompose, self).__init__(transforms, num_classes)", "prediction_line": "        super(BatchCompose, self).__init__(transforms, num_classes)", "ground_truth": "        super(BatchCompose, self).__init__(transforms, num_classes)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.worker_num = worker_num", "prediction_line": "        self.worker_num = worker_num", "ground_truth": "        self.dataset.check_or_download_dataset()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.dataset.parse_dataset()", "prediction_line": "        self.dataset.parse_dataset()", "ground_truth": "        self.dataset.parse_dataset()", "line_class": "commited", "zero_context": true}
{"original_prediction": "loader\n        if batch_sampler is None:", "prediction_line": "loader", "ground_truth": "        self.dataset.set_transform(self._sample_transforms)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.dataset.set_kwargs(self.kwargs)", "prediction_line": "        self.dataset.set_kwargs(self.kwargs)", "ground_truth": "        self.dataset.set_kwargs(**self.kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(TrainReader, self).__init__(", "prediction_line": "        super(TrainReader, self).__init__(", "ground_truth": "        super(TrainReader, self).__init__(sample_transforms, batch_transforms,", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(TestReader, self).__init__(sample_transforms, batch_transforms,", "prediction_line": "        super(TestReader, self).__init__(sample_transforms, batch_transforms,", "ground_truth": "        super(TestReader, self).__init__(sample_transforms, batch_transforms,", "line_class": "commited", "zero_context": true}
{"original_prediction": "            {'K': 1.0 / 1024, 'M': 1.0, 'G': 1024, 'T': 1024 * 1024}[unit]", "prediction_line": "            {'K': 1.0 / 1024, 'M': 1.0, 'G': 1024, 'T': 1024 * 1024}[unit]", "ground_truth": "            (1024 ** (SIZE_UNIT.index(unit) - 1))", "line_class": "common", "zero_context": true}
{"original_prediction": "            data = next(self.loader)", "prediction_line": "            data = next(self.loader)", "ground_truth": "            return next(self.loader)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._batch_transforms = BatchCompose(", "prediction_line": "        self._batch_transforms = BatchCompose(", "ground_truth": "        self._batch_transforms = BatchCompose(batch_transforms, num_classes,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.__next__()", "prediction_line": "        return self.__next__()", "ground_truth": "        return self.__next__()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            shm_size = _get_shared_memory_size_in_M()", "prediction_line": "            shm_size = _get_shared_memory_size_in_M()", "ground_truth": "            shm_size = _get_shared_memory_size_in_M()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return _parse_size_in_M(shm_infos[0][1])", "prediction_line": "            return _parse_size_in_M(shm_infos[0][1])", "ground_truth": "            return _parse_size_in_M(shm_infos[0][3])", "line_class": "infile", "zero_context": true}
{"original_prediction": "                return _parse_size_in_M(default_mount_infos[0][3])", "prediction_line": "                return _parse_size_in_M(default_mount_infos[0][3])", "ground_truth": "                return _parse_size_in_M(default_mount_infos[0][3])", "line_class": "infile", "zero_context": true}
{"original_prediction": "s\n        self.sample_transforms = Compose(sample_transforms, num_classes)", "prediction_line": "s", "ground_truth": "        self._sample_transforms = Compose(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                return _parse_size_in_M(shm_infos[0][3])", "prediction_line": "                return _parse_size_in_M(shm_infos[0][3])", "ground_truth": "                return max([_parse_size_in_M(si[3]) for si in shm_infos])", "line_class": "inproject", "zero_context": true}
{"original_prediction": ",\n        # please set collate_batch=False", "prediction_line": ",", "ground_truth": "        # use user-defined here", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            and the samples will be collate into list.", "prediction_line": "            and the samples will be collate into list.", "ground_truth": "            which is used when the number of ground-truch is different in ", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        dataset (paddle.io.Dataset): a paddle.io.Dataset object", "prediction_line": "        dataset (paddle.io.Dataset): a paddle.io.Dataset object", "ground_truth": "        sample_transforms (list): a list of transforms to perform", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        shuffle (bool): whether to shuffle samples", "prediction_line": "        shuffle (bool): whether to shuffle samples", "ground_truth": "        shuffle (bool): whether to shuffle samples", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "load data,\n            default False.", "prediction_line": "load data,", "ground_truth": "                accelerate data loading, enable this only if you", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            else:\n                return _parse_size_in_M(shm_infos[0][3])", "prediction_line": "            else:", "ground_truth": "            else:", "line_class": "random", "zero_context": true}
{"original_prediction": "        return len(self.dataset)", "prediction_line": "        return len(self.dataset)", "ground_truth": "        return len(self._batch_sampler)", "line_class": "random", "zero_context": true}
{"original_prediction": "                 use_shared_memory=False,", "prediction_line": "                 use_shared_memory=False,", "ground_truth": "                 **kwargs):", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.shuffle = shuffle", "prediction_line": "        self.shuffle = shuffle", "ground_truth": "        self.shuffle = shuffle", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.collate_batch = collate_batch", "prediction_line": "        self.collate_batch = collate_batch", "ground_truth": "        self.collate_batch = collate_batch", "line_class": "random", "zero_context": true}
{"original_prediction": "        results = copy.deepcopy(self.db[idx])", "prediction_line": "        results = copy.deepcopy(self.db[idx])", "ground_truth": "        records = copy.deepcopy(self.db[idx])", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(dataset_dir, image_dir, anno_path, num_joints, transform)", "prediction_line": "        super().__init__(dataset_dir, image_dir, anno_path, num_joints, transform)", "ground_truth": "        super().__init__(dataset_dir, image_dir, anno_path, num_joints,", "line_class": "commited", "zero_context": true}
{"original_prediction": "@register\n@serializable", "prediction_line": "@register", "ground_truth": "@register", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(KeypointTopDownBaseDataset, self).__init__()", "prediction_line": "        super(KeypointTopDownBaseDataset, self).__init__()", "ground_truth": "        super().__init__(dataset_dir, image_dir, anno_path)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        \"\"\"Ground truth bbox and keypoints.\"\"\"", "prediction_line": "        \"\"\"Ground truth bbox and keypoints.\"\"\"", "ground_truth": "        coco = COCO(self.get_anno())", "line_class": "commited", "zero_context": true}
{"original_prediction": "           im_path = os.path.join(self.img_prefix, file_name)", "prediction_line": "           im_path = os.path.join(self.img_prefix, file_name)", "ground_truth": "            annIds = coco.getAnnIds(imgIds=index, iscrowd=False)", "line_class": "common", "zero_context": true}
{"original_prediction": "        for img_id in img_ids:", "prediction_line": "        for img_id in img_ids:", "ground_truth": "        for index in img_ids:", "line_class": "common", "zero_context": true}
{"original_prediction": "            img_id = index", "prediction_line": "            img_id = index", "ground_truth": "            im_ann = coco.loadImgs(index)[0]", "line_class": "common", "zero_context": true}
{"original_prediction": "            all_boxes = json.load(f)", "prediction_line": "            all_boxes = json.load(f)", "ground_truth": "            all_boxes = json.load(f)", "line_class": "common", "zero_context": true}
{"original_prediction": "            self.db = self._get_db_from_gt()", "prediction_line": "            self.db = self._get_db_from_gt()", "ground_truth": "            self.db = self._load_coco_keypoint_annotations()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.db = self._load_coco_person_detection_results()", "prediction_line": "            self.db = self._load_coco_person_detection_results()", "ground_truth": "            self.db = self._load_coco_person_detection_results()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        scale = np.array(", "prediction_line": "        scale = np.array(", "ground_truth": "        scale = np.array(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            center, scale = self._box2cs(box)", "prediction_line": "            center, scale = self._box2cs(box)", "ground_truth": "            center, scale = self._box2cs(box)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            scale = scale * 1.25", "prediction_line": "            scale = scale * 1.25", "ground_truth": "            scale = scale * 1.25", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return center, scale", "prediction_line": "        return center, scale", "ground_truth": "        return center, scale", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                center, scale = self._xywh2cs(*obj['clean_bbox'][:4])", "prediction_line": "                center, scale = self._xywh2cs(*obj['clean_bbox'][:4])", "ground_truth": "                center, scale = self._box2cs(obj['clean_bbox'][:4])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                'scale': scale,", "prediction_line": "                'scale': scale,", "ground_truth": "                'scale': scale,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                x1 = max(0, x)", "prediction_line": "                x1 = max(0, x)", "ground_truth": "                x1 = np.max((0, x))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                y1 = np.max((0, y))", "prediction_line": "                y1 = np.max((0, y))", "ground_truth": "                y1 = np.max((0, y))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                x2 = np.min((width - 1, x1 + np.max((0, w - 1))))", "prediction_line": "                x2 = np.min((width - 1, x1 + np.max((0, w - 1))))", "ground_truth": "                x2 = np.min((width - 1, x1 + np.max((0, w - 1))))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                y2 = np.min((height - 1, y1 + np.max((0, h - 1))))", "prediction_line": "                y2 = np.min((height - 1, y1 + np.max((0, h - 1))))", "ground_truth": "                y2 = np.min((height - 1, y1 + np.max((0, h - 1))))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if max(obj['keypoints']) == 0:", "prediction_line": "                if max(obj['keypoints']) == 0:", "ground_truth": "                if max(obj['keypoints']) == 0:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "# See the License for the specific language governing permissions and", "prediction_line": "# See the License for the specific language governing permissions and", "ground_truth": "# See the License for the specific language governing permissions and", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        image_thre (float): The threshold of the image", "prediction_line": "        image_thre (float): The threshold of the image", "ground_truth": "        image_thre (float): The threshold to filter the detection box", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import os\nimport sys", "prediction_line": "import os", "ground_truth": "from __future__ import absolute_import", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        7: 'left_elbow',", "prediction_line": "        7: 'left_elbow',", "ground_truth": "        7: 'left_elbow',", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from .preprocess import transform", "prediction_line": "from .preprocess import transform", "ground_truth": "from lib.utils.workspace import register, serializable", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                 image_dir,", "prediction_line": "                 image_dir,", "ground_truth": "                 image_dir,", "line_class": "random", "zero_context": true}
{"original_prediction": "                    'bbox': obj['clean_bbox'],", "prediction_line": "                    'bbox': obj['clean_bbox'],", "ground_truth": "                    'im_id': im_id,", "line_class": "random", "zero_context": true}
{"original_prediction": "                continue\n\n            center, scale = self._box2cs(box)", "prediction_line": "                continue", "ground_truth": "                continue", "line_class": "random", "zero_context": true}
{"original_prediction": "        if center[0] != -1:", "prediction_line": "        if center[0] != -1:", "ground_truth": "        if center[0] != -1:", "line_class": "random", "zero_context": true}
{"original_prediction": "        super(SpatialWeightingModule, self).__init__()", "prediction_line": "        super(SpatialWeightingModule, self).__init__()", "ground_truth": "        super(SpatialWeightingModule, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(ConditionalChannelWeightingBlock, self).__init__()", "prediction_line": "        super(ConditionalChannelWeightingBlock, self).__init__()", "ground_truth": "        super(ConditionalChannelWeightingBlock, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(LiteHRNet, self).__init__()", "prediction_line": "        super(LiteHRNet, self).__init__()", "ground_truth": "        super(LiteHRNet, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ShapeSpec(channels=self.stages_config[\"num_channels\"][2][-1])", "prediction_line": "            ShapeSpec(channels=self.stages_config[\"num_channels\"][2][-1])", "ground_truth": "            ShapeSpec(", "line_class": "commited", "zero_context": true}
{"original_prediction": "class LiteHRNet(nn.Layer):", "prediction_line": "class LiteHRNet(nn.Layer):", "ground_truth": "@register", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(ConvNormLayer, self).__init__()", "prediction_line": "        super(ConvNormLayer, self).__init__()", "ground_truth": "        super(ConvNormLayer, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(ShuffleUnit, self).__init__()", "prediction_line": "        super(ShuffleUnit, self).__init__()", "ground_truth": "        super(ShuffleUnit, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(LiteHRNetModule, self).__init__()", "prediction_line": "        super(LiteHRNetModule, self).__init__()", "ground_truth": "        super(LiteHRNetModule, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(DepthWiseSeparableConvNormLayer, self).__init__()", "prediction_line": "        super(DepthWiseSeparableConvNormLayer, self).__init__()", "ground_truth": "        super(DepthWiseSeparableConvNormLayer, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(CrossResolutionWeightingModule, self).__init__()", "prediction_line": "        super(CrossResolutionWeightingModule, self).__init__()", "ground_truth": "        super(CrossResolutionWeightingModule, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(Stem, self).__init__()", "prediction_line": "        super(Stem, self).__init__()", "ground_truth": "        super(Stem, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(IterativeHead, self).__init__()", "prediction_line": "        super(IterativeHead, self).__init__()", "ground_truth": "        super(IterativeHead, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.iterative_head = IterativeHead(", "prediction_line": "        self.iterative_head = IterativeHead(", "ground_truth": "        self.head_layer = IterativeHead(num_channels_pre_layer, 'bn',", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.branches = self._make_branches(num_branches, num_blocks,", "prediction_line": "            self.branches = self._make_branches(num_branches, num_blocks,", "ground_truth": "            self.layers = self._make_weighting_blocks(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.pointwise_conv = ConvNormLayer(", "prediction_line": "        self.pointwise_conv = ConvNormLayer(", "ground_truth": "        self.pointwise_conv = ConvNormLayer(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.layers = self._make_naive_blocks(", "prediction_line": "            self.layers = self._make_naive_blocks(", "ground_truth": "            self.layers = self._make_naive_branches(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return out", "prediction_line": "        return out", "ground_truth": "        out = [channel_shuffle(s, groups=2) for s in out]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.fuse_layers = self._make_fuse_layers()", "prediction_line": "            self.fuse_layers = self._make_fuse_layers()", "ground_truth": "            self.fuse_layers = self._make_fuse_layers(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                ConditionalChannelWeightingBlock(", "prediction_line": "                ConditionalChannelWeightingBlock(", "ground_truth": "                ConditionalChannelWeightingBlock(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.conv1 = ConvNormLayer(", "prediction_line": "        self.conv1 = ConvNormLayer(", "ground_truth": "        self.conv1 = ConvNormLayer(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            ConvNormLayer(", "prediction_line": "            ConvNormLayer(", "ground_truth": "            ConvNormLayer(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.conv2 = ConvNormLayer(", "prediction_line": "        self.conv2 = ConvNormLayer(", "ground_truth": "        self.conv2 = ConvNormLayer(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    ShuffleUnit(", "prediction_line": "                    ShuffleUnit(", "ground_truth": "                    ShuffleUnit(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.branch2 = nn.Sequential(", "prediction_line": "        self.branch2 = nn.Sequential(", "ground_truth": "        self.expand_conv = ConvNormLayer(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.dw_act = dw_act", "prediction_line": "        self.dw_act = dw_act", "ground_truth": "        self.depthwise_conv = ConvNormLayer(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.linear_conv = ConvNormLayer(", "prediction_line": "        self.linear_conv = ConvNormLayer(", "ground_truth": "        self.linear_conv = ConvNormLayer(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return out", "prediction_line": "        return out", "ground_truth": "        out = channel_shuffle(out, groups=2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                LiteHRNetModule(", "prediction_line": "                LiteHRNetModule(", "ground_truth": "                LiteHRNetModule(", "line_class": "infile", "zero_context": true}
{"original_prediction": "       self.branch_channels = branch_channels", "prediction_line": "       self.branch_channels = branch_channels", "ground_truth": "        self.cross_resolution_weighting = CrossResolutionWeightingModule(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    ConvNormLayer(", "prediction_line": "                    ConvNormLayer(", "ground_truth": "                    DepthWiseSeparableConvNormLayer(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            SpatialWeightingModule(", "prediction_line": "            SpatialWeightingModule(", "ground_truth": "            SpatialWeightingModule(", "line_class": "infile", "zero_context": true}
{"original_prediction": "       self.stem = Stem(", "prediction_line": "       self.stem = Stem(", "ground_truth": "        self.stem = Stem(3, 32, 32, 1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self._make_transition_layer(num_channels_pre_layer[-1],", "prediction_line": "                    self._make_transition_layer(num_channels_pre_layer[-1],", "ground_truth": "                    self._make_transition_layer(num_channels_pre_layer,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            stage, num_channels_pre_layer = self._make_stage(", "prediction_line": "            stage, num_channels_pre_layer = self._make_stage(", "ground_truth": "            stage, num_channels_pre_layer = self._make_stage(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return_raw (bool): whether to return the raw output of each stage", "prediction_line": "        return_raw (bool): whether to return the raw output of each stage", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        in_channels (int): Number of input image channels. Default: 3.", "prediction_line": "        in_channels (int): Number of input image channels. Default: 3.", "ground_truth": "        network_type (str): the network_type should be one of [\"lite_18\", \"lite_30\", \"naive\", \"wider_naive\"],", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from paddleseg.cvlibs import manager", "prediction_line": "from paddleseg.cvlibs import manager", "ground_truth": "from numbers import Integral", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.projects = nn.LayerList(projects)", "prediction_line": "        self.projects = nn.LayerList(projects)", "ground_truth": "        self.projects = nn.LayerList(projects)", "line_class": "random", "zero_context": true}
{"original_prediction": ",\n            filter_size=1,", "prediction_line": ",", "ground_truth": "            if stem_channel == out_channel else stem_channel,", "line_class": "random", "zero_context": true}
{"original_prediction": "        x1, x2 = x.chunk(2, axis=1)", "prediction_line": "        x1, x2 = x.chunk(2, axis=1)", "ground_truth": "        x1, x2 = x.chunk(2, axis=1)", "line_class": "random", "zero_context": true}
{"original_prediction": "                 ch_in,", "prediction_line": "                 ch_in,", "ground_truth": "                 ch_in,", "line_class": "random", "zero_context": true}
{"original_prediction": "       if self.act is not None:", "prediction_line": "       if self.act is not None:", "ground_truth": "        if self.act == 'relu':", "line_class": "random", "zero_context": true}
{"original_prediction": "   if _equal(width, 0):", "prediction_line": "   if _equal(width, 0):", "ground_truth": "    if _equal(width, 0):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'ShearY_BBox': lambda image, bboxes, level, replace: shear_with_bboxes(", "prediction_line": "        'ShearY_BBox': lambda image, bboxes, level, replace: shear_with_bboxes(", "ground_truth": "        'ShearY_BBox': lambda image, bboxes, level, replace: shear_with_bboxes(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return wrapper", "prediction_line": "    return wrapper", "ground_truth": "    return wrapper", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if height <= 0.0:", "prediction_line": "    if height <= 0.0:", "ground_truth": "    if _equal(height, 0):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'v3': policy_v3,", "prediction_line": "        'v3': policy_v3,", "ground_truth": "        'v3': policy_v3,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        image = translate_x(image, pixels, replace)", "prediction_line": "        image = translate_x(image, pixels, replace)", "ground_truth": "        image = translate_x(image, pixels, replace)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return _apply_multi_bbox_augmentation_wrapper(", "prediction_line": "    return _apply_multi_bbox_augmentation_wrapper(", "ground_truth": "    return _apply_multi_bbox_augmentation_wrapper(image, bboxes, prob,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    grey_tensor = np.zeros_like(mask) + replace[0]", "prediction_line": "    grey_tensor = np.zeros_like(mask) + replace[0]", "ground_truth": "    image = mask_and_add_image(new_min_y, new_min_x, new_max_y, new_max_x,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    'AutoContrast': autocontrast,", "prediction_line": "    'AutoContrast': autocontrast,", "ground_truth": "        'AutoContrast': autocontrast,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return final_policy", "prediction_line": "            return final_policy", "ground_truth": "            return final_policy", "line_class": "infile", "zero_context": true}
{"original_prediction": "    augmentation_hparams['cutout_const'] = 100", "prediction_line": "    augmentation_hparams['cutout_const'] = 100", "ground_truth": "    return build_and_apply_nas_policy(policy, image, bboxes,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'Cutout_Only_BBoxes': cutout_only_bboxes,", "prediction_line": "        'Cutout_Only_BBoxes': cutout_only_bboxes,", "ground_truth": "        'Cutout_Only_BBoxes': cutout_only_bboxes,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if new_min_bbox_coords is None:", "prediction_line": "    if new_min_bbox_coords is None:", "ground_truth": "    minval_y = clip_y(min_y - np.int32(pixel_scaling * float(bbox_height) /", "line_class": "infile", "zero_context": true}
{"original_prediction": "    maxval_y = clip_y(min_y + np.int32(pixel_scaling * float(bbox_height) /", "prediction_line": "    maxval_y = clip_y(min_y + np.int32(pixel_scaling * float(bbox_height) /", "ground_truth": "    maxval_y = clip_y(min_y + np.int32(pixel_scaling * float(bbox_height) /", "line_class": "infile", "zero_context": true}
{"original_prediction": "    image = rotate(image, degrees, replace)", "prediction_line": "    image = rotate(image, degrees, replace)", "ground_truth": "    image = rotate(image, degrees, replace)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'CutoutBBox': cutout_bbox,", "prediction_line": "        'CutoutBBox': cutout_bbox,", "ground_truth": "        'BBox_Cutout': bbox_cutout,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        image = shear_x(image, level, replace)", "prediction_line": "        image = shear_x(image, level, replace)", "ground_truth": "        image = shear_x(image, level, replace)", "line_class": "infile", "zero_context": true}
{"original_prediction": "           tf_policy.append(_parse_policy_info(*policy_info))", "prediction_line": "           tf_policy.append(_parse_policy_info(*policy_info))", "ground_truth": "            tf_policy.append(_parse_policy_info(*policy_info))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'v1': policy_v1,", "prediction_line": "        'v1': policy_v1,", "ground_truth": "        'v1': policy_v1,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        image = translate_y(image, pixels, replace)", "prediction_line": "        image = translate_y(image, pixels, replace)", "ground_truth": "        image = translate_y(image, pixels, replace)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        image, bboxes, prob, translate_x, func_changes_bbox, pixels, replace)", "prediction_line": "        image, bboxes, prob, translate_x, func_changes_bbox, pixels, replace)", "ground_truth": "        image, bboxes, prob, translate_x, func_changes_bbox, pixels, replace)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Check to see if prob is passed into function call.", "prediction_line": "    # Check to see if prob is passed into function call.", "ground_truth": "    args = level_to_arg(augmentation_hparams)[name](level)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'Equalize_Only_BBoxes': equalize_only_bboxes,", "prediction_line": "        'Equalize_Only_BBoxes': equalize_only_bboxes,", "ground_truth": "        'Equalize_Only_BBoxes': equalize_only_bboxes,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Convert from degrees to radians.", "prediction_line": "    # Convert from degrees to radians.", "ground_truth": "    image = wrap(image)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'ShearX': shear_x,", "prediction_line": "        'ShearX': shear_x,", "ground_truth": "        'Cutout': cutout,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        image = apply_bbox_cutout(image, bboxes, pad_fraction)", "prediction_line": "        image = apply_bbox_cutout(image, bboxes, pad_fraction)", "ground_truth": "        image = apply_bbox_cutout(image, bboxes, pad_fraction)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'Spatial_Cutout': spatial_cutout,", "prediction_line": "        'Spatial_Cutout': spatial_cutout,", "ground_truth": "        'Rotate_BBox': rotate_with_bboxes,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    image = wrap(image)", "prediction_line": "    image = wrap(image)", "ground_truth": "    image = Image.fromarray(wrap(image))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'Sharpness': sharpness,", "prediction_line": "        'Sharpness': sharpness,", "ground_truth": "        'Sharpness': sharpness,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    bboxes = np.array([", "prediction_line": "    bboxes = np.array([", "ground_truth": "    wrapped_rotate_bbox = lambda bbox: _rotate_bbox(bbox, image_height, image_width, degrees)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # pylint:enable=g-long-lambda", "prediction_line": "        # pylint:enable=g-long-lambda", "ground_truth": "        'ShearX_BBox': lambda image, bboxes, level, replace: shear_with_bboxes(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    s1 = scale_channel(image[:, :, 0])", "prediction_line": "    s1 = scale_channel(image[:, :, 0])", "ground_truth": "    s1 = scale_channel(image[:, :, 0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rotated = image.rotate(degrees, resample=Image.BILINEAR, expand=1)", "prediction_line": "    rotated = image.rotate(degrees, resample=Image.BILINEAR, expand=1)", "ground_truth": "    image = image.rotate(degrees)", "line_class": "infile", "zero_context": true}
{"original_prediction": ".\n    if bboxes_sum_check == -4.0:", "prediction_line": ".", "ground_truth": "    if _equal(bboxes_sum_check, -4):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'Rotate_Only_BBoxes': _rotate_level_to_arg,", "prediction_line": "        'Rotate_Only_BBoxes': _rotate_level_to_arg,", "ground_truth": "        'Rotate_Only_BBoxes': _rotate_level_to_arg,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'Equalize': equalize,", "prediction_line": "        'Equalize': equalize,", "ground_truth": "        'Equalize': equalize,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if func_changes_bbox:", "prediction_line": "    if func_changes_bbox:", "ground_truth": "    new_bboxes = _concat_bbox(bbox, new_bboxes)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        min_y, max_y = _adjust_bbox_boundaries(min_y, max_y)", "prediction_line": "        min_y, max_y = _adjust_bbox_boundaries(min_y, max_y)", "ground_truth": "        min_y, max_y = _adjust_bbox_boundaries(min_y, max_y)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    mask = np.zeros(cutout_shape, dtype=image.dtype)", "prediction_line": "    mask = np.zeros(cutout_shape, dtype=image.dtype)", "ground_truth": "    mask = np.pad(np.zeros(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        hi = float(np.max(image))", "prediction_line": "        hi = float(np.max(image))", "ground_truth": "        hi = float(np.max(image))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # Copy the augmented_bbox_content into the masked region of the original image.", "prediction_line": "    # Copy the augmented_bbox_content into the masked region of the original image.", "ground_truth": "    mask_tensor = np.pad(mask_tensor,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    max_y = float(np.max(new_coords[0, :])) / image_height", "prediction_line": "    max_y = float(np.max(new_coords[0, :])) / image_height", "ground_truth": "    max_y = float(np.max(new_coords[0, :])) / image_height", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    max_x = float(np.max(new_coords[1, :])) / image_width", "prediction_line": "    max_x = float(np.max(new_coords[1, :])) / image_width", "ground_truth": "    max_x = float(np.max(new_coords[1, :])) / image_width", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            scale = 255.0 / (hi - lo)", "prediction_line": "            scale = 255.0 / (hi - lo)", "ground_truth": "            scale = 255.0 / (hi - lo)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            offset = -lo * scale", "prediction_line": "            offset = -lo * scale", "ground_truth": "            offset = -lo * scale", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            im = im * scale + offset", "prediction_line": "            im = im * scale + offset", "ground_truth": "            im = im.astype(np.float32) * scale + offset", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    min_y, min_x = np.min(new_coords, 1)", "prediction_line": "    min_y, min_x = np.min(new_coords, 1)", "ground_truth": "    min_y = -(float(np.max(new_coords[0, :])) / image_height - 0.5)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        image_[min_y_:max_y_ + 1, min_x_:max_x_ + 1, :] = (", "prediction_line": "        image_[min_y_:max_y_ + 1, min_x_:max_x_ + 1, :] = (", "ground_truth": "        mask = np.pad(mask, [[min_y_, (image_height - 1) - max_y_],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    max_x = float(np.max(new_coords[1, :])) / image_width + 0.5", "prediction_line": "    max_x = float(np.max(new_coords[1, :])) / image_width + 0.5", "ground_truth": "    max_x = float(np.max(new_coords[1, :])) / image_width + 0.5", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    augmented_bbox_content = np.pad(", "prediction_line": "    augmented_bbox_content = np.pad(", "ground_truth": "    augmented_bbox_content = np.pad(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       mask = np.tile(mask, [1, 1, 3])", "prediction_line": "       mask = np.tile(mask, [1, 1, 3])", "ground_truth": "        content_tensor = np.pad(content_tensor,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            applied in sequence.", "prediction_line": "            applied in sequence.", "ground_truth": "            applied in parallel to a single image (2 vs 3).", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    Returns:\n        image: A 3D Image Tensor with 3 channels.", "prediction_line": "    Returns:", "ground_truth": "    Returns:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    bounding boxes in the training set.", "prediction_line": "    bounding boxes in the training set.", "ground_truth": "    bounding boxes that are close to each other. The value of 3.0 was a chosen", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # Make image 4D for conv operation.", "prediction_line": "    # Make image 4D for conv operation.", "ground_truth": "    # Make image 4D for conv operation.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # of 'addition' is between -128 and 128.", "prediction_line": "    # of 'addition' is between -128 and 128.", "ground_truth": "    # of 'addition' is between -128 and 128.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        nonzero_histo = histo[im.nonzero()[0]]", "prediction_line": "        nonzero_histo = histo[im.nonzero()[0]]", "ground_truth": "        nonzero = np.where(np.not_equal(histo, 0))", "line_class": "random", "zero_context": true}
{"original_prediction": "policy_info)\n            # Check to see if this is a bbox operation (starts with BBox).", "prediction_line": "policy_info)", "ground_truth": "                policy_info) + [replace_value, augmentation_hparams]", "line_class": "random", "zero_context": true}
{"original_prediction": "        [('Equalize', 0.0, 10), ('TranslateX_Only_BBoxes', 0.6, 6)],", "prediction_line": "        [('Equalize', 0.0, 10), ('TranslateX_Only_BBoxes', 0.6, 6)],", "ground_truth": "        [('Sharpness', 0.4, 4), ('TranslateY_Only_BBoxes', 0.0, 4)],", "line_class": "random", "zero_context": true}
{"original_prediction": "    extended = np.concatenate((image, extended_channel), axis=2)", "prediction_line": "    extended = np.concatenate((image, extended_channel), axis=2)", "ground_truth": "    extended = np.concatenate([image, extended_channel], 2).astype(image.dtype)", "line_class": "random", "zero_context": true}
{"original_prediction": "        [('Sharpness', 0.0, 8), ('ShearX_BBox', 0.4, 0)],", "prediction_line": "        [('Sharpness', 0.0, 8), ('ShearX_BBox', 0.4, 0)],", "ground_truth": "        [('Sharpness', 0.0, 8), ('ShearX_BBox', 0.4, 0)],", "line_class": "random", "zero_context": true}
{"original_prediction": "            return \"new \" + classname.replace(\"$\", \".\") + \"(\" + \",\".join(", "prediction_line": "            return \"new \" + classname.replace(\"$\", \".\") + \"(\" + \",\".join(", "ground_truth": "            possible_target.exceptions_to_handle.update(", "line_class": "common", "zero_context": true}
{"original_prediction": "    # Heuristic 1", "prediction_line": "    # Heuristic 1", "ground_truth": "    _generate_heuristic_1(yaml_dict, possible_targets)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                _handle_argument(argType, yaml_dict, possible_target))", "prediction_line": "                _handle_argument(argType, yaml_dict, possible_target))", "ground_truth": "                _handle_argument(argType, None, possible_target))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    _handle_argument(argType, init_dict, possible_target))", "prediction_line": "                    _handle_argument(argType, init_dict, possible_target))", "ground_truth": "                    _handle_argument(argType, init_dict, possible_target))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return _search_concrete_subclass(java_info['superClass'], init_dict)", "prediction_line": "            return _search_concrete_subclass(java_info['superClass'], init_dict)", "ground_truth": "            result = _search_concrete_subclass(func_elem['functionSourceFile'],", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Create fuzz target", "prediction_line": "        # Create fuzz target", "ground_truth": "        possible_target = FuzzTarget()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # If the argument type is not primitive, then it is a class.", "prediction_line": "        # If the argument type is not primitive, then it is a class.", "ground_truth": "        return _handle_object_creation(argType, init_dict, possible_target)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                return _handle_object_creation(", "prediction_line": "                return _handle_object_creation(", "ground_truth": "                func_elem = _search_concrete_subclass(classname, init_dict)", "line_class": "infile", "zero_context": true}
{"original_prediction": "#\n#     http://www.apache.org/licenses/LICENSE-2.0", "prediction_line": "#", "ground_truth": "#", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    # Insert the rest of the code", "prediction_line": "                    # Insert the rest of the code", "ground_truth": "                    # Copy other lines from the base fuzzer", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __repr__(self):", "prediction_line": "    def __repr__(self):", "ground_truth": "    def generate_patched_fuzzer(self, filename):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        func_elem = init_dict[classname]", "prediction_line": "        func_elem = init_dict[classname]", "ground_truth": "        # Process arguments for constructor", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                                                           func_name)", "prediction_line": "                                                           func_name)", "ground_truth": "                                                          func_name)", "line_class": "random", "zero_context": true}
{"original_prediction": "            continue\n        if \"test\" in func_elem['functionName']:", "prediction_line": "            continue", "ground_truth": "            continue", "line_class": "random", "zero_context": true}
{"original_prediction": "    elif argType == \"float\" or argType == \"java.lang.Float\":", "prediction_line": "    elif argType == \"float\" or argType == \"java.lang.Float\":", "ground_truth": "    elif argType == \"float\" or argType == \"java.lang.Float\":", "line_class": "random", "zero_context": true}
{"original_prediction": "        possible_target.fuzzer_source_code = fuzzer_source_code", "prediction_line": "        possible_target.fuzzer_source_code = fuzzer_source_code", "ground_truth": "        possible_target.fuzzer_source_code = fuzzer_source_code", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"boolean\", \"byte\", \"char\", \"double\", \"float\", \"int\", \"long\", \"short\",", "prediction_line": "        \"boolean\", \"byte\", \"char\", \"double\", \"float\", \"int\", \"long\", \"short\",", "ground_truth": "        \"boolean\", \"byte\", \"char\", \"short\", \"int\", \"long\", \"float\", \"double\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    fuzz_driver_generation_python.patch_fuzzer(", "prediction_line": "    fuzz_driver_generation_python.patch_fuzzer(", "ground_truth": "    fuzzer_source = possible_target.generate_patched_fuzzer(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        with open(os.path.join(base_oss_fuzz_project_dir,", "prediction_line": "        with open(os.path.join(base_oss_fuzz_project_dir,", "ground_truth": "        possible_targets = fuzz_driver_generation_python.generate_possible_targets(", "line_class": "commited", "zero_context": true}
{"original_prediction": "def main():\n    \"\"\"Main entrypoint for autofuzz generation.\"\"\"", "prediction_line": "def main():", "ground_truth": "if __name__ == \"__main__\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "        timer.start()", "prediction_line": "        timer.start()", "ground_truth": "        timer.start()", "line_class": "common", "zero_context": true}
{"original_prediction": "    try:\n        subprocess.check_call(\" \".join(cmd),", "prediction_line": "    try:", "ground_truth": "    ret = run_cmd(\" \".join(cmd), 1800)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    pool.starmap(build_and_test_single_possible_target, arg_list)", "prediction_line": "    pool.starmap(build_and_test_single_possible_target, arg_list)", "ground_truth": "    pool.starmap(build_and_test_single_possible_target, arg_list)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"\"\"Copy core OSS-Fuzz project files to a new OSS-Fuzz project.", "prediction_line": "    \"\"\"Copy core OSS-Fuzz project files to a new OSS-Fuzz project.", "ground_truth": "    shutil.copy(src_oss_project.build_script, dst_oss_project.build_script)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    shutil.copy(src_oss_project.dockerfile, dst_oss_project.dockerfile)", "prediction_line": "    shutil.copy(src_oss_project.dockerfile, dst_oss_project.dockerfile)", "ground_truth": "    shutil.copy(src_oss_project.project_yaml, dst_oss_project.project_yaml)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    shutil.copy(src_oss_project.dockerfile, dst_oss_project.dockerfile)", "prediction_line": "    shutil.copy(src_oss_project.dockerfile, dst_oss_project.dockerfile)", "ground_truth": "    shutil.copy(src_oss_project.dockerfile, dst_oss_project.dockerfile)", "line_class": "infile", "zero_context": true}
{"original_prediction": "\"src\"),\n        os.path.join(dst_oss_project.project_folder, \"src\"))", "prediction_line": "\"src\"),", "ground_truth": "                     src_oss_project.project_name),", "line_class": "infile", "zero_context": true}
{"original_prediction": "                     dst_oss_project.project_name))", "prediction_line": "                     dst_oss_project.project_name))", "ground_truth": "                     dst_oss_project.project_name))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Create a new OSS-Fuzz project for the given Github project.", "prediction_line": "    # Create a new OSS-Fuzz project for the given Github project.", "ground_truth": "    autofuzz_base_workdir = get_next_project_folder(base_dir=os.getcwd())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    oss_fuzz_base_project = OSS_FUZZ_PROJECT(base_oss_fuzz_project_dir,", "prediction_line": "    oss_fuzz_base_project = OSS_FUZZ_PROJECT(base_oss_fuzz_project_dir,", "ground_truth": "    oss_fuzz_base_project = OSS_FUZZ_PROJECT(base_oss_fuzz_project_dir,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # the FuzzTarget", "prediction_line": "    # the FuzzTarget", "ground_truth": "    dst_oss_fuzz_project = OSS_FUZZ_PROJECT(auto_fuzz_proj_dir,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if not git_clone_project(github_url,", "prediction_line": "    if not git_clone_project(github_url,", "ground_truth": "    if not git_clone_project(", "line_class": "infile", "zero_context": true}
{"original_prediction": "to new OSS-Fuzz project", "prediction_line": "to new OSS-Fuzz project", "ground_truth": "    copy_core_oss_fuzz_project_files(oss_fuzz_base_project,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                         oss_fuzz_base_project.project_name)):", "prediction_line": "                         oss_fuzz_base_project.project_name)):", "ground_truth": "                         oss_fuzz_base_project.project_name)):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Copy source files from base OSS-Fuzz project", "prediction_line": "    # Copy source files from base OSS-Fuzz project", "ground_truth": "    copy_oss_fuzz_project_source(oss_fuzz_base_project, dst_oss_fuzz_project)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    oss_fuzz_base_project.write_basefiles()", "prediction_line": "    oss_fuzz_base_project.write_basefiles()", "ground_truth": "    oss_fuzz_base_project.write_basefiles()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.oss_fuzz_project_name + \"_fuzzer\"", "prediction_line": "        return self.oss_fuzz_project_name + \"_fuzzer\"", "ground_truth": "        return os.path.basename(self.base_fuzzer).replace(\".py\", \"\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if not run_static_analysis(github_url, base_oss_fuzz_project_dir):", "prediction_line": "        if not run_static_analysis(github_url, base_oss_fuzz_project_dir):", "ground_truth": "        static_res = run_static_analysis(github_url,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        dst_oss_fuzz_project.base_fuzzer)", "prediction_line": "        dst_oss_fuzz_project.base_fuzzer)", "ground_truth": "        oss_fuzz_base_project.base_fuzzer)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    with open(dst_oss_fuzz_project.base_fuzzer, \"w\") as ffile:", "prediction_line": "    with open(dst_oss_fuzz_project.base_fuzzer, \"w\") as ffile:", "ground_truth": "    with open(dst_oss_fuzz_project.base_fuzzer, \"w\") as fl:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"Write base files for a new OSS-Fuzz project.", "prediction_line": "        \"\"\"Write base files for a new OSS-Fuzz project.", "ground_truth": "        with open(self.build_script, \"w\") as bfile:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        with open(self.dockerfile, \"w\") as dfile:", "prediction_line": "        with open(self.dockerfile, \"w\") as dfile:", "ground_truth": "        with open(self.base_fuzzer, \"w\") as ffile:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        with open(self.dockerfile, \"w\") as dfile:", "prediction_line": "        with open(self.dockerfile, \"w\") as dfile:", "ground_truth": "        with open(self.project_yaml, \"w\") as yfile:", "line_class": "infile", "zero_context": true}
{"original_prediction": "auto_fuzz_proj_dir,", "prediction_line": "auto_fuzz_proj_dir,", "ground_truth": "        OSS_FUZZ_BASE, dst_oss_fuzz_project.oss_fuzz_project_name,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        log_dir=idx_logdir)", "prediction_line": "        log_dir=idx_logdir)", "ground_truth": "        dst_oss_fuzz_project.oss_fuzz_fuzzer_namer, idx_logdir)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def write_dockerfile(self):", "prediction_line": "    def write_dockerfile(self):", "ground_truth": "        with open(self.dockerfile, \"w\") as dfile:", "line_class": "infile", "zero_context": true}
{"original_prediction": "base_files.gen_dockerfile())", "prediction_line": "base_files.gen_dockerfile())", "ground_truth": "                base_files.gen_dockerfile(self.github_url, self.project_name))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    run_builder_pool(autofuzz_base_workdir, oss_fuzz_base_project,", "prediction_line": "    run_builder_pool(autofuzz_base_workdir, oss_fuzz_base_project,", "ground_truth": "    run_builder_pool(autofuzz_base_workdir, oss_fuzz_base_project,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        autofuzz_project_from_github(repo)", "prediction_line": "        autofuzz_project_from_github(repo)", "ground_truth": "        autofuzz_project_from_github(repo, do_static_analysis=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if len(sys.argv) > 1:", "prediction_line": "    if len(sys.argv) > 1:", "ground_truth": "    run_on_projects()", "line_class": "infile", "zero_context": true}
{"original_prediction": "       if src_dir == \"autofuzz-log\":", "prediction_line": "       if src_dir == \"autofuzz-log\":", "ground_truth": "        if dst_oss_fuzz_project.project_name not in src_dir:", "line_class": "infile", "zero_context": true}
{"original_prediction": "    pool of threads.", "prediction_line": "    pool of threads.", "ground_truth": "    multithreaded manner using ThreadPools.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    fuzz_driver_generation_python.patch_fuzzer(", "prediction_line": "    fuzz_driver_generation_python.patch_fuzzer(", "ground_truth": "    # we want to validate.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # github.com/<org>/<repo>", "prediction_line": "        # github.com/<org>/<repo>", "ground_truth": "        # github.com/{user}/{proj_name}", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    if ret:", "prediction_line": "    if ret:", "ground_truth": "    ret = True", "line_class": "random", "zero_context": true}
{"original_prediction": "def get_fuzz_targets(oss_fuzz_targets: List[str]) -> List[str]:", "prediction_line": "def get_fuzz_targets(oss_fuzz_targets: List[str]) -> List[str]:", "ground_truth": "if not os.path.isdir(FUZZ_INTRO_BASE):", "line_class": "random", "zero_context": true}
{"original_prediction": "shell=True)\n    except:", "prediction_line": "shell=True)", "ground_truth": "                              shell=True,", "line_class": "random", "zero_context": true}
{"original_prediction": "        os.path.join(dst_oss_project.project_folder,", "prediction_line": "        os.path.join(dst_oss_project.project_folder,", "ground_truth": "        os.path.join(dst_oss_project.project_folder,", "line_class": "random", "zero_context": true}
{"original_prediction": "    # Clean up", "prediction_line": "    # Clean up", "ground_truth": "        f.write(f\"Target: {possible_target.function_target}\")", "line_class": "random", "zero_context": true}
{"original_prediction": "            class_path = \".\".join(class_path.split(\".\")[1:])", "prediction_line": "            class_path = \".\".join(class_path.split(\".\")[1:])", "ground_truth": "            class_path = give_right_path(class_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                func_name = give_right_path(func_name)", "prediction_line": "                func_name = give_right_path(func_name)", "ground_truth": "                func_name = give_right_path(func_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            possible_target = FuzzTarget()", "prediction_line": "            possible_target = FuzzTarget()", "ground_truth": "            possible_target = FuzzTarget()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Heuristic 1", "prediction_line": "    # Heuristic 1", "ground_truth": "    _generate_heuristic_1(yaml_dict, possible_targets)", "line_class": "infile", "zero_context": true}
{"original_prediction": "that calls the function on the object", "prediction_line": "that calls the function on the object", "ground_truth": "            possible_target2 = FuzzTarget()", "line_class": "infile", "zero_context": true}
{"original_prediction": "by the function\n            exceptions_thrown = find_all_exceptions(func_elem,", "prediction_line": "by the function", "ground_truth": "            exceptions_thrown = find_all_exceptions(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _generate_heuristic_2(yaml_dict, possible_targets)", "prediction_line": "    _generate_heuristic_2(yaml_dict, possible_targets)", "ground_truth": "    _generate_heuristic_2(yaml_dict, possible_targets)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _generate_heuristic_3(yaml_dict, possible_targets)", "prediction_line": "    _generate_heuristic_3(yaml_dict, possible_targets)", "ground_truth": "    _generate_heuristic_3(yaml_dict, possible_targets)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _generate_heuristic_4(yaml_dict, possible_targets)", "prediction_line": "    _generate_heuristic_4(yaml_dict, possible_targets)", "ground_truth": "    _generate_heuristic_4(yaml_dict, possible_targets)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # catch them.", "prediction_line": "    # catch them.", "ground_truth": "    # prioritise those.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    return import_str", "prediction_line": "    return import_str", "ground_truth": "    return split_import_str[0]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            except:\n                continue", "prediction_line": "            except:", "ground_truth": "            except:", "line_class": "random", "zero_context": true}
{"original_prediction": "            for exc in possible_target.exceptions_to_handle:", "prediction_line": "            for exc in possible_target.exceptions_to_handle:", "ground_truth": "            for exc in possible_target.exceptions_to_handle:", "line_class": "random", "zero_context": true}
{"original_prediction": "    return possible_targets", "prediction_line": "    return possible_targets", "ground_truth": "    return possible_targets", "line_class": "random", "zero_context": true}
{"original_prediction": "    # Get all the functions that are reachable from the target function.", "prediction_line": "    # Get all the functions that are reachable from the target function.", "ground_truth": "    HEURISTIC_NAME = \"Heuristic 1\"", "line_class": "random", "zero_context": true}
{"original_prediction": "            if \"test\" in func_elem['functionName']:", "prediction_line": "            if \"test\" in func_elem['functionName']:", "ground_truth": "            if \"test\" in func_elem['functionName']:", "line_class": "random", "zero_context": true}
{"original_prediction": "                        parent_class = retrieve_tag_content(link_element.getparent().getparent())", "prediction_line": "                        parent_class = retrieve_tag_content(link_element.getparent().getparent())", "ground_truth": "                        parent_class = link_element.get('href')", "line_class": "common", "zero_context": true}
{"original_prediction": "        assert actual_name == f'Fuzzer {i}: {class_name[i]}'", "prediction_line": "        assert actual_name == f'Fuzzer {i}: {class_name[i]}'", "ground_truth": "        actual_name_link = item.getchildren()[0].get('href')", "line_class": "common", "zero_context": true}
{"original_prediction": "        assert fuzzer in class_name", "prediction_line": "        assert fuzzer in class_name", "ground_truth": "        fuzzer_data_link = td_list[1].getchildren()[0].get('href')", "line_class": "common", "zero_context": true}
{"original_prediction": "        fuzzer_yaml_link = td_list[2].getchildren()[0].get('href')", "prediction_line": "        fuzzer_yaml_link = td_list[2].getchildren()[0].get('href')", "ground_truth": "        fuzzer_yaml_link = td_list[2].getchildren()[0].get('href')", "line_class": "common", "zero_context": true}
{"original_prediction": "                actual_link = link_element.get('href')", "prediction_line": "                actual_link = link_element.get('href')", "ground_truth": "                actual_link = link_element.get('href')", "line_class": "common", "zero_context": true}
{"original_prediction": "    # Generate the report", "prediction_line": "    # Generate the report", "ground_truth": "    class_name = config.get('test', 'entryclass').split(':')", "line_class": "common", "zero_context": true}
{"original_prediction": "    actual_project_name = retrieve_tag_content(item)", "prediction_line": "    actual_project_name = retrieve_tag_content(item)", "ground_truth": "    actual_project_name = retrieve_tag_content(item.getchildren()[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actual_fuzzer_name = retrieve_tag_content(item.getchildren()[0])", "prediction_line": "        actual_fuzzer_name = retrieve_tag_content(item.getchildren()[0])", "ground_truth": "        actual_name = retrieve_tag_content(item.getchildren()[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actual_name = retrieve_tag_content(item.getchildren()[0])", "prediction_line": "        actual_name = retrieve_tag_content(item.getchildren()[0])", "ground_truth": "        if retrieve_tag_content(item.getchildren()[0]).startswith(\"Functions\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            actual_reached = int(retrieve_tag_content(item.getchildren()[1]))", "prediction_line": "            actual_reached = int(retrieve_tag_content(item.getchildren()[1]))", "ground_truth": "            count_str = retrieve_tag_content(item.getchildren()[2])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actual_file = retrieve_tag_content(td_list[0])", "prediction_line": "        actual_file = retrieve_tag_content(td_list[0])", "ground_truth": "        actual_file = retrieve_tag_content(td_list[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        fuzzer_class_name = html.xpath(", "prediction_line": "        fuzzer_class_name = html.xpath(", "ground_truth": "        actual_class = retrieve_tag_content(html.find_class('top-navbar-title')[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actual_reached_count = int(retrieve_tag_content(td_list[1]))", "prediction_line": "        actual_reached_count = int(retrieve_tag_content(td_list[1]))", "ground_truth": "        actual_reached = [item for item in retrieve_tag_content(td_list[1]).strip('[]').split(', ')]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actual_covered = [item for item in retrieve_tag_content(td_list[2]).strip('[]').split(', ')]", "prediction_line": "        actual_covered = [item for item in retrieve_tag_content(td_list[2]).strip('[]').split(', ')]", "ground_truth": "        actual_covered = [item for item in retrieve_tag_content(td_list[2]).strip('[]').split(', ')]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert retrieve_tag_content(first_line.find_class('coverage-line-inner-text')[0]) == \\", "prediction_line": "        assert retrieve_tag_content(first_line.find_class('coverage-line-inner-text')[0]) == \\", "ground_truth": "        depth = int(retrieve_tag_content(first_line.find_class('node-depth-wrapper')[0]))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actual_key = retrieve_tag_content(td_list[0])", "prediction_line": "        actual_key = retrieve_tag_content(td_list[0])", "ground_truth": "        fuzzer = retrieve_tag_content(td_list[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actual_reached = [item for item in retrieve_tag_content(td_list[1]).strip('[]').split(', ')]", "prediction_line": "        actual_reached = [item for item in retrieve_tag_content(td_list[1]).strip('[]').split(', ')]", "ground_truth": "        fuzzer_data = retrieve_tag_content(td_list[1].getchildren()[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "       assert retrieve_tag_content(first_line.find_class('node-name')[0]) == \"main\"", "prediction_line": "       assert retrieve_tag_content(first_line.find_class('node-name')[0]) == \"main\"", "ground_truth": "        actual_line = retrieve_tag_content(first_line.find_class('language-clike')[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert fuzzer in class_name", "prediction_line": "        assert fuzzer in class_name", "ground_truth": "        fuzzer_yaml = retrieve_tag_content(td_list[2].getchildren()[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actual_depth = int(retrieve_tag_content(last_line.find_class('node-depth-wrapper')[0]))", "prediction_line": "        actual_depth = int(retrieve_tag_content(last_line.find_class('node-depth-wrapper')[0]))", "ground_truth": "        actual_depth = int(retrieve_tag_content(last_line.find_class('node-depth-wrapper')[0]))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actual_line = retrieve_tag_content(last_line.find_class('language-clike')[0])", "prediction_line": "        actual_line = retrieve_tag_content(last_line.find_class('language-clike')[0])", "ground_truth": "        actual_line = retrieve_tag_content(last_line.find_class('language-clike')[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if element.get('class') is not None and 'call-site-link' in element.get('class'):", "prediction_line": "            if element.get('class') is not None and 'call-site-link' in element.get('class'):", "ground_truth": "            element_depth = int(retrieve_tag_content(element.find_class('node-depth-wrapper')[0]))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    if link_element.tag == 'a':", "prediction_line": "                    if link_element.tag == 'a':", "ground_truth": "                    if retrieve_tag_content(link_element) == '[function]':", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    break", "prediction_line": "                    break", "ground_truth": "                    parent_lines = retrieve_tag_content(element.find_class('language-clike')[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if retrieve_tag_content(link_element) == '[function]':", "prediction_line": "            if retrieve_tag_content(link_element) == '[function]':", "ground_truth": "            if retrieve_tag_content(link_element) == '[call site]':", "line_class": "infile", "zero_context": true}
{"original_prediction": "[-1]\n    class_name = class_name.replace('.', '/')", "prediction_line": "[-1]", "ground_truth": "    optimal_reached = safe_split(config.get('test', 'optimalreached'), \":\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    optimal_reached_mapping = process_mapping(config.get('test', 'optimalreachedmapping'))", "prediction_line": "    optimal_reached_mapping = process_mapping(config.get('test', 'optimalreachedmapping'))", "ground_truth": "    optimal_unreached = safe_split(config.get('test', 'optimalunreached'), \":\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    optimal_reached_mapping = process_mapping(config.get('test', 'optimalreachedmapping'))", "prediction_line": "    optimal_reached_mapping = process_mapping(config.get('test', 'optimalreachedmapping'))", "ground_truth": "    reached = safe_split(config.get('test', 'reached'), \":\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    unreached = safe_split(config.get('test', 'unreached'), \":\")", "prediction_line": "    unreached = safe_split(config.get('test', 'unreached'), \":\")", "ground_truth": "    unreached = safe_split(config.get('test', 'unreached'), \":\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    mapping = process_mapping(config.get('test', 'mapping'))", "prediction_line": "    mapping = process_mapping(config.get('test', 'mapping'))", "ground_truth": "    files_reached = process_mapping(config.get('test', 'filereached'))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    files_unreached = process_mapping(config.get('test', 'fileunreached'))", "prediction_line": "    files_unreached = process_mapping(config.get('test', 'fileunreached'))", "ground_truth": "    files_covered = process_mapping(config.get('test', 'filecovered'))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    check_coverage_view(tmpdir, files, class_name)", "prediction_line": "    check_coverage_view(tmpdir, files, class_name)", "ground_truth": "    check_function_list(tmpdir, optimal_reached, optimal_unreached, 'analysis_1.js')", "line_class": "infile", "zero_context": true}
{"original_prediction": "   assert \"report.html\" in files", "prediction_line": "   assert \"report.html\" in files", "ground_truth": "    check_essential_files(files, class_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    check_optimal_reached(files, optimal_reached)", "prediction_line": "    check_optimal_reached(files, optimal_reached)", "ground_truth": "    check_calltree_view(tmpdir, files, class_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actual_class = retrieve_tag_content(item.find_class('pfc-list-item-title')[0])", "prediction_line": "        actual_class = retrieve_tag_content(item.find_class('pfc-list-item-title')[0])", "ground_truth": "        actual_class = retrieve_tag_content(item)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    check_function_list(tmpdir, reached, unreached, 'analysis_2.js')", "prediction_line": "    check_function_list(tmpdir, reached, unreached, 'analysis_2.js')", "ground_truth": "    check_function_list(tmpdir, reached, unreached, 'all_functions.js')", "line_class": "infile", "zero_context": true}
{"original_prediction": "    check_file_list(tmpdir, files_reached, files_covered)", "prediction_line": "    check_file_list(tmpdir, files_reached, files_covered)", "ground_truth": "    check_fuzz_report(tmpdir, class_name, files_reached, files_covered, reached, unreached)", "line_class": "infile", "zero_context": true}
{"original_prediction": "   commands.run_analysis(", "prediction_line": "   commands.run_analysis(", "ground_truth": "    assert commands.run_analysis_on_dir(", "line_class": "inproject", "zero_context": true}
{"original_prediction": ". All Rights Reserved.", "prediction_line": ". All Rights Reserved.", "ground_truth": "#", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import subprocess\nimport tempfile", "prediction_line": "import subprocess", "ground_truth": "import shutil", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"Check the content of the generated fuzz report\"\"\"", "prediction_line": "    \"\"\"Check the content of the generated fuzz report\"\"\"", "ground_truth": "    \"\"\"Check main fuzz_report.html\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# Licensed under the Apache License, Version 2.0 (the \"License\");", "prediction_line": "# Licensed under the Apache License, Version 2.0 (the \"License\");", "ground_truth": "# Licensed under the Apache License, Version 2.0 (the \"License\");", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        assert actual_name_link == f'fuzzer_table_data.js#{actual_name.split(\" \")[1]}'", "prediction_line": "        assert actual_name_link == f'fuzzer_table_data.js#{actual_name.split(\" \")[1]}'", "ground_truth": "        assert actual_name_link.split('-')[1] in class_name", "line_class": "random", "zero_context": true}
{"original_prediction": "                break\n        assert actual_link == parent_class", "prediction_line": "                break", "ground_truth": "                break", "line_class": "random", "zero_context": true}
{"original_prediction": "        expected_files.append(f'{class_name[i]}_calltree.js')", "prediction_line": "        expected_files.append(f'{class_name[i]}_calltree.js')", "ground_truth": "        expected_files.append(f'calltree_view_{i}.html')", "line_class": "random", "zero_context": true}
{"original_prediction": "        assert fuzzer_yaml == fuzzer_yaml_link", "prediction_line": "        assert fuzzer_yaml == fuzzer_yaml_link", "ground_truth": "        assert fuzzer_yaml == fuzzer_yaml_link", "line_class": "random", "zero_context": true}
{"original_prediction": "                    break", "prediction_line": "                    break", "ground_truth": "                    else:", "line_class": "random", "zero_context": true}
{"original_prediction": "        # Add conclusion", "prediction_line": "        # Add conclusion", "ground_truth": "        logger.info(f\" - Finish running analysis {Analysis.get_name()}\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        self._get_source_file(callsite),", "prediction_line": "                        self._get_source_file(callsite),", "ground_truth": "                        self._get_source_file(callsite),", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        callsite.dst_function_line_number,", "prediction_line": "                        callsite.dst_function_line_number,", "ground_truth": "                        self._get_parent_func_name(callsite),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Retrieve all call sites and functions from all fuzzers profile", "prediction_line": "        # Retrieve all call sites and functions from all fuzzers profile", "ground_truth": "        logger.info(f\" - Running analysis {Analysis.get_name()}\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        (callsite_list, function_list) = self.retrieve_data_list(proj_profile, profiles)", "prediction_line": "        (callsite_list, function_list) = self.retrieve_data_list(proj_profile, profiles)", "ground_truth": "        callsite_list, function_list = self.retrieve_data_list(proj_profile, profiles)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        function_callsites = self.map_function_callsite(function_list, callsite_list)", "prediction_line": "        function_callsites = self.map_function_callsite(function_list, callsite_list)", "ground_truth": "        function_callsite_dict = self.map_function_callsite(function_list, callsite_list)", "line_class": "infile", "zero_context": true}
{"original_prediction": "ites\n        reachable_function_list = self.retrieve_reachable_functions(function_list, function_callsite_dict)", "prediction_line": "ites", "ground_truth": "        reachable_function_list = self.retrieve_reachable_functions(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if target_lang == 'c-cpp':", "prediction_line": "            if target_lang == 'c-cpp':", "ground_truth": "            if target_lang == \"c-cpp\":", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                for (key, callsite) in profile.function_call_depths.items():", "prediction_line": "                for (key, callsite) in profile.function_call_depths.items():", "ground_truth": "                callsite_list.extend(cfg_load.extract_all_callsites(profile.function_call_depths))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if parent_func in coverage:", "prediction_line": "                    if parent_func in coverage:", "ground_truth": "                    if coverage.is_func_lineno_hit(parent_func, lineno):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        callsite_list: List[cfg_load.CalltreeCallsite]", "prediction_line": "        callsite_list: List[cfg_load.CalltreeCallsite]", "ground_truth": "        callsites: List[cfg_load.CalltreeCallsite]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        project_profile: project_profile.ProjectProfile,", "prediction_line": "        project_profile: project_profile.ProjectProfile,", "ground_truth": "        proj_profile: project_profile.MergedProjectProfile,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        target_lang: str", "prediction_line": "        target_lang: str", "ground_truth": "        conclusions: List[html_helpers.HTMLConclusion]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Loop through the all function list for a project", "prediction_line": "        # Loop through the all function list for a project", "ground_truth": "        for fd in self.filter_function_list(function_list, profiles[0].target_lang):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        functions: List[function_profile.FunctionProfile],", "prediction_line": "        functions: List[function_profile.FunctionProfile],", "ground_truth": "        functions: List[function_profile.FunctionProfile],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                # Check if the function name is in the sink function list", "prediction_line": "                # Check if the function name is in the sink function list", "ground_truth": "                func_name = utils.demangle_cpp_func(fd.function_name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ) -> List[Tuple[str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str", "prediction_line": "    ) -> List[Tuple[str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str, str", "ground_truth": "    ) -> Tuple[List[cfg_load.CalltreeCallsite], List[function_profile.FunctionProfile]]:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "            elif target_lang == \"jvm\":", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        html_string += html_helpers.html_add_table_with_header(", "prediction_line": "        html_string += html_helpers.html_add_table_with_header(", "ground_truth": "        html_string += html_helpers.html_create_table_head(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Table with all function calls for each files", "prediction_line": "        # Table with all function calls for each files", "ground_truth": "        html_string += html_helpers.html_add_header_with_link(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            elif target_lang == \"python\":", "prediction_line": "            elif target_lang == \"python\":", "ground_truth": "            elif target_lang == \"python\":", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        fuzzer_profile: fuzzer_profile.FuzzerProfile,", "prediction_line": "        fuzzer_profile: fuzzer_profile.FuzzerProfile,", "ground_truth": "        profiles: List[fuzzer_profile.FuzzerProfile]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        callable entry points for fuzzer developers to improve their fuzzers to", "prediction_line": "        callable entry points for fuzzer developers to improve their fuzzers to", "ground_truth": "        entry point to reach them.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        # Retrieve all call sites and functions from all fuzzers profile", "prediction_line": "        \"\"\"", "ground_truth": "        1) Loop through the all function list of the project and see if any of the sink", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "by any of the fuzzers.", "prediction_line": "by any of the fuzzers.", "ground_truth": "        3) Analyse and show closet entry point suggestions for fuzzers developer to", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        This function aims to analyse the sink functions / methods", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        ('java.lang.ProcessBuilder', 'start'),", "prediction_line": "        ('java.lang.ProcessBuilder', 'start'),", "ground_truth": "        ('java.lang.ProcessBuilder', 'start')", "line_class": "random", "zero_context": true}
{"original_prediction": "    utils\n)", "prediction_line": "    utils", "ground_truth": "    utils", "line_class": "random", "zero_context": true}
{"original_prediction": "        target_lang: str", "prediction_line": "        target_lang: str", "ground_truth": "        basefolder: str,", "line_class": "random", "zero_context": true}
{"original_prediction": "        reachable_functions: List[str] = []", "prediction_line": "        reachable_functions: List[str] = []", "ground_truth": "        function_list = []", "line_class": "random", "zero_context": true}
{"original_prediction": "            if func_name in callsite_dict:", "prediction_line": "            if func_name in callsite_dict:", "ground_truth": "            if func_name in callsite_dict.keys():", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"\"\"Returns the order of the stain channels in the ``stain_matrix``.\"\"\"", "prediction_line": "            \"\"\"Returns the order of the stain channels in the ``stain_matrix``.\"\"\"", "ground_truth": "            first = MacenkoStainNormalizer._find_stain_index(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                MacenkoStainNormalizer.stain_color_map[\"hematoxylin\"], stain_matrix", "prediction_line": "                MacenkoStainNormalizer.stain_color_map[\"hematoxylin\"], stain_matrix", "ground_truth": "                MacenkoStainNormalizer.stain_color_map[stains[0]], stain_matrix", "line_class": "infile", "zero_context": true}
{"original_prediction": "       stain_matrix = stain_matrix.copy()", "prediction_line": "       stain_matrix = stain_matrix.copy()", "ground_truth": "        stain0 = stain_matrix[:, 0]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return np.stack([stain_matrix[:, i] for i in order])", "prediction_line": "            return np.stack([stain_matrix[:, i] for i in order])", "ground_truth": "            return np.stack([stain_matrix[..., j] for j in order], -1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        stain1 = stain_matrix[:, 1]", "prediction_line": "        stain1 = stain_matrix[:, 1]", "ground_truth": "        stain1 = stain_matrix[:, 1]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        order = _get_channel_order(stain_matrix)", "prediction_line": "        order = _get_channel_order(stain_matrix)", "ground_truth": "        return _ordered_stack(stain_matrix, _get_channel_order(stain_matrix))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Reorder the stain matrix", "prediction_line": "        # Reorder the stain matrix", "ground_truth": "        ordered_stain_matrix = self._reorder_stains(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        img_od = RgbToOd().apply(img_rgb, background_intensity=background_intensity)", "prediction_line": "        img_od = RgbToOd().apply(img_rgb, background_intensity=background_intensity)", "ground_truth": "        tile = Tile(img_rgb, None, None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        tile.filter(RgbToOd())", "prediction_line": "        tile.filter(RgbToOd())", "ground_truth": "        tissue_mask = TissueMask()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        tile.mask = tissue_mask.mask(tile)", "prediction_line": "        tile.mask = tissue_mask.mask(tile)", "ground_truth": "        mask = tissue_mask(tile)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       img_od = RgbToOd()(tile, mask)", "prediction_line": "       img_od = RgbToOd()(tile, mask)", "ground_truth": "        OD = RgbToOd(background_intensity)(img_rgb)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            min_v, max_v, stains, ODhat", "prediction_line": "            min_v, max_v, stains, ODhat", "ground_truth": "            self.normalize_columns(np.hstack([min_v, max_v]))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Calculate the stain matrix", "prediction_line": "        # Calculate the stain matrix", "ground_truth": "        # Min and max angles", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            Alpha value for the background color, by default 1", "prediction_line": "            Alpha value for the background color, by default 1", "ground_truth": "            Minimum angular percentile. Default is 1.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"Fill out empty columns in the stain matrix", "prediction_line": "        \"\"\"Fill out empty columns in the stain matrix", "ground_truth": "        \"\"\"Generates a complemented stain matrix.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# Unless required by applicable law or agreed to in writing, software", "prediction_line": "# Unless required by applicable law or agreed to in writing, software", "ground_truth": "# Unless required by applicable law or agreed to in writing, software", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# you may not use this file except in compliance with the License.", "prediction_line": "# you may not use this file except in compliance with the License.", "ground_truth": "# you may not use this file except in compliance with the License.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            )\n            second = MacenkoStainNormalizer._find_stain_index(", "prediction_line": "            )", "ground_truth": "            )", "line_class": "random", "zero_context": true}
{"original_prediction": "        beta: int = 1,", "prediction_line": "        beta: int = 1,", "ground_truth": "        beta: float = 0.15,", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"hematoxylin\": (0.644, 0.710, 0.285),", "prediction_line": "        \"hematoxylin\": (0.644, 0.710, 0.285),", "ground_truth": "        \"hematoxylin\": [0.65, 0.70, 0.29],", "line_class": "random", "zero_context": true}
{"original_prediction": "        if stains is None:", "prediction_line": "        if stains is None:", "ground_truth": "        stains = [\"hematoxylin\", \"eosin\"] if stains is None else stains", "line_class": "random", "zero_context": true}
{"original_prediction": "    @staticmethod", "prediction_line": "    @staticmethod", "ground_truth": "    @staticmethod", "line_class": "random", "zero_context": true}
{"original_prediction": "            request, MacenkoStainNormalizer, \"_find_stain_index\"", "prediction_line": "            request, MacenkoStainNormalizer, \"_find_stain_index\"", "ground_truth": "            request, MacenkoStainNormalizer, \"_find_stain_index\", autospec=False", "line_class": "commited", "zero_context": true}
{"original_prediction": "        reordered_stain_matrix = MacenkoStainNormalizer._reorder_stains(", "prediction_line": "        reordered_stain_matrix = MacenkoStainNormalizer._reorder_stains(", "ground_truth": "        reordered_stain_matrix = MacenkoStainNormalizer._reorder_stains(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            stain_matrix, stains, first_stain_reference", "prediction_line": "            stain_matrix, stains, first_stain_reference", "ground_truth": "            stain_matrix, stains", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _find_stain_index_.assert_called_once_with(first_stain_reference, stain_matrix)", "prediction_line": "        _find_stain_index_.assert_called_once_with(first_stain_reference, stain_matrix)", "ground_truth": "        _find_stain_index_.assert_called_once_with(first_stain_reference, stain_matrix)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        stain_matrix = np.array(", "prediction_line": "        stain_matrix = np.array(", "ground_truth": "        stain_matrix = np.array(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        complemented_stain_matrix = MacenkoStainNormalizer._complement_stain_matrix(stain_matrix)", "prediction_line": "        complemented_stain_matrix = MacenkoStainNormalizer._complement_stain_matrix(stain_matrix)", "ground_truth": "        complemented_stain_matrix = MacenkoStainNormalizer._complement_stain_matrix(", "line_class": "commited", "zero_context": true}
{"original_prediction": "stain_matrix)", "prediction_line": "stain_matrix)", "ground_truth": "            stain_matrix", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _complement_stain_matrix = method_mock(", "prediction_line": "        _complement_stain_matrix = method_mock(", "ground_truth": "        _complement_stain_matrix = method_mock(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            request, MacenkoStainNormalizer, \"_complement_stain_matrix\"", "prediction_line": "            request, MacenkoStainNormalizer, \"_complement_stain_matrix\"", "ground_truth": "            request, MacenkoStainNormalizer, \"_complement_stain_matrix\", autospec=False", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _complement_stain_matrix.return_value = np.array(", "prediction_line": "        _complement_stain_matrix.return_value = np.array(", "ground_truth": "        _complement_stain_matrix.return_value = np.array(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _reorder_stains = method_mock(", "prediction_line": "        _reorder_stains = method_mock(", "ground_truth": "        _reorder_stains = method_mock(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            request, MacenkoStainNormalizer, \"_reorder_stains\", autospec=False", "prediction_line": "            request, MacenkoStainNormalizer, \"_reorder_stains\", autospec=False", "ground_truth": "            request, MacenkoStainNormalizer, \"_reorder_stains\", autospec=False", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _reorder_stains.return_value = np.array(", "prediction_line": "        _reorder_stains.return_value = np.array(", "ground_truth": "        _reorder_stains.return_value = np.array(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        stain_index = MacenkoStainNormalizer._find_stain_index(stain_vector, reference)", "prediction_line": "        stain_index = MacenkoStainNormalizer._find_stain_index(stain_vector, reference)", "ground_truth": "        stain_index = MacenkoStainNormalizer._find_stain_index(reference, stain_vector)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        macenko_stain_normalizer = MacenkoStainNormalizer()", "prediction_line": "        macenko_stain_normalizer = MacenkoStainNormalizer()", "ground_truth": "        macenko_stain_normalizer = MacenkoStainNormalizer()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        stain_matrix = macenko_stain_normalizer.stain_matrix(img)", "prediction_line": "        stain_matrix = macenko_stain_normalizer.stain_matrix(img)", "ground_truth": "        stain_matrix = macenko_stain_normalizer.stain_matrix(img)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert isinstance(stain_matrix, np.ndarray)", "prediction_line": "        assert isinstance(stain_matrix, np.ndarray)", "ground_truth": "        assert isinstance(stain_matrix, np.ndarray)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        np.testing.assert_array_almost_equal(stain_matrix, expected_stain_matrix)", "prediction_line": "        np.testing.assert_array_almost_equal(stain_matrix, expected_stain_matrix)", "ground_truth": "        np.testing.assert_array_almost_equal(stain_matrix, expected_stain_matrix)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _complement_stain_matrix.assert_called_once()", "prediction_line": "        _complement_stain_matrix.assert_called_once()", "ground_truth": "        _complement_stain_matrix.assert_called_once()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _reorder_stains.assert_called_once()", "prediction_line": "        _reorder_stains.assert_called_once()", "ground_truth": "        _reorder_stains.assert_called_once()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            _ = macenko_stain_normalizer.stain_matrix(img)", "prediction_line": "            _ = macenko_stain_normalizer.stain_matrix(img)", "ground_truth": "            macenko_stain_normalizer.stain_matrix(img)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            macenko_stain_normalizer.stain_matrix(img, stains=[\"hematoxylin\", \"eosin\"])", "prediction_line": "            macenko_stain_normalizer.stain_matrix(img, stains=[\"hematoxylin\", \"eosin\"])", "ground_truth": "            macenko_stain_normalizer.stain_matrix(img, stains=[\"one\", \"two\", \"three\"])", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _complement_stain_matrix = method_mock(", "prediction_line": "        _complement_stain_matrix = method_mock(", "ground_truth": "        _normalize_columns = method_mock(request, LinalgMixin, \"normalize_columns\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        _get_stain_matrix_ = method_mock(", "prediction_line": "        _get_stain_matrix_ = method_mock(", "ground_truth": "        _tissue_mask_call = method_mock(request, TissueMask, \"__call__\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        _tissue_mask_call.return_value = NpArrayMock(", "prediction_line": "        _tissue_mask_call.return_value = NpArrayMock(", "ground_truth": "        _tissue_mask_call.return_value = NpArrayMock.ONES_500X500_BOOL", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        _linalg_norm_call = method_mock(request, LinalgMixin, \"norm\")", "prediction_line": "        _linalg_norm_call = method_mock(request, LinalgMixin, \"norm\")", "ground_truth": "        _two_principal_components = method_mock(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            request, LinalgMixin, \"two_principal_components\"", "prediction_line": "            request, LinalgMixin, \"two_principal_components\"", "ground_truth": "            request, LinalgMixin, \"two_principal_components\", autospec=False", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        reordered_stain_matrix = MacenkoStainNormalizer._reorder_stains(", "prediction_line": "        reordered_stain_matrix = MacenkoStainNormalizer._reorder_stains(", "ground_truth": "        _find_stain_index_ = method_mock(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    )\n    def it_knows_how_to_reorder_stain_matrix(", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def it_knows_how_to_reorder_stain_matrix(", "prediction_line": "    def it_knows_how_to_reorder_stain_matrix(", "ground_truth": "    def it_knows_how_to_reorder_stains(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class Test_MacenkoStainNormalizer_init:", "prediction_line": "class Test_MacenkoStainNormalizer_init:", "ground_truth": "class Describe_MacenkoStainNormalizer:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def it_knows_how_to_normalize_stains_issue(self, img, request):", "prediction_line": "    def it_knows_how_to_normalize_stains_issue(self, img, request):", "ground_truth": "    def it_knows_its_stain_matrix(self, request, img):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                0,\n                [0.65, 0.7, 0.29],", "prediction_line": "                0,", "ground_truth": "                0,", "line_class": "random", "zero_context": true}
{"original_prediction": "            ]\n        )", "prediction_line": "            ]", "ground_truth": "            ]", "line_class": "random", "zero_context": true}
{"original_prediction": "        )\n        _find_stain_index_.return_value = first_stain_index", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"\"\"Initialize the Gaussian descriptor class.", "prediction_line": "        \"\"\"Initialize the Gaussian descriptor class.", "ground_truth": "        super(GaussianDescriptors, self).__init__(parameters)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return self.__calculate_gaussian_descriptors(atoms,", "prediction_line": "        return self.__calculate_gaussian_descriptors(atoms,", "ground_truth": "        return self.__calculate_gaussian_descriptors(atoms, working_directory,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Calculate the descriptors.", "prediction_line": "        # Calculate the descriptors.", "ground_truth": "        return self.__calculate_gaussian_descriptors(atoms,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.grid_dimensions_lammps = []", "prediction_line": "        self.grid_dimensions_lammps = []", "ground_truth": "        self.verbosity = parameters.verbosity", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Add the LAMMPS arguments.", "prediction_line": "        # Add the LAMMPS arguments.", "ground_truth": "        lmp_cmdargs = set_cmdlinevars(lmp_cmdargs, lammps_dict)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        atoms = self.enforce_pbc(atoms)", "prediction_line": "        atoms = self.enforce_pbc(atoms)", "ground_truth": "        atoms = self.enforce_pbc(atoms)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        descriptors = lmp.extract_compute(\"ggrid\", \"array\")", "prediction_line": "        descriptors = lmp.extract_compute(\"ggrid\", \"array\")", "ground_truth": "        nrows_ggrid = extract_compute_np(lmp, \"ggrid\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ncols_ggrid = extract_compute_np(lmp, \"ggrid\",", "prediction_line": "        ncols_ggrid = extract_compute_np(lmp, \"ggrid\",", "ground_truth": "        ncols_ggrid = extract_compute_np(lmp, \"ggrid\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    barrier", "prediction_line": "    barrier", "ground_truth": "    barrier", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            extract_compute_np(lmp, \"ggrid\", lammps_constants.LMP_STYLE_LOCAL,", "prediction_line": "            extract_compute_np(lmp, \"ggrid\", lammps_constants.LMP_STYLE_LOCAL,", "ground_truth": "            extract_compute_np(lmp, \"ggrid\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # We need to convert the atoms to a format that LAMMPS can read.", "prediction_line": "        # We need to convert the atoms to a format that LAMMPS can read.", "ground_truth": "        # Get the grid dimensions.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def calculate_from_qe_in(self, qe_in_file, qe_in_directory,", "prediction_line": "    def calculate_from_qe_in(self, qe_in_file, qe_in_directory,", "ground_truth": "    def calculate_from_atoms(self, atoms, grid_dimensions,", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # Clean up.", "prediction_line": "        # Clean up.", "ground_truth": "        print(gaussian_descriptors_np[100, 0:6])", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # Check if the LAMMPS executable is available.", "prediction_line": "        # Check if the LAMMPS executable is available.", "ground_truth": "        self.in_format_ase = \"espresso-out\"", "line_class": "random", "zero_context": true}
{"original_prediction": "            grid_dimensions = self.dbg_grid_dimensions", "prediction_line": "            grid_dimensions = self.dbg_grid_dimensions", "ground_truth": "            nx = self.dbg_grid_dimensions[0]", "line_class": "random", "zero_context": true}
{"original_prediction": "                       \"ncount\": self.parameters.gaussian_descriptors_ncount,", "prediction_line": "                       \"ncount\": self.parameters.gaussian_descriptors_ncount,", "ground_truth": "                       \"atom_config_fname\": ase_out_path}", "line_class": "random", "zero_context": true}
{"original_prediction": "        if out_units == \"None\":", "prediction_line": "        if out_units == \"None\":", "ground_truth": "        if out_units == \"None\":", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.out_format_ase = \"\"", "prediction_line": "        self.out_format_ase = \"\"", "ground_truth": "        self.grid_dimensions = []", "line_class": "random", "zero_context": true}
{"original_prediction": "            with open(overlaps_dump_path, \"rb\") as f:", "prediction_line": "            with open(overlaps_dump_path, \"rb\") as f:", "ground_truth": "            duplicates[(task_name, task_set)] = pickle.load(open(overlaps_dump_path, \"rb\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "                clean_chunks.append(dirty_string[splice_idx:start])", "prediction_line": "                clean_chunks.append(dirty_string[splice_idx:start])", "ground_truth": "                clean_chunks.append(dirty_string[splice_idx: start])", "line_class": "common", "zero_context": true}
{"original_prediction": "           if start > splice_idx:", "prediction_line": "           if start > splice_idx:", "ground_truth": "            if start - splice_idx > self.minimum_slice_length:", "line_class": "common", "zero_context": true}
{"original_prediction": "    print(f\"Lookups built in {time.perf_counter() - start:.2f} seconds\")", "prediction_line": "    print(f\"Lookups built in {time.perf_counter() - start:.2f} seconds\")", "ground_truth": "    elapsed = time.perf_counter() - start", "line_class": "common", "zero_context": true}
{"original_prediction": "                        line_counter = 0", "prediction_line": "                        line_counter = 0", "ground_truth": "                        progress.update(bytes_read)", "line_class": "common", "zero_context": true}
{"original_prediction": "            lookups[(task_name, task_set)] = pickle.load(open(task_set_lookup_path, \"rb\"))", "prediction_line": "            lookups[(task_name, task_set)] = pickle.load(open(task_set_lookup_path, \"rb\"))", "ground_truth": "            lookups[(task_name, task_set)] = pickle.load(open(task_set_lookup_path, \"rb\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "    task_set_ngrams = {}", "prediction_line": "    task_set_ngrams = {}", "ground_truth": "    start = time.perf_counter()", "line_class": "common", "zero_context": true}
{"original_prediction": "        dirt_string = dirt_string.lower()", "prediction_line": "        dirt_string = dirt_string.lower()", "ground_truth": "        self.dirt_ngrams.update(janitor_util.clean_ngram(dirt_string, self.delete_chars, self.ngram_n))", "line_class": "common", "zero_context": true}
{"original_prediction": "        for dirty_part in dirty_parts:", "prediction_line": "        for dirty_part in dirty_parts:", "ground_truth": "        for i, (ngram, start, end) in enumerate(dirty_parts):", "line_class": "common", "zero_context": true}
{"original_prediction": "            return pickle.load(fp)", "prediction_line": "            return pickle.load(fp)", "ground_truth": "            self.dirt_ngrams = pickle.load(fp)", "line_class": "common", "zero_context": true}
{"original_prediction": "            if start > splice_idx:", "prediction_line": "            if start > splice_idx:", "ground_truth": "            start = max(0, start - self.window_to_remove)", "line_class": "common", "zero_context": true}
{"original_prediction": "            janitor_util.register_contaminant(dirt_string, self.ngram_n)", "prediction_line": "            janitor_util.register_contaminant(dirt_string, self.ngram_n)", "ground_truth": "            return self.register_contaminant_cpp(dirt_string)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.register_contaminant_py(dirt_string)", "prediction_line": "            return self.register_contaminant_py(dirt_string)", "ground_truth": "            return self.register_contaminant_python(dirt_string)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.clean_cpp(dirty_string)", "prediction_line": "            return self.clean_cpp(dirty_string)", "ground_truth": "            return self.clean_cpp(dirty_string)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.clean_python(dirty_string)", "prediction_line": "            return self.clean_python(dirty_string)", "ground_truth": "            return self.clean_python(dirty_string)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            overlaps_dump_path = get_overlaps_dump_path(task_name, task_set, ngrams_n_size, limit)", "prediction_line": "            overlaps_dump_path = get_overlaps_dump_path(task_name, task_set, ngrams_n_size, limit)", "ground_truth": "            overlaps_dump_path = get_overlaps_dump_path(task_name, task_set, ngrams_n_size, limit)", "line_class": "infile", "zero_context": true}
{"original_prediction": "   # print(\"get_train_overlap\", ngrams_path, ngrams_n_size)", "prediction_line": "   # print(\"get_train_overlap\", ngrams_path, ngrams_n_size)", "ground_truth": "    janitor = Janitor()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        print(\"Decompressing file, please wait...\")", "prediction_line": "        print(\"Decompressing file, please wait...\")", "ground_truth": "        reader = TextReader(decompressed_file)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return reader.read_tqdm()", "prediction_line": "        return reader.read_tqdm()", "ground_truth": "        yield from reader.read_tqdm()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self._split_chunks(dirty_string, contamination_indices)", "prediction_line": "        return self._split_chunks(dirty_string, contamination_indices)", "ground_truth": "        return self._split_chunks(dirty_string, contamination_indices)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return form_ngrams(tokens, n)", "prediction_line": "    return form_ngrams(tokens, n)", "ground_truth": "    ngram_seqs = form_ngrams(iter(tokens), n)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.dirt_ngrams.update(word_ngrams(self.normalize_string(dirt_string), self.ngram_n))", "prediction_line": "        self.dirt_ngrams.update(word_ngrams(self.normalize_string(dirt_string), self.ngram_n))", "ground_truth": "        self.dirt_ngrams.update(word_ngrams(self.normalize_string(dirt_string), self.ngram_n))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ngram_seqs = form_ngrams(split_indices(s), n)", "prediction_line": "    ngram_seqs = form_ngrams(split_indices(s), n)", "ground_truth": "    tokens_with_indices = split_indices(s)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for ngram, idx_pair in word_ngrams_indices(self.normalize_string(dirty_string), self.ngram_n)", "prediction_line": "            for ngram, idx_pair in word_ngrams_indices(self.normalize_string(dirty_string), self.ngram_n)", "ground_truth": "            for dirty_ngram, idx_pair in word_ngrams_indices(dirty_string, self.ngram_n)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if dirty_ngram in self.dirt_ngrams", "prediction_line": "            if dirty_ngram in self.dirt_ngrams", "ground_truth": "            if self.normalize_string(dirty_ngram) in self.dirt_ngrams", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ngram_seqs = form_ngrams(iter(tokens_with_indices), n)", "prediction_line": "    ngram_seqs = form_ngrams(iter(tokens_with_indices), n)", "ground_truth": "    ngram_seqs_with_indices = form_ngrams(tokens_with_indices, n)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                for ngram in janitor.get_ngrams(document, ngrams_n_size):", "prediction_line": "                for ngram in janitor.get_ngrams(document, ngrams_n_size):", "ground_truth": "                ngrams = word_ngrams(janitor.normalize_string(document), ngrams_n_size)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            ngrams = janitor.load_ngrams(file)", "prediction_line": "            ngrams = janitor.load_ngrams(file)", "ground_truth": "            reader = ZStdTextReader(file)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    start = 0", "prediction_line": "    start = 0", "ground_truth": "    return ((m.group(0), (m.start(), m.end() - 1)) for m in re.finditer(r'\\S+', s))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # Generator of ngrams of (ngram words, their start/end indices)", "prediction_line": "    # Generator of ngrams of (ngram words, their start/end indices)", "ground_truth": "    # Generator of pairs of word and index ngrams", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"Clean a string of contamination\"\"\"", "prediction_line": "        \"\"\"Clean a string of contamination\"\"\"", "ground_truth": "        \"\"\"Clean a string (e.g. a training set) by removing all ngrams previously", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "The cache is invalidated if the ngrams_path or ngrams_n_size changes.", "prediction_line": "The cache is invalidated if the ngrams_path or ngrams_n_size changes.", "ground_truth": "# Currently calculating some per file ngram stats for interest, might remove before merging into main", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def write(self, s):", "prediction_line": "    def write(self, s):", "ground_truth": "    def add_data(self, data, meta={}):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        else:\n            return self.register_contaminant_py(dirt_string)", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "self, delete_chars=string.punctuation + \" \"):", "prediction_line": "self, delete_chars=string.punctuation + \" \"):", "ground_truth": "            self,", "line_class": "random", "zero_context": true}
{"original_prediction": "        dirty_string_length = len(dirty_string)", "prediction_line": "        dirty_string_length = len(dirty_string)", "ground_truth": "        splice_idx = 0", "line_class": "random", "zero_context": true}
{"original_prediction": "    def get_lookup_dump_path(task_name, task_set, ngrams_n_size, limit):", "prediction_line": "    def get_lookup_dump_path(task_name, task_set, ngrams_n_size, limit):", "ground_truth": "    lookups = {}", "line_class": "random", "zero_context": true}
{"original_prediction": "    return (\" \".join(ngram) for ngram in ngram_seqs)", "prediction_line": "    return (\" \".join(ngram) for ngram in ngram_seqs)", "ground_truth": "    return (\" \".join(ngram) for ngram in ngram_seqs)", "line_class": "random", "zero_context": true}
{"original_prediction": "        max_memory[\"max_memory_per_gpu\"] = max_memory_per_gpu_map", "prediction_line": "        max_memory[\"max_memory_per_gpu\"] = max_memory_per_gpu_map", "ground_truth": "        max_memory.update(max_memory_per_gpu_map)", "line_class": "common", "zero_context": true}
{"original_prediction": "                        string, self.tokenizer.eos_token, self.max_length", "prediction_line": "                        string, self.tokenizer.eos_token, self.max_length", "ground_truth": "                        token_list=self.tok_encode(string),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self._loglikelihood_tokens(new_requests)", "prediction_line": "        return self._loglikelihood_tokens(new_requests)", "ground_truth": "        return self._loglikelihood_tokens(new_requests)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._device = torch.device(device)", "prediction_line": "        self._device = torch.device(device)", "ground_truth": "        self._device = device", "line_class": "infile", "zero_context": true}
{"original_prediction": "            # Fill empty continuations with the EOS token.", "prediction_line": "            # Fill empty continuations with the EOS token.", "ground_truth": "            context_enc = self.tok_encode_batch(context)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            accelerate_kwargs = _get_accelerate_args(", "prediction_line": "            accelerate_kwargs = _get_accelerate_args(", "ground_truth": "            accelerate_kwargs = _get_accelerate_args(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    \"attention_mask\": torch.ones_like(contexts_enc),", "prediction_line": "                    \"attention_mask\": torch.ones_like(contexts_enc),", "ground_truth": "                    \"attention_mask\": (contexts_enc != self.eot_token_id).long(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "                stop_sequences = [self.eot_token]", "prediction_line": "                stop_sequences = [self.eot_token]", "ground_truth": "                until = [self.eot_token]", "line_class": "infile", "zero_context": true}
{"original_prediction": "self.tokenizer, self.max_length", "prediction_line": "self.tokenizer, self.max_length", "ground_truth": "                pad_token_id=self.eot_token_id,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._dtype = _get_dtype(dtype, self._config)", "prediction_line": "        self._dtype = _get_dtype(dtype, self._config)", "ground_truth": "        self.tokenizer.model_max_length = self.max_length", "line_class": "infile", "zero_context": true}
{"original_prediction": "        attention_mask = inputs[\"attention_mask\"][:, -self.max_length :].to(self.device)", "prediction_line": "        attention_mask = inputs[\"attention_mask\"][:, -self.max_length :].to(self.device)", "ground_truth": "        attention_mask = inputs[\"attention_mask\"][:, -self.max_length :].to(self.device)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._dtype = _get_dtype(dtype, self._config)", "prediction_line": "        self._dtype = _get_dtype(dtype, self._config)", "ground_truth": "        self.model = self._create_auto_model(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            truncation=True,", "prediction_line": "            truncation=True,", "ground_truth": "            add_special_tokens=self.add_special_tokens,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    sequence=sequence,", "prediction_line": "                    sequence=sequence,", "ground_truth": "                    sequence, tokenizer, initial_decoder_input_length, batch_size", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for i, response in enumerate(responses):", "prediction_line": "            for i, response in enumerate(responses):", "ground_truth": "            responses = self.tok_decode(responses.tolist())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Ensure that the context does not encroach into the `space`", "prediction_line": "        # Ensure that the context does not encroach into the `space`", "ground_truth": "        input_ids = inputs[\"input_ids\"][:, -self.max_length :].to(self.device)", "line_class": "infile", "zero_context": true}
{"original_prediction": "class TransformerLM(BaseLM):", "prediction_line": "class TransformerLM(BaseLM):", "ground_truth": "_DeviceMapping = NewType(\"DeviceMapping\", Mapping[str, Union[int, str, torch.device]])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        attention_mask = attention_mask.to(self.device)", "prediction_line": "        attention_mask = attention_mask.to(self.device)", "ground_truth": "        attention_mask = attention_mask.to(self.device)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                continuation_enc[key] = continuation_enc[key][:, : self.max_length]", "prediction_line": "                continuation_enc[key] = continuation_enc[key][:, : self.max_length]", "ground_truth": "                continuation_enc[key] = continuation_enc[key][:, -self.max_length :]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        device_map_option: Optional[str] = \"auto\",", "prediction_line": "        device_map_option: Optional[str] = \"auto\",", "ground_truth": "        batch_size: Optional[int] = 1,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        **kwargs,", "prediction_line": "        **kwargs,", "ground_truth": "        device: Optional[Union[int, str]] = \"cuda\",", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # TODO: Add `past` support.", "prediction_line": "        # TODO: Add `past` support.", "ground_truth": "        input_ids = input_ids.to(self.device)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        device: Optional[Union[str, torch.device]] = None,", "prediction_line": "        device: Optional[Union[str, torch.device]] = None,", "ground_truth": "        add_special_tokens: Optional[bool] = None,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            targets_tokens = targets_tokens.to(self.device)", "prediction_line": "            targets_tokens = targets_tokens.to(self.device)", "ground_truth": "            targets_tokens = targets_tokens.to(self.device)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        device: Optional[Union[str, torch.device]] = \"cuda\" if torch.cuda.is_available() else \"cpu\",", "prediction_line": "        device: Optional[Union[str, torch.device]] = \"cuda\" if torch.cuda.is_available() else \"cpu\",", "ground_truth": "        max_length: Optional[int] = None,", "line_class": "infile", "zero_context": true}
{"original_prediction": "c if c else self.eot_token for c in context]", "prediction_line": "c if c else self.eot_token for c in context]", "ground_truth": "                f\"{self.eot_token}\" if len(text) == 0 else text for text in context", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return x", "prediction_line": "            return x", "ground_truth": "            tokens = self.tok_encode(x[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.sequence = sequence", "prediction_line": "        self.sequence = sequence", "ground_truth": "        self.done_tracker = [False] * batch_size", "line_class": "infile", "zero_context": true}
{"original_prediction": "            loglikelihoods.append(", "prediction_line": "            loglikelihoods.append(", "ground_truth": "            string_nll = self._loglikelihood_tokens(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            continuation_enc = self.tok_encode_batch(continuation)", "prediction_line": "            continuation_enc = self.tok_encode_batch(continuation)", "ground_truth": "            continuation_enc = self.tok_encode_batch(list(continuation))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                max_seq_len=self.max_length,", "prediction_line": "                max_seq_len=self.max_length,", "ground_truth": "                max_seq_len=self.max_length,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._max_length = max_length", "prediction_line": "        self._max_length = max_length", "ground_truth": "        self._max_length = max_length", "line_class": "infile", "zero_context": true}
{"original_prediction": "            logits = self._model_call(inputs_tokens, targets_tokens)", "prediction_line": "            logits = self._model_call(inputs_tokens, targets_tokens)", "ground_truth": "            outputs = self._model_call(inputs=inputs_tokens, labels=targets_tokens)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        device: Optional[Union[str, torch.device]] = None,", "prediction_line": "        device: Optional[Union[str, torch.device]] = None,", "ground_truth": "        max_gen_toks: Optional[int] = 256,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                not add_special_tokens", "prediction_line": "                not add_special_tokens", "ground_truth": "                not add_special_tokens", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        max_window_size=self.max_length,", "prediction_line": "                        max_window_size=self.max_length,", "ground_truth": "                        prefix_token=self.eot_token_id,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.tokenizer = tokenizer", "prediction_line": "        self.tokenizer = tokenizer", "ground_truth": "        self.sequence_ids = tokenizer.encode(sequence, add_special_tokens=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"Returns a pre-trained tokenizer from a pre-trained tokenizer configuration.\"\"\"", "prediction_line": "        \"\"\"Returns a pre-trained tokenizer from a pre-trained tokenizer configuration.\"\"\"", "ground_truth": "        tokenizer = super()._create_auto_tokenizer(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            :, self.max_gen_toks - self.max_length :", "prediction_line": "            :, self.max_gen_toks - self.max_length :", "ground_truth": "            :, self.max_gen_toks - self.max_length :", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return results", "prediction_line": "        return results", "ground_truth": "        return reorder.get_original(results)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    self.cache_hook.add_partial(\"loglikelihood\", cache_key, answer)", "prediction_line": "                    self.cache_hook.add_partial(\"loglikelihood\", cache_key, answer)", "ground_truth": "                    self.cache_hook.add_partial(\"loglikelihood\", cache_key, answer)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    utils.rolling_window(string, self.max_length),", "prediction_line": "                    utils.rolling_window(string, self.max_length),", "ground_truth": "                    utils.get_rolling_token_windows(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    lambda x: self.tokenizer.encode(x, add_special_tokens=False),", "prediction_line": "                    lambda x: self.tokenizer.encode(x, add_special_tokens=False),", "ground_truth": "                    utils.make_disjoint_window,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for batch in tqdm(reorder.get_batches(self.batch_size)):", "prediction_line": "        for batch in tqdm(reorder.get_batches(self.batch_size)):", "ground_truth": "        for chunk in utils.chunks(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "reorder.reorder(), self.batch_size):", "prediction_line": "reorder.reorder(), self.batch_size):", "ground_truth": "            tqdm(reorder.get_reordered(), disable=False), self.batch_size", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for context, continuation in requests:", "prediction_line": "        for context, continuation in requests:", "ground_truth": "        for chunk in utils.chunks(requests, self.batch_size):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for batch in utils.chunked(requests, self.batch_size):", "prediction_line": "        for batch in utils.chunked(requests, self.batch_size):", "ground_truth": "        reorder = utils.Reorderer(requests, _collate)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        determine if a model was trained with special tokens.", "prediction_line": "        determine if a model was trained with special tokens.", "ground_truth": "        check whether or not an arbitrary model was trained with special tokens.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"Creates an `AutoModel` from the given `pretrained` model ID or path.", "prediction_line": "        \"\"\"Creates an `AutoModel` from the given `pretrained` model ID or path.", "ground_truth": "        \"\"\"Returns a pre-trained pytorch model from a pre-trained model configuration.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from lm_eval.base import LM", "prediction_line": "from lm_eval.base import LM", "ground_truth": "from lm_eval.base import BaseLM", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def _model_generate(", "prediction_line": "    def _model_generate(", "ground_truth": "    def _model_generate(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            contexts = BatchEncoding(", "prediction_line": "            contexts = BatchEncoding(", "ground_truth": "            contexts_enc = torch.Tensor(contexts).long()", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    if max_cpu_memory is not None:", "prediction_line": "    if max_cpu_memory is not None:", "ground_truth": "    if max_cpu_memory is not None:", "line_class": "random", "zero_context": true}
{"original_prediction": "        device_map_option: Optional[str] = \"auto\",", "prediction_line": "        device_map_option: Optional[str] = \"auto\",", "ground_truth": "        revision: Optional[str] = \"main\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        return self._device", "prediction_line": "        return self._device", "ground_truth": "        return self._device", "line_class": "random", "zero_context": true}
{"original_prediction": "            raise NotImplementedError(", "prediction_line": "            raise NotImplementedError(", "ground_truth": "            raise ValueError(", "line_class": "random", "zero_context": true}
{"original_prediction": "            pretrained,", "prediction_line": "            pretrained,", "ground_truth": "            pretrained,", "line_class": "random", "zero_context": true}
{"original_prediction": "        # 1.0.0: Initial release", "prediction_line": "        # 1.0.0: Initial release", "ground_truth": "        super().__init__(version=datasets.Version(\"0.0.1\"), **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        EthicsConfig(", "prediction_line": "        EthicsConfig(", "ground_truth": "        EthicsConfig(", "line_class": "infile", "zero_context": true}
{"original_prediction": "import sys\nfrom typing import Any, Callable, Dict, List, Optional, Tuple", "prediction_line": "import sys", "ground_truth": "import datasets", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def _download_and_prepare(self, dl_manager, download_config=None):", "prediction_line": "    def _download_and_prepare(self, dl_manager, download_config=None):", "ground_truth": "    def _split_generators(self, dl_manager):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    # Scenarios come in groups of 4.", "prediction_line": "                    # Scenarios come in groups of 4.", "ground_truth": "                    # Scenarios come in groups of 5.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "to\nbetter align AI with human values.", "prediction_line": "to", "ground_truth": "to steer chatbot outputs or eventually regularize open-ended reinforcement", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def _generate_examples(self, filepath, split):", "prediction_line": "    def _generate_examples(self, filepath, split):", "ground_truth": "    def _generate_examples(self, filepath, split):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                \"group_id\": datasets.Value(\"int32\"),", "prediction_line": "                \"group_id\": datasets.Value(\"int32\"),", "ground_truth": "                \"group_id\": datasets.Value(\"int32\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "            prefix=\"commonsense\",", "prediction_line": "            prefix=\"commonsense\",", "ground_truth": "            prefix=\"cm\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            name=\"duty\",", "prediction_line": "            name=\"duty\",", "ground_truth": "            name=\"justice\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                if self.config.name == \"virtue\":", "prediction_line": "                if self.config.name == \"virtue\":", "ground_truth": "                if self.config.name == \"deontology\":", "line_class": "random", "zero_context": true}
{"original_prediction": "                        group_id += 1", "prediction_line": "                        group_id += 1", "ground_truth": "                        group_id += 1", "line_class": "random", "zero_context": true}
{"original_prediction": "    XNLI_ar,", "prediction_line": "    XNLI_ar,", "ground_truth": "    XNLI_ar,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_bg,", "prediction_line": "    XNLI_bg,", "ground_truth": "    XNLI_bg,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_de,", "prediction_line": "    XNLI_de,", "ground_truth": "    XNLI_de,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_el,", "prediction_line": "    XNLI_el,", "ground_truth": "    XNLI_el,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_en,", "prediction_line": "    XNLI_en,", "ground_truth": "    XNLI_en,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_es,", "prediction_line": "    XNLI_es,", "ground_truth": "    XNLI_es,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_fr,", "prediction_line": "    XNLI_fr,", "ground_truth": "    XNLI_fr,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_hi,", "prediction_line": "    XNLI_hi,", "ground_truth": "    XNLI_hi,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_ru,", "prediction_line": "    XNLI_ru,", "ground_truth": "    XNLI_ru,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_sw,", "prediction_line": "    XNLI_sw,", "ground_truth": "    XNLI_sw,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_th,", "prediction_line": "    XNLI_th,", "ground_truth": "    XNLI_th,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_tr,", "prediction_line": "    XNLI_tr,", "ground_truth": "    XNLI_tr,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_ur,", "prediction_line": "    XNLI_ur,", "ground_truth": "    XNLI_ur,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_vi,", "prediction_line": "    XNLI_vi,", "ground_truth": "    XNLI_vi,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    XNLI_zh,", "prediction_line": "    XNLI_zh,", "ground_truth": "    XNLI_zh,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        ll_false = rf.loglikelihood_rolling(ctx.replace(\"[MASK]\", self.CONTRADICTION_LABEL))", "prediction_line": "        ll_false = rf.loglikelihood_rolling(ctx.replace(\"[MASK]\", self.CONTRADICTION_LABEL))", "ground_truth": "        ll_false = rf.loglikelihood_rolling(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return {\n            \"acc\": mean,", "prediction_line": "        return {", "ground_truth": "        return {\"acc\": mean}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        target = self.doc_to_target(doc)", "prediction_line": "        target = self.doc_to_target(doc)", "ground_truth": "        ll_true = rf.loglikelihood_rolling(ctx.replace(\"[MASK]\", self.ENTAILMENT_LABEL))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ll_false = rf.loglikelihood_rolling(ctx.replace(\"[MASK]\", self.CONTRADICTION_LABEL))", "prediction_line": "        ll_false = rf.loglikelihood_rolling(ctx.replace(\"[MASK]\", self.CONTRADICTION_LABEL))", "ground_truth": "        ll_neither = rf.loglikelihood_rolling(ctx.replace(\"[MASK]\", self.NEUTRAL_LABEL))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            A dictionary where keys are the names of submetrics and values are", "prediction_line": "            A dictionary where keys are the names of submetrics and values are", "ground_truth": "            A dictionary where keys are the names of submetrics and values are", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    QUESTION_WORD = \"correcto\"", "prediction_line": "    QUESTION_WORD = \"correcto\"", "ground_truth": "    QUESTION_WORD = \"correcto\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        and Conneau, Aurelie\",", "prediction_line": "        and Conneau, Aurelie\",", "ground_truth": "        and Williams, Adina", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    DATASET_NAME = \"ur\"", "prediction_line": "    DATASET_NAME = \"ur\"", "ground_truth": "    DATASET_NAME = \"ur\"", "line_class": "random", "zero_context": true}
{"original_prediction": "    QUESTION_WORD = \"правилно\"", "prediction_line": "    QUESTION_WORD = \"правилно\"", "ground_truth": "    QUESTION_WORD = \"правилно\"", "line_class": "random", "zero_context": true}
{"original_prediction": "    NEUTRAL_LABEL = \"इसलिए\"", "prediction_line": "    NEUTRAL_LABEL = \"इसलिए\"", "ground_truth": "    NEUTRAL_LABEL = \"इसलिए\"", "line_class": "random", "zero_context": true}
{"original_prediction": "       return ll_true, ll_neither, ll_false", "prediction_line": "       return ll_true, ll_neither, ll_false", "ground_truth": "        return ll_true, ll_neither, ll_false", "line_class": "random", "zero_context": true}
{"original_prediction": "    DATASET_NAME = \"tr\"", "prediction_line": "    DATASET_NAME = \"tr\"", "ground_truth": "    DATASET_NAME = \"tr\"", "line_class": "random", "zero_context": true}
{"original_prediction": "            super().__init__(json_path)", "prediction_line": "            super().__init__(json_path)", "ground_truth": "            super().__init__(json_path)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if self._has_multi_choice:", "prediction_line": "        if self._has_multi_choice:", "ground_truth": "        choice_prefix = self._task_json.get(\"choice_prefix\", \"\\n  choice: \")", "line_class": "common", "zero_context": true}
{"original_prediction": "        if self._has_multi_choice:", "prediction_line": "        if self._has_multi_choice:", "ground_truth": "        append_choices = self._task_json.get(\"append_choices_to_input\", True)", "line_class": "common", "zero_context": true}
{"original_prediction": "        return res", "prediction_line": "        return res", "ground_truth": "        res = f\"{self._task_json.get('task_prefix', '')}{res}\"", "line_class": "common", "zero_context": true}
{"original_prediction": "            self._data = json.load(file)", "prediction_line": "            self._data = json.load(file)", "ground_truth": "            self._task_json = json.load(file)", "line_class": "common", "zero_context": true}
{"original_prediction": "        rng.shuffle(samples)", "prediction_line": "        rng.shuffle(samples)", "ground_truth": "        separator = self._task_json.get(\"few_shot_example_separator\", \"\\n\")", "line_class": "common", "zero_context": true}
{"original_prediction": "       return res\n\n    def doc_to_target(self, doc):", "prediction_line": "       return res", "ground_truth": "        example_output_prefix = self._task_json.get(\"example_output_prefix\", \"\\nA: \")", "line_class": "common", "zero_context": true}
{"original_prediction": "        self._has_multiple_choice = \"multiple_choice_grade\" in self._task_json[\"metrics\"]", "prediction_line": "        self._has_multiple_choice = \"multiple_choice_grade\" in self._task_json[\"metrics\"]", "ground_truth": "        self.output_regex = self._task_json.get(\"output_regex\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.input_regex = self._task_json.get(\"input_regex\", None)", "prediction_line": "        self.input_regex = self._task_json.get(\"input_regex\", None)", "ground_truth": "        self.stop_string = self._task_json.get(\"stop_string\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "        if index >= 0:", "prediction_line": "        if index >= 0:", "ground_truth": "        if index > 0:", "line_class": "common", "zero_context": true}
{"original_prediction": "            text = text[:index]", "prediction_line": "            text = text[:index]", "ground_truth": "            text = text[: index + len(stop_string)]", "line_class": "common", "zero_context": true}
{"original_prediction": "        return doc[\"input\"]", "prediction_line": "        return doc[\"input\"]", "ground_truth": "        example_input_prefix = self._task_json.get(\"example_input_prefix\", \"\\nQ: \")", "line_class": "common", "zero_context": true}
{"original_prediction": "            res = self._doc_to_few_shot_context(num_fewshot)", "prediction_line": "            res = self._doc_to_few_shot_context(num_fewshot)", "ground_truth": "            res = self._doc_to_few_shot_context(shots=num_fewshot)[json.dumps(doc)]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return WrappedTask()", "prediction_line": "    return WrappedTask()", "ground_truth": "    return WrappedTask", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for metric in self._task_json[\"metrics\"]:", "prediction_line": "        for metric in self._task_json[\"metrics\"]:", "ground_truth": "        samples = self.test_docs()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                res[metric] = mean(likelihoods)", "prediction_line": "                res[metric] = mean(likelihoods)", "ground_truth": "                queries = self._doc_to_queries(doc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                res[metric] = mean(", "prediction_line": "                res[metric] = mean(", "ground_truth": "                highest_score_index = _argmax(likelihoods)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if self._has_generative:", "prediction_line": "                if self._has_generative:", "ground_truth": "                postprocessed = _postprocess_output(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        res[task_name] = create_task_from_path(task_path)", "prediction_line": "        res[task_name] = create_task_from_path(task_path)", "ground_truth": "        res[f\"bigbench_{task_name}\"] = create_task_from_path(task_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        f\"{self.doc_to_text(shot_example)}{separator}{self.doc_to_target(shot_example)}\"", "prediction_line": "                        f\"{self.doc_to_text(shot_example)}{separator}{self.doc_to_target(shot_example)}\"", "ground_truth": "                        self.doc_to_text(example)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        for example in shot_examples", "prediction_line": "                        for example in shot_examples", "ground_truth": "                        + rng.choice(_get_valid_answers(example[\"target_scores\"]))", "line_class": "infile", "zero_context": true}
{"original_prediction": "self.doc_to_text(example) for example in shot_examples]", "prediction_line": "self.doc_to_text(example) for example in shot_examples]", "ground_truth": "                        self.doc_to_text(example) + example[\"target\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self._task_json[\"test\"]", "prediction_line": "        return self._task_json[\"test\"]", "ground_truth": "        return _get_unique_examples(self._task_json[\"examples\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            res[sample[\"input\"]] = context", "prediction_line": "            res[sample[\"input\"]] = context", "ground_truth": "            res[json.dumps(sample)] = context + separator + self.doc_to_text(sample)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.doc_to_text(doc)", "prediction_line": "            return self.doc_to_text(doc)", "ground_truth": "            res = self.doc_to_text(doc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            _postprocess_output(t, max_length, stop_string, output_regex) for t in text", "prediction_line": "            _postprocess_output(t, max_length, stop_string, output_regex) for t in text", "ground_truth": "            _postprocess_output(mo, max_length, stop_string, output_regex)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "self.output_regex, self.stop_string", "prediction_line": "self.output_regex, self.stop_string", "ground_truth": "                    max_length=self.max_length,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"multiple_choice_grade\": mean,", "prediction_line": "            \"multiple_choice_grade\": mean,", "ground_truth": "            \"multiple_choice_grade\": mean,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"exact_str_match\": mean,", "prediction_line": "            \"exact_str_match\": mean,", "ground_truth": "            \"exact_str_match\": mean,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                rf.greedy_until(", "prediction_line": "                rf.greedy_until(", "ground_truth": "                rf.loglikelihood(ctx, continuation)[0] for continuation in queries", "line_class": "inproject", "zero_context": true}
{"original_prediction": "rf.greedy_until(ctx, self.stop_string))", "prediction_line": "rf.greedy_until(ctx, self.stop_string))", "ground_truth": "                rf.greedy_until(ctx, {\"until\": [], \"max_length\": self.max_length})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    )\n    return max_indices[idx]", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ",\n                   arithmetic_comprehension, arithmetic_expression,", "prediction_line": ",", "ground_truth": "\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    max_value = max(array)", "prediction_line": "    max_value = max(array)", "ground_truth": "    max_indices = np.arange(len(array))[array == np.max(array)]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def doc_to_target(self, doc):", "prediction_line": "    def doc_to_target(self, doc):", "ground_truth": "    def doc_to_target(self, doc):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            res[sample[\"input\"]] = separator.join(", "prediction_line": "            res[sample[\"input\"]] = separator.join(", "ground_truth": "            if self._has_multi_choice:", "line_class": "random", "zero_context": true}
{"original_prediction": "            choices = list(choice_dict.keys())", "prediction_line": "            choices = list(choice_dict.keys())", "ground_truth": "            permuted_choices = rng.permutation(sorted(list(choice_dict.keys())))", "line_class": "random", "zero_context": true}
{"original_prediction": "        if self._has_multi_choice:", "prediction_line": "        if self._has_multi_choice:", "ground_truth": "        return res", "line_class": "random", "zero_context": true}
{"original_prediction": "            if metric == \"multiple_choice_grade\":", "prediction_line": "            if metric == \"multiple_choice_grade\":", "ground_truth": "            if metric == \"multiple_choice_grade\":", "line_class": "random", "zero_context": true}
{"original_prediction": "            else:\n                context = separator.join(", "prediction_line": "            else:", "ground_truth": "            else:", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(name)", "prediction_line": "        super().__init__(name)", "ground_truth": "        super().__init__(name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.rst = self.input(\"rst\", 1)", "prediction_line": "        self.rst = self.input(\"rst\", 1)", "ground_truth": "        self.reset = self.reset(\"reset\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        if self.reset:", "prediction_line": "        if self.reset:", "ground_truth": "        if self.reset:", "line_class": "common", "zero_context": true}
{"original_prediction": "       self.packet_addr_bank_sel_msb = _params.bank_addr_width + _params.bank_sel_addr_width - 1", "prediction_line": "       self.packet_addr_bank_sel_msb = _params.bank_addr_width + _params.bank_sel_addr_width - 1", "ground_truth": "        self.add_always(self.packet_wsti_muxed_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.packet_esto_logic)", "prediction_line": "        self.add_always(self.packet_esto_logic)", "ground_truth": "        self.add_always(self.packet_esti_muxed_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.add_always(self.wr_packet_w2e_wsti_muxed_logic)", "prediction_line": "            self.add_always(self.wr_packet_w2e_wsti_muxed_logic)", "ground_truth": "            self.add_always(self.wr_packet_switch_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.add_always(self.rdrq_packet_switch_logic)", "prediction_line": "            self.add_always(self.rdrq_packet_switch_logic)", "ground_truth": "            self.add_always(self.rdrq_packet_switch_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.add_always(self.rdrs_packet_switch_logic)", "prediction_line": "            self.add_always(self.rdrs_packet_switch_logic)", "ground_truth": "            self.add_always(self.rdrs_packet_switch_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @always_comb", "prediction_line": "    @always_comb", "ground_truth": "        self.add_always(self.packet_pipeline)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            name += \"_RD\"", "prediction_line": "            name += \"_RD\"", "ground_truth": "            name += \"_RD\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self._wr_channel = wr_channel", "prediction_line": "        self._wr_channel = wr_channel", "ground_truth": "        self.header = GlbHeader(self._params)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def rdrq_packet_switch_logic(self):", "prediction_line": "    def rdrq_packet_switch_logic(self):", "ground_truth": "    def rdrq_packet_switch_logic(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def wr_packet_switch_logic(self):", "prediction_line": "    def wr_packet_switch_logic(self):", "ground_truth": "    def wr_packet_switch_logic(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        super().__init__(name)", "prediction_line": "        super().__init__(name)", "ground_truth": "        if wr_channel:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def rdrs_packet_switch_logic(self):", "prediction_line": "    def rdrs_packet_switch_logic(self):", "ground_truth": "    def rdrs_packet_switch_logic(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            self.rdrs_packet_w2e_wsti_muxed = self.var(\"rdrs_packet_w2e_wsti_muxed\", self.header.rdrs_packet_t)", "prediction_line": "            self.rdrs_packet_w2e_wsti_muxed = self.var(\"rdrs_packet_w2e_wsti_muxed\", self.header.rdrs_packet_t)", "ground_truth": "            self.rdrs_packet_w2e_wsti_muxed = self.var(\"rdrs_packet_w2e_wsti_muxed\", self.header.rdrs_packet_t)", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.wr_packet_w2e_esto_w = 0", "prediction_line": "            self.wr_packet_w2e_esto_w = 0", "ground_truth": "            self.wr_packet_w2e_esto_w = 0", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.wr_packet_e2w_wsto_muxed = self.var(\"wr_packet_e2w_wsto_muxed\", self.header.wr_packet_t)", "prediction_line": "            self.wr_packet_e2w_wsto_muxed = self.var(\"wr_packet_e2w_wsto_muxed\", self.header.wr_packet_t)", "ground_truth": "            self.wr_packet_w2e_esto_w = self.var(\"wr_packet_w2e_esto_w\", self.header.wr_packet_t)", "line_class": "random", "zero_context": true}
{"original_prediction": "        else:\n            self.wr_packet_r2sw_w = 0", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "                       reset=self.reset,", "prediction_line": "                       reset=self.reset,", "ground_truth": "                       reset=self.reset,", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.rst = self.reset(\"rst\")", "prediction_line": "        self.rst = self.reset(\"rst\")", "ground_truth": "        self.reset = self.reset(\"reset\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        if self.reset:", "prediction_line": "        if self.reset:", "ground_truth": "        if self.reset:", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.add_always_comb(", "prediction_line": "        self.add_always_comb(", "ground_truth": "        self.add_always(self.wr_sw2bank_muxed_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.wr_sw2bank_logic)", "prediction_line": "        self.add_always(self.wr_sw2bank_logic)", "ground_truth": "        self.add_always(self.wr_sw2bankarr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.wr_sw2sr_logic)", "prediction_line": "        self.add_always(self.wr_sw2sr_logic)", "ground_truth": "        self.add_always(self.wr_sw2sr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # rdrq packet", "prediction_line": "        # rdrq packet", "ground_truth": "        self.add_always(self.wr_sw2sr_pipeline)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrq_sw2bank_muxed_logic)", "prediction_line": "        self.add_always(self.rdrq_sw2bank_muxed_logic)", "ground_truth": "        self.add_always(self.rdrq_sw2bank_muxed_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrq_sw2bankarr_logic)", "prediction_line": "        self.add_always(self.rdrq_sw2bankarr_logic)", "ground_truth": "        self.add_always(self.rdrq_sw2bankarr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrq_sw2sr_logic)", "prediction_line": "        self.add_always(self.rdrq_sw2sr_logic)", "ground_truth": "        self.add_always(self.rdrq_sw2sr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrq_sw2pcfgr_logic)", "prediction_line": "        self.add_always(self.rdrq_sw2pcfgr_logic)", "ground_truth": "        self.add_always(self.rdrq_sw2sr_pipeline)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrq_sw2pcfgr_logic)", "prediction_line": "        self.add_always(self.rdrq_sw2pcfgr_logic)", "ground_truth": "        self.add_always(self.rdrq_sw2pcfgr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrq_sw2pcfgr_pipeline)", "prediction_line": "        self.add_always(self.rdrq_sw2pcfgr_pipeline)", "ground_truth": "        self.add_always(self.rdrq_sw2pcfgr_pipeline)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_sw2bankarr_logic)", "prediction_line": "        self.add_always(self.rdrs_sw2bankarr_logic)", "ground_truth": "        self.add_always(self.rdrs_sw2dma_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_sw2pcfgr_logic)", "prediction_line": "        self.add_always(self.rdrs_sw2pcfgr_logic)", "ground_truth": "        self.add_always(self.rdrs_sw2sr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_sw2sr_pipeline)", "prediction_line": "        self.add_always(self.rdrs_sw2sr_pipeline)", "ground_truth": "        self.add_always(self.rdrs_sw2pr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "prediction_line": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "ground_truth": "        self.add_always(self.rdrs_sw2pcfgdma_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_sw2pcfgr_logic)", "prediction_line": "        self.add_always(self.rdrs_sw2pcfgr_logic)", "ground_truth": "        self.add_always(self.rdrs_sw2pcfgr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "prediction_line": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "ground_truth": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_child(\"wr_muxed_pipeline\",", "prediction_line": "        self.add_child(\"wr_muxed_pipeline\",", "ground_truth": "        self.add_child(\"wr_muxed_pipeline\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.add_child(f\"rdrs_bank2sw_pipeline_{i}\",", "prediction_line": "            self.add_child(f\"rdrs_bank2sw_pipeline_{i}\",", "ground_truth": "            self.add_child(f\"rdrs_bank2sw_pipeline_{i}\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.add_child(\"rdrq_muxed_pipeline\",", "prediction_line": "        self.add_child(\"rdrq_muxed_pipeline\",", "ground_truth": "        self.add_child(\"rdrq_muxed_pipeline\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.rdrq_sw2bank_pipeline = Pipeline(", "prediction_line": "            self.rdrq_sw2bank_pipeline = Pipeline(", "ground_truth": "            self.rdrq_sw2bank_pipeline = Pipeline(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.wr_muxed_pipeline = Pipeline(width=self.wr_packet_sw2bank_muxed.width + self.wr_bank_sel.width,", "prediction_line": "        self.wr_muxed_pipeline = Pipeline(width=self.wr_packet_sw2bank_muxed.width + self.wr_bank_sel.width,", "ground_truth": "        self.wr_muxed_pipeline = Pipeline(width=self.wr_packet_sw2bank_muxed.width + self.wr_bank_sel.width,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.add_child(f\"rdrs_pcfgr2sw_pipeline\",", "prediction_line": "        self.add_child(f\"rdrs_pcfgr2sw_pipeline\",", "ground_truth": "        self.add_child(f\"rdrs_pcfgr2sw_pipeline\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.add_child(f\"rdrq_sw2bank_pipeline_{i}\",", "prediction_line": "            self.add_child(f\"rdrq_sw2bank_pipeline_{i}\",", "ground_truth": "            self.add_child(f\"rdrq_sw2bank_pipeline_{i}\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.rdrs_pcfgr2sw_pipeline = Pipeline(width=self.rdrs_packet_pcfgr2sw.width,", "prediction_line": "        self.rdrs_pcfgr2sw_pipeline = Pipeline(width=self.rdrs_packet_pcfgr2sw.width,", "ground_truth": "        self.rdrs_pcfgr2sw_pipeline = Pipeline(width=self.rdrs_packet_pcfgr2sw.width,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.add_child(\"rdrs_sr2sw_pipeline\",", "prediction_line": "        self.add_child(\"rdrs_sr2sw_pipeline\",", "ground_truth": "        self.add_child(f\"rdrs_sr2sw_pipeline\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.rdrq_pipeline = Pipeline(width=self.rdrq_pipeline_in.width, depth=pipeline_depth)", "prediction_line": "        self.rdrq_pipeline = Pipeline(width=self.rdrq_pipeline_in.width, depth=pipeline_depth)", "ground_truth": "        self.rdrq_pipeline = Pipeline(width=self.rdrq_pipeline_in.width, depth=pipeline_depth)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.add_child(\"rdrq_pipeline\",", "prediction_line": "        self.add_child(\"rdrq_pipeline\",", "ground_truth": "        self.add_child(\"rdrq_pipeline\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.pipeline = Pipeline(self._params)", "prediction_line": "        self.pipeline = Pipeline(self._params)", "ground_truth": "        self.header = GlbHeader(self._params)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.rdrs_pipeline = Pipeline(width=self.rdrs_packet_bankarr2sw_d[i].width,", "prediction_line": "            self.rdrs_pipeline = Pipeline(width=self.rdrs_packet_bankarr2sw_d[i].width,", "ground_truth": "            self.rdrs_bank2sw_pipeline = Pipeline(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.wr_packet_sw2bankarr_w[i] = Pipeline(", "prediction_line": "            self.wr_packet_sw2bankarr_w[i] = Pipeline(", "ground_truth": "            self.wr_sw2bank_pipeline = Pipeline(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.rdrs_pipeline_in = concat(self.rd_type, self.rdrq_bank_sel)", "prediction_line": "        self.rdrs_pipeline_in = concat(self.rd_type, self.rdrq_bank_sel)", "ground_truth": "        self.rdrs_sr2sw_pipeline = Pipeline(width=self.rdrs_packet_sr2sw.width,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def rdrq_sw2pcfgr_pipeline(self):", "prediction_line": "    def rdrq_sw2pcfgr_pipeline(self):", "ground_truth": "    def rdrq_sw2pcfgr_pipeline(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def rdrq_sw2bankarr_logic(self):", "prediction_line": "    def rdrq_sw2bankarr_logic(self):", "ground_truth": "    def rdrq_sw2bankarr_logic(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       self.wr_packet_sw2bankarr_valid = self.output(", "prediction_line": "       self.wr_packet_sw2bankarr_valid = self.output(", "ground_truth": "        # rdrq packet", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # rdrs pipeline", "prediction_line": "        # rdrs pipeline", "ground_truth": "        # rdrq_muxed_pipeline", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                else:\n                    self.rdrs_packet_sw2dma = 0", "prediction_line": "                else:", "ground_truth": "                else:", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.rdrq_packet_sw2sr = self.rdrq_packet_sw2sr_w", "prediction_line": "            self.rdrq_packet_sw2sr = self.rdrq_packet_sw2sr_w", "ground_truth": "            self.rdrq_packet_sw2sr = self.rdrq_packet_sw2sr_w", "line_class": "random", "zero_context": true}
{"original_prediction": "                       in_=self.rdrs_packet_pcfgr2sw,", "prediction_line": "                       in_=self.rdrs_packet_pcfgr2sw,", "ground_truth": "                       in_=self.rdrs_packet_pcfgr2sw,", "line_class": "random", "zero_context": true}
{"original_prediction": "        elif ((self.rdrq_packet_dma2sw['rd_en'] == 1)", "prediction_line": "        elif ((self.rdrq_packet_dma2sw['rd_en'] == 1)", "ground_truth": "        elif ((self.rdrq_packet_pcfgdma2sw['rd_en'] == 1)", "line_class": "random", "zero_context": true}
{"original_prediction": "                self.wr_packet_sw2bankarr_w[i] = 0", "prediction_line": "                self.wr_packet_sw2bankarr_w[i] = 0", "ground_truth": "                self.wr_packet_sw2bankarr_w[i] = 0", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.rst = self.reset(\"rst\")", "prediction_line": "        self.rst = self.reset(\"rst\")", "ground_truth": "        self.reset = self.reset(\"reset\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.if_sram_cfg_est_m.wr_en.next = self.if_sram_cfg_est_m_wr_en_w", "prediction_line": "        self.if_sram_cfg_est_m.wr_en.next = self.if_sram_cfg_est_m_wr_en_w", "ground_truth": "        if self.reset:", "line_class": "common", "zero_context": true}
{"original_prediction": "                       rst=self.reset,", "prediction_line": "                       rst=self.reset,", "ground_truth": "                       reset=self.reset,", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.pipeline = Pipeline(self, self._params)", "prediction_line": "        self.pipeline = Pipeline(self, self._params)", "ground_truth": "        self.add_bank_rd_addr_sel_pipeline()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_bank_rd_data_sel_pipeline()", "prediction_line": "        self.add_bank_rd_data_sel_pipeline()", "ground_truth": "        self.add_always(self.tile_id_match)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.wr_packet_gen)", "prediction_line": "        self.add_always(self.wr_packet_gen)", "ground_truth": "        self.add_always(self.wr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rd_logic)", "prediction_line": "        self.add_always(self.rd_logic)", "ground_truth": "        self.add_always(self.rdrq_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_logic)", "prediction_line": "        self.add_always(self.rdrs_logic)", "ground_truth": "        self.add_always(self.rdrs_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def add_bank_rd_addr_sel_pipeline(self):", "prediction_line": "    def add_bank_rd_addr_sel_pipeline(self):", "ground_truth": "        self.add_always(self.pipeline)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.bank_rd_addr_sel_q = self.var(\"bank_rd_addr_sel_q\", 1)", "prediction_line": "        self.bank_rd_addr_sel_q = self.var(\"bank_rd_addr_sel_q\", 1)", "ground_truth": "        self.bank_rd_addr_sel_pipeline = Pipeline(width=1, depth=self.bank_rd_latency)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.bank_rd_addr_sel_pipeline.add_stage(self.bank_rd_addr_sel_d)", "prediction_line": "        self.bank_rd_addr_sel_pipeline.add_stage(self.bank_rd_addr_sel_d)", "ground_truth": "        self.add_child(\"bank_rd_addr_sel_pipeline\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.sram_cfg_ifc = GlbConfigInterface(", "prediction_line": "        self.sram_cfg_ifc = GlbConfigInterface(", "ground_truth": "        self.header = GlbHeader(self._params)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       self.glb_cfg_ifc = GlbConfigInterface(self._params)", "prediction_line": "       self.glb_cfg_ifc = GlbConfigInterface(self._params)", "ground_truth": "        self.sram_cfg_ifc = GlbConfigInterface(addr_width=self._params.glb_addr_width,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       else:\n            self.rd_data_valid_w = 0", "prediction_line": "       else:", "ground_truth": "    def add_bank_rd_addr_sel_pipeline(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ", always, always_latch, reg, m, n, always_seq, reg_file, reg_file_load, reg_file_store, reg_file_load_store, reg_file_load_store_byte, reg_file_load_store_half, reg_file_load_store_word, reg_file_load_store_double, reg_file_load_store_quad, reg_file_load_store_", "prediction_line": ", always, always_latch, reg, m, n, always_seq, reg_file, reg_file_load, reg_file_store, reg_file_load_store, reg_file_load_store_byte, reg_file_load_store_half, reg_file_load_store_word, reg_file_load_store_double, reg_file_load_store_quad, reg_file_load_store_", "ground_truth": "from global_buffer.design.global_buffer_parameter import GlobalBufferParams", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "            self.wr_packet['wr_strb'] = 0", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.bank_rd_src_tile = 0", "prediction_line": "            self.bank_rd_src_tile = 0", "ground_truth": "            self.bank_rd_src_tile = 0", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.if_sram_cfg_est_m_rd_data_w = self.var(\"if_sram_cfg_est_m_rd_data_w\", self._params.axi_data_width)", "prediction_line": "        self.if_sram_cfg_est_m_rd_data_w = self.var(\"if_sram_cfg_est_m_rd_data_w\", self._params.axi_data_width)", "ground_truth": "        self.bank_wr_en = self.var(\"bank_wr_en\", 1)", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.pipeline = Pipeline(self._params)", "prediction_line": "        self.pipeline = Pipeline(self._params)", "ground_truth": "        self.bank_lsb_data_width = self._params.axi_data_width", "line_class": "random", "zero_context": true}
{"original_prediction": "                self.if_sram_cfg_est_m_rd_addr_w = 0", "prediction_line": "                self.if_sram_cfg_est_m_rd_addr_w = 0", "ground_truth": "                self.if_sram_cfg_est_m_rd_addr_w = 0", "line_class": "random", "zero_context": true}
{"original_prediction": "                       reset=self.reset,", "prediction_line": "                       reset=self.reset,", "ground_truth": "                       reset=self.reset,", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.rst = self.reset(\"rst\")", "prediction_line": "        self.rst = self.reset(\"rst\")", "ground_truth": "        self.reset = self.reset(\"reset\")", "line_class": "common", "zero_context": true}
{"original_prediction": "            self.wr_packet_sw2bankarr_w[i] <<= self.wr_packet_sw2bankarr[i]", "prediction_line": "            self.wr_packet_sw2bankarr_w[i] <<= self.wr_packet_sw2bankarr[i]", "ground_truth": "            self.add_always(self.wr_sw2bankarr_logic, i=i)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # rdrq packet", "prediction_line": "        # rdrq packet", "ground_truth": "        self.add_always(self.wr_sw2sr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.add_always(self.rdrq_sw2bankarr_logic, i=i)", "prediction_line": "            self.add_always(self.rdrq_sw2bankarr_logic, i=i)", "ground_truth": "            self.add_always(self.rdrq_sw2bankarr_logic, i=i)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrq_sw2pcfgr_logic)", "prediction_line": "        self.add_always(self.rdrq_sw2pcfgr_logic)", "ground_truth": "        self.add_always(self.rdrq_sw2sr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrq_sw2pcfgr_logic)", "prediction_line": "        self.add_always(self.rdrq_sw2pcfgr_logic)", "ground_truth": "        self.add_always(self.rdrq_sw2pcfgr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for i in range(self._params.banks_per_tile):", "prediction_line": "        for i in range(self._params.banks_per_tile):", "ground_truth": "        self.add_always(self.rdrs_sw2dma_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "prediction_line": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "ground_truth": "        self.add_always(self.rdrs_sw2sr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_sw2pcfgr_logic)", "prediction_line": "        self.add_always(self.rdrs_sw2pcfgr_logic)", "ground_truth": "        self.add_always(self.rdrs_sw2pr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "prediction_line": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "ground_truth": "        self.add_always(self.rdrs_sw2pcfgdma_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_sw2pcfgr_logic)", "prediction_line": "        self.add_always(self.rdrs_sw2pcfgr_logic)", "ground_truth": "        self.add_always(self.rdrs_sw2pcfgr_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "prediction_line": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "ground_truth": "        self.add_always(self.rdrs_sw2sramcfg_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.rd_type_pipeline = Pipeline(", "prediction_line": "        self.rd_type_pipeline = Pipeline(", "ground_truth": "        self.rd_type_pipeline = Pipeline(width=rd_type_pipeline_in.width, depth=self._params.tile2sram_rd_delay)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.add_child(\"rd_type_pipeline\",", "prediction_line": "        self.add_child(\"rd_type_pipeline\",", "ground_truth": "        self.add_child(f\"rd_type_pipeline_{i}\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def gen(self):", "prediction_line": "    def gen(self):", "ground_truth": "        self.header = GlbHeader(self._params)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.wr_packet_sw2bankarr_w[i] = Pipeline(", "prediction_line": "            self.wr_packet_sw2bankarr_w[i] = Pipeline(", "ground_truth": "            self.wr_sw2bank_pipeline = Pipeline(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.wr_sw2bank_pipeline.clk(self.clk)", "prediction_line": "            self.wr_sw2bank_pipeline.clk(self.clk)", "ground_truth": "            self.add_child(f\"wr_sw2bank_pipeline_{i}\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.rdrs_bankarr2sw_pipeline = Pipeline(", "prediction_line": "            self.rdrs_bankarr2sw_pipeline = Pipeline(", "ground_truth": "            self.rdrs_bank2sw_pipeline = Pipeline(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.add_child(f\"rdrs_bank2sw_pipeline_{i}\",", "prediction_line": "            self.add_child(f\"rdrs_bank2sw_pipeline_{i}\",", "ground_truth": "            self.add_child(f\"rdrs_bank2sw_pipeline_{i}\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.rdrq_sw2bank_pipeline = Pipeline(", "prediction_line": "            self.rdrq_sw2bank_pipeline = Pipeline(", "ground_truth": "            self.rdrq_sw2bank_pipeline = Pipeline(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.add_child(f\"rdrq_sw2bank_pipeline_{i}\",", "prediction_line": "            self.add_child(f\"rdrq_sw2bank_pipeline_{i}\",", "ground_truth": "            self.add_child(f\"rdrq_sw2bank_pipeline_{i}\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.params = _params", "prediction_line": "        self.params = _params", "ground_truth": "        self._params = _params", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def rdrs_sw2pcfgr_logic(self):", "prediction_line": "    def rdrs_sw2pcfgr_logic(self):", "ground_truth": "    def rdrs_sw2pcfgr_logic(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       self.glb_tile_id_out = self.output(\"glb_tile_id_out\", self._params.tile_sel_addr_width)", "prediction_line": "       self.glb_tile_id_out = self.output(\"glb_tile_id_out\", self._params.tile_sel_addr_width)", "ground_truth": "        # wr packet", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # rdr packet", "prediction_line": "        # rdr packet", "ground_truth": "        # rdrs packet", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # rdrq pipeline", "prediction_line": "        # rdrq pipeline", "ground_truth": "        # rdrq pipeline", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                & (self.rdrq_packet_pcfgdma2sw['rd_addr'][self.tile_sel_msb, self.tile_sel_lsb] == self.glb_tile_id)", "prediction_line": "                & (self.rdrq_packet_pcfgdma2sw['rd_addr'][self.tile_sel_msb, self.tile_sel_lsb] == self.glb_tile_id)", "ground_truth": "                & (self.rdrq_packet_pcfgdma2sw['rd_addr'][self.tile_sel_msb, self.tile_sel_lsb] == self.glb_tile_id)", "line_class": "random", "zero_context": true}
{"original_prediction": "                for i in range(self._params.banks_per_tile):", "prediction_line": "                for i in range(self._params.banks_per_tile):", "ground_truth": "                self.rdrs_packet_sw2dma = self.rdrs_packet_sr2sw", "line_class": "random", "zero_context": true}
{"original_prediction": "    @always_comb", "prediction_line": "    @always_comb", "ground_truth": "    @ always_comb", "line_class": "random", "zero_context": true}
{"original_prediction": "                & (self.wr_packet_dma2sw['wr_addr'][self.tile_sel_msb, self.tile_sel_lsb] == self.glb_tile_id)", "prediction_line": "                & (self.wr_packet_dma2sw['wr_addr'][self.tile_sel_msb, self.tile_sel_lsb] == self.glb_tile_id)", "ground_truth": "                & ((~self.cfg_tile_connected_prev) & (~self.cfg_tile_connected_next))", "line_class": "random", "zero_context": true}
{"original_prediction": "                           clk=self.clk,", "prediction_line": "                           clk=self.clk,", "ground_truth": "                           clk=self.clk,", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(name)", "prediction_line": "        super().__init__(name)", "ground_truth": "        super().__init__(name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if self.reset:", "prediction_line": "        if self.reset:", "ground_truth": "        if self.reset:", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.rst = self.input(\"rst\", 1)", "prediction_line": "        self.rst = self.input(\"rst\", 1)", "ground_truth": "        self.reset = self.reset(\"reset\")", "line_class": "common", "zero_context": true}
{"original_prediction": "       self.bank_sel_msb = _params.bank_addr_width + _params.bank_sel_addr_width - 1", "prediction_line": "       self.bank_sel_msb = _params.bank_addr_width + _params.bank_sel_addr_width - 1", "ground_truth": "        self.add_always(self.packet_wsti_muxed_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.add_always(self.packet_esto_logic)", "prediction_line": "        self.add_always(self.packet_esto_logic)", "ground_truth": "        self.add_always(self.packet_esti_muxed_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.add_always(self.wr_packet_w2e_wsti_muxed_logic)", "prediction_line": "            self.add_always(self.wr_packet_w2e_wsti_muxed_logic)", "ground_truth": "            self.add_always(self.wr_packet_switch_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.add_always(self.rdrq_packet_switch_logic)", "prediction_line": "            self.add_always(self.rdrq_packet_switch_logic)", "ground_truth": "            self.add_always(self.rdrq_packet_switch_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.add_always(self.rdrs_packet_switch_logic)", "prediction_line": "            self.add_always(self.rdrs_packet_switch_logic)", "ground_truth": "            self.add_always(self.rdrs_packet_switch_logic)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @always_comb", "prediction_line": "    @always_comb", "ground_truth": "        self.add_always(self.packet_pipeline)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            name += \"_RD\"", "prediction_line": "            name += \"_RD\"", "ground_truth": "            name += \"_RD\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.wr_channel = wr_channel", "prediction_line": "        self.wr_channel = wr_channel", "ground_truth": "        self.header = GlbHeader(self._params)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def packet_esti_muxed_logic(self):", "prediction_line": "    def packet_esti_muxed_logic(self):", "ground_truth": "    def packet_esti_muxed_logic(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    @always_comb", "prediction_line": "    @always_comb", "ground_truth": "    @always_comb", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.wr_packet_e2w_wsti = self.input(\"wr_packet_e2w_wsti\", self.header.wr_packet_t)", "prediction_line": "            self.wr_packet_e2w_wsti = self.input(\"wr_packet_e2w_wsti\", self.header.wr_packet_t)", "ground_truth": "            self.wr_packet_e2w_esti = self.input(\"wr_packet_e2w_esti\", self.header.wr_packet_t)", "line_class": "random", "zero_context": true}
{"original_prediction": "                self.wr_packet_w2e_esto_w = self.wr_packet_w2e_wsti_muxed", "prediction_line": "                self.wr_packet_w2e_esto_w = self.wr_packet_w2e_wsti_muxed", "ground_truth": "                self.wr_packet_w2e_esto_w = self.wr_packet_w2e_wsti_muxed", "line_class": "random", "zero_context": true}
{"original_prediction": "       self.params = _params", "prediction_line": "       self.params = _params", "ground_truth": "        self._params = _params", "line_class": "random", "zero_context": true}
{"original_prediction": "                self.rdrs_packet_w2e_wsti_muxed = self.rdrs_packet_e2w_wsto", "prediction_line": "                self.rdrs_packet_w2e_wsti_muxed = self.rdrs_packet_e2w_wsto", "ground_truth": "                self.rdrs_packet_w2e_wsti_muxed = self.rdrs_packet_e2w_wsto", "line_class": "random", "zero_context": true}
{"original_prediction": "            reset: str", "prediction_line": "            reset: str", "ground_truth": "            reset: str", "line_class": "common", "zero_context": true}
{"original_prediction": "        spider: MobActions", "prediction_line": "        spider: MobActions", "ground_truth": "        spider: MobActions", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ban: Ban", "prediction_line": "    ban: Ban", "ground_truth": "    ban: Ban", "line_class": "infile", "zero_context": true}
{"original_prediction": "    meth: Meth", "prediction_line": "    meth: Meth", "ground_truth": "    meth: Meth", "line_class": "infile", "zero_context": true}
{"original_prediction": "    gift: Gift", "prediction_line": "    gift: Gift", "ground_truth": "    gift: Gift", "line_class": "infile", "zero_context": true}
{"original_prediction": "    cmd: Cmd", "prediction_line": "    cmd: Cmd", "ground_truth": "    cmd: Cmd", "line_class": "infile", "zero_context": true}
{"original_prediction": "        zombie_pigman: MobActions", "prediction_line": "        zombie_pigman: MobActions", "ground_truth": "        creeper: MobActions", "line_class": "infile", "zero_context": true}
{"original_prediction": "    mccolors: Mccolors", "prediction_line": "    mccolors: Mccolors", "ground_truth": "    mccolors: Mccolors", "line_class": "infile", "zero_context": true}
{"original_prediction": "        s_emeralds: str", "prediction_line": "        s_emeralds: str", "ground_truth": "        cats: Cats", "line_class": "infile", "zero_context": true}
{"original_prediction": "    prefix: Prefix", "prediction_line": "    prefix: Prefix", "ground_truth": "    prefix: Prefix", "line_class": "infile", "zero_context": true}
{"original_prediction": "    time: Time", "prediction_line": "    time: Time", "ground_truth": "    time: Time", "line_class": "infile", "zero_context": true}
{"original_prediction": "    econ: Econ", "prediction_line": "    econ: Econ", "ground_truth": "    econ: Econ", "line_class": "infile", "zero_context": true}
{"original_prediction": "    mobs_mech: MobsMech", "prediction_line": "    mobs_mech: MobsMech", "ground_truth": "    mobs_mech: MobsMech", "line_class": "infile", "zero_context": true}
{"original_prediction": "    errors: Errors", "prediction_line": "    errors: Errors", "ground_truth": "    errors: Errors", "line_class": "infile", "zero_context": true}
{"original_prediction": "        question: Question", "prediction_line": "        question: Question", "ground_truth": "        questions: list[Question]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    lb: Lb", "prediction_line": "    lb: Lb", "ground_truth": "    lb: Lb", "line_class": "infile", "zero_context": true}
{"original_prediction": "    minecraft: Minecraft", "prediction_line": "    minecraft: Minecraft", "ground_truth": "    minecraft: Minecraft", "line_class": "infile", "zero_context": true}
{"original_prediction": "    snipe: Snipe", "prediction_line": "    snipe: Snipe", "ground_truth": "    snipe: Snipe", "line_class": "infile", "zero_context": true}
{"original_prediction": "    pp: Pp", "prediction_line": "    pp: Pp", "ground_truth": "    pp: Pp", "line_class": "infile", "zero_context": true}
{"original_prediction": "    mobs: Mobs", "prediction_line": "    mobs: Mobs", "ground_truth": "    mobs: Mobs", "line_class": "infile", "zero_context": true}
{"original_prediction": "       error_1: str", "prediction_line": "       error_1: str", "ground_truth": "    vote: Vote", "line_class": "infile", "zero_context": true}
{"original_prediction": "    lang: Lang", "prediction_line": "    lang: Lang", "ground_truth": "    lang: Lang", "line_class": "infile", "zero_context": true}
{"original_prediction": "    stealskin: Stealskin", "prediction_line": "    stealskin: Stealskin", "ground_truth": "    stealskin: Stealskin", "line_class": "infile", "zero_context": true}
{"original_prediction": "        creeper: MobActions", "prediction_line": "        creeper: MobActions", "ground_truth": "        cave_spider: MobActions", "line_class": "infile", "zero_context": true}
{"original_prediction": "    kick: Kick", "prediction_line": "    kick: Kick", "ground_truth": "    kick: Kick", "line_class": "infile", "zero_context": true}
{"original_prediction": "    replies: Replies", "prediction_line": "    replies: Replies", "ground_truth": "    replies: Replies", "line_class": "infile", "zero_context": true}
{"original_prediction": "    misc: Misc", "prediction_line": "    misc: Misc", "ground_truth": "    misc: Misc", "line_class": "infile", "zero_context": true}
{"original_prediction": "    diff: Diff", "prediction_line": "    diff: Diff", "ground_truth": "    diff: Diff", "line_class": "infile", "zero_context": true}
{"original_prediction": "    fishing: Fishing", "prediction_line": "    fishing: Fishing", "ground_truth": "    fishing: Fishing", "line_class": "infile", "zero_context": true}
{"original_prediction": "    fun: Fun", "prediction_line": "    fun: Fun", "ground_truth": "    fun: Fun", "line_class": "infile", "zero_context": true}
{"original_prediction": "    dep: Dep", "prediction_line": "    dep: Dep", "ground_truth": "    dep: Dep", "line_class": "infile", "zero_context": true}
{"original_prediction": "        commands: FarmCommands", "prediction_line": "        commands: FarmCommands", "ground_truth": "        commands: FarmCommands", "line_class": "infile", "zero_context": true}
{"original_prediction": "        class Mob(BaseModel):", "prediction_line": "        class Mob(BaseModel):", "ground_truth": "        zombie: MobActions", "line_class": "infile", "zero_context": true}
{"original_prediction": "    mcs: Mcs", "prediction_line": "    mcs: Mcs", "ground_truth": "    mcs: Mcs", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ginf: Ginf", "prediction_line": "    ginf: Ginf", "ground_truth": "    ginf: Ginf", "line_class": "infile", "zero_context": true}
{"original_prediction": "        spider: MobActions", "prediction_line": "        spider: MobActions", "ground_truth": "        skeleton: MobActions", "line_class": "infile", "zero_context": true}
{"original_prediction": "    inv: Inv", "prediction_line": "    inv: Inv", "ground_truth": "    inv: Inv", "line_class": "infile", "zero_context": true}
{"original_prediction": "    mcping: Mcping", "prediction_line": "    mcping: Mcping", "ground_truth": "    mcping: Mcping", "line_class": "infile", "zero_context": true}
{"original_prediction": "    lost: Lost", "prediction_line": "    lost: Lost", "ground_truth": "    lost: Lost", "line_class": "infile", "zero_context": true}
{"original_prediction": "    profile: Profile", "prediction_line": "    profile: Profile", "ground_truth": "    profile: Profile", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    purge: Purge", "prediction_line": "    purge: Purge", "ground_truth": "    purge: Purge", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    give: Give", "prediction_line": "    give: Give", "ground_truth": "    give: Give", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    warn: Warn", "prediction_line": "    warn: Warn", "ground_truth": "    warn: Warn", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    credits: Credits", "prediction_line": "    credits: Credits", "ground_truth": "    credits: Credits", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        fish: str", "prediction_line": "        fish: str", "ground_truth": "        fish: str", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    search: Search", "prediction_line": "    search: Search", "ground_truth": "    search: Search", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    mine: Mine", "prediction_line": "    mine: Mine", "ground_truth": "    mine: Mine", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    shop: Shop", "prediction_line": "    shop: Shop", "ground_truth": "    shop: Shop", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        smoke_seaweed_2: str", "prediction_line": "        smoke_seaweed_2: str", "ground_truth": "        use_bonemeal: str", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    bubblewrap: Bubblewrap", "prediction_line": "    bubblewrap: Bubblewrap", "ground_truth": "    bubblewrap: Bubblewrap", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    mute: Mute", "prediction_line": "    mute: Mute", "ground_truth": "    mute: Mute", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        title: str", "prediction_line": "        title: str", "ground_truth": "        rules: str", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        credits: str", "prediction_line": "        credits: str", "ground_truth": "        credits: str", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    stats: Stats", "prediction_line": "    stats: Stats", "ground_truth": "    stats: Stats", "line_class": "inproject", "zero_context": true}
{"original_prediction": "class Help(BaseModel):", "prediction_line": "class Help(BaseModel):", "ground_truth": "class Help(BaseModel):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       ender: list[str]", "prediction_line": "       ender: list[str]", "ground_truth": "    class Mobs(BaseModel):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    class Logs(BaseModel):", "prediction_line": "    class Logs(BaseModel):", "ground_truth": "    class Mcs(BaseModel):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        class Reply(BaseModel):", "prediction_line": "        class Reply(BaseModel):", "ground_truth": "        enabled: str", "line_class": "random", "zero_context": true}
{"original_prediction": "            category: str", "prediction_line": "            category: str", "ground_truth": "            d: int", "line_class": "random", "zero_context": true}
{"original_prediction": "    time: Time", "prediction_line": "    time: Time", "ground_truth": "    cooldown_msgs: list[str]", "line_class": "random", "zero_context": true}
{"original_prediction": "        oops: str", "prediction_line": "        oops: str", "ground_truth": "        nope: str", "line_class": "random", "zero_context": true}
{"original_prediction": "        stupid_2: str", "prediction_line": "        stupid_2: str", "ground_truth": "        stupid_2: str", "line_class": "random", "zero_context": true}
{"original_prediction": "    sell_price: int", "prediction_line": "    sell_price: int", "ground_truth": "    db_entry: DbEntry", "line_class": "infile", "zero_context": true}
{"original_prediction": "    anibug: str", "prediction_line": "    anibug: str", "ground_truth": "    farming: FarmingEmojis", "line_class": "infile", "zero_context": true}
{"original_prediction": "    mobs: MobsMech", "prediction_line": "    mobs: MobsMech", "ground_truth": "    mobs_mech: MobsMech", "line_class": "infile", "zero_context": true}
{"original_prediction": "    fishing: Fishing", "prediction_line": "    fishing: Fishing", "ground_truth": "    mining: Mining", "line_class": "infile", "zero_context": true}
{"original_prediction": "    fishing: Fishing", "prediction_line": "    fishing: Fishing", "ground_truth": "    fishing: Fishing", "line_class": "infile", "zero_context": true}
{"original_prediction": "    shop: list[ShopItem]", "prediction_line": "    shop: list[ShopItem]", "ground_truth": "    shop_items: list[ShopItem]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    valid_skills: set[str]", "prediction_line": "    valid_skills: set[str]", "ground_truth": "    mobs: list[Mob]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    yields_mining_levels: dict[str, list[int]] # emerald yield from different mining levels", "prediction_line": "    yields_mining_levels: dict[str, list[int]] # emerald yield from different mining levels", "ground_truth": "    findables: list[Findable]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    emojis: Emojis", "prediction_line": "    emojis: Emojis", "ground_truth": "    emojis: Emojis", "line_class": "infile", "zero_context": true}
{"original_prediction": "    square: SquareEmojis", "prediction_line": "    square: SquareEmojis", "ground_truth": "    squares: SquareEmojis", "line_class": "infile", "zero_context": true}
{"original_prediction": "    emoji_items_proper: dict[str, str]", "prediction_line": "    emoji_items_proper: dict[str, str]", "ground_truth": "    farming: Farming", "line_class": "infile", "zero_context": true}
{"original_prediction": "    build_ideas: BuildIdeas", "prediction_line": "    build_ideas: BuildIdeas", "ground_truth": "    build_ideas: BuildIdeas", "line_class": "infile", "zero_context": true}
{"original_prediction": "       normal: dict[str, str]", "prediction_line": "       normal: dict[str, str]", "ground_truth": "    emojis: FarmingEmojis", "line_class": "infile", "zero_context": true}
{"original_prediction": "        normal: Normal", "prediction_line": "        normal: Normal", "ground_truth": "        normal: Normal", "line_class": "infile", "zero_context": true}
{"original_prediction": "    fun_langs: FunLangs", "prediction_line": "    fun_langs: FunLangs", "ground_truth": "    fun_langs: FunLangs", "line_class": "infile", "zero_context": true}
{"original_prediction": "           potato: str", "prediction_line": "           potato: str", "ground_truth": "        growing: Growing", "line_class": "infile", "zero_context": true}
{"original_prediction": "        seeds: Seeds", "prediction_line": "        seeds: Seeds", "ground_truth": "        seeds: Seeds", "line_class": "infile", "zero_context": true}
{"original_prediction": "    fishing: FishEmojis", "prediction_line": "    fishing: FishEmojis", "ground_truth": "    fish: FishEmojis", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    fishes: list[Fish]", "prediction_line": "    fishes: list[Fish]", "ground_truth": "    fish: dict[str, Fish]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    badges: BadgeEmojis", "prediction_line": "    badges: BadgeEmojis", "ground_truth": "    badges: BadgeEmojis", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return list(self.fish.keys())", "prediction_line": "        return list(self.fish.keys())", "ground_truth": "        return list(self.fish.keys())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return [fish.value[0] for fish in self.fish.values()]", "prediction_line": "        return [fish.value[0] for fish in self.fish.values()]", "ground_truth": "        return [(len(self.fish_ids) - f.rarity) ** self.exponent for f in self.fish.values()]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def findables_by_name(self) -> dict[str, Findable]:", "prediction_line": "    def findables_by_name(self) -> dict[str, Findable]:", "ground_truth": "    def pickaxes(self) -> list[str]:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class Misc(BaseModel):", "prediction_line": "class Misc(BaseModel):", "ground_truth": "class FunLangs(BaseModel):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class FindableMech(BaseModel):", "prediction_line": "class FindableMech(BaseModel):", "ground_truth": "class Mining(BaseModel):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from discord.ext import commands", "prediction_line": "from discord.ext import commands", "ground_truth": "from pydantic import BaseModel, Extra, Field, HttpUrl", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            melon: str", "prediction_line": "            melon: str", "ground_truth": "            melon: str", "line_class": "random", "zero_context": true}
{"original_prediction": "class Embeds(BaseModel):", "prediction_line": "class Embeds(BaseModel):", "ground_truth": "    numbers: list[str]", "line_class": "random", "zero_context": true}
{"original_prediction": "    rainbow_shep_stud: str", "prediction_line": "    rainbow_shep_stud: str", "ground_truth": "    emerald_spinn: str", "line_class": "random", "zero_context": true}
{"original_prediction": "            class GrowingEmojis(BaseModel):", "prediction_line": "            class GrowingEmojis(BaseModel):", "ground_truth": "            emerald_fruit: str", "line_class": "random", "zero_context": true}
{"original_prediction": "        green: str", "prediction_line": "        green: str", "ground_truth": "        red: str", "line_class": "random", "zero_context": true}
{"original_prediction": "            return gr.update(visible=not x)", "prediction_line": "            return gr.update(visible=not x)", "ground_truth": "            return gr.Column.update(visible=not x)", "line_class": "common", "zero_context": true}
{"original_prediction": "            return gr.Dropdown.update(value=x, options=new_options)", "prediction_line": "            return gr.Dropdown.update(value=x, options=new_options)", "ground_truth": "            return gr.Dropdown.update(value=x, choices=new_options), \\", "line_class": "common", "zero_context": true}
{"original_prediction": "                gr.Dropdown.update(choices=new_options)", "prediction_line": "                gr.Dropdown.update(choices=new_options)", "ground_truth": "                   gr.Dropdown.update(value=x, choices=new_options), \\", "line_class": "common", "zero_context": true}
{"original_prediction": "            return gr.Column.update(visible=x)", "prediction_line": "            return gr.Column.update(visible=x)", "ground_truth": "            return gr.Column.update(visible=x)", "line_class": "common", "zero_context": true}
{"original_prediction": "            return gr.Textbox.update(value=x)", "prediction_line": "            return gr.Textbox.update(value=x)", "ground_truth": "            return gr.Textbox.update(visible=not x)", "line_class": "common", "zero_context": true}
{"original_prediction": "    kwargs['model_state'] = model_state0", "prediction_line": "    kwargs['model_state'] = model_state0", "ground_truth": "    kwargs.update(locals())", "line_class": "common", "zero_context": true}
{"original_prediction": "                   gr.Dropdown.update(value=x2, choices=new_options), \\", "prediction_line": "                   gr.Dropdown.update(value=x2, choices=new_options), \\", "ground_truth": "                   gr.Dropdown.update(value=x2, choices=new_options), \\", "line_class": "common", "zero_context": true}
{"original_prediction": "            return gr.Dropdown.update(value=x1, choices=new_options), \\", "prediction_line": "            return gr.Dropdown.update(value=x1, choices=new_options), \\", "ground_truth": "            return gr.Dropdown.update(value=x1, choices=new_options), \\", "line_class": "common", "zero_context": true}
{"original_prediction": "                if len(history) > kwargs['chat_history']:", "prediction_line": "                if len(history) > kwargs['chat_history']:", "ground_truth": "                prompt_type_arg_id = eval_func_param_names.index('prompt_type')", "line_class": "common", "zero_context": true}
{"original_prediction": "                if prompt_type1 == 'QA':", "prediction_line": "                if prompt_type1 == 'QA':", "ground_truth": "                chat_arg_id = eval_func_param_names.index('chat')", "line_class": "common", "zero_context": true}
{"original_prediction": "        # FIXME: compare", "prediction_line": "        # FIXME: compare", "ground_truth": "        go_btn.click(lambda: gr.update(visible=False), None, go_btn, api_name=\"go\" if allow_api else None) \\", "line_class": "common", "zero_context": true}
{"original_prediction": "            .then(lambda: gr.update(visible=True), None, go_btn)", "prediction_line": "            .then(lambda: gr.update(visible=True), None, go_btn)", "ground_truth": "            .then(lambda: gr.update(visible=True), None, normal_block) \\", "line_class": "common", "zero_context": true}
{"original_prediction": "            return gr.Textbox.update(value=x)", "prediction_line": "            return gr.Textbox.update(value=x)", "ground_truth": "            return gr.Textbox.update(visible=x)", "line_class": "common", "zero_context": true}
{"original_prediction": "            return gr.Dropdown.update(visible=x)", "prediction_line": "            return gr.Dropdown.update(visible=x)", "ground_truth": "            return gr.Dropdown.update(visible=x)", "line_class": "common", "zero_context": true}
{"original_prediction": "        def log_flagged_input_output(x, y, z, w, flagged_input_output_file):", "prediction_line": "        def log_flagged_input_output(x, y, z, w, flagged_input_output_file):", "ground_truth": "        callback.setup(inputs_list + [text_output], \"flagged_data_points\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                question = args_list[-2]", "prediction_line": "                question = args_list[-2]", "ground_truth": "                instruction_nochat_arg_id = eval_func_param_names.index('instruction_nochat')", "line_class": "common", "zero_context": true}
{"original_prediction": "            if x == admin_pass:", "prediction_line": "            if x == admin_pass:", "ground_truth": "            return gr.update(visible=x == admin_pass)", "line_class": "common", "zero_context": true}
{"original_prediction": "            return gr.Dropdown.update(options=prompt_type_options_state.value[0], value=x)", "prediction_line": "            return gr.Dropdown.update(options=prompt_type_options_state.value[0], value=x)", "ground_truth": "            return gr.Dropdown.update(value=x)", "line_class": "common", "zero_context": true}
{"original_prediction": "            return gr.update(visible=x != admin_pass)", "prediction_line": "            return gr.update(visible=x != admin_pass)", "ground_truth": "            return gr.update(visible=not (x == admin_pass))", "line_class": "common", "zero_context": true}
{"original_prediction": "            return gr.Textbox.update(value='')", "prediction_line": "            return gr.Textbox.update(value='')", "ground_truth": "            return gr.Textbox.update(value='')", "line_class": "common", "zero_context": true}
{"original_prediction": "            return gr.Dropdown.update(value=x, visible=model_used_in)", "prediction_line": "            return gr.Dropdown.update(value=x, visible=model_used_in)", "ground_truth": "            return gr.Textbox.update(label=f'h2oGPT [Model: {model_used_in}]')", "line_class": "common", "zero_context": true}
{"original_prediction": "        all_kwargs.update(locals())", "prediction_line": "        all_kwargs.update(locals())", "ground_truth": "        all_kwargs.update(locals())", "line_class": "common", "zero_context": true}
{"original_prediction": "    no_lora_msg = 'h2oGPT [   !!! Please Load Lora Weights in Models Tab !!!   ]'", "prediction_line": "    no_lora_msg = 'h2oGPT [   !!! Please Load Lora Weights in Models Tab !!!   ]'", "ground_truth": "    output_label0 = f'h2oGPT [Model: {kwargs.get(\"base_model\")}]' if kwargs.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "                .then(clear_instruct, None, instruction) \\", "prediction_line": "                .then(clear_instruct, None, instruction) \\", "ground_truth": "                .then(clear_instruct, None, instruction) \\", "line_class": "infile", "zero_context": true}
{"original_prediction": "                .then(clear_torch_cache)", "prediction_line": "                .then(clear_torch_cache)", "ground_truth": "                .then(clear_instruct, None, instruction)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        def dropdown_lora_list(list0, x):", "prediction_line": "        def dropdown_lora_list(list0, x):", "ground_truth": "        add_model_event = add_model_button.click(fn=dropdown_model_list,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        def instruction_fun(x):", "prediction_line": "        def instruction_fun(x):", "ground_truth": "        chat.select(col_nochat_fun, chat, col_nochat, api_name=\"chat_checkbox\" if allow_api else None) \\", "line_class": "infile", "zero_context": true}
{"original_prediction": "            .then(col_chat_fun, chat, col_chat, api_name=\"chat_checkbox\" if allow_api else None) \\", "prediction_line": "            .then(col_chat_fun, chat, col_chat, api_name=\"chat_checkbox\" if allow_api else None) \\", "ground_truth": "            .then(col_chat_fun, chat, col_chat) \\", "line_class": "infile", "zero_context": true}
{"original_prediction": "            .then(context_fun, chat, context)", "prediction_line": "            .then(context_fun, chat, context)", "ground_truth": "            .then(context_fun, chat, context)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        add_lora_event = add_lora_button.click(fn=dropdown_lora_list,", "prediction_line": "        add_lora_event = add_lora_button.click(fn=dropdown_lora_list,", "ground_truth": "        add_lora_event = add_lora_button.click(fn=dropdown_lora_list,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        def compare_model_fun(x):", "prediction_line": "        def compare_model_fun(x):", "ground_truth": "        compare_checkbox.select(compare_textbox_fun, compare_checkbox, text_output2,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            .then(compare_column_fun, compare_checkbox, col_compare, api_name=\"compare_checkbox\" if allow_api else None) \\", "prediction_line": "            .then(compare_column_fun, compare_checkbox, col_compare, api_name=\"compare_checkbox\" if allow_api else None) \\", "ground_truth": "            .then(compare_column_fun, compare_checkbox, col_model2) \\", "line_class": "infile", "zero_context": true}
{"original_prediction": "            .then(compare_prompt_fun, compare_checkbox, prompt_type2)", "prediction_line": "            .then(compare_prompt_fun, compare_checkbox, prompt_type2)", "ground_truth": "            .then(compare_prompt_fun, compare_checkbox, prompt_type2) \\", "line_class": "infile", "zero_context": true}
{"original_prediction": "            .then(**load_model_args2) \\", "prediction_line": "            .then(**load_model_args2) \\", "ground_truth": "            .then(compare_textbox_fun, compare_checkbox, score_text2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        system_btn.click(get_system_info, None, system_text, api_name=\"system\" if allow_api else None)", "prediction_line": "        system_btn.click(get_system_info, None, system_text, api_name=\"system\" if allow_api else None)", "ground_truth": "        system_event = system_btn.click(get_system_info, outputs=system_text,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            score_btn.click(score_last_response, inputs=inputs_list, outputs=score_text,", "prediction_line": "            score_btn.click(score_last_response, inputs=inputs_list, outputs=score_text,", "ground_truth": "            score_fun = score_last_response", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # user and bot", "prediction_line": "        # user and bot", "ground_truth": "        user_args = dict(fn=functools.partial(user, sanitize_user_prompt=kwargs['sanitize_user_prompt']),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            score_fun = noop_score_last_response", "prediction_line": "            score_fun = noop_score_last_response", "ground_truth": "            score_fun = noop_score_last_response", "line_class": "infile", "zero_context": true}
{"original_prediction": "        user_args_nochat = dict(fn=functools.partial(user, sanitize_user_prompt=kwargs['sanitize_user_prompt'],", "prediction_line": "        user_args_nochat = dict(fn=functools.partial(user, sanitize_user_prompt=kwargs['sanitize_user_prompt'],", "ground_truth": "        bot_args = dict(fn=bot,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        user_args_nochat = dict(fn=functools.partial(user, sanitize_user_prompt=kwargs['sanitize_user_prompt'],", "prediction_line": "        user_args_nochat = dict(fn=functools.partial(user, sanitize_user_prompt=kwargs['sanitize_user_prompt'],", "ground_truth": "        retry_bot_args = dict(fn=functools.partial(bot, retry=True),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        undo_user_args = dict(fn=functools.partial(user, undo=True),", "prediction_line": "        undo_user_args = dict(fn=functools.partial(user, undo=True),", "ground_truth": "        undo_user_args = dict(fn=functools.partial(user, undo=True),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        Chatbot._postprocess_chat_messages = _postprocess_chat_messages", "prediction_line": "        Chatbot._postprocess_chat_messages = _postprocess_chat_messages", "ground_truth": "        Chatbot._postprocess_chat_messages = _postprocess_chat_messages", "line_class": "infile", "zero_context": true}
{"original_prediction": "        user_args2 = dict(fn=functools.partial(user, sanitize_user_prompt=kwargs['sanitize_user_prompt'],", "prediction_line": "        user_args2 = dict(fn=functools.partial(user, sanitize_user_prompt=kwargs['sanitize_user_prompt'],", "ground_truth": "        user_args2 = dict(fn=functools.partial(user, sanitize_user_prompt=kwargs['sanitize_user_prompt'], model2=True),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        bot_args2 = dict(fn=functools.partial(bot, model2=True),", "prediction_line": "        bot_args2 = dict(fn=functools.partial(bot, model2=True),", "ground_truth": "        bot_args2 = dict(fn=bot,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        retry_bot_args2 = dict(fn=functools.partial(bot, retry=True),", "prediction_line": "        retry_bot_args2 = dict(fn=functools.partial(bot, retry=True),", "ground_truth": "        retry_bot_args2 = dict(fn=functools.partial(bot, retry=True),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        undo_user_args2 = dict(fn=functools.partial(user, undo=True, model2=True),", "prediction_line": "        undo_user_args2 = dict(fn=functools.partial(user, undo=True, model2=True),", "ground_truth": "        undo_user_args2 = dict(fn=functools.partial(user, undo=True),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        admin_btn.click(check_admin_pass, inputs=admin_pass_textbox, outputs=admin_row)", "prediction_line": "        admin_btn.click(check_admin_pass, inputs=admin_pass_textbox, outputs=admin_row)", "ground_truth": "        admin_btn.click(check_admin_pass, inputs=admin_pass_textbox, outputs=system_row) \\", "line_class": "infile", "zero_context": true}
{"original_prediction": "            .click(close_admin, inputs=admin_pass_textbox, outputs=admin_row)", "prediction_line": "            .click(close_admin, inputs=admin_pass_textbox, outputs=admin_row)", "ground_truth": "            .then(close_admin, inputs=admin_pass_textbox, outputs=admin_row)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        def chatbot_list2(x, model_used_in):", "prediction_line": "        def chatbot_list2(x, model_used_in):", "ground_truth": "        load_model_args = dict(fn=load_model,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        all_kwargs.update(kwargs)", "prediction_line": "        all_kwargs.update(kwargs)", "ground_truth": "        inputs_list = get_inputs_list(all_kwargs, kwargs['model_lower'])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        load_model_args2 = dict(fn=load_model,", "prediction_line": "        load_model_args2 = dict(fn=load_model,", "ground_truth": "        prompt_update_args = dict(fn=dropdown_prompt_type_list, inputs=prompt_type, outputs=prompt_type)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        chatbot_update_args = dict(fn=chatbot_list, inputs=model_used, outputs=chatbot_text)", "prediction_line": "        chatbot_update_args = dict(fn=chatbot_list, inputs=model_used, outputs=chatbot_text)", "ground_truth": "        chatbot_update_args = dict(fn=chatbot_list, inputs=[text_output, model_used], outputs=text_output)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # FIXME: compare", "prediction_line": "        # FIXME: compare", "ground_truth": "        nochat_update_args = dict(fn=chatbot_list, inputs=[text_output, model_used], outputs=text_output_nochat)", "line_class": "infile", "zero_context": true}
{"original_prediction": "           load_model_event2 = load_model_button2.click(**load_model_args) \\", "prediction_line": "           load_model_event2 = load_model_button2.click(**load_model_args) \\", "ground_truth": "        load_model_args2 = dict(fn=load_model,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        prompt_update_args2 = dict(fn=dropdown_prompt_type_list, inputs=prompt_type2, outputs=prompt_type2)", "prediction_line": "        prompt_update_args2 = dict(fn=dropdown_prompt_type_list, inputs=prompt_type2, outputs=prompt_type2)", "ground_truth": "        prompt_update_args2 = dict(fn=dropdown_prompt_type_list, inputs=prompt_type2, outputs=prompt_type2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        chatbot_update_args2 = dict(fn=chatbot_list, inputs=[text_output2, model_used2], outputs=text_output2)", "prediction_line": "        chatbot_update_args2 = dict(fn=chatbot_list, inputs=[text_output2, model_used2], outputs=text_output2)", "ground_truth": "        chatbot_update_args2 = dict(fn=chatbot_list, inputs=[text_output2, model_used2], outputs=text_output2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    inputs_list = []", "prediction_line": "    inputs_list = []", "ground_truth": "    inputs_list_names = list(inspect.signature(evaluate).parameters)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   demo.add_text_input(instruction_label, label=\"Instruction\", default=\"\", placeholder=\"Type your message here\",", "prediction_line": "   demo.add_text_input(instruction_label, label=\"Instruction\", default=\"\", placeholder=\"Type your message here\",", "ground_truth": "    model_options = flatten_list(list(prompt_type_to_model_name.values())) + kwargs['extra_model_options']", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        <style>", "prediction_line": "        <style>", "ground_truth": "            {get_h2o_title(title) if kwargs['h2ocolors'] else get_simple_title(title)}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                .then(**bot_args, api_name='instruction_bot' if allow_api else None) \\", "prediction_line": "                .then(**bot_args, api_name='instruction_bot' if allow_api else None) \\", "ground_truth": "                .then(clear_torch_cache)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                      \"\"\"\n    else:", "prediction_line": "                      \"\"\"", "ground_truth": "                      Hash: {get_githash()}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # callback for logging flagged input/output", "prediction_line": "        # callback for logging flagged input/output", "ground_truth": "        flag_btn.click(lambda *args: callback.flag(args), inputs_list + [text_output], None, preprocess=False,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            outputs=gr.Output(type=\"html\", value=get_dark_js()),", "prediction_line": "            outputs=gr.Output(type=\"html\", value=get_dark_js()),", "ground_truth": "            _js=get_dark_js(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # don't pass text_output, don't want to clear output, just stop it", "prediction_line": "        # don't pass text_output, don't want to clear output, just stop it", "ground_truth": "        demo.load(None, None, None, _js=get_dark_js() if kwargs['h2ocolors'] else None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # ensure not present", "prediction_line": "        # ensure not present", "ground_truth": "        fun = partial(evaluate,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if kwargs['chat_history'] == 1:", "prediction_line": "                    if kwargs['chat_history'] == 1:", "ground_truth": "                    context1 += generate_prompt(data_point, prompt_type1, chat1, reduced=True)[0].replace(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Get system info", "prediction_line": "        # Get system info", "ground_truth": "        s3up_btn.click(s3up, inputs=zip_text, outputs=s3up_text)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                       api_name='stop' if allow_api else None)", "prediction_line": "                       api_name='stop' if allow_api else None)", "ground_truth": "                       queue=False, api_name='stop' if allow_api else None).then(clear_torch_cache)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # callback for logging flagged input/output", "prediction_line": "        # callback for logging flagged input/output", "ground_truth": "        flag_btn_nochat.click(lambda *args: callback.flag(args), inputs_list + [text_output], None, preprocess=False,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            text_input = gr.Textbox(lines=4, label=\"Input text to translate\",", "prediction_line": "                            text_input = gr.Textbox(lines=4, label=\"Input text to translate\",", "ground_truth": "                            src_lang = gr.Dropdown(list(languages_covered().keys()),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # FIXME: why do we need this?", "prediction_line": "        # FIXME: why do we need this?", "ground_truth": "        fun2 = partial(evaluate,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            all_kwargs1['gpu_id'] = gpu_id", "prediction_line": "            all_kwargs1['gpu_id'] = gpu_id", "ground_truth": "            all_kwargs1['gpu_id'] = int(gpu_id)  # detranscribe", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        def col_chat_fun(x):", "prediction_line": "        def col_chat_fun(x):", "ground_truth": "        def col_chat_fun(x):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   if kwargs['model_lower'].strip() not in model_options:", "prediction_line": "   if kwargs['model_lower'].strip() not in model_options:", "ground_truth": "    # transcribe, will be detranscribed before use by evaluate()", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        description += \"This model is publicly accessible.\"", "prediction_line": "        description += \"This model is publicly accessible.\"", "ground_truth": "        description += \"If this host is busy, try [gpt.h2o.ai 20B](https://gpt.h2o.ai) and [HF Spaces1 12B](https://huggingface.co/spaces/h2oai/h2ogpt-chatbot) and [HF Spaces2 12B](https://huggingface.co/spaces/h2oai/h2ogpt-chatbot2)<br>\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            :param args:", "prediction_line": "            :param args:", "ground_truth": "            User that fills history for bot", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   else:\n        description += \"If this host is busy, try [gpt.h2o.ai 20B](https://gpt.h2o.ai) and [HF Spaces1 12B](https://huggingface.co/spaces/h2oai/h2ogpt-chatbot) and [HF Spaces2 12B](https://huggingface.co/spaces/h", "prediction_line": "   else:", "ground_truth": "    if kwargs['verbose']:", "line_class": "random", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "                .then(**score_args, api_name='undo_score' if allow_api else None) \\", "line_class": "random", "zero_context": true}
{"original_prediction": "                return f\"<a href='{filepath}' target='_blank'><img src='{filepath}'></a>\"", "prediction_line": "                return f\"<a href='{filepath}' target='_blank'><img src='{filepath}'></a>\"", "ground_truth": "                return {", "line_class": "random", "zero_context": true}
{"original_prediction": "       if kwargs['auto_score']:", "prediction_line": "       if kwargs['auto_score']:", "ground_truth": "        score_args_nochat = dict(fn=partial(score_fun, nochat=True),", "line_class": "random", "zero_context": true}
{"original_prediction": "                                outputs=[model_state2, model_used2, lora_used2, prompt_type2])", "prediction_line": "                                outputs=[model_state2, model_used2, lora_used2, prompt_type2])", "ground_truth": "                                outputs=[model_state2, model_used2, lora_used2, prompt_type2])", "line_class": "random", "zero_context": true}
{"original_prediction": "   print(docs[0])", "prediction_line": "   print(docs[0])", "ground_truth": "    chain.run(input_documents=docs, question=query)", "line_class": "common", "zero_context": true}
{"original_prediction": "            chain = ConversationalRetrievalChain(", "prediction_line": "            chain = ConversationalRetrievalChain(", "ground_truth": "            res = agent.run(input=\"What is the weather forecast for Poznan, Poland\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                    agent=initialize_agent(", "prediction_line": "                    agent=initialize_agent(", "ground_truth": "                    func=serpapi.run,", "line_class": "common", "zero_context": true}
{"original_prediction": "    # pdf_filename = '/home/jon/Downloads/1706.03762.pdf'", "prediction_line": "    # pdf_filename = '/home/jon/Downloads/1706.03762.pdf'", "ground_truth": "    db = get_db(pdf_filename, split_method='chunk', use_openai=use_openai)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    query = \"Who created transformers?\"", "prediction_line": "    query = \"Who created transformers?\"", "ground_truth": "    answer = get_context(db, query=\"Who created transformers?\", chat_history='', use_openai=use_openai)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # test_demo_openai()", "prediction_line": "    # test_demo_openai()", "ground_truth": "    test_demo_hf()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    counts = [count_tokens(chunk.text) for chunk in chunks]", "prediction_line": "    counts = [count_tokens(chunk.text) for chunk in chunks]", "ground_truth": "    token_counts = [count_tokens(chunk.page_content) for chunk in chunks]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            # Set a custom function to count tokens", "prediction_line": "            # Set a custom function to count tokens", "ground_truth": "            length_function=count_tokens,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    pdf_filename = \"./data/pdfs/transformers.pdf\"", "prediction_line": "    pdf_filename = \"./data/pdfs/transformers.pdf\"", "ground_truth": "    return run_demo(use_openai=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return run_demo(use_openai=False)", "prediction_line": "    return run_demo(use_openai=False)", "ground_truth": "    return run_demo(use_openai=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if use_openai:", "prediction_line": "    if use_openai:", "ground_truth": "    # Check similarity search is working", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        print(f\"Using {n_gpus} GPUs\")", "prediction_line": "        print(f\"Using {n_gpus} GPUs\")", "ground_truth": "        # from utils import NullContext", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            if load_8bit:", "prediction_line": "            if load_8bit:", "ground_truth": "            # device_map={\"\": 0} if load_8bit and device == 'cuda' else \"auto\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    else:\n        from langchain.llms import GPT2LM", "prediction_line": "    else:", "ground_truth": "    else:", "line_class": "random", "zero_context": true}
{"original_prediction": ",\n                num_beams=1, num_return_sequences=1,", "prediction_line": ",", "ground_truth": "            )", "line_class": "random", "zero_context": true}
{"original_prediction": "        text_splitter = RecursiveCharacterTextSplitter()", "prediction_line": "        text_splitter = RecursiveCharacterTextSplitter()", "ground_truth": "        pages = loader.load_and_split()", "line_class": "random", "zero_context": true}
{"original_prediction": "    plt.show()", "prediction_line": "    plt.show()", "ground_truth": "    plt.show()", "line_class": "random", "zero_context": true}
{"original_prediction": "        device = torch.device(\"cpu\")", "prediction_line": "        device = torch.device(\"cpu\")", "ground_truth": "        n_gpus = torch.cuda.device_count() if torch.cuda.is_available else 0", "line_class": "random", "zero_context": true}
{"original_prediction": "        mock_spark_session._jsc.hadoopConfiguration().set(constants.AWS_S3ACCESSKEY, \"xyz\")", "prediction_line": "        mock_spark_session._jsc.hadoopConfiguration().set(constants.AWS_S3ACCESSKEY, \"xyz\")", "ground_truth": "        mock_spark_session.read.format().option().option().option().option().load.return_value = mock_spark_session.dataframe.DataFrame", "line_class": "common", "zero_context": true}
{"original_prediction": "        redshift_to_gcs_template.run(mock_spark_session, mock_parsed_args)", "prediction_line": "        redshift_to_gcs_template.run(mock_spark_session, mock_parsed_args)", "ground_truth": "        redshift_to_gcs_template.run(mock_spark_session, mock_parsed_args)", "line_class": "common", "zero_context": true}
{"original_prediction": "        mock_spark_session.read.format().option().option().option().option().load()", "prediction_line": "        mock_spark_session.read.format().option().option().option().option().load()", "ground_truth": "        mock_spark_session.read.format().option().option().option().option().load()", "line_class": "common", "zero_context": true}
{"original_prediction": "        mock_spark_session.dataframe.DataFrame.write.mode().format().save.assert_called_once_with(\"gs://test\")", "prediction_line": "        mock_spark_session.dataframe.DataFrame.write.mode().format().save.assert_called_once_with(\"gs://test\")", "ground_truth": "        mock_spark_session.dataframe.DataFrame.write.mode().format().save.assert_called_once_with(\"gs://test\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        args = redshift_to_gcs_template.parse_args(", "prediction_line": "        args = redshift_to_gcs_template.parse_args(", "ground_truth": "        parsed_args = redshift_to_gcs_template.parse_args(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       args = [\n            \"--redshift-host\",", "prediction_line": "       args = [", "ground_truth": "        redshift_to_gcs_template = RedshiftToGCSTemplate()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        mock_parsed_args = redshift_to_gcs_template.parse_args(", "prediction_line": "        mock_parsed_args = redshift_to_gcs_template.parse_args(", "ground_truth": "        mock_parsed_args = redshift_to_gcs_template.parse_args(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "class TestRedshiftToGCSTemplate:", "prediction_line": "class TestRedshiftToGCSTemplate:", "ground_truth": "class TestRedshiftToGCSTemplate:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Tests that the parse_args function returns the correct values when the correct arguments are provided", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"Tests RedshiftToGCSTemplate.parse_args()\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        mock_spark_session.read.format().option().option().option().option.assert_called_with(constants.REDSHIFT_IAMROLE, \"arn:aws:iam::xxxx:role/role\")", "prediction_line": "        mock_spark_session.read.format().option().option().option().option.assert_called_with(constants.REDSHIFT_IAMROLE, \"arn:aws:iam::xxxx:role/role\")", "ground_truth": "        mock_spark_session.read.format().option().option().option().option.assert_called_with(constants.REDSHIFT_IAMROLE, \"arn:aws:iam::xxxx:role/role\")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \n    @mock.patch.object(pyspark.sql, 'SparkSession')", "prediction_line": "        ", "ground_truth": "        ", "line_class": "random", "zero_context": true}
{"original_prediction": "             \"--redshifttogcs.input.table=table1\",", "prediction_line": "             \"--redshifttogcs.input.table=table1\",", "ground_truth": "             \"--redshifttogcs.input.table=table1\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        mock_spark_session.read.format.assert_called_with(constants.FORMAT_REDSHIFT)", "prediction_line": "        mock_spark_session.read.format.assert_called_with(constants.FORMAT_REDSHIFT)", "ground_truth": "        mock_spark_session.read.format.assert_called_with(constants.FORMAT_REDSHIFT)", "line_class": "random", "zero_context": true}
{"original_prediction": "            [\"--redshifttogcs.input.url=url\",", "prediction_line": "            [\"--redshifttogcs.input.url=url\",", "ground_truth": "            [\"--redshifttogcs.input.url=url\",", "line_class": "random", "zero_context": true}
{"original_prediction": "             \"--redshifttogcs.output.location=gs://test\",", "prediction_line": "             \"--redshifttogcs.output.location=gs://test\",", "ground_truth": "             \"--redshifttogcs.output.location=gs://test\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        input_data = input_data.load()", "prediction_line": "        input_data = input_data.load()", "ground_truth": "        input_data = input_data.load()        ", "line_class": "common", "zero_context": true}
{"original_prediction": "                .save(gcs_output_location)", "prediction_line": "                .save(gcs_output_location)", "ground_truth": "                .save(gcs_output_location)", "line_class": "common", "zero_context": true}
{"original_prediction": "        # Read\n        sf_options, data_options = self.get_read_options(logger=logger, args=args)", "prediction_line": "        # Read", "ground_truth": "        sf_options, data_options = self.get_read_options(logger, args)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        input_data = self.read_data(logger, spark, sf_options, data_options)", "prediction_line": "        input_data = self.read_data(logger, spark, sf_options, data_options)", "ground_truth": "        input_data = self.read_data(logger, spark, sf_options, data_options)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.write_data(logger, args, input_data)", "prediction_line": "        self.write_data(logger, args, input_data)", "ground_truth": "        self.write_data(logger, args, input_data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            choices=[\n                constants.FORMAT_AVRO,", "prediction_line": "            choices=[", "ground_truth": "            choices=[", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Arguments", "prediction_line": "        # Arguments", "ground_truth": "        logger: Logger = self.get_logger(spark=spark)  ", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from pyspark.sql.functions import col, lit, when", "prediction_line": "from pyspark.sql.functions import col, lit, when", "ground_truth": "from dataproc_templates import BaseTemplate", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#\n# Unless required by applicable law or agreed to in writing, software", "prediction_line": "#", "ground_truth": "#", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from absl import logging", "prediction_line": "from absl import logging", "ground_truth": "from logging import Logger", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    A template for exporting data from Snowflake to GCS.", "prediction_line": "    A template for exporting data from Snowflake to GCS.", "ground_truth": "    Dataproc template implementing loads from Snowflake to GCS", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            default=\"\",", "prediction_line": "            default=\"\",", "ground_truth": "            default=\"\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                'Output file format '", "prediction_line": "                'Output file format '", "ground_truth": "                'Output write format '", "line_class": "random", "zero_context": true}
{"original_prediction": "        \n        writer: DataFrameWriter = input_data.write.format(gcs_output_format)", "prediction_line": "        ", "ground_truth": "        ", "line_class": "random", "zero_context": true}
{"original_prediction": "        logger.info(", "prediction_line": "        logger.info(", "ground_truth": "        logger.info(", "line_class": "random", "zero_context": true}
{"original_prediction": "            help='Snowflake URL'", "prediction_line": "            help='Snowflake URL'", "ground_truth": "            help='Snowflake connection URL'", "line_class": "random", "zero_context": true}
{"original_prediction": "        mock_parsed_args = snowflake_to_gcs_template.parse_args(", "prediction_line": "        mock_parsed_args = snowflake_to_gcs_template.parse_args(", "ground_truth": "        mock_parsed_args = snowflake_to_gcs_template.parse_args(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        snowflake_to_gcs_template = SnowflakeToGCSTemplate()", "prediction_line": "        snowflake_to_gcs_template = SnowflakeToGCSTemplate()", "ground_truth": "        snowflake_to_gcs_template = SnowflakeToGCSTemplate()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        args = mock.MagicMock()", "prediction_line": "        args = mock.MagicMock()", "ground_truth": "        parsed_args = snowflake_to_gcs_template.parse_args(", "line_class": "commited", "zero_context": true}
{"original_prediction": "()\n        \n        snowflake_to_gcs_template.write_data(Logger,mock_spark_session,mock_parsed_args)", "prediction_line": "()", "ground_truth": "        snowflake_to_gcs_template.write_data(Logger, mock_parsed_args, mock_spark_session.dataframe.DataFrame)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        read_options = snowflake_to_gcs_template.get_read_options(mock_parsed_args)", "prediction_line": "        read_options = snowflake_to_gcs_template.get_read_options(mock_parsed_args)", "ground_truth": "        sf_options, table_options = snowflake_to_gcs_template.get_read_options(Logger, mock_parsed_args)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        mock_spark_session.read.format.return_value.options.return_value.load.return_value = \"data\"", "prediction_line": "        mock_spark_session.read.format.return_value.options.return_value.load.return_value = \"data\"", "ground_truth": "        snowflake_to_gcs_template.read_data(Logger,mock_spark_session,sf_opt,data_opt)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        mock_spark_session.read.format().options().option().load.return_value = mock_spark_session.dataframe.DataFrame", "prediction_line": "        mock_spark_session.read.format().options().option().load.return_value = mock_spark_session.dataframe.DataFrame", "ground_truth": "        mock_spark_session.read.format().options().option().load.return_value = mock_spark_session.dataframe.DataFrame", "line_class": "common", "zero_context": true}
{"original_prediction": "        mock_spark_session.dataframe.DataFrame.write.mode().format().save.assert_called_with(\"gs://test\")", "prediction_line": "        mock_spark_session.dataframe.DataFrame.write.mode().format().save.assert_called_with(\"gs://test\")", "ground_truth": "        mock_spark_session.dataframe.DataFrame.write.mode().format().save.assert_called_with(\"gs://test\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        mock_spark_session.read.format().options().option().load.assert_called_once()      ", "prediction_line": "        mock_spark_session.read.format().options().option().load.assert_called_once()      ", "ground_truth": "        mock_spark_session.read.format().options().option().load.assert_called_once()      ", "line_class": "common", "zero_context": true}
{"original_prediction": "    def test_run_template_1(self, Logger, SparkSession):  ", "prediction_line": "    def test_run_template_1(self, Logger, SparkSession):  ", "ground_truth": "    def test_read_data_1(self, Logger, mock_spark_session):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_read_data_2(self, Logger, mock_spark_session):", "prediction_line": "    def test_read_data_2(self, Logger, mock_spark_session):", "ground_truth": "    def test_read_data_2(self, Logger, mock_spark_session):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_write_data_parquet(self, Logger, mock_spark_session):", "prediction_line": "    def test_write_data_parquet(self, Logger, mock_spark_session):", "ground_truth": "    def test_write_data_parquet(self, Logger, mock_spark_session):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    Test SnowflakeToGCSTemplate", "prediction_line": "    Test SnowflakeToGCSTemplate", "ground_truth": "    Test suite for SnowflakeToGCSTemplate", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_snowflake_to_gcs_template(self):", "prediction_line": "    def test_snowflake_to_gcs_template(self):", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "             \"--snowflake.to.gcs.output.format=csv\", ", "prediction_line": "             \"--snowflake.to.gcs.output.format=csv\", ", "ground_truth": "             \"--snowflake.to.gcs.output.format=csv\", ", "line_class": "random", "zero_context": true}
{"original_prediction": "        )\n        ", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "             \"--snowflake.to.gcs.sf.warehouse=dwh\",", "prediction_line": "             \"--snowflake.to.gcs.sf.warehouse=dwh\",", "ground_truth": "             \"--snowflake.to.gcs.sf.warehouse=dwh\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        \n        mock_spark_session.read.format().options().option().load.return_value = mock_spark_session.dataframe.DataFrame", "prediction_line": "        ", "ground_truth": "        ", "line_class": "random", "zero_context": true}
{"original_prediction": "             \"--snowflake.to.gcs.output.location=gs://test\", ", "prediction_line": "             \"--snowflake.to.gcs.output.location=gs://test\", ", "ground_truth": "             \"--snowflake.to.gcs.output.location=gs://test\", ", "line_class": "random", "zero_context": true}
{"original_prediction": "        s3_to_bigquery_template.run(mock_spark_session, mock_parsed_args)", "prediction_line": "        s3_to_bigquery_template.run(mock_spark_session, mock_parsed_args)", "ground_truth": "        s3_to_bigquery_template.run(mock_spark_session, mock_parsed_args)", "line_class": "common", "zero_context": true}
{"original_prediction": "            .load \\", "prediction_line": "            .load \\", "ground_truth": "            .load \\", "line_class": "common", "zero_context": true}
{"original_prediction": "        args = s3_to_bigquery_template.parse_args(", "prediction_line": "        args = s3_to_bigquery_template.parse_args(", "ground_truth": "        parsed_args = s3_to_bigquery_template.parse_args(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        s3_to_bigquery_template = S3ToBigQueryTemplate()", "prediction_line": "        s3_to_bigquery_template = S3ToBigQueryTemplate()", "ground_truth": "        s3_to_bigquery_template = S3ToBigQueryTemplate()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        mock_parsed_args = s3_to_bigquery_template.parse_args(", "prediction_line": "        mock_parsed_args = s3_to_bigquery_template.parse_args(", "ground_truth": "        mock_parsed_args = s3_to_bigquery_template.parse_args(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_s3_to_bigquery_template(spark_session: pyspark.sql.SparkSession):", "prediction_line": "def test_s3_to_bigquery_template(spark_session: pyspark.sql.SparkSession):", "ground_truth": "import dataproc_templates.util.template_constants as constants", "line_class": "non_informative", "zero_context": true}
{"original_prediction": " *     https://www.apache.org/licenses/LICENSE-2.0", "prediction_line": " *     https://www.apache.org/licenses/LICENSE-2.0", "ground_truth": " * https://www.apache.org/licenses/LICENSE-2.0", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class TestS3ToBigQueryTemplate:", "prediction_line": "class TestS3ToBigQueryTemplate:", "ground_truth": "class TestS3ToBigQueryTemplate:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"Tests S3ToBigQueryTemplate reads orc\"\"\"", "prediction_line": "        \"\"\"Tests S3ToBigQueryTemplate reads orc\"\"\"", "ground_truth": "        \"\"\"Tests S3ToBigQueryTemplate write mode defaults to append\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            .parquet.return_value = mock_spark_session.createDataFrame(", "prediction_line": "            .parquet.return_value = mock_spark_session.createDataFrame(", "ground_truth": "            .parquet \\", "line_class": "random", "zero_context": true}
{"original_prediction": "            .set(constants.AWS_S3SECRETKEY, \"SomeSecretKey\")", "prediction_line": "            .set(constants.AWS_S3SECRETKEY, \"SomeSecretKey\")", "ground_truth": "            .set(constants.AWS_S3SECRETKEY, \"SomeSecretKey\")", "line_class": "random", "zero_context": true}
{"original_prediction": "             \"--s3.bq.output.location=gs://bucket/file\",", "prediction_line": "             \"--s3.bq.output.location=gs://bucket/file\",", "ground_truth": "             \"--s3.bq.access.key=SomeAccessKey\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            .return_value = mock_spark_session.dataframe.DataFrame", "prediction_line": "            .return_value = mock_spark_session.dataframe.DataFrame", "ground_truth": "            .return_value = mock_spark_session.dataframe.DataFrame", "line_class": "random", "zero_context": true}
{"original_prediction": "            .format() \\", "prediction_line": "            .format() \\", "ground_truth": "            .format() \\", "line_class": "random", "zero_context": true}
{"original_prediction": "        nb_parameters = self.get_env_var(nb_parameters)", "prediction_line": "        nb_parameters = self.get_env_var(nb_parameters)", "ground_truth": "        nb_parameters = self.get_env_var(nb_parameters)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            choices=[constants.OUTPUT_MODE_OVERWRITE, constants.OUTPUT_MODE_APPEND]", "prediction_line": "            choices=[constants.OUTPUT_MODE_OVERWRITE, constants.OUTPUT_MODE_APPEND]", "ground_truth": "            choices=[", "line_class": "inproject", "zero_context": true}
{"original_prediction": "# See the License for the specific language governing permissions and", "prediction_line": "# See the License for the specific language governing permissions and", "ground_truth": "# See the License for the specific language governing permissions and", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# limitations under the License.", "prediction_line": "# limitations under the License.", "ground_truth": "# limitations under the License.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# Licensed under the Apache License, Version 2.0 (the \"License\");", "prediction_line": "# Licensed under the Apache License, Version 2.0 (the \"License\");", "ground_truth": "# Licensed under the Apache License, Version 2.0 (the \"License\");", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#\n# Licensed under the Apache License, Version 2.0 (the \"License\");", "prediction_line": "#", "ground_truth": "#", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                help='Postgres Password'", "prediction_line": "                help='Postgres Password'", "ground_truth": "                help='Postgres Password'", "line_class": "random", "zero_context": true}
{"original_prediction": "                f'--{constants.POSTGRES_DATABASE_ARG}',", "prediction_line": "                f'--{constants.POSTGRES_DATABASE_ARG}',", "ground_truth": "                f'--{constants.POSTGRES_DATABASE_ARG}',", "line_class": "random", "zero_context": true}
{"original_prediction": "            f'--{constants.ORACLE_SID_ARG}',", "prediction_line": "            f'--{constants.ORACLE_SID_ARG}',", "ground_truth": "            f'--{constants.ORACLE_USERNAME_ARG}',", "line_class": "random", "zero_context": true}
{"original_prediction": "        parameters[constants.GCS_STAGING_LOCATION_BUCKET] = environ[constants.GCS_STAGING_LOCATION_BUCKET]", "prediction_line": "        parameters[constants.GCS_STAGING_LOCATION_BUCKET] = environ[constants.GCS_STAGING_LOCATION_BUCKET]", "ground_truth": "        parameters[constants.SUBNET] = environ[constants.SUBNET] if constants.SUBNET in environ else \"\"", "line_class": "random", "zero_context": true}
{"original_prediction": "            default=None,", "prediction_line": "            default=None,", "ground_truth": "            default='',", "line_class": "random", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "load()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        voxels = json.load(file)", "prediction_line": "        voxels = json.load(file)", "ground_truth": "        voxels = json.load(file)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            code_variant[index] = possible_combination[j]", "prediction_line": "            code_variant[index] = possible_combination[j]", "ground_truth": "            code_variant[index] = possible_combination[j]", "line_class": "common", "zero_context": true}
{"original_prediction": "       for j, e in enumerate(possible_combination):", "prediction_line": "       for j, e in enumerate(possible_combination):", "ground_truth": "        for j, index in enumerate(variable_indices):", "line_class": "common", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "app.run()", "line_class": "common", "zero_context": true}
{"original_prediction": "    **generate_codes_for('11_111?0?11_111???11_111?????', 'wall_to_floor'),", "prediction_line": "    **generate_codes_for('11_111?0?11_111???11_111?????', 'wall_to_floor'),", "ground_truth": "    **generate_codes_for('01_111?0?11_????????_????????', 'top_edge'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    **generate_codes_for('01_111?0?11_????????_????????', 'top_inner_corner'),", "prediction_line": "    **generate_codes_for('01_111?0?11_????????_????????', 'top_inner_corner'),", "ground_truth": "    **generate_codes_for('01_1?000?11_????????_????????', 'top_corner'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    **generate_codes_for('01_111?0?11_????????_????????', 'top_inner_corner'),", "prediction_line": "    **generate_codes_for('01_111?0?11_????????_????????', 'top_inner_corner'),", "ground_truth": "    **generate_codes_for('01_11101111_????????_????????', 'top_inner_corner'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    **generate_codes_for('01_11111111_????????_????????', 'corner'),", "prediction_line": "    **generate_codes_for('01_11111111_????????_????????', 'corner'),", "ground_truth": "    **generate_codes_for('11_1?000?11_????????_????????', 'corner'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    **generate_codes_for('11_11101111_????????_????????', 'inner_corner'),", "prediction_line": "    **generate_codes_for('11_11101111_????????_????????', 'inner_corner'),", "ground_truth": "    **generate_codes_for('11_11101111_111?1111_????????', 'inner_corner'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # **generate_codes_for('11_11111111_11100011_11111111', 'wall_to_floor_corner'),", "prediction_line": "    # **generate_codes_for('11_11111111_11100011_11111111', 'wall_to_floor_corner'),", "ground_truth": "    **generate_codes_for('11_??111111_111?0?11_????????', 'wall_to_floor'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    **generate_codes_for('11_1?011111_111?1111_????????', 'wall_to_floor_corner'),", "prediction_line": "    **generate_codes_for('11_1?011111_111?1111_????????', 'wall_to_floor_corner'),", "ground_truth": "    **generate_codes_for('11_11111111_1?000?11_11111111', 'wall_to_floor_corner'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # **generate_codes_for('11_11111111_11101111_????????', 'wall_to_floor_inner_corner'),", "prediction_line": "    # **generate_codes_for('11_11111111_11101111_????????', 'wall_to_floor_inner_corner'),", "ground_truth": "    **generate_codes_for('11_1?111111_11101111_????????', 'wall_to_floor_inner_corner'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "   # '1111100111111000011': 'wall_to_edge_back',", "prediction_line": "   # '1111100111111000011': 'wall_to_edge_back',", "ground_truth": "    **generate_codes_for('11_11111011_111?0011_????????', 'wall_to_edge_back_flipped'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "voxels_to_autoblock()", "prediction_line": "voxels_to_autoblock()", "ground_truth": "voxels_to_autoblock()", "line_class": "infile", "zero_context": true}
{"original_prediction": "   # '11_11111011_11110011_11111101': 'wall_to_edge_back_flipped',", "prediction_line": "   # '11_11111011_11110011_11111101': 'wall_to_edge_back_flipped',", "ground_truth": "    **generate_codes_for('11_111?0?11_1?000?11_????????', 'wall_to_edge'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "   # '11_11110111_11000011_11111011': 'wall_to_edge',", "prediction_line": "   # '11_11110111_11000011_11111011': 'wall_to_edge',", "ground_truth": "    **generate_codes_for('11_111?0?11_111?000?_????????', 'wall_to_edge_flipped'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # '11_11100111_11100001_11101111': 'wall_to_edge_flipped',", "prediction_line": "    # '11_11100111_11100001_11101111': 'wall_to_edge_flipped',", "ground_truth": "    **generate_codes_for('11_11101111_11100?11_????????', 'wall_to_edge_back'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "   # '11_11101111_11100011_11111111': 'wall_to_edge_back',", "prediction_line": "   # '11_11101111_11100011_11111111': 'wall_to_edge_back',", "ground_truth": "    **generate_codes_for('10_111?0?11_111?0?11_????????', 'bottom_edge'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "                # if re.match('11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111", "prediction_line": "                # if re.match('11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111", "ground_truth": "                add('fallback', pos, 0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "    **generate_codes_for('01_11111111_????????_????????', 'top'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    **generate_codes_for('01_11111111_????????_????????', 'top_variation', unknown='?'),", "prediction_line": "    **generate_codes_for('01_11111111_????????_????????', 'top_variation', unknown='?'),", "ground_truth": "    **generate_codes_for('11_111?0?11_111???11_111?????', 'wall'),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        level.model.colors.extend(tiles[type].colors)", "prediction_line": "        level.model.colors.extend(tiles[type].colors)", "ground_truth": "        level.model.colors.extend(tiles[type].colors)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def get_code(x, y, z):", "prediction_line": "def get_code(x, y, z):", "ground_truth": "    level.collider = 'mesh'", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def get_tile_name(x, y, z):", "prediction_line": "def get_tile_name(x, y, z):", "ground_truth": "depth = tilemap.height", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                # print(x,y,z)", "prediction_line": "                # print(x,y,z)", "ground_truth": "                pos = Vec3(x,y,z)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with open('autoblock_3_level.json', 'r') as file:", "prediction_line": "    with open('autoblock_3_level.json', 'r') as file:", "ground_truth": "    with open('autoblock_3_level.json', 'r') as file:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def get_tile_name(x, y, z):", "prediction_line": "def get_tile_name(x, y, z):", "ground_truth": "level = Entity(model=Mesh(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for y in range(16):", "prediction_line": "        for y in range(16):", "ground_truth": "        pixel = tilemap.get_pixel(x, z)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def get_tile_name(x, y, z):", "prediction_line": "def get_tile_name(x, y, z):", "ground_truth": "c = Empty()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "sun.color = color.white", "prediction_line": "sun.color = color.white", "ground_truth": "sun.look_at(Vec3(-.1,-.2,-.5))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def get_tile_name(x, y, z):", "prediction_line": "def get_tile_name(x, y, z):", "ground_truth": "possible_colors = [color.white, color.red, color.green, color.blue].reverse()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def get_tile_name(x, y, z):", "prediction_line": "def get_tile_name(x, y, z):", "ground_truth": "width = tilemap.width", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        vertices[f'{tile_name}_rotated_{angle}'] = [rotate_point(v, angle) for v in vertices[f'{tile_name}']]", "prediction_line": "        vertices[f'{tile_name}_rotated_{angle}'] = [rotate_point(v, angle) for v in vertices[f'{tile_name}']]", "ground_truth": "        vertices[f'{tile_name}_{angle}'] = [rotate_point(v, angle) for v in vertices[tile_name]]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    [Vec3(0,0,1), Vec3(0,0,-1)],  # n, s", "prediction_line": "    [Vec3(0,0,1), Vec3(0,0,-1)],  # n, s", "ground_truth": "    [Vec3(0,1,1), Vec3(1,1,1), Vec3(1,1,0), Vec3(1,1,-1), Vec3(0,1,-1), Vec3(-1,1,-1), Vec3(-1,1,0), Vec3(-1,1,1)],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def get_code(x, y, z):", "prediction_line": "def get_code(x, y, z):", "ground_truth": "    point_renderer.model.generate()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def get_tile_name(x, y, z):", "prediction_line": "def get_tile_name(x, y, z):", "ground_truth": "for z in range(tilemap.height):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # '111110011111000111': 'wall_to_edge',", "prediction_line": "    # '111110011111000111': 'wall_to_edge',", "ground_truth": "    # **generate_codes_for('11_11100011_1?000?11_????????', 'wall_to_edge'),", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # '11_11100011_11100001_11100011': 'wall_to_edge',", "prediction_line": "    # '11_11100011_11100001_11100011': 'wall_to_edge',", "ground_truth": "    # '11_11100111_10000111_11100111': 'wall_to_edge',", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    x, y = point", "prediction_line": "    x, y = point", "ground_truth": "    from math import pi, cos, sin", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    '000': 'wall',", "prediction_line": "    '000': 'wall',", "ground_truth": "    # '01_1111_11110000_????????': 'top',", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # '111111101111000111': 'wall_to_edge',", "prediction_line": "    # '111111101111000111': 'wall_to_edge',", "ground_truth": "    # '111111011111000011': 'wall_to_edge',", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        binary_number = f'{i:0{number_of_possible_combinations}b}'", "prediction_line": "        binary_number = f'{i:0{number_of_possible_combinations}b}'", "ground_truth": "        possible_combination = format(i, f'0{number_of_possible_combinations}b')", "line_class": "random", "zero_context": true}
{"original_prediction": "# bottom = [Vec3(*v) for v in tiles['bottom'].vertices]", "prediction_line": "# bottom = [Vec3(*v) for v in tiles['bottom'].vertices]", "ground_truth": "vertices = {}", "line_class": "random", "zero_context": true}
{"original_prediction": "for shape in shapes:", "prediction_line": "for shape in shapes:", "ground_truth": "for tile_name in shapes:", "line_class": "random", "zero_context": true}
{"original_prediction": "   rad = deg * pi / 180", "prediction_line": "   rad = deg * pi / 180", "ground_truth": "    angle_rad = -deg/180 * pi", "line_class": "random", "zero_context": true}
{"original_prediction": "                    continue", "prediction_line": "                    continue", "ground_truth": "                    continue", "line_class": "random", "zero_context": true}
{"original_prediction": "   # ursinamesh_to_obj(m, 'cube')", "prediction_line": "   # ursinamesh_to_obj(m, 'cube')", "ground_truth": "    app.run()", "line_class": "common", "zero_context": true}
{"original_prediction": "    print('-------', perf_counter() - t)", "prediction_line": "    print('-------', perf_counter() - t)", "ground_truth": "    ursinamesh_to_dae(m, 'dae_export_test.dae')", "line_class": "infile", "zero_context": true}
{"original_prediction": "    <visual_scene id=\"Scene\" name=\"Scene\">", "prediction_line": "    <visual_scene id=\"Scene\" name=\"Scene\">", "ground_truth": "    <visual_scene id=\"Scene\" name=\"Scene\">", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    from ursina.mesh import Mesh", "prediction_line": "    from ursina.mesh import Mesh", "ground_truth": "    app = Ursina()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        <source id=\"Cube-mesh-colors\">", "prediction_line": "        <source id=\"Cube-mesh-colors\">", "ground_truth": "        <source id=\"Cube-mesh-colors-Col\" name=\"Col\">", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with open(folder / (name + '.dae'), 'w') as f:", "prediction_line": "    with open(folder / (name + '.dae'), 'w') as f:", "ground_truth": "    with (folder / f'{name}.dae').open('w') as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    <material id=\"Material\" name=\"Material\">", "prediction_line": "    <material id=\"Material\" name=\"Material\">", "ground_truth": "    <material id=\"Material-material\" name=\"Material\">", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    obj += f'o {name}\\n'", "prediction_line": "    obj += f'o {name}\\n'", "ground_truth": "    obj += f'usemtl {name}\\n'", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        new_tris.extend([t[0], t[2], t[1]])", "prediction_line": "                        new_tris.extend([t[0], t[2], t[1]])", "ground_truth": "                        new_tris.extend([t[2], t[1], t[0]])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if not out_path:", "prediction_line": "    if not out_path:", "ground_truth": "    obj += 'o ' + name + '\\n'", "line_class": "inproject", "zero_context": true}
{"original_prediction": "          <input semantic=\"VERTEX\" source=\"#Cube-mesh-vertices\" offset=\"0\"/>", "prediction_line": "          <input semantic=\"VERTEX\" source=\"#Cube-mesh-vertices\" offset=\"0\"/>", "ground_truth": "          <input semantic=\"VERTEX\" source=\"#Cube-mesh-vertices\" offset=\"0\"/>", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    <geometry id=\"{name}-geometry\" name=\"{name}\">", "prediction_line": "    <geometry id=\"{name}-geometry\" name=\"{name}\">", "ground_truth": "    <geometry id=\"Cube-mesh\" name=\"Cube\">", "line_class": "inproject", "zero_context": true}
{"original_prediction": "              <param name=\"X\" type=\"float\"/>", "prediction_line": "              <param name=\"X\" type=\"float\"/>", "ground_truth": "              <param name=\"X\" type=\"float\"/>", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        obj += f'v {v[0]:.{max_decimals}f} {v[1]:.{max_decimals}f} {v[2]:.{max_decimals}f}\\n'", "prediction_line": "        obj += f'v {v[0]:.{max_decimals}f} {v[1]:.{max_decimals}f} {v[2]:.{max_decimals}f}\\n'", "ground_truth": "        v = [round(e, max_decimals) for e in v]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        f.write(text)", "prediction_line": "        f.write(text)", "ground_truth": "        f.write(text)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   norms = mesh.normals", "prediction_line": "   norms = mesh.normals", "ground_truth": "    for v in verts:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # ursinamesh_to_obj(m, 'obj_export_test')", "prediction_line": "    # ursinamesh_to_obj(m, 'obj_export_test')", "ground_truth": "    EditorCamera()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "import os", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    from ursina import *", "prediction_line": "    from ursina import *", "ground_truth": "    from ursina import *", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import numpy as np", "prediction_line": "import numpy as np", "ground_truth": "import platform", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ", CullFaceAttribBit, CullFaceAttribCullFace, CullFaceAttribCullFaceMode, CullFaceAttribCullFaceModeOpposite, CullFaceAttribCullFaceModeOff, CullFaceAttribCullFaceModeOn, CullFaceAttribCullFaceModeShadow, CullFaceAttribCullFaceModeShadowOff, CullFaceAttribCullFaceModeShadowOn", "prediction_line": ", CullFaceAttribBit, CullFaceAttribCullFace, CullFaceAttribCullFaceMode, CullFaceAttribCullFaceModeOpposite, CullFaceAttribCullFaceModeOff, CullFaceAttribCullFaceModeOn, CullFaceAttribCullFaceModeShadow, CullFaceAttribCullFaceModeShadowOff, CullFaceAttribCullFaceModeShadowOn", "ground_truth": "from time import perf_counter", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "from ursina.mesh import Mesh", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "  <library_geometries>", "prediction_line": "  <library_geometries>", "ground_truth": "  <library_geometries>", "line_class": "random", "zero_context": true}
{"original_prediction": "            <ambient>", "prediction_line": "            <ambient>", "ground_truth": "            <diffuse>", "line_class": "random", "zero_context": true}
{"original_prediction": "          <sampler2D>", "prediction_line": "          <sampler2D>", "ground_truth": "          <sampler2D>", "line_class": "random", "zero_context": true}
{"original_prediction": "          </technique_common>", "prediction_line": "          </technique_common>", "ground_truth": "          </technique_common>", "line_class": "random", "zero_context": true}
{"original_prediction": "                    else:", "prediction_line": "                    else:", "ground_truth": "                    else:", "line_class": "random", "zero_context": true}
{"original_prediction": "    nmn_subnet = nmn_network.subnets().get(\"mac_vlan\")", "prediction_line": "    nmn_subnet = nmn_network.subnets().get(\"mac_vlan\")", "ground_truth": "    uai_macvlan_subnet = nmn_network.subnets().get(\"uai_macvlan\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "   uai_macvlan_subnet.dhcp_start_address(None)", "prediction_line": "   uai_macvlan_subnet.dhcp_start_address(None)", "ground_truth": "    uai_macvlan_subnet.dhcp_start_address(None)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    uai_macvlan_subnet.dhcp_end_address(None)", "prediction_line": "    uai_macvlan_subnet.dhcp_end_address(None)", "ground_truth": "    uai_macvlan_subnet.dhcp_end_address(None)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    IPAM,", "prediction_line": "    IPAM,", "ground_truth": "    free_ipv4_addresses,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    free_ipv6_addresses,", "prediction_line": "    free_ipv6_addresses,", "ground_truth": "    free_ipv4_subnets,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    free_ipv6_addresses,", "prediction_line": "    free_ipv6_addresses,", "ground_truth": "    hosts_from_prefixlength,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    ipv4_address_from_prefixlength,", "prediction_line": "    ipv4_address_from_prefixlength,", "ground_truth": "    last_free_ipv4_address,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    last_free_ipv4_subnet,", "prediction_line": "    last_free_ipv4_subnet,", "ground_truth": "    next_free_ipv4_address,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    next_free_ipv4_subnet,", "prediction_line": "    next_free_ipv4_subnet,", "ground_truth": "    prefixlength,", "line_class": "commited", "zero_context": true}
{"original_prediction": ")\nfrom sls_utils.network import (", "prediction_line": ")", "ground_truth": "    prefixlength_from_hosts,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    chn.bgp_peers().update(", "prediction_line": "    chn.bgp_peers().update(", "ground_truth": "    if chn is not None and None in chn.bgp():", "line_class": "commited", "zero_context": true}
{"original_prediction": "        chn.bgp().update({\"MyASN\": bgp_chn_asn, \"PeerASN\": bgp_asn})", "prediction_line": "        chn.bgp().update({\"MyASN\": bgp_chn_asn, \"PeerASN\": bgp_asn})", "ground_truth": "        chn.bgp(bgp_chn_asn, bgp_asn)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if network.name() == \"CHN\":", "prediction_line": "        if network.name() == \"CHN\":", "ground_truth": "        for subnet in network.subnets().values():", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if subnet.name().find(\"metallb\") != -1:", "prediction_line": "            if subnet.name().find(\"metallb\") != -1:", "ground_truth": "            pool_name = metallb_subnet_name_map.get(subnet.name())", "line_class": "commited", "zero_context": true}
{"original_prediction": "                f\"    Updating MetalLBPool name for {subnet.name()} to {pool_name}\",", "prediction_line": "                f\"    Updating MetalLBPool name for {subnet.name()} to {pool_name}\",", "ground_truth": "                f\"    Updating {subnet.name()} subnet in the {network.name()} network with MetalLBPoolName {pool_name}\",", "line_class": "commited", "zero_context": true}
{"original_prediction": "            subnet.metallb_pool_name(pool_name)", "prediction_line": "            subnet.metallb_pool_name(pool_name)", "ground_truth": "            subnet.metallb_pool_name(pool_name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    # Check that the user network exists", "prediction_line": "    # Check that the user network exists", "ground_truth": "    can_subnet = networks.get(\"CAN\").ipv4_network()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    chn_subnet = networks.get(\"CHN\").ipv4_network()", "prediction_line": "    chn_subnet = networks.get(\"CHN\").ipv4_network()", "ground_truth": "    cmn_subnet = networks.get(\"CMN\").ipv4_network()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        networks.get(\"BICAN\").set_default_route_network(default_route_network_name)", "prediction_line": "        networks.get(\"BICAN\").set_default_route_network(default_route_network_name)", "ground_truth": "        bican = BicanNetwork(default_route_network_name=default_route_network_name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        networks.add(bican)", "prediction_line": "        networks.add(bican)", "ground_truth": "        networks.update({bican.name(): bican})", "line_class": "commited", "zero_context": true}
{"original_prediction": "        click.secho(", "prediction_line": "        click.secho(", "ground_truth": "        default_route = networks.get(\"BICAN\").system_default_route()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    chn = Network(", "prediction_line": "    chn = Network(", "ground_truth": "    chn = Network(\"CHN\", \"ethernet\", chn_ipv4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    chn.set_vlan(chn_vlan)", "prediction_line": "    chn.set_vlan(chn_vlan)", "ground_truth": "    chn.full_name(\"Customer High-Speed Network\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    chn.vlan(chn_vlan)", "prediction_line": "    chn.vlan(chn_vlan)", "ground_truth": "    chn.mtu(9000)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    can_subnets = networks.get(\"CAN\").subnets()", "prediction_line": "    can_subnets = networks.get(\"CAN\").subnets()", "ground_truth": "    for can_subnet in networks.get(\"CAN\").subnets().values():", "line_class": "commited", "zero_context": true}
{"original_prediction": "        chn.add_subnet(", "prediction_line": "        chn.add_subnet(", "ground_truth": "        chn.subnets().update(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            {\n                can_subnet.name(): Subnet(", "prediction_line": "            {", "ground_truth": "            {can_subnet.name(): Subnet.subnet_from_sls_data(can_subnet.to_sls())},", "line_class": "commited", "zero_context": true}
{"original_prediction": "    for subnet in chn.subnets().values():", "prediction_line": "    for subnet in chn.subnets().values():", "ground_truth": "    for subnet in chn.subnets().values():", "line_class": "commited", "zero_context": true}
{"original_prediction": "        subnet.name(subnet.name().replace(\"CAN\", \"CHN\"))", "prediction_line": "        subnet.name(subnet.name().replace(\"CAN\", \"CHN\"))", "ground_truth": "        subnet.name(subnet.name().replace(\"can_\", \"chn_\"))", "line_class": "commited", "zero_context": true}
{"original_prediction": "    # Update CHN subnets with CHN data", "prediction_line": "    # Update CHN subnets with CHN data", "ground_truth": "        subnet.full_name(subnet.full_name().replace(\"CAN\", \"CHN\"))", "line_class": "commited", "zero_context": true}
{"original_prediction": "    # Update CHN subnets with CHN data", "prediction_line": "    # Update CHN subnets with CHN data", "ground_truth": "        click.echo(f\"    Updating subnet naming for {subnet.name()}\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    # Update subnets with CHN data", "prediction_line": "    # Update subnets with CHN data", "ground_truth": "        click.echo(f\"    Updating reservation names and aliases for {subnet.name()}\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "       for reservation in subnet.reservations().values():", "prediction_line": "       for reservation in subnet.reservations().values():", "ground_truth": "        for reservation in list(subnet.reservations().keys()):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                subnet.reservations().pop(reservation, None)", "prediction_line": "                subnet.reservations().pop(reservation, None)", "ground_truth": "                del subnet.reservations()[reservation]", "line_class": "commited", "zero_context": true}
{"original_prediction": "        for reservation in subnet.reservations().values():", "prediction_line": "        for reservation in subnet.reservations().values():", "ground_truth": "        for reservation in subnet.reservations().values():", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if reservation.name().startswith(\"ncn-s\") or reservation.name().startswith(", "prediction_line": "            if reservation.name().startswith(\"ncn-s\") or reservation.name().startswith(", "ground_truth": "            reservation.name(reservation.name().replace(\"can-\", \"chn-\"))", "line_class": "commited", "zero_context": true}
{"original_prediction": "            reservation.alias(reservation.alias().replace(\"can-\", \"chn-\"))", "prediction_line": "            reservation.alias(reservation.alias().replace(\"can-\", \"chn-\"))", "ground_truth": "            reservation.name(reservation.name().replace(\"-can\", \"-chn\"))", "line_class": "commited", "zero_context": true}
{"original_prediction": "    # Add CHN edge switches", "prediction_line": "    # Add CHN edge switches", "ground_truth": "    bootstrap = chn.subnets().get(\"bootstrap_dhcp\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "f\"    Updating bootstrap subnet {bootstrap.name()}\")", "prediction_line": "f\"    Updating bootstrap subnet {bootstrap.name()}\")", "ground_truth": "        f\"    Updating subnet IPv4 addresses for {bootstrap.name()} to {chn_ipv4}\",", "line_class": "commited", "zero_context": true}
{"original_prediction": "    bootstrap.ipv4_network(chn_ipv4)", "prediction_line": "    bootstrap.ipv4_network(chn_ipv4)", "ground_truth": "    bootstrap.ipv4_address(chn_ipv4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    # Update CHN subnets", "prediction_line": "    # Update CHN subnets", "ground_truth": "    bootstrap.ipv4_gateway(list(chn_ipv4.hosts())[0])", "line_class": "commited", "zero_context": true}
{"original_prediction": "    # Update CHN subnets", "prediction_line": "    # Update CHN subnets", "ground_truth": "    bootstrap.vlan(chn_vlan)", "line_class": "commited", "zero_context": true}
{"original_prediction": "   for i in range(number_of_chn_edge_switches):", "prediction_line": "   for i in range(number_of_chn_edge_switches):", "ground_truth": "    click.echo(f\"    Updating reservation IPv4 addresses for {bootstrap.name()}\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    for reservation in bootstrap.reservations().values():", "prediction_line": "    for reservation in bootstrap.reservations().values():", "ground_truth": "    for reservation in bootstrap.reservations().values():", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if reservation.name().startswith(\"ncn-s\"):", "prediction_line": "        if reservation.name().startswith(\"ncn-s\"):", "ground_truth": "        reservation.ipv4_address(next_free_ipv4_address(bootstrap))", "line_class": "commited", "zero_context": true}
{"original_prediction": "    # Create CHN subnets", "prediction_line": "    # Create CHN subnets", "ground_truth": "    hold_ipv4 = bootstrap.ipv4_network()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    for i in range(number_of_chn_edge_switches):", "prediction_line": "    for i in range(number_of_chn_edge_switches):", "ground_truth": "    bootstrap.ipv4_address(f\"{hold_ipv4.network_address}/{hold_ipv4.prefixlen+1}\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    click.echo(f\"    Updating subnet IPv4 addresses for {bootstrap.name()}\")", "prediction_line": "    click.echo(f\"    Updating subnet IPv4 addresses for {bootstrap.name()}\")", "ground_truth": "    dhcp_start = next_free_ipv4_address(bootstrap)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    dhcp_end = last_free_ipv4_address(bootstrap)", "prediction_line": "    dhcp_end = last_free_ipv4_address(bootstrap)", "ground_truth": "    dhcp_end = sorted(free_ipv4_addresses(bootstrap))[-1]", "line_class": "commited", "zero_context": true}
{"original_prediction": "    bootstrap.dhcp_start(dhcp_start)", "prediction_line": "    bootstrap.dhcp_start(dhcp_start)", "ground_truth": "    bootstrap.dhcp_start_address(dhcp_start)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    bootstrap.dhcp_end_address(dhcp_end)", "prediction_line": "    bootstrap.dhcp_end_address(dhcp_end)", "ground_truth": "    bootstrap.dhcp_end_address(dhcp_end)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    # Create CHN subnets", "prediction_line": "    # Create CHN subnets", "ground_truth": "    bootstrap.ipv4_address(hold_ipv4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if subnet.name() == \"bootstrap_dhcp\":", "prediction_line": "        if subnet.name() == \"bootstrap_dhcp\":", "ground_truth": "        if subnet.name() == \"bootstrap_dhcp\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "        click.echo(", "prediction_line": "        click.echo(", "ground_truth": "        subnet.ipv4_address(subnet_ipv4_address)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        subnet.ipv4_gateway(subnet_ipv4_gateway)", "prediction_line": "        subnet.ipv4_gateway(subnet_ipv4_gateway)", "ground_truth": "        subnet.ipv4_gateway(subnet_ipv4_gateway)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        subnet.vlan(chn_vlan)", "prediction_line": "        subnet.vlan(chn_vlan)", "ground_truth": "        subnet.vlan(chn_vlan)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        click.echo(f\"    Updating reservation IPv4 addresses for {subnet.name()}\")", "prediction_line": "        click.echo(f\"    Updating reservation IPv4 addresses for {subnet.name()}\")", "ground_truth": "        if subnet.reservations() is None:", "line_class": "commited", "zero_context": true}
{"original_prediction": "            reservation.ipv4_address(next_free_ipv4_address(subnet))", "prediction_line": "            reservation.ipv4_address(next_free_ipv4_address(subnet))", "ground_truth": "            reservation.ipv4_address(next_free_ipv4_address(subnet))", "line_class": "commited", "zero_context": true}
{"original_prediction": "            del chn.subnets().get(\"bootstrap_dhcp\").reservations()[switch]", "prediction_line": "            del chn.subnets().get(\"bootstrap_dhcp\").reservations()[switch]", "ground_truth": "            if switch not in bootstrap.reservations().keys():", "line_class": "commited", "zero_context": true}
{"original_prediction": "            del bootstrap.reservations()[switch]", "prediction_line": "            del bootstrap.reservations()[switch]", "ground_truth": "            del bootstrap.reservations()[switch]", "line_class": "commited", "zero_context": true}
{"original_prediction": "    new_network = Network(destination_network_name, old_network.type(), old_network.ipv4_network())", "prediction_line": "    new_network = Network(destination_network_name, old_network.type(), old_network.ipv4_network())", "ground_truth": "    network_ipv4_address = old_network.ipv4_network()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    network_ipv4_gateway = old_network.ipv4_gateway()", "prediction_line": "    network_ipv4_gateway = old_network.ipv4_gateway()", "ground_truth": "    new_network = Network(destination_network_name, \"ethernet\", network_ipv4_address)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    new_network.full_name(destination_network_full_name)", "prediction_line": "    new_network.full_name(destination_network_full_name)", "ground_truth": "    new_network.full_name(destination_network_full_name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    new_network.mtu(old_network.mtu())", "prediction_line": "    new_network.mtu(old_network.mtu())", "ground_truth": "    new_network.mtu(9000)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    #\n    # Clone subnets from old network", "prediction_line": "    #", "ground_truth": "    new_network.ipv4_address(network_ipv4_address)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if preserve_subnet == old_subnet_name:", "prediction_line": "        if preserve_subnet == old_subnet_name:", "ground_truth": "        old_subnet = old_network.subnets().get(old_subnet_name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            old_subnet = old_network.subnets().get(\"hmn_bootstrap_dhcp\")", "prediction_line": "            old_subnet = old_network.subnets().get(\"hmn_bootstrap_dhcp\")", "ground_truth": "            old_subnet = networks.get(\"HMN\").subnets().get(old_subnet_name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "old_network.subnets().values())[0].vlan()", "prediction_line": "old_network.subnets().values())[0].vlan()", "ground_truth": "                dict.fromkeys([s.vlan() for s in old_network.subnets().values()]),", "line_class": "commited", "zero_context": true}
{"original_prediction": "        new_subnet = Subnet.subnet_from_sls_data(old_subnet.to_sls())", "prediction_line": "        new_subnet = Subnet.subnet_from_sls_data(old_subnet.to_sls())", "ground_truth": "        new_subnet = Subnet.subnet_from_sls_data(old_subnet.to_sls())", "line_class": "commited", "zero_context": true}
{"original_prediction": "        new_subnet.name(new_subnet_name)", "prediction_line": "        new_subnet.name(new_subnet_name)", "ground_truth": "        if old_subnet.full_name().find(\"HMN\") != -1:", "line_class": "commited", "zero_context": true}
{"original_prediction": "            new_subnet.full_name(", "prediction_line": "            new_subnet.full_name(", "ground_truth": "            new_subnet.full_name(", "line_class": "commited", "zero_context": true}
{"original_prediction": "new_subnet.full_name().replace(\"HMN\", destination_network_name))", "prediction_line": "new_subnet.full_name().replace(\"HMN\", destination_network_name))", "ground_truth": "                old_subnet.full_name().replace(\"HMN\", f\"{destination_network_name}\"),", "line_class": "commited", "zero_context": true}
{"original_prediction": "                old_subnet.full_name().replace(", "prediction_line": "                old_subnet.full_name().replace(", "ground_truth": "                old_subnet.full_name().replace(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        new_subnet.name(new_subnet_name)", "prediction_line": "        new_subnet.name(new_subnet_name)", "ground_truth": "        new_subnet.name(new_subnet_name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        new_subnet.ipv4_address(old_subnet.ipv4_network())", "prediction_line": "        new_subnet.ipv4_address(old_subnet.ipv4_network())", "ground_truth": "        for reservation in new_subnet.reservations().values():", "line_class": "commited", "zero_context": true}
{"original_prediction": "            reservation.name(", "prediction_line": "            reservation.name(", "ground_truth": "            reservation.name(", "line_class": "commited", "zero_context": true}
{"original_prediction": "                reservation.name().replace(", "prediction_line": "                reservation.name().replace(", "ground_truth": "                reservation.name().replace(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        #\n        # Override subnet IPv4 addressing", "prediction_line": "        #", "ground_truth": "        devices = len(new_subnet.reservations())", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if devices == 0:", "prediction_line": "        if devices == 0:", "ground_truth": "        new_subnet_prefixlen = prefixlength_from_hosts(devices)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        new_subnet_ipv4 = ipaddress.IPv4Network(", "prediction_line": "        new_subnet_ipv4 = ipaddress.IPv4Network(", "ground_truth": "        total_hosts_in_prefixlen = hosts_from_prefixlength(new_subnet_prefixlen)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            seed_subnet = [", "prediction_line": "            seed_subnet = [", "ground_truth": "            remaining_ipv4_addresses = free_ipv4_subnets(new_network)", "line_class": "commited", "zero_context": true}
{"original_prediction": "new_network.subnets())", "prediction_line": "new_network.subnets())", "ground_truth": "                new_network.subnets(),", "line_class": "commited", "zero_context": true}
{"original_prediction": "                key=lambda x: x.prefixlen,", "prediction_line": "                key=lambda x: x.prefixlen,", "ground_truth": "                key=prefixlength,", "line_class": "commited", "zero_context": true}
{"original_prediction": "                seed_subnet = ipaddress.IPv4Network(", "prediction_line": "                seed_subnet = ipaddress.IPv4Network(", "ground_truth": "                seed_subnet = list(seed_subnet.subnets(prefix_delta))[0]", "line_class": "commited", "zero_context": true}
{"original_prediction": "            click.echo(", "prediction_line": "            click.echo(", "ground_truth": "            if new_subnet.ipv4_network() == network_ipv4_address:", "line_class": "commited", "zero_context": true}
{"original_prediction": "            else:\n                click.echo(", "prediction_line": "            else:", "ground_truth": "                new_subnet.ipv4_address(seed_subnet)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    f\"    Preserving subnet {new_subnet_name} with {new_subnet.ipv4_network()}\",", "prediction_line": "                    f\"    Preserving subnet {new_subnet_name} with {new_subnet.ipv4_network()}\",", "ground_truth": "                    f\"    Preserving {new_subnet_name} with {new_subnet.ipv4_network()}\",", "line_class": "commited", "zero_context": true}
{"original_prediction": "                f\"{hosts_from_prefixlength(seed_subnet.prefixlen)} devices\",", "prediction_line": "                f\"{hosts_from_prefixlength(seed_subnet.prefixlen)} devices\",", "ground_truth": "                f\"{hosts_from_prefixlength(seed_subnet.prefixlen)} devices (including gateway)\",", "line_class": "commited", "zero_context": true}
{"original_prediction": "                new_subnet.vlan(old_subnet_base_vlan)", "prediction_line": "                new_subnet.vlan(old_subnet_base_vlan)", "ground_truth": "                new_subnet.vlan(old_subnet_base_vlan)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            new_subnet.ipv4_address(seed_subnet)", "prediction_line": "            new_subnet.ipv4_address(seed_subnet)", "ground_truth": "            old_reservations = new_subnet.reservations()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            new_subnet.reservations().clear()", "prediction_line": "            new_subnet.reservations().clear()", "ground_truth": "            new_subnet.ipv4_gateway(\"0.0.0.0\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "            new_subnet.ipv4_address(seed_subnet)", "prediction_line": "            new_subnet.ipv4_address(seed_subnet)", "ground_truth": "            new_subnet.reservations(defaultdict())", "line_class": "commited", "zero_context": true}
{"original_prediction": "            new_subnet.ipv4_gateway(list(new_subnet.ipv4_network().hosts())[0])", "prediction_line": "            new_subnet.ipv4_gateway(list(new_subnet.ipv4_network().hosts())[0])", "ground_truth": "            new_subnet.ipv4_gateway(next_free_ipv4_address(new_subnet))", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    new_subnet.reservations().update(", "prediction_line": "                    new_subnet.reservations().update(", "ground_truth": "                    new_subnet.reservations().update(", "line_class": "commited", "zero_context": true}
{"original_prediction": "                            old.name(): Reservation.reservation_from_sls_data(", "prediction_line": "                            old.name(): Reservation.reservation_from_sls_data(", "ground_truth": "                            old.name(): Reservation(", "line_class": "commited", "zero_context": true}
{"original_prediction": "                                old.name(),", "prediction_line": "                                old.name(),", "ground_truth": "                                old.name(),", "line_class": "commited", "zero_context": true}
{"original_prediction": "                                next_free_ipv4_address(new_subnet),", "prediction_line": "                                next_free_ipv4_address(new_subnet),", "ground_truth": "                                next_free_ipv4_address(new_subnet),", "line_class": "commited", "zero_context": true}
{"original_prediction": "                dhcp_start = next_free_ipv4_address(new_subnet)", "prediction_line": "                dhcp_start = next_free_ipv4_address(new_subnet)", "ground_truth": "                if new_subnet.dhcp_start_address() is not None:", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    new_subnet.dhcp_start_address(next_free_ipv4_address(new_subnet))", "prediction_line": "                    new_subnet.dhcp_start_address(next_free_ipv4_address(new_subnet))", "ground_truth": "                    new_subnet.dhcp_start_address(next_free_ipv4_address(new_subnet))", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    new_subnet.dhcp_end_address(last_free_ipv4_address(new_subnet))", "prediction_line": "                    new_subnet.dhcp_end_address(last_free_ipv4_address(new_subnet))", "ground_truth": "                if new_subnet.dhcp_end_address() is not None:", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    new_subnet.dhcp_end_address(last_free_ipv4_address(new_subnet))", "prediction_line": "                    new_subnet.dhcp_end_address(last_free_ipv4_address(new_subnet))", "ground_truth": "                    new_subnet.dhcp_end_address(last_free_ipv4_address(new_subnet))", "line_class": "commited", "zero_context": true}
{"original_prediction": "        new_network.subnets().update({new_subnet.name(): new_subnet})", "prediction_line": "        new_network.subnets().update({new_subnet.name(): new_subnet})", "ground_truth": "        new_network.subnets().update({new_subnet_name: new_subnet})", "line_class": "commited", "zero_context": true}
{"original_prediction": "            s\n            for s in subnet_names", "prediction_line": "            s", "ground_truth": "            str(i) for i in sorted(free_ipv4_subnets(new_network), key=prefixlength)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    if preserve_subnet == \"bootstrap_dhcp\":", "prediction_line": "    if preserve_subnet == \"bootstrap_dhcp\":", "ground_truth": "    for subnet in new_network.subnets().values():", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if subnet.name() == preserve_subnet:", "prediction_line": "        if subnet.name() == preserve_subnet:", "ground_truth": "        if subnet.name().find(\"metallb\") != -1:", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if subnet.ipv4_network() == network_ipv4_address:", "prediction_line": "        if subnet.ipv4_network() == network_ipv4_address:", "ground_truth": "        click.echo(f\"    Applying supernet hack to {subnet.name()}\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "        subnet.ipv4_address(network_ipv4_address)", "prediction_line": "        subnet.ipv4_address(network_ipv4_address)", "ground_truth": "        subnet.ipv4_address(new_network.ipv4_address())", "line_class": "commited", "zero_context": true}
{"original_prediction": "    #\n    # Add the new network to the networks", "prediction_line": "    #", "ground_truth": "        subnet.ipv4_gateway(", "line_class": "commited", "zero_context": true}
{"original_prediction": "new_network.ipv4_address())", "prediction_line": "new_network.ipv4_address())", "ground_truth": "            next_free_ipv4_address(", "line_class": "commited", "zero_context": true}
{"original_prediction": "                new_network.ipv4_address(),", "prediction_line": "                new_network.ipv4_address(),", "ground_truth": "                Subnet(\"temp\", new_network.ipv4_network(), \"0.0.0.0\", 1),", "line_class": "commited", "zero_context": true}
{"original_prediction": "    networks.update({new_network.name(): new_network})", "prediction_line": "    networks.update({new_network.name(): new_network})", "ground_truth": "    networks.update({new_network.name(): new_network})", "line_class": "commited", "zero_context": true}
{"original_prediction": "    if networks.get(\"CHN\").ipv4_network() != chn_subnet[1]:", "prediction_line": "    if networks.get(\"CHN\").ipv4_network() != chn_subnet[1]:", "ground_truth": "    chn = networks.get(\"CHN\")", "line_class": "common", "zero_context": true}
{"original_prediction": "   click.secho(", "prediction_line": "   click.secho(", "ground_truth": "    if networks.get(\"CHN\") is None:", "line_class": "common", "zero_context": true}
{"original_prediction": "    nmn = networks.get(\"NMN\")", "prediction_line": "    nmn = networks.get(\"NMN\")", "ground_truth": "    nmn_network = networks.get(\"NMN\")", "line_class": "common", "zero_context": true}
{"original_prediction": "    if networks.get(\"CHN\") is not None:", "prediction_line": "    if networks.get(\"CHN\") is not None:", "ground_truth": "    if networks.get(\"CHN\") is not None:", "line_class": "common", "zero_context": true}
{"original_prediction": "    # Update BGP ASNs", "prediction_line": "    # Update BGP ASNs", "ground_truth": "    networks.update({\"CHN\": chn})", "line_class": "common", "zero_context": true}
{"original_prediction": "    click.echo(", "prediction_line": "    click.echo(", "ground_truth": "    old_network = networks.get(source_network_name)", "line_class": "common", "zero_context": true}
{"original_prediction": "    if networks.get(\"CAN\") is None:", "prediction_line": "    if networks.get(\"CAN\") is None:", "ground_truth": "    if networks.get(\"BICAN\") is not None:", "line_class": "common", "zero_context": true}
{"original_prediction": "    click.secho(", "prediction_line": "    click.secho(", "ground_truth": "    if networks.get(\"CAN\") is not None:", "line_class": "common", "zero_context": true}
{"original_prediction": "    #\n    chn.bgp_asn(bgp_chn_asn)", "prediction_line": "    #", "ground_truth": "    create_metallb_pools_and_asns(", "line_class": "infile", "zero_context": true}
{"original_prediction": "           reservation.name(reservation.name().replace(\"-can-\", \"-chn-\"))", "prediction_line": "           reservation.name(reservation.name().replace(\"-can-\", \"-chn-\"))", "ground_truth": "            if reservation.aliases() is None:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                old.aliases(),", "prediction_line": "                                old.aliases(),", "ground_truth": "                                list(old.aliases()),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for i, alias in enumerate(reservation.aliases()):", "prediction_line": "            for i, alias in enumerate(reservation.aliases()):", "ground_truth": "            for i, alias in enumerate(reservation.aliases()):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                reservation.aliases()[i] = alias.replace(", "prediction_line": "                reservation.aliases()[i] = alias.replace(", "ground_truth": "                reservation.aliases()[i] = alias.replace(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            ),\n                        },", "prediction_line": "                            ),", "ground_truth": "                                old.comment(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if alias.startswith(\"ncn-s\") or alias.startswith(\"ncn-m\"):", "prediction_line": "                if alias.startswith(\"ncn-s\") or alias.startswith(\"ncn-m\"):", "ground_truth": "                reservation.aliases()[i] = alias.replace(\"-can\", \"-chn\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        subnet = old_network.subnets().get(subnet_name)", "prediction_line": "        subnet = old_network.subnets().get(subnet_name)", "ground_truth": "        #", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"\n    click.secho(", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        customer_highspeed_network (int, ipaddress.IPv4Network): VLAN and IPv4 CIDR for the CHN", "prediction_line": "        customer_highspeed_network (int, ipaddress.IPv4Network): VLAN and IPv4 CIDR for the CHN", "ground_truth": "        chn_data (int, ipaddress.IPv4Network): VLAN and IPv4 CIDR for the CHN", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    Args:", "prediction_line": "    Args:", "ground_truth": "    Args:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       if chn.ipv4_network() != chn_subnet[1]:", "prediction_line": "       if chn.ipv4_network() != chn_subnet[1]:", "ground_truth": "def create_bican_network(networks, default_route_network_name):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    for subnet_name in subnet_names:", "prediction_line": "    for subnet_name in subnet_names:", "ground_truth": "    click.echo(f\"    Creating subnets in the following order {subnet_names}\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        bgp_chn_asn,", "prediction_line": "        bgp_chn_asn,", "ground_truth": "        bgp_chn_asn,", "line_class": "random", "zero_context": true}
{"original_prediction": "                ),\n            )", "prediction_line": "                ),", "ground_truth": "                ),", "line_class": "random", "zero_context": true}
{"original_prediction": "    chn_subnet = customer_highspeed_network[1]", "prediction_line": "    chn_subnet = customer_highspeed_network[1]", "ground_truth": "    chn_ipv4 = customer_highspeed_network[1]", "line_class": "random", "zero_context": true}
{"original_prediction": "   click.echo(", "prediction_line": "   click.echo(", "ground_truth": "    click.secho(", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.ssh_conn.close_connection(recursive)", "prediction_line": "            self.ssh_conn.close_connection(recursive)", "ground_truth": "            self.ssh_conn.close_connection()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Runs a command on the remote host and verifies that the output matches the expected output.", "prediction_line": "        \"\"\"", "ground_truth": "        self.__check_connected()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            raise UnexpectedRunCommandOutput()", "prediction_line": "            raise UnexpectedRunCommandOutput()", "ground_truth": "            raise UnexpectedRunCommandOutput", "line_class": "infile", "zero_context": true}
{"original_prediction": "            raise SshConnectionException", "prediction_line": "            raise SshConnectionException", "ground_truth": "            raise SshConnectionException", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.__check_child_process()", "prediction_line": "        self.__check_child_process()", "ground_truth": "        self.__check_child_process()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for i in range(len(regex_list)):", "prediction_line": "        for i in range(len(regex_list)):", "ground_truth": "            raise TimeoutException", "line_class": "infile", "zero_context": true}
{"original_prediction": "        i = self.__expect(pattern_list, timeout=DEFAULT_TIMEOUT)", "prediction_line": "        i = self.__expect(pattern_list, timeout=DEFAULT_TIMEOUT)", "ground_truth": "        i = self.__expect(pattern_list)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            logging.info(\"Hostname {} could not be resolved. Trying again.\".format(self.ssh_host.get_full_domain_name()))", "prediction_line": "            logging.info(\"Hostname {} could not be resolved. Trying again.\".format(self.ssh_host.get_full_domain_name()))", "ground_truth": "            raise UnresolvedHostname", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.__open_connection_dance()", "prediction_line": "            self.__open_connection_dance()", "ground_truth": "            i = self.__expect([PASSWORD_PROMPT, pexpect.TIMEOUT], timeout=DEFAULT_TIMEOUT)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            i = self.__expect([PASSWORD_PROMPT, pexpect.TIMEOUT], timeout=DEFAULT_TIMEOUT)", "prediction_line": "            i = self.__expect([PASSWORD_PROMPT, pexpect.TIMEOUT], timeout=DEFAULT_TIMEOUT)", "ground_truth": "            i = self.__expect([PASSWORD_PROMPT, self.command_prompt_host_pattern, pexpect.TIMEOUT], timeout=DEFAULT_TIMEOUT)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        raise CannotLoginException", "prediction_line": "        raise CannotLoginException", "ground_truth": "        raise CannotLoginException", "line_class": "infile", "zero_context": true}
{"original_prediction": ", so we need to connect it first", "prediction_line": ", so we need to connect it first", "ground_truth": "                self.ssh_conn.connect()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.ssh_conn.child_process.sendline(\"exit\")", "prediction_line": "                self.ssh_conn.child_process.sendline(\"exit\")", "ground_truth": "                self.__expect([pexpect.EOF, COMMAND_PROMPT_ONE_LINE, pexpect.TIMEOUT])", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.__expect([pexpect.EOF, pexpect.TIMEOUT])", "prediction_line": "                self.__expect([pexpect.EOF, pexpect.TIMEOUT])", "ground_truth": "                self.__expect([pexpect.EOF, pexpect.TIMEOUT])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.child_process.expect(PASSWORD_PROMPT)", "prediction_line": "        self.child_process.expect(PASSWORD_PROMPT)", "ground_truth": "        self.__open_connection_dance()", "line_class": "infile", "zero_context": true}
{"original_prediction": "       if self.connected:", "prediction_line": "       if self.connected:", "ground_truth": "        self.__close_connection_dance()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.connected = True", "prediction_line": "            self.connected = True", "ground_truth": "            logging.info(\"Connected to {}\".format(self.ssh_host.get_full_domain_name()))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                for regex in regex_list:", "prediction_line": "                for regex in regex_list:", "ground_truth": "        except Exception as err:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.child_process.sendline(\"exit\")", "prediction_line": "            self.child_process.sendline(\"exit\")", "ground_truth": "            logging.info(\"Exiting from {}\".format(self.ssh_host.get_full_domain_name()))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.child_process.sendline(command_to_run)", "prediction_line": "        self.child_process.sendline(command_to_run)", "ground_truth": "        logging.info(\"Running command '{}' and expecting {} on {}\".format(command_to_run, expected, self.ssh_host.get_full_domain_name()))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for regex in regex_list:", "prediction_line": "        for regex in regex_list:", "ground_truth": "        logging.info(\"Expecting the following '{}' and actual '{}'\".format(regex_list, output))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise UnexpectedRunCommandOutput(\"Expected output '{}' but got '{}'\".format(expected, self.child_process.before))", "prediction_line": "            raise UnexpectedRunCommandOutput(\"Expected output '{}' but got '{}'\".format(expected, self.child_process.before))", "ground_truth": "            logging.error(\"Unexpected run_test_command output. See above for actual and expected outputs.\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise SshConnectionException(\"No child process\")", "prediction_line": "            raise SshConnectionException(\"No child process\")", "ground_truth": "            logging.error(\"No SSH child process has been spawned off yet.\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            logging.error(\"SSH connection is not connected.\")", "prediction_line": "            logging.error(\"SSH connection is not connected.\")", "ground_truth": "            logging.error(\"Not connected yet.\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # wait for the password prompt", "prediction_line": "        # wait for the password prompt", "ground_truth": "        logging.info(\"Connecting to {}\".format(self.ssh_host.get_full_domain_name()))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if i == 2:", "prediction_line": "        if i == 2:", "ground_truth": "        logging.error(\"Could not login to {}.\".format(self.ssh_host.get_full_domain_name()))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Cannot login to host.", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# copy of this software and associated documentation files (the \"Software\"),", "prediction_line": "# copy of this software and associated documentation files (the \"Software\"),", "ground_truth": "# copy of this software and associated documentation files (the \"Software\"),", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# Software is furnished to do so, subject to the following conditions:", "prediction_line": "# Software is furnished to do so, subject to the following conditions:", "ground_truth": "# Software is furnished to do so, subject to the following conditions:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        if i == 0:", "prediction_line": "        if i == 0:", "ground_truth": "        if i == 4:", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.child_process.sendline(self.ssh_host.password)", "prediction_line": "            self.child_process.sendline(self.ssh_host.password)", "ground_truth": "            password = self.ssh_host.get_password(False if num_tries == 1 else True)", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.child_process.expect(PASSWORD_PROMPT)", "prediction_line": "            self.child_process.expect(PASSWORD_PROMPT)", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "class SshClient(object):", "prediction_line": "class SshClient(object):", "ground_truth": "DEFAULT_TIMEOUT = 5", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.connected = True", "prediction_line": "            self.connected = True", "ground_truth": "            self.connected = True", "line_class": "random", "zero_context": true}
{"original_prediction": "    try:\n        sys.exit(main())", "prediction_line": "    try:", "ground_truth": "    sys.exit(main())", "line_class": "commited", "zero_context": true}
{"original_prediction": "            session.headers.update({'Authorization': f'Bearer {token}'})", "prediction_line": "            session.headers.update({'Authorization': f'Bearer {token}'})", "ground_truth": "            session.headers.update({'Authorization': f'Bearer {token}'})", "line_class": "common", "zero_context": true}
{"original_prediction": "    parser = argparse.ArgumentParser(description='Allocate or deallocate UAN IP addresses')", "prediction_line": "    parser = argparse.ArgumentParser(description='Allocate or deallocate UAN IP addresses')", "ground_truth": "    token = os.environ.get('TOKEN')", "line_class": "common", "zero_context": true}
{"original_prediction": "        args.func(session, args)", "prediction_line": "        args.func(session, args)", "ground_truth": "        session.headers.update({'Content-Type': 'application/json'})", "line_class": "common", "zero_context": true}
{"original_prediction": "    allocate_ip_parser.set_defaults(func=deallocate_uan_ip_cmd, show_help=False)", "prediction_line": "    allocate_ip_parser.set_defaults(func=deallocate_uan_ip_cmd, show_help=False)", "ground_truth": "    allocate_ip_parser.set_defaults(func=deallocate_uan_ip_cmd, show_help=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    allocate_ip_parser.set_defaults(func=allocate_uan_ip_cmd)", "prediction_line": "    allocate_ip_parser.set_defaults(func=allocate_uan_ip_cmd)", "ground_truth": "    allocate_ip_parser.set_defaults(func=allocate_uan_ip_cmd, show_help=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for sls_network_name, sls_network in sls_networks.items():", "prediction_line": "        for sls_network_name, sls_network in sls_networks.items():", "ground_truth": "        for subnet in sls_network.subnets().values():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                same_comment = ip_reservation.comment() == args.xname", "prediction_line": "                same_comment = ip_reservation.comment() == args.xname", "ground_truth": "                same_xname = ip_reservation.comment() == args.xname", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # print(json.dumps(bootstrap_dhcp_subnet_reservations, indent=2))", "prediction_line": "        # print(json.dumps(bootstrap_dhcp_subnet_reservations, indent=2))", "ground_truth": "        if alias in bootstrap_dhcp_subnet.reservations() and bootstrap_dhcp_subnet.reservations()[alias].comment() == args.xname:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            dhcp_range_start = bootstrap_dhcp_subnet.dhcp_range_start()", "prediction_line": "            dhcp_range_start = bootstrap_dhcp_subnet.dhcp_range_start()", "ground_truth": "            old_dhcp_start_address = netaddr.IPAddress(str(bootstrap_dhcp_subnet.dhcp_start_address()))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # This indicates that the network is too small", "prediction_line": "            # This indicates that the network is too small", "ground_truth": "            action_log(action, f\"Static range in the bootstrap_dhcp subnet of network {network_name} is too small. Attempting to expand the subnet\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        action, ip_address = allocate_ip_address_in_subnet(session, sls_network, \"bootstrap_dhcp\", args.xname, alias)", "prediction_line": "        action, ip_address = allocate_ip_address_in_subnet(session, sls_network, \"bootstrap_dhcp\", args.xname, alias)", "ground_truth": "        action_log(action, f\"Allocating UAN node IP address in network {network_name}\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        action, hsm_ethernet_interfaces = search_hsm_inventory_ethernet_interfaces(session, ip)", "prediction_line": "        action, hsm_ethernet_interfaces = search_hsm_inventory_ethernet_interfaces(session, ip)", "ground_truth": "        action, found_ethernet_interfaces = search_hsm_inventory_ethernet_interfaces(session, ip_address=ip)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        action_log(action, f'Node {args.xname} has expected Role of Application')", "prediction_line": "        action_log(action, f'Node {args.xname} has expected Role of Application')", "ground_truth": "        action_log(action, f'Pass node {args.xname} has expected node Role of Application')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if new_dhcp_start_address > bootstrap_dhcp_subnet.dhcp_end_address():", "prediction_line": "            if new_dhcp_start_address > bootstrap_dhcp_subnet.dhcp_end_address():", "ground_truth": "            subnet = netaddr.IPNetwork(str(bootstrap_dhcp_subnet.ipv4_address()))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        action_log(action, f'Pass node {args.xname} has alias of {alias}')", "prediction_line": "        action_log(action, f'Pass node {args.xname} has alias of {alias}')", "ground_truth": "        action_log(action, f'Pass node {args.xname} has alias of {alias}')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    http_get,", "prediction_line": "    http_get,", "ground_truth": "    action_log,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        raise Exception(f\"Node {args.xname} does not have the role of Application\")", "prediction_line": "        raise Exception(f\"Node {args.xname} does not have the role of Application\")", "ground_truth": "        action_log(action, f'Unexpected node Role for {args.xname} of {node[\"ExtraProperties\"][\"Role\"]}, expected Application')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            action_log(action, f'Pass allocated IP {ip} for UAN Node {args.xname} ({alias}) is not currently in use in HSM EthernetInterfaces')", "prediction_line": "            action_log(action, f'Pass allocated IP {ip} for UAN Node {args.xname} ({alias}) is not currently in use in HSM EthernetInterfaces')", "ground_truth": "            action_log(action, f\"Pass {network_name} IP address {ip} is not currently in use in HSM Ethernet Interfaces\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        action_log(action, f'Unexpected node Role for {args.xname} of {node[\"ExtraProperties\"][\"Role\"]}, expected Application')", "prediction_line": "        action_log(action, f'Unexpected node Role for {args.xname} of {node[\"ExtraProperties\"][\"Role\"]}, expected Application')", "ground_truth": "        action_log(f'Unexpected node Role for {args.xname} of {node[\"ExtraProperties\"][\"Role\"]}, expected Application')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    base_parser.add_argument(\"--network-allowed-in-dhcp-range\", type=str, required=False, help=\"The IP address range that is allowed to be allocated in the DHCP range. This is used to validate that the IP address range is large enough to allocate the new IP address. If not specified, the default is 1000 IP addresses.\")", "prediction_line": "    base_parser.add_argument(\"--network-allowed-in-dhcp-range\", type=str, required=False, help=\"The IP address range that is allowed to be allocated in the DHCP range. This is used to validate that the IP address range is large enough to allocate the new IP address. If not specified, the default is 1000 IP addresses.\")", "ground_truth": "    base_parser.add_argument(\"--url-hsm\", type=str, required=False, default=\"https://api-gw-service-nmn.local/apis/smd/hsm/v2\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            action_log(action, f\"Skipping network {network_name} as it already has a reservation for {alias} with comment {args.xname}\")", "prediction_line": "            action_log(action, f\"Skipping network {network_name} as it already has a reservation for {alias} with comment {args.xname}\")", "ground_truth": "            action_log(action, f\"Found existing UAN node IP Reservation in subnet bootstrap_dhcp in network {network_name} in SLS: {bootstrap_dhcp_subnet.reservations()[alias].to_sls()}\")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import os\nimport sys", "prediction_line": "import os", "ground_truth": "#pylint: disable=missing-docstring, C0301, C0103, C0302", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import os\nimport sys", "prediction_line": "import os", "ground_truth": "#", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            # Allocate the IP address", "prediction_line": "            # Allocate the IP address", "ground_truth": "            # Attempt to allocate the IP address again with the expanded IP address range", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    action_log(action, f\"Found existing UAN node IP Reservation in subnet {subnet.name()} in network {network_name} in SLS: {ip_reservation.to_sls()}\")", "prediction_line": "                    action_log(action, f\"Found existing UAN node IP Reservation in subnet {subnet.name()} in network {network_name} in SLS: {ip_reservation.to_sls()}\")", "ground_truth": "                    action_log(action, f'Error found existing IP Reservation in subnet {subnet.name()} of network {network_name} in SLS: {ip_reservation.to_sls()}')", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    if node.get(\"role\") != \"Application\":", "prediction_line": "    if node.get(\"role\") != \"Application\":", "ground_truth": "    if node[\"ExtraProperties\"][\"Role\"] != \"Application\":", "line_class": "random", "zero_context": true}
{"original_prediction": "    #\n    # Add the UAN node to HSM", "prediction_line": "    #", "ground_truth": "    if len(allocated_ips) == 0:", "line_class": "random", "zero_context": true}
{"original_prediction": "       if alias not in bootstrap_dhcp_subnet_reservations:", "prediction_line": "       if alias not in bootstrap_dhcp_subnet_reservations:", "ground_truth": "        fail_sls_network_check = False", "line_class": "random", "zero_context": true}
{"original_prediction": "            if new_dhcp_start_address not in subnet:", "prediction_line": "            if new_dhcp_start_address not in subnet:", "ground_truth": "            if new_dhcp_start_address not in subnet[2:-2]:", "line_class": "random", "zero_context": true}
{"original_prediction": "        sys.exit(1)", "prediction_line": "        sys.exit(1)", "ground_truth": "        sys.exit(1)", "line_class": "random", "zero_context": true}
{"original_prediction": "        if toNodeSshConnection:", "prediction_line": "        if toNodeSshConnection:", "ground_truth": "        toNodeSshConnection.close_connection(False)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            to_node = get_ssh_host_for_node_type(to_node_type, [\"ncn-m001\"])", "prediction_line": "            to_node = get_ssh_host_for_node_type(to_node_type, [\"ncn-m001\"])", "ground_truth": "            fromNodeSshConnection = SshConnection(from_node)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        fromNodeSshConnection.connect()", "prediction_line": "        fromNodeSshConnection.connect()", "ground_truth": "        toNodeSshConnection = SshConnection(to_node, fromNodeSshConnection)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if expected:", "prediction_line": "        if expected:", "ground_truth": "        toNodeSshConnection.connect()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    for to_node_type in config:", "prediction_line": "    for to_node_type in config:", "ground_truth": "    network_suffix = \"{}.{}\".format(network, csm_api_utils.get_system_domain())", "line_class": "commited", "zero_context": true}
{"original_prediction": "            toNodeSshConnection.send_command(\"show version\")", "prediction_line": "            toNodeSshConnection.send_command(\"show version\")", "ground_truth": "            toNodeSshConnection.run_test_command(\"show hostname\", to_node.hostname)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            toNodeSshConnection.run_test_command(\"hostname\", to_node.hostname)", "prediction_line": "            toNodeSshConnection.run_test_command(\"hostname\", to_node.hostname)", "ground_truth": "            toNodeSshConnection.run_test_command(\"echo hello\", \"hello\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    TEST_PLAN = yaml.safe_load(open(\"test_plan.yaml\"))", "prediction_line": "    TEST_PLAN = yaml.safe_load(open(\"test_plan.yaml\"))", "ground_truth": "    if csm_api_utils.is_bican_chm():", "line_class": "commited", "zero_context": true}
{"original_prediction": "            total_ran += test_from_node_type_over_network(from_node_type, network, config[network])", "prediction_line": "            total_ran += test_from_node_type_over_network(from_node_type, network, config[network])", "ground_truth": "            total_ran += test_from_node_type_over_network(from_node_type, network, config[network])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            collect_passwords_from_node_type_over_network_to_node_type(from_node_type, network, to_node_type, config[to_node_type])", "prediction_line": "            collect_passwords_from_node_type_over_network_to_node_type(from_node_type, network, to_node_type, config[to_node_type])", "ground_truth": "            from_node = get_ssh_host_for_node_type(from_node_type, [\"ncn-m001\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for to_node_type in TEST_PLAN[from_node_type]:", "prediction_line": "            for to_node_type in TEST_PLAN[from_node_type]:", "ground_truth": "            collect_passwords_from_node_type(from_node_type, TEST_PLAN[from_node_type])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    print(\"\"\"\\nTesting SSH access:", "prediction_line": "    print(\"\"\"\\nTesting SSH access:", "ground_truth": "    to_node = get_ssh_host_for_node_type(to_node_type, [\"ncn-m001\", from_node.hostname])", "line_class": "infile", "zero_context": true}
{"original_prediction": "def test_from_node_type_over_network(from_node_type, network, config):", "prediction_line": "def test_from_node_type_over_network(from_node_type, network, config):", "ground_truth": "            collect_passwords_from_node_type_to_node_type_over_network(from_node_type, from_node, to_node_type, network)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    logging.basicConfig(format='%(asctime)s %(message)s', level=logging.INFO)", "prediction_line": "    logging.basicConfig(format='%(asctime)s %(message)s', level=logging.INFO)", "ground_truth": "    load_test_plan()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    for test in TEST_PLAN:", "prediction_line": "    for test in TEST_PLAN:", "ground_truth": "    execute_test_plan()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for to_node_type in TEST_PLAN[from_node_type]:", "prediction_line": "            for to_node_type in TEST_PLAN[from_node_type]:", "ground_truth": "            total_ran += test_from_node_type(from_node_type, TEST_PLAN[from_node_type])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for to_node_type in config[network]:", "prediction_line": "            for to_node_type in config[network]:", "ground_truth": "            collect_passwords_from_node_type_over_network(from_node_type, network, config[network])", "line_class": "infile", "zero_context": true}
{"original_prediction": "       toNodeSshConnection.disconnect()", "prediction_line": "       toNodeSshConnection.disconnect()", "ground_truth": "        if \"switch\" in to_node.type:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    except Exception as e:", "prediction_line": "    except Exception as e:", "ground_truth": "    except Exception as err:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "import os", "prediction_line": "import os", "ground_truth": "import os", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "TOTAL_FAIL = 0", "prediction_line": "TOTAL_FAIL = 0", "ground_truth": "def start_test(from_types, to_types, networks):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR", "prediction_line": "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR", "ground_truth": "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        else:\n            toNodeSshConnection.run_test_command(\"hostname\", to_node.hostname)", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "            return i", "prediction_line": "            return i", "ground_truth": "            return i", "line_class": "random", "zero_context": true}
{"original_prediction": "    global SSH_TARGETS", "prediction_line": "    global SSH_TARGETS", "ground_truth": "    for network in config:", "line_class": "random", "zero_context": true}
{"original_prediction": "    return 1", "prediction_line": "    return 1", "ground_truth": "    finally:", "line_class": "random", "zero_context": true}
{"original_prediction": "    main()", "prediction_line": "    main()", "ground_truth": "    main()", "line_class": "commited", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "            subprocess.run([\"podman\", \"pull\", remote_registry + \"/ceph/ceph:\" + new_vers])", "line_class": "common", "zero_context": true}
{"original_prediction": "            image_exists = subprocess.run([\"podman\", \"image\", \"exists\", remote_registry + \"/ceph/ceph:\" + new_vers], check=True)", "prediction_line": "            image_exists = subprocess.run([\"podman\", \"image\", \"exists\", remote_registry + \"/ceph/ceph:\" + new_vers], check=True)", "ground_truth": "            image_present = subprocess.run([\"podman\", \"image\", \"exists\", remote_registry + \"/ceph/ceph:\" + new_vers], check=True)", "line_class": "common", "zero_context": true}
{"original_prediction": "        init_connect()", "prediction_line": "        init_connect()", "ground_truth": "        init_connect()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        fetch_per_service_count(service, cmd, new_version, current_version)", "prediction_line": "        fetch_per_service_count(service, cmd, new_version, current_version)", "ground_truth": "        fetch_per_service_sha_count(service, cmd, curr_sha, new_sha)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        current_version = fetch_base_current_vers()", "prediction_line": "        current_version = fetch_base_current_vers()", "ground_truth": "        curr_sha = fetch_curr_sha(mon, new_version)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        image_status = image_check(args.registry, pretty_version)", "prediction_line": "        image_status = image_check(args.registry, pretty_version)", "ground_truth": "        image_status = image_check(args.registry, pretty_version)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        new_sha = fetch_new_sha(args.registry, pretty_version)", "prediction_line": "        new_sha = fetch_new_sha(args.registry, pretty_version)", "ground_truth": "        new_sha = fetch_new_sha(args.registry, pretty_version)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if image_status != 0:", "prediction_line": "        if image_status != 0:", "ground_truth": "        current_version = fetch_base_current_vers()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        upgrade_check_success = upgrade_check(pretty_version, args.registry, current_version, args.quiet, args.in_family_override, image_status)", "prediction_line": "        upgrade_check_success = upgrade_check(pretty_version, args.registry, current_version, args.quiet, args.in_family_override, image_status)", "ground_truth": "        upgrade_proceed = upgrade_check(pretty_version, args.registry, current_version, args.quiet, args.in_family_override, image_status)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if upgrade_check_success:", "prediction_line": "        if upgrade_check_success:", "ground_truth": "        disconnect()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        fetch_per_service_count(service, cmd, new_version, current_version)", "prediction_line": "        fetch_per_service_count(service, cmd, new_version, current_version)", "ground_truth": "      total = fetch_service_count_total(service,cmd, new_version)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    cmd_results = cluster.mon_command(json.dumps(cmd), b'', timeout=5)", "prediction_line": "    cmd_results = cluster.mon_command(json.dumps(cmd), b'', timeout=5)", "ground_truth": "    fetch_per_service_count(service, cmd, new_version, current_version)", "line_class": "infile", "zero_context": true}
{"original_prediction": "          if globals()[old_sha_vers_count] == 0 and globals()[new_sha_vers_count] == total:", "prediction_line": "          if globals()[old_sha_vers_count] == 0 and globals()[new_sha_vers_count] == total:", "ground_truth": "            service_upgr =  in_family_upgrade_watch(service, cmd, curr_sha, new_sha, total_upgr, old_sha_vers_count, new_sha_vers_count, final_count)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            service_upgr = upgrade_watch(service, cmd, total_upgr, old_vers_count, new_vers_count, final_count)", "prediction_line": "            service_upgr = upgrade_watch(service, cmd, total_upgr, old_vers_count, new_vers_count, final_count)", "ground_truth": "            total_upgr =  watch_upgrade(service, cmd, new_version, current_version, total_upgr, old_vers_count, new_vers_count, final_count)", "line_class": "infile", "zero_context": true}
{"original_prediction": "          fetch_status(service, cmd)", "prediction_line": "          fetch_status(service, cmd)", "ground_truth": "            fetch_status(service,cmd)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if not args.quiet:", "prediction_line": "        if not args.quiet:", "ground_truth": "        upgrade_check_success = upgrade_check(pretty_version, args.registry, current_version, args.quiet, args.in_family_override, image_status)", "line_class": "infile", "zero_context": true}
{"original_prediction": "      table.add_row([host, type, id, vers, status, image_name])", "prediction_line": "      table.add_row([host, type, id, vers, status, image_name])", "ground_truth": "      table.add_row([host, type, id, vers, status, image_name])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "      cluster.connect()", "prediction_line": "      cluster.connect()", "ground_truth": "      cluster.connect(1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    try:\n        subprocess.check_output([\"podman\", \"pull\", remote_registry + \"/ceph/ceph:\" + new_vers])", "prediction_line": "    try:", "ground_truth": "    image_exists = subprocess.run([\"podman\", \"image\", \"exists\", remote_registry + \"/ceph/ceph:\" + new_vers], stdout=subprocess.PIPE)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if image_exists.returncode == 0:", "prediction_line": "    if image_exists.returncode == 0:", "ground_truth": "    image_present = image_exists.returncode", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        type = (results[s][\"daemon_type\"])", "prediction_line": "        type = (results[s][\"daemon_type\"])", "ground_truth": "        type = (results[s][\"daemon_type\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   args = parser.parse_args()", "prediction_line": "   args = parser.parse_args()", "ground_truth": "    args = parser.parse_args()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return results", "prediction_line": "    return results", "ground_truth": "    for key,value in results.items():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        dest='version',", "prediction_line": "                        dest='version',", "ground_truth": "                        type=str,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "      daemon_type = (refined_results[s][\"daemon_type\"])", "prediction_line": "      daemon_type = (refined_results[s][\"daemon_type\"])", "ground_truth": "      type = (refined_results[s][\"daemon_type\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"\"\"\n\n    if args.version is not None:", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "\"\"\"\n\ndef connect_cluster(cluster_name, cluster_user, cluster_keyring):", "prediction_line": "\"\"\"", "ground_truth": "All functions or checks related to connecting/disconnecting to the cluster should live below.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            print(\"The image cannot be pulled from the registry.  Please ensure you have the right image path and version.\")", "prediction_line": "            print(\"The image cannot be pulled from the registry.  Please ensure you have the right image path and version.\")", "ground_truth": "            print(\"The image cannot be pulled from the registry.  Please ensure you have the right image path and version.\")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    if args.registry is not None:", "prediction_line": "    if args.registry is not None:", "ground_truth": "    ## Set cmds ##", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            upgrade_success = upgrade_execute(new_version, args.registry, upgrade_cmd, current_version, services, args.quiet, args.in_family_override, curr_sha, new_sha)", "prediction_line": "            upgrade_success = upgrade_execute(new_version, args.registry, upgrade_cmd, current_version, services, args.quiet, args.in_family_override, curr_sha, new_sha)", "ground_truth": "          upgrade_success = upgrade_execute(new_version, args.registry, upgrade_cmd, current_version, services, args.quiet, args.in_family_override, curr_sha, new_sha)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    if registry == \"localhost\":", "prediction_line": "    if registry == \"localhost\":", "ground_truth": "    if registry == \"localhost\":", "line_class": "random", "zero_context": true}
{"original_prediction": "    return image_present", "prediction_line": "    return image_present", "ground_truth": "    if image_present != 0:", "line_class": "random", "zero_context": true}
{"original_prediction": "        vers = (results[s][\"version\"])", "prediction_line": "        vers = (results[s][\"version\"])", "ground_truth": "        vers = (results[s][\"version\"])", "line_class": "random", "zero_context": true}
{"original_prediction": "    else:\n        remote_registry = registry", "prediction_line": "    else:", "ground_truth": "    else:", "line_class": "random", "zero_context": true}
{"original_prediction": "        old_sha_count = (\"%s_sha_curr_count\" % (service))", "prediction_line": "        old_sha_count = (\"%s_sha_curr_count\" % (service))", "ground_truth": "        old_sha_vers_count = (\"%s_sha_curr_count\" % (service))", "line_class": "random", "zero_context": true}
{"original_prediction": "    if is_accelerated_module(pickle):", "prediction_line": "    if is_accelerated_module(pickle):", "ground_truth": "    if is_accelerated_module(pickle):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"pickle\": (bench_pickle, 20),", "prediction_line": "    \"pickle\": (bench_pickle, 20),", "ground_truth": "    \"pickle\": (bench_pickle, 20),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"unpickle\": (bench_unpickle, 20),", "prediction_line": "    \"unpickle\": (bench_unpickle, 20),", "ground_truth": "    \"unpickle\": (bench_unpickle, 20),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # 10 inner-loops: don't count the 10 pickled objects", "prediction_line": "    # 10 inner-loops: don't count the 10 pickled objects", "ground_truth": "    \"pickle_list\": (bench_pickle_list, 10),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if not is_accelerated_module(pickle):", "prediction_line": "    if not is_accelerated_module(pickle):", "ground_truth": "    if not is_accelerated_module(pickle):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"unpickle_list\": (bench_unpickle_list, 10),", "prediction_line": "    \"unpickle_list\": (bench_unpickle_list, 10),", "ground_truth": "    \"unpickle_list\": (bench_unpickle_list, 10),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"pickle_dict\": (bench_pickle_dict, 5),", "prediction_line": "    \"pickle_dict\": (bench_pickle_dict, 5),", "ground_truth": "    \"pickle_dict\": (bench_pickle_dict, 5),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        run_benchmark_pure_python(bench)", "prediction_line": "        run_benchmark_pure_python(bench)", "ground_truth": "        run_benchmark_pure_python(bench)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        run_benchmark_c(bench)", "prediction_line": "        run_benchmark_c(bench)", "ground_truth": "        run_benchmark_c(bench)", "line_class": "infile", "zero_context": true}
{"original_prediction": "def main():", "prediction_line": "def main():", "ground_truth": "DICT_GROUP = [mutate_dict(DICT, random_source) for _ in range(3)]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # micro-optimization: use fast local variables", "prediction_line": "    # micro-optimization: use fast local variables", "ground_truth": "    # micro-optimization: use fast local variables", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "to the methodology used by the Python core developers for testing the", "prediction_line": "to the methodology used by the Python core developers for testing the", "ground_truth": "to real-world scenarios which operate on single objects at a time. Note that if", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def main():\n    import pickle", "prediction_line": "def main():", "ground_truth": "LIST = [[list(range(10)), list(range(10))] for _ in range(10)]", "line_class": "random", "zero_context": true}
{"original_prediction": "        265867233,", "prediction_line": "        265867233,", "ground_truth": "        265463699,", "line_class": "random", "zero_context": true}
{"original_prediction": "            dumps(obj, protocol)", "prediction_line": "            dumps(obj, protocol)", "ground_truth": "            dumps(obj, protocol)", "line_class": "random", "zero_context": true}
{"original_prediction": "    loads = pickle.loads", "prediction_line": "    loads = pickle.loads", "ground_truth": "    loads = pickle.loads", "line_class": "random", "zero_context": true}
{"original_prediction": "    pickle_module = pickle", "prediction_line": "    pickle_module = pickle", "ground_truth": "    dumps = pickle.dumps", "line_class": "random", "zero_context": true}
{"original_prediction": "   if n % width:", "prediction_line": "   if n % width:", "ground_truth": "    probs, chars = make_cumulative(table)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    seq = init_benchmarks(args.fasta_length, args.rng_seed)", "prediction_line": "    seq = init_benchmarks(args.fasta_length, args.rng_seed)", "ground_truth": "    seq = init_benchmarks(args.fasta_length, args.rng_seed)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            res = run_benchmarks(seq)", "prediction_line": "            res = run_benchmarks(seq)", "ground_truth": "            res = run_benchmarks(seq)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    runner = pyperf.Runner(add_cmdline_args=add_cmdline_args)", "prediction_line": "    runner = pyperf.Runner(add_cmdline_args=add_cmdline_args)", "ground_truth": "    runner = pyperf.Runner(add_cmdline_args=add_cmdline_args)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    runner.bench_time_func(\"regex_dna\", bench_regex_dna, seq, expected_res)", "prediction_line": "    runner.bench_time_func(\"regex_dna\", bench_regex_dna, seq, expected_res)", "ground_truth": "    runner.bench_time_func(\"regex_dna\", bench_regex_dna, seq, expected_res)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    nprint(ALU * 2 ** 12)", "prediction_line": "    nprint(ALU * 2 ** 12)", "ground_truth": "    repeat_fasta(ALU, n * 2, nprint=nprint)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        is_trailing_line = True", "prediction_line": "        is_trailing_line = True", "ground_truth": "        # We don't end on a 60 char wide line", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# -*- coding: utf-8 -*-", "prediction_line": "# -*- coding: utf-8 -*-", "ground_truth": "\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def regex_dna(seq):", "prediction_line": "def regex_dna(seq):", "ground_truth": "DEFAULT_INIT_LEN = 100000", "line_class": "random", "zero_context": true}
{"original_prediction": "    is_trailing_line = False", "prediction_line": "    is_trailing_line = False", "ground_truth": "    is_trailing_line = False", "line_class": "random", "zero_context": true}
{"original_prediction": "    i = 0", "prediction_line": "    i = 0", "ground_truth": "    width = 60", "line_class": "random", "zero_context": true}
{"original_prediction": "def track_benchmarks(n, rng_seed):", "prediction_line": "def track_benchmarks(n, rng_seed):", "ground_truth": "VARIANTS = (", "line_class": "random", "zero_context": true}
{"original_prediction": "    (\"g\", 0.1975473066391),", "prediction_line": "    (\"g\", 0.1975473066391),", "ground_truth": "    (\"g\", 0.1975473066391),", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.total_memory = 0", "prediction_line": "        self.total_memory = 0", "ground_truth": "        self.start = datetime.now()", "line_class": "common", "zero_context": true}
{"original_prediction": "            f\"[b]Memory[/]: {size_fmt(self._current_memory_size)}\",", "prediction_line": "            f\"[b]Memory[/]: {size_fmt(self._current_memory_size)}\",", "ground_truth": "            f\"[b]Duration[/]: {(self._last_update - self.start).total_seconds()} seconds\",", "line_class": "common", "zero_context": true}
{"original_prediction": "        layout[\"header\"].update(", "prediction_line": "        layout[\"header\"].update(", "ground_truth": "        layout[\"footer\"].update(", "line_class": "common", "zero_context": true}
{"original_prediction": "f\"[b]Native[/]: {self._native}\")", "prediction_line": "f\"[b]Native[/]: {self._native}\")", "ground_truth": "            f\"[b]TID[/]: {hex(self.current_thread)}\",", "line_class": "infile", "zero_context": true}
{"original_prediction": ") -> Dict[Location, AllocationEntry]:", "prediction_line": ") -> Dict[Location, AllocationEntry]:", "ground_truth": ") -> Dict[Location, AllocationEntry]:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.stream.reset_max(self._max_memory_seen)", "prediction_line": "            self.stream.reset_max(self._max_memory_seen)", "ground_truth": "            self.stream.reset_max(self._max_memory_seen)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.stream.add_value(self._current_memory_size)", "prediction_line": "        self.stream.add_value(self._current_memory_size)", "ground_truth": "        self.stream.add_value(self._current_memory_size)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       metadata.add_row(", "prediction_line": "       metadata.add_row(", "ground_truth": "        graph = \"\\n\".join(self.stream.graph)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        AllocationEntry", "prediction_line": "        AllocationEntry", "ground_truth": "        lambda: AllocationEntry(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            graph,\n            title=\"[b]Memory[/]\",", "prediction_line": "            graph,", "ground_truth": "            f\"[color({2})]{graph}[/]\",", "line_class": "infile", "zero_context": true}
{"original_prediction": "            continue\n\n        for frame in stack_trace:", "prediction_line": "            continue", "ground_truth": "            frame = processed_allocations[Location(function=\"???\", file=\"???\")]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            location = Location(function=function, file=file_name)", "prediction_line": "            location = Location(function=function, file=file_name)", "ground_truth": "            location = Location(function=function, file=file_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        frame = processed_allocations[location]", "prediction_line": "        frame = processed_allocations[location]", "ground_truth": "        processed_allocations[location] = AllocationEntry(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        total_memory = sum(record.total_memory for record in self._snapshot)", "prediction_line": "        total_memory = sum(record.total_memory for record in self._snapshot)", "ground_truth": "        allocation_entries = aggregate_allocations(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            table.add_row(", "prediction_line": "            table.add_row(", "ground_truth": "            if self.current_thread not in result.thread_ids:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._values.append(value)", "prediction_line": "        self._values.append(value)", "ground_truth": "        blocks = self._value_to_blocks(value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            table.add_row(", "prediction_line": "            table.add_row(", "ground_truth": "            total_color = _size_to_color(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            own_color = _size_to_color(result.own_memory / self._current_memory_size)", "prediction_line": "            own_color = _size_to_color(result.own_memory / self._current_memory_size)", "ground_truth": "            own_color = _size_to_color(result.own_memory / self._current_memory_size)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            table.add_row(", "prediction_line": "            table.add_row(", "ground_truth": "            allocation_colors = _size_to_color(result.n_allocations / total_allocations)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.add_value(value)", "prediction_line": "            self.add_value(value)", "ground_truth": "            self.add_value(value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._sort_reverse = False", "prediction_line": "        self._sort_reverse = False", "ground_truth": "        self._terminal_size = _get_terminal_lines()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._memory_graph = MemoryGraph(", "prediction_line": "        self._memory_graph = MemoryGraph(", "ground_truth": "        self.stream = MemoryGraph(50, 4, 0.0, 1024.0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @message.setter", "prediction_line": "    @message.setter", "ground_truth": "    @message.setter", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._message = message", "prediction_line": "        self._message = message", "ground_truth": "        self._message = message", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.layout[\"header\"].update(self.get_header())", "prediction_line": "        self.layout[\"header\"].update(self.get_header())", "ground_truth": "        self.layout[\"header\"].update(self.get_header())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.layout[\"heap_size\"].update(self.get_heap_size())", "prediction_line": "        self.layout[\"heap_size\"].update(self.get_heap_size())", "ground_truth": "        self.layout[\"heap_size\"].update(self.get_heap_size())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.layout[\"table\"].update(self.get_body())", "prediction_line": "        self.layout[\"table\"].update(self.get_body())", "ground_truth": "        self.layout[\"table\"].update(self.get_body())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.layout[\"message\"].update(self.message)", "prediction_line": "        self.layout[\"message\"].update(self.message)", "ground_truth": "        self.layout[\"message\"].update(self.message)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for frame in stack_trace:", "prediction_line": "        for frame in stack_trace:", "ground_truth": "        (function, file_name, _), *caller_frames = stack_trace", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return heap_grid", "prediction_line": "        return heap_grid", "ground_truth": "        bar = ProgressBar(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        bar.update_bar()", "prediction_line": "        bar.update_bar()", "ground_truth": "        heap_grid.add_row(bar)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       if allocation.size < memory_threshold:", "prediction_line": "       if allocation.size < memory_threshold:", "ground_truth": "        stack_trace = list(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "allocation.stack_trace)", "prediction_line": "allocation.stack_trace)", "ground_truth": "            allocation.hybrid_stack_trace()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            else allocation.python_stack_trace()", "prediction_line": "            else allocation.python_stack_trace()", "ground_truth": "            else allocation.stack_trace()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if not stack_trace:", "prediction_line": "        if not stack_trace:", "ground_truth": "        if not stack_trace:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@dataclass\nclass MemoryGraphs:", "prediction_line": "@dataclass", "ground_truth": "def _get_terminal_lines() -> int:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def render(self) -> str:", "prediction_line": "    def render(self) -> str:", "ground_truth": "    def reset_max(self, value: float) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def message(self, message: str) -> None:", "prediction_line": "    def message(self, message: str) -> None:", "ground_truth": "    def message(self, message: str) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        6: \"n_allocations\",", "prediction_line": "        6: \"n_allocations\",", "ground_truth": "    }", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            blocks.append(n_dots % dots_per_block)", "prediction_line": "            blocks.append(n_dots % dots_per_block)", "ground_truth": "            blocks += [n_dots % dots_per_block]", "line_class": "random", "zero_context": true}
{"original_prediction": "        self._thread_id = None", "prediction_line": "        self._thread_id = None", "ground_truth": "        self._seen_threads: Set[int] = set()", "line_class": "random", "zero_context": true}
{"original_prediction": "    location: Location", "prediction_line": "    location: Location", "ground_truth": "    n_allocations: int", "line_class": "random", "zero_context": true}
{"original_prediction": "        table = Table.grid(expand=False, padding=(0, 0, 0, 4))", "prediction_line": "        table = Table.grid(expand=False, padding=(0, 0, 0, 4))", "ground_truth": "        heap_grid = Table.grid(expand=True)", "line_class": "random", "zero_context": true}
{"original_prediction": "            frame.own_memory += allocation.size", "prediction_line": "            frame.own_memory += allocation.size", "ground_truth": "            frame.total_memory += allocation.size", "line_class": "random", "zero_context": true}
{"original_prediction": "        super(CheckerboardSurface, self).__init__(**kwargs)", "prediction_line": "        super(CheckerboardSurface, self).__init__(**kwargs)", "ground_truth": "        SimpleSurface.__init__(self, **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.colour = kwargs.get(\"colour\", (1, 1, 1))", "prediction_line": "        self.colour = kwargs.get(\"colour\", (1, 1, 1))", "ground_truth": "        self.baseColour = kwargs.get(\"baseColour\", (1, 1, 1))", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.ambient = kwargs.get(\"ambient\", 0.1)", "prediction_line": "        self.ambient = kwargs.get(\"ambient\", 0.1)", "ground_truth": "        self.specularCoefficient = kwargs.get(\"specularCoefficient\", 0.2)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.specularExponent = kwargs.get(\"specularExponent\", 10)", "prediction_line": "        self.specularExponent = kwargs.get(\"specularExponent\", 10)", "ground_truth": "        self.lambertCoefficient = kwargs.get(\"lambertCoefficient\", 0.6)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.checkerSize = kwargs.get(\"checkerSize\", 1)", "prediction_line": "        self.checkerSize = kwargs.get(\"checkerSize\", 1)", "ground_truth": "        self.otherColour = kwargs.get(\"otherColour\", (0, 0, 0))", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.checkerSize = kwargs.get(\"checkerSize\", 1)", "prediction_line": "        self.checkerSize = kwargs.get(\"checkerSize\", 1)", "ground_truth": "        self.checkSize = kwargs.get(\"checkSize\", 1)", "line_class": "common", "zero_context": true}
{"original_prediction": "                Sphere(Point(0, 0, -10), 2),", "prediction_line": "                Sphere(Point(0, 0, -10), 2),", "ground_truth": "                Sphere(Point(-3 - y * 0.4, 2.3, -5), 0.4),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.vector = vector", "prediction_line": "        self.vector = vector", "ground_truth": "        self.vector = vector.normalized()", "line_class": "infile", "zero_context": true}
{"original_prediction": "       for y in range(canvas.height):", "prediction_line": "       for y in range(canvas.height):", "ground_truth": "        eye = Ray(self.position, self.lookingAt - self.position)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    import argparse", "prediction_line": "    import argparse", "ground_truth": "    bench_raytrace(1, DEFAULT_WIDTH, DEFAULT_HEIGHT, None)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            intersections = self.intersections(ray)", "prediction_line": "            intersections = self.intersections(ray)", "ground_truth": "            intersections = [(o, o.intersectionTime(ray), s) for (o, s) in self.objects]", "line_class": "infile", "zero_context": true}
{"original_prediction": "class Scene(object):", "prediction_line": "class Scene(object):", "ground_truth": "Point.ZERO = Point(0, 0, 0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.normal = normal", "prediction_line": "        self.normal = normal", "ground_truth": "        self.normal = normal.normalized()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                lightVector = lightPoint - p", "prediction_line": "                lightVector = lightPoint - p", "ground_truth": "                contribution = (lightPoint - p).normalized().dot(normal)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        other.mustBeVector()", "prediction_line": "        other.mustBeVector()", "ground_truth": "        other.mustBeVector()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        s.addLight(Point(30, 30, 30))", "prediction_line": "        s.addLight(Point(30, 30, 30))", "ground_truth": "        s.addLight(Point(-10, 100, 30))", "line_class": "infile", "zero_context": true}
{"original_prediction": "Vector.UP = Vector(0, 1, 0)", "prediction_line": "Vector.UP = Vector(0, 1, 0)", "ground_truth": "Vector.UP = Vector(0, 1, 0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        scene = Scene()", "prediction_line": "        scene = Scene()", "ground_truth": "        canvas = Canvas(width, height)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return Vector(self.x + other.x, self.y + other.y, self.z + other.z)", "prediction_line": "        return Vector(self.x + other.x, self.y + other.y, self.z + other.z)", "ground_truth": "        if other.isPoint():", "line_class": "infile", "zero_context": true}
{"original_prediction": "Vector.FORWARD = Vector(0, 0, 1)", "prediction_line": "Vector.FORWARD = Vector(0, 0, 1)", "ground_truth": "Vector.OUT = Vector(0, 0, 1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        b = 2 * cp.dot(ray.direction)", "prediction_line": "        b = 2 * cp.dot(ray.direction)", "ground_truth": "        v = cp.dot(ray.vector)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                canvas.plot(x, y, colour[0], colour[1], colour[2])", "prediction_line": "                canvas.plot(x, y, colour[0], colour[1], colour[2])", "ground_truth": "                canvas.plot(x, y, *colour)", "line_class": "infile", "zero_context": true}
{"original_prediction": "class Point(Vector):", "prediction_line": "class Point(Vector):", "ground_truth": "assert Vector.RIGHT.reflectThrough(Vector.UP) == Vector.RIGHT", "line_class": "infile", "zero_context": true}
{"original_prediction": "        s.addObject(Sphere(Point(0, 0, 0), 1), SimpleSurface())", "prediction_line": "        s.addObject(Sphere(Point(0, 0, 0), 1), SimpleSurface())", "ground_truth": "        s.lookAt(Point(0, 3, 0))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for x in range(6):", "prediction_line": "            for x in range(6):", "ground_truth": "            s.addObject(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return Vector(", "prediction_line": "        return Vector(", "ground_truth": "        return Vector(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.point + self.vector.scale(t)", "prediction_line": "        return self.point + self.vector.scale(t)", "ground_truth": "        return self.point + self.vector.scale(t)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            intersection = firstIntersection(intersections)", "prediction_line": "            intersection = firstIntersection(intersections)", "ground_truth": "            i = firstIntersection(intersections)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.scale(1.0 / self.magnitude())", "prediction_line": "        return self.scale(1.0 / self.magnitude())", "ground_truth": "        return self.scale(1.0 / self.magnitude())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return ray.vector.dot(self.normal) - ray.vector.dot(self.normal)", "prediction_line": "        return ray.vector.dot(self.normal) - ray.vector.dot(self.normal)", "ground_truth": "        v = ray.vector.dot(self.normal)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return Vector(self.x - other.x, self.y - other.y, self.z - other.z)", "prediction_line": "            return Vector(self.x - other.x, self.y - other.y, self.z - other.z)", "ground_truth": "            return Vector(self.x - other.x, self.y - other.y, self.z - other.z)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                pixel = Point(", "prediction_line": "                pixel = Point(", "ground_truth": "                xcomp = vpRight.scale(x * pixelWidth - halfWidth)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return Vector(self.x + other.x, self.y + other.y, self.z + other.z)", "prediction_line": "            return Vector(self.x + other.x, self.y + other.y, self.z + other.z)", "ground_truth": "            return Vector(self.x + other.x, self.y + other.y, self.z + other.z)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        s.addObject(", "prediction_line": "        s.addObject(", "ground_truth": "        s.addObject(Halfspace(Point(0, 0, 0), Vector.UP), CheckerboardSurface())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        s.render(canvas)", "prediction_line": "        s.render(canvas)", "ground_truth": "        s.render(canvas)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                CheckerboardSurface(", "prediction_line": "                CheckerboardSurface(", "ground_truth": "                SimpleSurface(baseColour=(y / 6.0, 1 - y / 6.0, 0.5)),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if o.intersectionTime(Ray(p, l - p)) is not None:", "prediction_line": "            if o.intersectionTime(Ray(p, l - p)) is not None:", "ground_truth": "            t = o.intersectionTime(Ray(p, l - p))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                p = ray.pointAtTime(t)", "prediction_line": "                p = ray.pointAtTime(t)", "ground_truth": "                p = ray.pointAtTime(t)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self - (normal * 2 * self.dot(normal))", "prediction_line": "        return self - (normal * 2 * self.dot(normal))", "ground_truth": "        d = normal.scale(self.dot(normal))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for l in scene.visibleLights(p):", "prediction_line": "            for l in scene.visibleLights(p):", "ground_truth": "            for lightPoint in scene.visibleLights(p):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        disc = v * v - cp.dot(cp) + self.radius * self.radius", "prediction_line": "        disc = v * v - cp.dot(cp) + self.radius * self.radius", "ground_truth": "        discriminant = (self.radius * self.radius) - (cp.dot(cp) - v * v)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for y in range(canvas.height - 1, -1, -1):", "prediction_line": "        for y in range(canvas.height - 1, -1, -1):", "ground_truth": "        vpRight = eye.vector.cross(Vector.UP).normalized()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                colour = self.traceRay(ray, self.recursionDepth)", "prediction_line": "                colour = self.traceRay(ray, self.recursionDepth)", "ground_truth": "                colour = self.rayColour(ray)", "line_class": "infile", "zero_context": true}
{"original_prediction": "class Point(Vector):", "prediction_line": "class Point(Vector):", "ground_truth": "Vector.RIGHT = Vector(1, 0, 0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def addObject(self, o):", "prediction_line": "    def addObject(self, o):", "ground_truth": "    def addObject(self, object, surface):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __repr__(self):", "prediction_line": "    def __repr__(self):", "ground_truth": "    def __repr__(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import math\nimport random", "prediction_line": "import math", "ground_truth": "import math", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __str__(self):", "prediction_line": "    def __str__(self):", "ground_truth": "    def __str__(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.radius = radius", "prediction_line": "        self.radius = radius", "ground_truth": "        self.radius = radius", "line_class": "random", "zero_context": true}
{"original_prediction": "        intersections = [(o, o.intersectionTime(Ray(p, l - p))) for (o, s) in self.objects]", "prediction_line": "        intersections = [(o, o.intersectionTime(Ray(p, l - p))) for (o, s) in self.objects]", "ground_truth": "        for (o, s) in self.objects:", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.x = initx", "prediction_line": "        self.x = initx", "ground_truth": "        self.x = initx", "line_class": "random", "zero_context": true}
{"original_prediction": "        for l in scene.visibleLights(p):", "prediction_line": "        for l in scene.visibleLights(p):", "ground_truth": "        if self.specularCoefficient > 0:", "line_class": "random", "zero_context": true}
{"original_prediction": "                (object, t, surface) = i", "prediction_line": "                (object, t, surface) = i", "ground_truth": "                (o, t, s) = i", "line_class": "random", "zero_context": true}
{"original_prediction": "    return out", "prediction_line": "    return out", "ground_truth": "    return list(set(out))", "line_class": "commited", "zero_context": true}
{"original_prediction": "                        n_pieces_left.remove(p)", "prediction_line": "                        n_pieces_left.remove(p)", "ground_truth": "                        n_pieces_left.remove(p)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    main()", "prediction_line": "    main()", "ground_truth": "    main()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        r_ido = rotate(r_ido)", "prediction_line": "        r_ido = rotate(r_ido)", "ground_truth": "        ps.append(rotate(ps[-1]))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        ps.append(flip(pp))", "prediction_line": "        ps.append(flip(pp))", "ground_truth": "        ps.append(flip(pp))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    board, cti, pieces = get_puzzle(WIDTH, HEIGHT)", "prediction_line": "    board, cti, pieces = get_puzzle(WIDTH, HEIGHT)", "ground_truth": "    board, cti, pieces = get_puzzle(WIDTH, HEIGHT)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    se_nh = get_senh(board, cti)", "prediction_line": "    se_nh = get_senh(board, cti)", "ground_truth": "    se_nh = get_senh(board, cti)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"meteor_contest\",", "prediction_line": "        \"meteor_contest\",", "ground_truth": "        \"meteor_contest\", bench_meteor_contest, board, pieces, solve_arg, fps, se_nh", "line_class": "infile", "zero_context": true}
{"original_prediction": "    idos = [p for p in perms if len(set(p)) == 5]", "prediction_line": "    idos = [p for p in perms if len(set(p)) == 5]", "ground_truth": "    pieces = [[convert(pp) for pp in p] for p in perms]", "line_class": "infile", "zero_context": true}
{"original_prediction": "to C2-symmetry", "prediction_line": "to C2-symmetry", "ground_truth": "    perms = (permute(p, idos[3]) for p in idos)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        n_solutions = solve(", "prediction_line": "                        n_solutions = solve(", "ground_truth": "                        solve(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    i_max,", "prediction_line": "    i_max,", "ground_truth": "    free,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if fp not in free:", "prediction_line": "            if fp not in free:", "ground_truth": "            if fp <= free:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    solve(", "prediction_line": "                    solve(", "ground_truth": "                    n_free = free - fp", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            solve(solve_arg, 0, set(board), board, pieces, [], fps, se_nh)", "prediction_line": "            solve(solve_arg, 0, set(board), board, pieces, [], fps, se_nh)", "ground_truth": "            free = frozenset(range(len(board)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            solve(solve_arg, min(free), free, curr_board, pieces_left, solutions, fps, se_nh)", "prediction_line": "            solve(solve_arg, min(free), free, curr_board, pieces_left, solutions, fps, se_nh)", "ground_truth": "            solve(solve_arg, 0, free, curr_board, pieces_left, solutions, fps, se_nh)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    )", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def flip(ido, fd={E: W, W: E, NE: SW, NW: SE, SE: NW, SW: NE}):", "prediction_line": "def flip(ido, fd={E: W, W: E, NE: SW, NW: SE, SE: NW, SW: NE}):", "ground_truth": "def flip(ido, fd={E: E, NE: SE, NW: SW, W: W, SW: NW, SE: NE}):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "Django settings for mysite project.", "prediction_line": "Django settings for mysite project.", "ground_truth": "Meteor Puzzle board:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    runner.bench_time_func(", "prediction_line": "    runner.bench_time_func(", "ground_truth": "    solve_arg = SOLVE_ARG", "line_class": "random", "zero_context": true}
{"original_prediction": "    if r_ido == ido:", "prediction_line": "    if r_ido == ido:", "ground_truth": "    ps = [ido]", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"00004555045534413334132221177266172677886888969999\",", "prediction_line": "    \"00004555045534413334132221177266172677886888969999\",", "ground_truth": "    \"00004555045534473334739967792617926192661882211888\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"27776272768221681166819958195548395443954033340000\",", "prediction_line": "    \"27776272768221681166819958195548395443954033340000\",", "ground_truth": "    \"33322392623926696648994485554855148117871077710000\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0", "prediction_line": "    (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0", "ground_truth": "    \"00001222012661126155865558633348893448934747977799\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        action = kwargs.get('action')", "prediction_line": "        action = kwargs.get('action')", "ground_truth": "        action = kwargs.get('action')", "line_class": "common", "zero_context": true}
{"original_prediction": "            moveMagnitude=move_magnitude,", "prediction_line": "            moveMagnitude=move_magnitude,", "ground_truth": "            objectId=kwargs.get(\"objectId\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "            receptacleObjectId=kwargs.get(\"receptacleObjectId\"),", "prediction_line": "            receptacleObjectId=kwargs.get(\"receptacleObjectId\"),", "ground_truth": "            receptacleObjectId=kwargs.get(\"receptacleObjectId\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "        action = kwargs.get('action')", "prediction_line": "        action = kwargs.get('action')", "ground_truth": "        force = kwargs.get(self.FORCE_KEY, self.DEFAULT_FORCE)", "line_class": "common", "zero_context": true}
{"original_prediction": "        horizon = self._get_number_with_default(", "prediction_line": "        horizon = self._get_number_with_default(", "ground_truth": "        horizon = kwargs.get(self.HORIZON_KEY, self.DEFAULT_HORIZON)", "line_class": "common", "zero_context": true}
{"original_prediction": "        if action in self.OBJECT_MOVE_ACTIONS:", "prediction_line": "        if action in self.OBJECT_MOVE_ACTIONS:", "ground_truth": "        amount = kwargs.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "        x_pos = kwargs.get(self.TELEPORT_X_POS, None)", "prediction_line": "        x_pos = kwargs.get(self.TELEPORT_X_POS, None)", "ground_truth": "        teleport_rotation = self._get_teleport_rotation(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        teleport_x_pos = self._get_teleport_x_pos(**kwargs)", "prediction_line": "        teleport_x_pos = self._get_teleport_x_pos(**kwargs)", "ground_truth": "        teleport_position = self._get_teleport_position(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x_pos = kwargs.get(self.TELEPORT_X_POS)", "prediction_line": "        x_pos = kwargs.get(self.TELEPORT_X_POS)", "ground_truth": "        teleport_pos_x_input = self._get_number(self.TELEPORT_X_POS, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        teleport_pos_z_input = self._get_number(self.TELEPORT_Z_POS, **kwargs)", "prediction_line": "        teleport_pos_z_input = self._get_number(self.TELEPORT_Z_POS, **kwargs)", "ground_truth": "        teleport_pos_z_input = self._get_number(self.TELEPORT_Z_POS, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        teleport_rotation_input = self._get_number(self.TELEPORT_Y_ROT, **kwargs)", "prediction_line": "        teleport_rotation_input = self._get_number(self.TELEPORT_Y_ROT, **kwargs)", "ground_truth": "        teleport_rot_input = self._get_number(self.TELEPORT_Y_ROT, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if action is None:", "prediction_line": "        if action is None:", "ground_truth": "        amount = self._get_amount(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        force = self._get_force(**kwargs)", "prediction_line": "        force = self._get_force(**kwargs)", "ground_truth": "        force = self._get_force(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        move_magnitude = self._get_move_magnitude(action, force, amount)", "prediction_line": "        move_magnitude = self._get_move_magnitude(action, force, amount)", "ground_truth": "        object_image_coords_x = int(self._get_number_with_default(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        object_image_coords_y = int(self._get_number_with_default(", "prediction_line": "        object_image_coords_y = int(self._get_number_with_default(", "ground_truth": "        object_image_coords_y = int(self._get_number_with_default(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        receptacle_image_coords_x = int(self._get_number_with_default(", "prediction_line": "        receptacle_image_coords_x = int(self._get_number_with_default(", "ground_truth": "        receptable_image_coords_x = int(self._get_number_with_default(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Create the step data dict for the AI2-THOR step function.", "prediction_line": "        # Create the step data dict for the AI2-THOR step function.", "ground_truth": "        action, params = self._validate_and_convert_params(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return action, self.wrap_step(**params)", "prediction_line": "        return action, self.wrap_step(**params)", "ground_truth": "        action = self._mcs_action_to_ai2thor_action(action)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return action, params", "prediction_line": "        return action, params", "ground_truth": "        wrapped_step = self.wrap_step(action=action, **params)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        receptable_image_coords_y = int(self._get_number_with_default(", "prediction_line": "        receptable_image_coords_y = int(self._get_number_with_default(", "ground_truth": "        receptacle_image_coords_y = int(self._get_number_with_default(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            'y': self._convert_y_image_coord_for_unity(object_image_coords_y)", "prediction_line": "            'y': self._convert_y_image_coord_for_unity(object_image_coords_y)", "ground_truth": "            'y': self._convert_y_image_coord_for_unity(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        move_magnitude = self._get_move_magnitude(action, force, amount)", "prediction_line": "        move_magnitude = self._get_move_magnitude(action, force, amount)", "ground_truth": "        move_magnitude = self._get_move_magnitude(action, force, amount)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        teleport_rotation, teleport_position = self._get_teleport(**kwargs)", "prediction_line": "        teleport_rotation, teleport_position = self._get_teleport(**kwargs)", "ground_truth": "        (teleport_rotation, teleport_position) = self._get_teleport(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return (", "prediction_line": "        return (", "ground_truth": "            horizon = horizon * (1 + self._generate_noise())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return (", "prediction_line": "        return (", "ground_truth": "            move_magnitude = move_magnitude * (1 + self._generate_noise())", "line_class": "infile", "zero_context": true}
{"original_prediction": "       move_magnitude = self._get_move_magnitude(action, force, amount)", "prediction_line": "       move_magnitude = self._get_move_magnitude(action, force, amount)", "ground_truth": "        rotation_vector = {'y': rotation}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            moveMagnitude=move_magnitude,", "prediction_line": "            moveMagnitude=move_magnitude,", "ground_truth": "            rotation=rotation_vector,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            noise = random.uniform(self.MIN_NOISE, self.MAX_NOISE)", "prediction_line": "            noise = random.uniform(self.MIN_NOISE, self.MAX_NOISE)", "ground_truth": "            rotation = rotation * (1 + self._generate_noise())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            renderInstanceSegmentation=self.config.is_instance_segmentation_enabled(),", "prediction_line": "            renderInstanceSegmentation=self.config.is_instance_segmentation_enabled(),", "ground_truth": "            renderObjectImage=self.config.is_object_masks_enabled(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Convert MCS action to AI2-THOR action.", "prediction_line": "        \"\"\"", "ground_truth": "        if action == Action.CLOSE_OBJECT.value:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "self, key: str, default: float, **kwargs) -> float:", "prediction_line": "self, key: str, default: float, **kwargs) -> float:", "ground_truth": "            self, key: str, default: Any, **kwargs) -> Any:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            val = default", "prediction_line": "            val = default", "ground_truth": "            val = float(default)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        val = kwargs.get(key)", "prediction_line": "        val = kwargs.get(key)", "ground_truth": "        val = kwargs.get(key, default)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        rotation = kwargs.get(self.ROTATION_KEY, self.DEFAULT_ROTATION)", "prediction_line": "        rotation = kwargs.get(self.ROTATION_KEY, self.DEFAULT_ROTATION)", "ground_truth": "        rotation = kwargs.get(self.ROTATION_KEY, self.DEFAULT_ROTATION)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                raise ValueError(f\"{key}\") from err", "prediction_line": "                raise ValueError(f\"{key}\") from err", "ground_truth": "                raise ValueError(f\"{key}\") from err", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # (for debugging)", "prediction_line": "        # (for debugging)", "ground_truth": "        metadata_tier = self.config.get_metadata_tier()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # noise = self._get_noise(**kwargs)", "prediction_line": "        # noise = self._get_noise(**kwargs)", "ground_truth": "        if self.config.is_noise_enabled():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self.config.get_height() - y_coord", "prediction_line": "        return self.config.get_height() - y_coord", "ground_truth": "        screen_height = self.config.get_screen_height()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif action == Action.END_HABITUATION.value:", "prediction_line": "        elif action == Action.END_HABITUATION.value:", "ground_truth": "        elif action == Action.OPEN_OBJECT.value:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif action == Action.OPEN_OBJECT.value:", "prediction_line": "        elif action == Action.OPEN_OBJECT.value:", "ground_truth": "        elif action == Action.DROP_OBJECT.value:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"\n        return random.uniform(self.MIN_NOISE, self.MAX_NOISE)", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def _get_teleport_rotation(self, **kwargs) -> float:", "prediction_line": "    def _get_teleport_rotation(self, **kwargs) -> float:", "ground_truth": "    def _get_teleport_position(self, **kwargs) -> Optional[Dict]:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Wraps the step input with the appropriate parameters", "prediction_line": "        \"\"\"", "ground_truth": "        # whether or not to randomize segmentation mask colors", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       self.metadata = self.config.get_metadata()", "prediction_line": "       self.metadata = self.config.get_metadata()", "ground_truth": "    def wrap_step(self, **kwargs) -> Dict:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    AMOUNT_KEY = 'amount'", "prediction_line": "    AMOUNT_KEY = 'amount'", "ground_truth": "    AMOUNT_KEY = 'amount'", "line_class": "random", "zero_context": true}
{"original_prediction": "            try:\n                force = float(force)", "prediction_line": "            try:", "ground_truth": "            try:", "line_class": "random", "zero_context": true}
{"original_prediction": "    DEFAULT_MOVE_FORWARD = 0.25", "prediction_line": "    DEFAULT_MOVE_FORWARD = 0.25", "ground_truth": "    DEFAULT_AMOUNT = 0.5", "line_class": "random", "zero_context": true}
{"original_prediction": "                raise ValueError(f\"Force {force} is not a number\") from err", "prediction_line": "                raise ValueError(f\"Force {force} is not a number\") from err", "ground_truth": "                raise ValueError('Force is not a number') from err", "line_class": "random", "zero_context": true}
{"original_prediction": "        if force is not None:", "prediction_line": "        if force is not None:", "ground_truth": "        if force is not None:", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.parameter_converter._convert_y_image_coord_for_unity(", "prediction_line": "            self.parameter_converter._convert_y_image_coord_for_unity(", "ground_truth": "            self.parameter_converter._convert_y_image_coord_for_unity(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        number = self.parameter_converter._get_number(", "prediction_line": "        number = self.parameter_converter._get_number(", "ground_truth": "        number = self.parameter_converter._get_number_with_default(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_number_with_default(", "prediction_line": "            lambda: self.parameter_converter._get_number_with_default(", "ground_truth": "            lambda: self.parameter_converter._get_number_with_default(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._convert_y_image_coord_for_unity(", "prediction_line": "            lambda: self.parameter_converter._convert_y_image_coord_for_unity(", "ground_truth": "            lambda: self.parameter_converter._convert_y_image_coord_for_unity(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        parameter_converter = Parameter(config)", "prediction_line": "        parameter_converter = Parameter(config)", "ground_truth": "        parameter_converter = Parameter(config)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        actual = parameter_converter.wrap_step(", "prediction_line": "        actual = parameter_converter.wrap_step(", "ground_truth": "        actual = parameter_converter.wrap_step(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        magnitude = self.parameter_converter._get_move_magnitude(", "prediction_line": "        magnitude = self.parameter_converter._get_move_magnitude(", "ground_truth": "        magnitude = self.parameter_converter._get_move_magnitude(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            action=Parameter.OBJECT_MOVE_ACTIONS[0],", "prediction_line": "            action=Parameter.OBJECT_MOVE_ACTIONS[0],", "ground_truth": "            action=Parameter.FORCE_ACTIONS[0],", "line_class": "commited", "zero_context": true}
{"original_prediction": "            action=Parameter.OBJECT_MOVE_ACTIONS[0],", "prediction_line": "            action=Parameter.OBJECT_MOVE_ACTIONS[0],", "ground_truth": "            action=Parameter.OBJECT_MOVE_ACTIONS[0],", "line_class": "commited", "zero_context": true}
{"original_prediction": "       noise = self.parameter_converter.generate_noise(", "prediction_line": "       noise = self.parameter_converter.generate_noise(", "ground_truth": "        current_noise = self.parameter_converter._generate_noise()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        teleport = self.parameter_converter._get_teleport(", "prediction_line": "        teleport = self.parameter_converter._get_teleport(", "ground_truth": "        (teleport_rot, teleport_pos) = self.parameter_converter._get_teleport()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        amount = self.parameter_converter._get_amount(", "prediction_line": "        amount = self.parameter_converter._get_amount(", "ground_truth": "        amount = self.parameter_converter._get_amount(action=\"\", amount=1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        (teleport_rot, teleport_pos) = self.parameter_converter._get_teleport(", "prediction_line": "        (teleport_rot, teleport_pos) = self.parameter_converter._get_teleport(", "ground_truth": "        (teleport_rot, teleport_pos) = self.parameter_converter._get_teleport(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        amount = self.parameter_converter._get_amount(action=\"\", amount=0.5)", "prediction_line": "        amount = self.parameter_converter._get_amount(action=\"\", amount=0.5)", "ground_truth": "        amount = self.parameter_converter._get_amount()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.assertAlmostEqual(amount, 1.0)", "prediction_line": "        self.assertAlmostEqual(amount, 1.0)", "ground_truth": "        self.assertAlmostEqual(amount, Parameter.DEFAULT_AMOUNT)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    def test_get_amount_with_noise(self):", "prediction_line": "    def test_get_amount_with_noise(self):", "ground_truth": "        amount = self.parameter_converter._get_amount(", "line_class": "commited", "zero_context": true}
{"original_prediction": "action=\"MoveAhead\")", "prediction_line": "action=\"MoveAhead\")", "ground_truth": "            action=Parameter.OBJECT_MOVE_ACTIONS[0])", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.assertAlmostEqual(amount, Parameter.DEFAULT_AMOUNT)", "prediction_line": "        self.assertAlmostEqual(amount, Parameter.DEFAULT_AMOUNT)", "ground_truth": "        self.assertAlmostEqual(amount, Parameter.DEFAULT_OBJECT_MOVE_AMOUNT)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        amount = self.parameter_converter._get_amount(", "prediction_line": "        amount = self.parameter_converter._get_amount(", "ground_truth": "        amount = self.parameter_converter._get_amount(amount=None)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self.parameter_converter._mcs_action_to_ai2thor_action(", "prediction_line": "            self.parameter_converter._mcs_action_to_ai2thor_action(", "ground_truth": "            self.parameter_converter._mcs_action_to_ai2thor_action(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.controller = config.get_controller()", "prediction_line": "        self.controller = config.get_controller()", "ground_truth": "        self.parameter_converter = Parameter(config)", "line_class": "commited", "zero_context": true}
{"original_prediction": "self.parameter_converter._get_amount, amount=\"test\")", "prediction_line": "self.parameter_converter._get_amount, amount=\"test\")", "ground_truth": "            lambda: self.parameter_converter._get_amount(amount=\"string\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_teleport(", "prediction_line": "            lambda: self.parameter_converter._get_teleport(", "ground_truth": "            lambda: self.parameter_converter._get_teleport(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.parameter_converter.wrap_step = True", "prediction_line": "        self.parameter_converter.wrap_step = True", "ground_truth": "        wrapped_step = self.parameter_converter.wrap_step(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_amount(amount=1.1)", "prediction_line": "            lambda: self.parameter_converter._get_amount(amount=1.1)", "ground_truth": "            lambda: self.parameter_converter._get_amount(amount=1.1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        wrapped_step = self.parameter_converter.wrap_step(", "prediction_line": "        wrapped_step = self.parameter_converter.wrap_step(", "ground_truth": "        wrapped_step, params = self.parameter_converter.build_ai2thor_step(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_amount(amount=-1)", "prediction_line": "            lambda: self.parameter_converter._get_amount(amount=-1)", "ground_truth": "            lambda: self.parameter_converter._get_amount(amount=-0.1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        wrapped_step = self.parameter_converter.wrap_step(", "prediction_line": "        wrapped_step = self.parameter_converter.wrap_step(", "ground_truth": "        actual = self.parameter_converter.wrap_step(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        force = self.parameter_converter._get_force(action=\"\", force=1)", "prediction_line": "        force = self.parameter_converter._get_force(action=\"\", force=1)", "ground_truth": "        force = self.parameter_converter._get_force(force=1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        force = self.parameter_converter._get_force()", "prediction_line": "        force = self.parameter_converter._get_force()", "ground_truth": "        force = self.parameter_converter._get_force()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.assertAlmostEqual(force, Parameter.DEFAULT_FORCE)", "prediction_line": "        self.assertAlmostEqual(force, Parameter.DEFAULT_FORCE)", "ground_truth": "        self.assertAlmostEqual(force, Parameter.DEFAULT_FORCE)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        force = self.parameter_converter._get_force(force=None)", "prediction_line": "        force = self.parameter_converter._get_force(force=None)", "ground_truth": "        force = self.parameter_converter._get_force(force=None)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        position = self.parameter_converter._get_teleport_position(", "prediction_line": "        position = self.parameter_converter._get_teleport_position(", "ground_truth": "        position = self.parameter_converter._get_teleport_position(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_force(force=\"string\")", "prediction_line": "            lambda: self.parameter_converter._get_force(force=\"string\")", "ground_truth": "            lambda: self.parameter_converter._get_force(force=\"string\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_force(force=1.1)", "prediction_line": "            lambda: self.parameter_converter._get_force(force=1.1)", "ground_truth": "            lambda: self.parameter_converter._get_force(force=1.1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_force(force=-0.1)", "prediction_line": "            lambda: self.parameter_converter._get_force(force=-0.1)", "ground_truth": "            lambda: self.parameter_converter._get_force(force=-0.1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        number = self.parameter_converter._get_number(number=1)", "prediction_line": "        number = self.parameter_converter._get_number(number=1)", "ground_truth": "        number = self.parameter_converter._get_number(key=\"val\", val=7)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        number = self.parameter_converter._get_number(key=\"val\", val=7.0)", "prediction_line": "        number = self.parameter_converter._get_number(key=\"val\", val=7.0)", "ground_truth": "        number = self.parameter_converter._get_number(key=\"val\", not_val=7)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        rotation = self.parameter_converter._get_teleport_rotation(", "prediction_line": "        rotation = self.parameter_converter._get_teleport_rotation(", "ground_truth": "        rotation = self.parameter_converter._get_teleport_rotation(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_number(key=\"val\", val=\"string\")", "prediction_line": "            lambda: self.parameter_converter._get_number(key=\"val\", val=\"string\")", "ground_truth": "            lambda: self.parameter_converter._get_number(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.assertIsNone(wrapped_step.get('sceneConfig'))", "prediction_line": "        self.assertIsNone(wrapped_step.get('sceneConfig'))", "ground_truth": "        self.assertIsNone(wrapped_step.get('sceneConfig'))", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.assertEqual(wrapped_step['sceneConfig'], self.sc)", "prediction_line": "        self.assertEqual(wrapped_step['sceneConfig'], self.sc)", "ground_truth": "        self.assertIsNotNone(wrapped_step.get('sceneConfig'))", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.assertIsInstance(position['z'], float)", "prediction_line": "        self.assertIsInstance(position['z'], float)", "ground_truth": "        self.assertIsInstance(position['z'], float)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertIsInstance(rotation, dict)", "prediction_line": "        self.assertIsInstance(rotation, dict)", "ground_truth": "        self.assertIsInstance(rotation, dict)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertIsNone(position)", "prediction_line": "        self.assertIsNone(position)", "ground_truth": "        self.assertIsNone(position)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(unity_coord, 0)", "prediction_line": "        self.assertEqual(unity_coord, 0)", "ground_truth": "        screen_height = self.parameter_converter.config.get_screen_height()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(position['x'], 1.0)", "prediction_line": "        self.assertEqual(position['x'], 1.0)", "ground_truth": "        self.assertEqual(position['x'], 1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        config = ConfigManager(config_file_or_dict={'metadata': 'level1'})", "prediction_line": "        config = ConfigManager(config_file_or_dict={'metadata': 'level1'})", "ground_truth": "        config = ConfigManager(config_file_or_dict={'metadata': 'level1'})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertIsInstance(rotation['y'], float)", "prediction_line": "        self.assertIsInstance(rotation['y'], float)", "ground_truth": "        self.assertIsInstance(rotation['y'], float)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(position['x'], 1.0)", "prediction_line": "        self.assertEqual(position['x'], 1.0)", "ground_truth": "        self.assertIsInstance(position['x'], float)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(position, {'x': 1.0, 'z': 2.0})", "prediction_line": "        self.assertEqual(position, {'x': 1.0, 'z': 2.0})", "ground_truth": "        self.assertIsInstance(position, dict)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actual = self.parameter_converter.wrap_step(", "prediction_line": "        actual = self.parameter_converter.wrap_step(", "ground_truth": "        config = ConfigManager(config_file_or_dict={'metadata': 'oracle'})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.cm = ConfigManager()", "prediction_line": "        self.cm = ConfigManager()", "ground_truth": "        config = ConfigManager(config_file_or_dict={})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "key=\"val\", val=\"string\")", "prediction_line": "key=\"val\", val=\"string\")", "ground_truth": "                key=\"string\", string=\"invalid\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            key=\"val\", val=7, default=1", "prediction_line": "            key=\"val\", val=7, default=1", "ground_truth": "            key=\"val\", default=5, val=7)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            key=\"val\", default=5, val=7.5)", "prediction_line": "            key=\"val\", default=5, val=7.5)", "ground_truth": "            key=\"val\", default=5, val=None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(position['z'], 2)", "prediction_line": "        self.assertEqual(position['z'], 2)", "ground_truth": "        self.assertEqual(position['z'], 2)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def test_generate_noise_with_seed(self):", "prediction_line": "    def test_generate_noise_with_seed(self):", "ground_truth": "    def test_get_amount(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_wrap_step_action_with_defaults(self):", "prediction_line": "    def test_wrap_step_action_with_defaults(self):", "ground_truth": "    def test_wrap_step_metadata_oracle(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # true.", "prediction_line": "        # true.", "ground_truth": "        # true.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.assertRaises(", "prediction_line": "        self.assertRaises(", "ground_truth": "    def test_teleport_rotation(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.assertIsInstance(amount, float)", "prediction_line": "        self.assertIsInstance(amount, float)", "ground_truth": "        self.assertIsInstance(amount, float)", "line_class": "random", "zero_context": true}
{"original_prediction": "          'floorMaterials': [],", "prediction_line": "          'floorMaterials': [],", "ground_truth": "          'intuitivePhysics': False,", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"renderDepthImage\": True,", "prediction_line": "            \"renderDepthImage\": True,", "ground_truth": "            \"renderDepthImage\": True,", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.assertRaises(", "prediction_line": "        self.assertRaises(", "ground_truth": "        self.assertRaises(", "line_class": "random", "zero_context": true}
{"original_prediction": "        image_coord = 'invalid'", "prediction_line": "        image_coord = 'invalid'", "ground_truth": "        image_coord = None", "line_class": "random", "zero_context": true}
{"original_prediction": "        amount = kwargs.get(self.AMOUNT_KEY, self.DEFAULT_AMOUNT)", "prediction_line": "        amount = kwargs.get(self.AMOUNT_KEY, self.DEFAULT_AMOUNT)", "ground_truth": "        action = kwargs.get('action')", "line_class": "common", "zero_context": true}
{"original_prediction": "            moveMagnitude=move_magnitude,", "prediction_line": "            moveMagnitude=move_magnitude,", "ground_truth": "            objectId=kwargs.get(\"objectId\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "            receptacleObjectId=kwargs.get(\"receptacleObjectId\"),", "prediction_line": "            receptacleObjectId=kwargs.get(\"receptacleObjectId\"),", "ground_truth": "            receptacleObjectId=kwargs.get(\"receptacleObjectId\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "        action = kwargs.get('action')", "prediction_line": "        action = kwargs.get('action')", "ground_truth": "        force = kwargs.get(self.FORCE_KEY, self.DEFAULT_FORCE)", "line_class": "common", "zero_context": true}
{"original_prediction": "        horizon = self._get_number_with_default(", "prediction_line": "        horizon = self._get_number_with_default(", "ground_truth": "        horizon = kwargs.get(self.HORIZON_KEY, self.DEFAULT_HORIZON)", "line_class": "common", "zero_context": true}
{"original_prediction": "        if action in self.OBJECT_MOVE_ACTIONS:", "prediction_line": "        if action in self.OBJECT_MOVE_ACTIONS:", "ground_truth": "        amount = kwargs.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "        x_pos = kwargs.get(self.TELEPORT_X_POS, None)", "prediction_line": "        x_pos = kwargs.get(self.TELEPORT_X_POS, None)", "ground_truth": "        teleport_rotation = self._get_teleport_rotation(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        teleport_x_pos = self._get_teleport_x_pos(**kwargs)", "prediction_line": "        teleport_x_pos = self._get_teleport_x_pos(**kwargs)", "ground_truth": "        teleport_position = self._get_teleport_position(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x_pos = kwargs.get(self.TELEPORT_X_POS)", "prediction_line": "        x_pos = kwargs.get(self.TELEPORT_X_POS)", "ground_truth": "        teleport_pos_x_input = self._get_number(self.TELEPORT_X_POS, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        teleport_pos_z_input = self._get_number(self.TELEPORT_Z_POS, **kwargs)", "prediction_line": "        teleport_pos_z_input = self._get_number(self.TELEPORT_Z_POS, **kwargs)", "ground_truth": "        teleport_pos_z_input = self._get_number(self.TELEPORT_Z_POS, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        teleport_rotation_input = self._get_number(self.TELEPORT_Y_ROT, **kwargs)", "prediction_line": "        teleport_rotation_input = self._get_number(self.TELEPORT_Y_ROT, **kwargs)", "ground_truth": "        teleport_rot_input = self._get_number(self.TELEPORT_Y_ROT, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if action is None:", "prediction_line": "        if action is None:", "ground_truth": "        amount = self._get_amount(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        force = self._get_force(**kwargs)", "prediction_line": "        force = self._get_force(**kwargs)", "ground_truth": "        force = self._get_force(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        move_magnitude = self._get_move_magnitude(action, force, amount)", "prediction_line": "        move_magnitude = self._get_move_magnitude(action, force, amount)", "ground_truth": "        object_image_coords_x = int(self._get_number_with_default(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        object_image_coords_y = int(self._get_number_with_default(", "prediction_line": "        object_image_coords_y = int(self._get_number_with_default(", "ground_truth": "        object_image_coords_y = int(self._get_number_with_default(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        receptacle_image_coords_x = int(self._get_number_with_default(", "prediction_line": "        receptacle_image_coords_x = int(self._get_number_with_default(", "ground_truth": "        receptable_image_coords_x = int(self._get_number_with_default(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Create the step data dict for the AI2-THOR step function.", "prediction_line": "        # Create the step data dict for the AI2-THOR step function.", "ground_truth": "        action, params = self._validate_and_convert_params(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return action, self.wrap_step(**params)", "prediction_line": "        return action, self.wrap_step(**params)", "ground_truth": "        action = self._mcs_action_to_ai2thor_action(action)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return action, params", "prediction_line": "        return action, params", "ground_truth": "        wrapped_step = self.wrap_step(action=action, **params)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        receptable_image_coords_y = int(self._get_number_with_default(", "prediction_line": "        receptable_image_coords_y = int(self._get_number_with_default(", "ground_truth": "        receptacle_image_coords_y = int(self._get_number_with_default(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            'y': self._convert_y_image_coord_for_unity(", "prediction_line": "            'y': self._convert_y_image_coord_for_unity(", "ground_truth": "            'y': self._convert_y_image_coord_for_unity(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        move_magnitude = self._get_move_magnitude(action, force, amount)", "prediction_line": "        move_magnitude = self._get_move_magnitude(action, force, amount)", "ground_truth": "        move_magnitude = self._get_move_magnitude(action, force, amount)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        teleport_rotation, teleport_position = self._get_teleport(**kwargs)", "prediction_line": "        teleport_rotation, teleport_position = self._get_teleport(**kwargs)", "ground_truth": "        (teleport_rotation, teleport_position) = self._get_teleport(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return (", "prediction_line": "        return (", "ground_truth": "            horizon = horizon * (1 + self._generate_noise())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return (", "prediction_line": "        return (", "ground_truth": "            move_magnitude = move_magnitude * (1 + self._generate_noise())", "line_class": "infile", "zero_context": true}
{"original_prediction": "            renderInstanceSegmentation=True,", "prediction_line": "            renderInstanceSegmentation=True,", "ground_truth": "            renderDepthImage=self.config.is_depth_maps_enabled(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # noise = self._get_noise(**kwargs)", "prediction_line": "        # noise = self._get_noise(**kwargs)", "ground_truth": "        if self.config.is_noise_enabled():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            val = default", "prediction_line": "            val = default", "ground_truth": "            val = float(default)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if metadata_tier == MetadataTier.NONE:", "prediction_line": "        if metadata_tier == MetadataTier.NONE:", "ground_truth": "        consistent_colors = (metadata_tier == MetadataTier.ORACLE)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif action == Action.OPEN_OBJECT.value:", "prediction_line": "        elif action == Action.OPEN_OBJECT.value:", "ground_truth": "        elif action == Action.DROP_OBJECT.value:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self.config.get_height() - y_coord", "prediction_line": "        return self.config.get_height() - y_coord", "ground_truth": "        screen_height = self.config.get_screen_height()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        rotation = kwargs.get(self.ROTATION_KEY, self.DEFAULT_ROTATION)", "prediction_line": "        rotation = kwargs.get(self.ROTATION_KEY, self.DEFAULT_ROTATION)", "ground_truth": "        rotation = kwargs.get(self.ROTATION_KEY, self.DEFAULT_ROTATION)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        value = kwargs.get(key)", "prediction_line": "        value = kwargs.get(key)", "ground_truth": "        val = kwargs.get(key)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            renderInstanceSegmentation=self.config.is_instance_segmentation_enabled(),", "prediction_line": "            renderInstanceSegmentation=self.config.is_instance_segmentation_enabled(),", "ground_truth": "            renderObjectImage=self.config.is_object_masks_enabled(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       move_magnitude = self._get_move_magnitude(action, force, amount)", "prediction_line": "       move_magnitude = self._get_move_magnitude(action, force, amount)", "ground_truth": "        rotation_vector = {'y': rotation}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "self, key: str, default: float, **kwargs) -> float:", "prediction_line": "self, key: str, default: float, **kwargs) -> float:", "ground_truth": "            self, key: str, default: Any, **kwargs) -> Any:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            noise = random.uniform(self.MIN_NOISE, self.MAX_NOISE)", "prediction_line": "            noise = random.uniform(self.MIN_NOISE, self.MAX_NOISE)", "ground_truth": "            rotation = rotation * (1 + self._generate_noise())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            moveMagnitude=move_magnitude,", "prediction_line": "            moveMagnitude=move_magnitude,", "ground_truth": "            rotation=rotation_vector,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif action == Action.END_HABITUATION.value:", "prediction_line": "        elif action == Action.END_HABITUATION.value:", "ground_truth": "        elif action == Action.OPEN_OBJECT.value:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # (for debugging)", "prediction_line": "        # (for debugging)", "ground_truth": "        metadata_tier = self.config.get_metadata_tier()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"\n        return random.uniform(self.MIN_NOISE, self.MAX_NOISE)", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "Generate a random noise value between -0.5 and 0.5", "prediction_line": "Generate a random noise value between -0.5 and 0.5", "ground_truth": "        Returns a random value between -0.05 and 0.05 used to add noise to all", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        float\n            A random value between -0.05 and 0.05", "prediction_line": "        float", "ground_truth": "        float", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def _get_horizon(self, **kwargs) -> float:", "prediction_line": "    def _get_horizon(self, **kwargs) -> float:", "ground_truth": "    def _get_teleport(self, **kwargs) -> Tuple:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        if action in self.FORCE_ACTIONS:", "prediction_line": "        if action in self.FORCE_ACTIONS:", "ground_truth": "        # Set the Move Magnitude to the appropriate amount based on the action", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   IMG_COORD_KEY = 'img_coord'", "prediction_line": "   IMG_COORD_KEY = 'img_coord'", "ground_truth": "    OBJECT_IMAGE_COORDS_X_KEY = 'objectImageCoordsX'", "line_class": "random", "zero_context": true}
{"original_prediction": "            move_magnitude = amount * self.MAX_AMOUNT", "prediction_line": "            move_magnitude = amount * self.MAX_AMOUNT", "ground_truth": "            move_magnitude = amount", "line_class": "random", "zero_context": true}
{"original_prediction": "**kwargs) -> float:", "prediction_line": "**kwargs) -> float:", "ground_truth": "                            amount: float) -> float:", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.RECEPTACLE_IMAGE_COORDS_Y_KEY,", "prediction_line": "            self.RECEPTACLE_IMAGE_COORDS_Y_KEY,", "ground_truth": "            self.RECEPTACLE_IMAGE_COORDS_Y_KEY,", "line_class": "random", "zero_context": true}
{"original_prediction": "        else:\n            force = self.DEFAULT_FORCE", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.parameter_converter._convert_y_image_coord_for_unity(", "prediction_line": "            self.parameter_converter._convert_y_image_coord_for_unity(", "ground_truth": "            self.parameter_converter._convert_y_image_coord_for_unity(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        number = self.parameter_converter._get_number_with_default(", "prediction_line": "        number = self.parameter_converter._get_number_with_default(", "ground_truth": "        number = self.parameter_converter._get_number_with_default(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_number_with_default(", "prediction_line": "            lambda: self.parameter_converter._get_number_with_default(", "ground_truth": "            lambda: self.parameter_converter._get_number_with_default(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._convert_y_image_coord_for_unity(", "prediction_line": "            lambda: self.parameter_converter._convert_y_image_coord_for_unity(", "ground_truth": "            lambda: self.parameter_converter._convert_y_image_coord_for_unity(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        parameter_converter = Parameter(config)", "prediction_line": "        parameter_converter = Parameter(config)", "ground_truth": "        parameter_converter = Parameter(config)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        actual = parameter_converter.wrap_step(", "prediction_line": "        actual = parameter_converter.wrap_step(", "ground_truth": "        actual = parameter_converter.wrap_step(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        magnitude = self.parameter_converter._get_move_magnitude(", "prediction_line": "        magnitude = self.parameter_converter._get_move_magnitude(", "ground_truth": "        magnitude = self.parameter_converter._get_move_magnitude(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            action=Parameter.OBJECT_MOVE_ACTIONS[0],", "prediction_line": "            action=Parameter.OBJECT_MOVE_ACTIONS[0],", "ground_truth": "            action=Parameter.FORCE_ACTIONS[0],", "line_class": "commited", "zero_context": true}
{"original_prediction": "            action=Parameter.OBJECT_MOVE_ACTIONS[0],", "prediction_line": "            action=Parameter.OBJECT_MOVE_ACTIONS[0],", "ground_truth": "            action=Parameter.OBJECT_MOVE_ACTIONS[0],", "line_class": "commited", "zero_context": true}
{"original_prediction": "       noise = self.parameter_converter.generate_noise(", "prediction_line": "       noise = self.parameter_converter.generate_noise(", "ground_truth": "        current_noise = self.parameter_converter._generate_noise()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        teleport = self.parameter_converter._get_teleport(", "prediction_line": "        teleport = self.parameter_converter._get_teleport(", "ground_truth": "        (teleport_rot, teleport_pos) = self.parameter_converter._get_teleport()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        amount = self.parameter_converter._get_amount(", "prediction_line": "        amount = self.parameter_converter._get_amount(", "ground_truth": "        amount = self.parameter_converter._get_amount(action=\"\", amount=1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        (teleport_rot, teleport_pos) = self.parameter_converter._get_teleport(", "prediction_line": "        (teleport_rot, teleport_pos) = self.parameter_converter._get_teleport(", "ground_truth": "        (teleport_rot, teleport_pos) = self.parameter_converter._get_teleport(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        amount = self.parameter_converter._get_amount(action=\"\", amount=0.5)", "prediction_line": "        amount = self.parameter_converter._get_amount(action=\"\", amount=0.5)", "ground_truth": "        amount = self.parameter_converter._get_amount()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.assertAlmostEqual(amount, Parameter.DEFAULT_AMOUNT)", "prediction_line": "        self.assertAlmostEqual(amount, Parameter.DEFAULT_AMOUNT)", "ground_truth": "        self.assertAlmostEqual(amount, Parameter.DEFAULT_AMOUNT)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    def test_get_amount_with_noise(self):", "prediction_line": "    def test_get_amount_with_noise(self):", "ground_truth": "        amount = self.parameter_converter._get_amount(", "line_class": "commited", "zero_context": true}
{"original_prediction": "action=\"MoveAhead\")", "prediction_line": "action=\"MoveAhead\")", "ground_truth": "            action=Parameter.OBJECT_MOVE_ACTIONS[0])", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.assertAlmostEqual(amount, Parameter.DEFAULT_AMOUNT)", "prediction_line": "        self.assertAlmostEqual(amount, Parameter.DEFAULT_AMOUNT)", "ground_truth": "        self.assertAlmostEqual(amount, Parameter.DEFAULT_OBJECT_MOVE_AMOUNT)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        amount = self.parameter_converter._get_amount(", "prediction_line": "        amount = self.parameter_converter._get_amount(", "ground_truth": "        amount = self.parameter_converter._get_amount(amount=None)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self.parameter_converter._mcs_action_to_ai2thor_action(", "prediction_line": "            self.parameter_converter._mcs_action_to_ai2thor_action(", "ground_truth": "            self.parameter_converter._mcs_action_to_ai2thor_action(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.controller = config.get_controller()", "prediction_line": "        self.controller = config.get_controller()", "ground_truth": "        self.parameter_converter = Parameter(config)", "line_class": "commited", "zero_context": true}
{"original_prediction": "self.parameter_converter._get_amount, amount=\"test\")", "prediction_line": "self.parameter_converter._get_amount, amount=\"test\")", "ground_truth": "            lambda: self.parameter_converter._get_amount(amount=\"string\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_teleport(", "prediction_line": "            lambda: self.parameter_converter._get_teleport(", "ground_truth": "            lambda: self.parameter_converter._get_teleport(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.parameter_converter.wrap_step = True", "prediction_line": "        self.parameter_converter.wrap_step = True", "ground_truth": "        wrapped_step = self.parameter_converter.wrap_step(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_amount(amount=1.1)", "prediction_line": "            lambda: self.parameter_converter._get_amount(amount=1.1)", "ground_truth": "            lambda: self.parameter_converter._get_amount(amount=1.1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        wrapped_step = self.parameter_converter.wrap_step(", "prediction_line": "        wrapped_step = self.parameter_converter.wrap_step(", "ground_truth": "        wrapped_step, params = self.parameter_converter.build_ai2thor_step(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_amount(amount=-1)", "prediction_line": "            lambda: self.parameter_converter._get_amount(amount=-1)", "ground_truth": "            lambda: self.parameter_converter._get_amount(amount=-0.1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        wrapped_step = self.parameter_converter.wrap_step(", "prediction_line": "        wrapped_step = self.parameter_converter.wrap_step(", "ground_truth": "        actual = self.parameter_converter.wrap_step(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        force = self.parameter_converter._get_force(action=\"\", force=1)", "prediction_line": "        force = self.parameter_converter._get_force(action=\"\", force=1)", "ground_truth": "        force = self.parameter_converter._get_force(force=1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        force = self.parameter_converter._get_force()", "prediction_line": "        force = self.parameter_converter._get_force()", "ground_truth": "        force = self.parameter_converter._get_force()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.assertAlmostEqual(force, Parameter.DEFAULT_FORCE)", "prediction_line": "        self.assertAlmostEqual(force, Parameter.DEFAULT_FORCE)", "ground_truth": "        self.assertAlmostEqual(force, Parameter.DEFAULT_FORCE)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        force = self.parameter_converter._get_force(force=None)", "prediction_line": "        force = self.parameter_converter._get_force(force=None)", "ground_truth": "        force = self.parameter_converter._get_force(force=None)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        position = self.parameter_converter._get_teleport_position(", "prediction_line": "        position = self.parameter_converter._get_teleport_position(", "ground_truth": "        position = self.parameter_converter._get_teleport_position(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_force(force=\"string\")", "prediction_line": "            lambda: self.parameter_converter._get_force(force=\"string\")", "ground_truth": "            lambda: self.parameter_converter._get_force(force=\"string\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_force(force=1.1)", "prediction_line": "            lambda: self.parameter_converter._get_force(force=1.1)", "ground_truth": "            lambda: self.parameter_converter._get_force(force=1.1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_force(force=-0.1)", "prediction_line": "            lambda: self.parameter_converter._get_force(force=-0.1)", "ground_truth": "            lambda: self.parameter_converter._get_force(force=-0.1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        number = self.parameter_converter._get_number(number=1)", "prediction_line": "        number = self.parameter_converter._get_number(number=1)", "ground_truth": "        number = self.parameter_converter._get_number(key=\"val\", val=7)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        number = self.parameter_converter._get_number(key=\"val\", val=7.0)", "prediction_line": "        number = self.parameter_converter._get_number(key=\"val\", val=7.0)", "ground_truth": "        number = self.parameter_converter._get_number(key=\"val\", not_val=7)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        rotation = self.parameter_converter._get_teleport_rotation(", "prediction_line": "        rotation = self.parameter_converter._get_teleport_rotation(", "ground_truth": "        rotation = self.parameter_converter._get_teleport_rotation(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lambda: self.parameter_converter._get_number(key=\"val\", val=\"string\")", "prediction_line": "            lambda: self.parameter_converter._get_number(key=\"val\", val=\"string\")", "ground_truth": "            lambda: self.parameter_converter._get_number(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.assertIsNone(wrapped_step.get('sceneConfig'))", "prediction_line": "        self.assertIsNone(wrapped_step.get('sceneConfig'))", "ground_truth": "        self.assertIsNone(wrapped_step.get('sceneConfig'))", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.assertEqual(wrapped_step['sceneConfig'], self.sc)", "prediction_line": "        self.assertEqual(wrapped_step['sceneConfig'], self.sc)", "ground_truth": "        self.assertIsNotNone(wrapped_step.get('sceneConfig'))", "line_class": "common", "zero_context": true}
{"original_prediction": "            key=\"val\", default=5, val=7.5)", "prediction_line": "            key=\"val\", default=5, val=7.5)", "ground_truth": "            key=\"val\", default=5, val=None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(position['z'], 2)", "prediction_line": "        self.assertEqual(position['z'], 2)", "ground_truth": "        self.assertEqual(position['z'], 2)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertIsNone(rotation)", "prediction_line": "        self.assertIsNone(rotation)", "ground_truth": "        self.assertIsNone(rotation)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertIsInstance(position['z'], float)", "prediction_line": "        self.assertIsInstance(position['z'], float)", "ground_truth": "        self.assertIsInstance(position['z'], float)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        config = ConfigManager(config_file_or_dict={'metadata': 'level1'})", "prediction_line": "        config = ConfigManager(config_file_or_dict={'metadata': 'level1'})", "ground_truth": "        config = ConfigManager(config_file_or_dict={'metadata': 'level1'})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            key=\"val\", val=7, default=1", "prediction_line": "            key=\"val\", val=7, default=1", "ground_truth": "            key=\"val\", default=5, val=7)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(position, {'x': 1.0, 'z': 2.0})", "prediction_line": "        self.assertEqual(position, {'x': 1.0, 'z': 2.0})", "ground_truth": "        self.assertIn('x', position)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertIn('z', position)", "prediction_line": "        self.assertIn('z', position)", "ground_truth": "        self.assertIn('z', position)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        config = ConfigManager(config_file_or_dict={'metadata': 'level2'})", "prediction_line": "        config = ConfigManager(config_file_or_dict={'metadata': 'level2'})", "ground_truth": "        config = ConfigManager(config_file_or_dict={'metadata': 'level2'})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(rotation['y'], 45)", "prediction_line": "        self.assertEqual(rotation['y'], 45)", "ground_truth": "        self.assertEqual(rotation['y'], 45)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.cm = ConfigManager()", "prediction_line": "        self.cm = ConfigManager()", "ground_truth": "        config = ConfigManager(config_file_or_dict={})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(position['x'], 1.0)", "prediction_line": "        self.assertEqual(position['x'], 1.0)", "ground_truth": "        self.assertIsInstance(position['x'], float)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertIn('y', rotation)", "prediction_line": "        self.assertIn('y', rotation)", "ground_truth": "        self.assertIn('y', rotation)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actual = self.parameter_converter.wrap_step(", "prediction_line": "        actual = self.parameter_converter.wrap_step(", "ground_truth": "        config = ConfigManager(config_file_or_dict={'metadata': 'oracle'})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(position, {'x': 1.0, 'z': 2.0})", "prediction_line": "        self.assertEqual(position, {'x': 1.0, 'z': 2.0})", "ground_truth": "        self.assertIsInstance(position, dict)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        image_coord = -1", "prediction_line": "        image_coord = -1", "ground_truth": "        # value much greater than the screen height", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        expected = {", "prediction_line": "        expected = {", "ground_truth": "        # Changed depth and object because oracle should result in both being", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                       'visible': True,", "prediction_line": "                       'visible': True,", "ground_truth": "                       'materials': ['AI2-THOR/Materials/Plastics/BlueRubber'],", "line_class": "random", "zero_context": true}
{"original_prediction": "                image_coord)", "prediction_line": "                image_coord)", "ground_truth": "                y_coord=image_coord", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.assertEqual(teleport_rot, {'y': 90.0})", "prediction_line": "        self.assertEqual(teleport_rot, {'y': 90.0})", "ground_truth": "        self.assertEqual(teleport_rot, {'y': 90.0})", "line_class": "random", "zero_context": true}
{"original_prediction": "                                  'objectType': 'Mug',", "prediction_line": "                                  'objectType': 'Mug',", "ground_truth": "                                  'scale': {'y': 0.5,", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.assertIsInstance(magnitude, float)", "prediction_line": "        self.assertIsInstance(magnitude, float)", "ground_truth": "        self.assertIsInstance(magnitude, float)", "line_class": "random", "zero_context": true}
{"original_prediction": "    copy(\n        str(src),", "prediction_line": "    copy(", "ground_truth": "    run_copy(str(src), dst, defaults=True, overwrite=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    (repo / \"copier.yml\").write_text(\"_symlinks: [link]\")", "prediction_line": "    (repo / \"copier.yml\").write_text(\"_symlinks: [link]\")", "ground_truth": "    build_file_tree(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # update\n    run_update(dst, defaults=True, overwrite=True)", "prediction_line": "    # update", "ground_truth": "    with pytest.warns(DirtyLocalWarning):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        run_update(dst, defaults=True, overwrite=True)", "prediction_line": "        run_update(dst, defaults=True, overwrite=True)", "ground_truth": "        run_update(dst, defaults=True, overwrite=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        vcs_ref=\"HEAD\",", "prediction_line": "        vcs_ref=\"HEAD\",", "ground_truth": "        exclude=[\"symlink.txt\"],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"\"\",\n            repo / \"symlink.txt\": Path(\"{{ target_name }}.txt\"),", "prediction_line": "            \"\"\",", "ground_truth": "            \"\"\",", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from .helpers import (", "prediction_line": "from .helpers import (", "ground_truth": "from .helpers import build_file_tree", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # Prepare repo bundle", "prediction_line": "    # Prepare repo bundle", "ground_truth": "    # Prepare repo bundle", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        str(repo),", "prediction_line": "        str(repo),", "ground_truth": "        str(repo),", "line_class": "random", "zero_context": true}
{"original_prediction": "            repo\n            / \"copier.yaml\": \"\"\"\\", "prediction_line": "            repo", "ground_truth": "            repo", "line_class": "random", "zero_context": true}
{"original_prediction": "        {\n            repo", "prediction_line": "        {", "ground_truth": "        {", "line_class": "random", "zero_context": true}
{"original_prediction": "        overwrite=True,", "prediction_line": "        overwrite=True,", "ground_truth": "        overwrite=True,", "line_class": "random", "zero_context": true}
{"original_prediction": "    repo.mkdir()", "prediction_line": "    repo.mkdir()", "ground_truth": "    repo.mkdir()", "line_class": "random", "zero_context": true}
{"original_prediction": "    build_file_tree({(src / \"copier.yaml\"): \"\"})", "prediction_line": "    build_file_tree({(src / \"copier.yaml\"): \"\"})", "ground_truth": "    build_file_tree(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    _, retcode = CopierApp.run(", "prediction_line": "    _, retcode = CopierApp.run(", "ground_truth": "    _, retcode = CopierApp.run(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with local.cwd(dst):", "prediction_line": "    with local.cwd(dst):", "ground_truth": "    run_copy(str(src), dst, unsafe=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    build_file_tree(", "prediction_line": "    build_file_tree(", "ground_truth": "    build_file_tree({(src / \"copier.yaml\"): yaml.safe_dump(spec)})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        run_copy(", "prediction_line": "        run_copy(", "ground_truth": "        run_copy(str(src), dst, unsafe=unsafe)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        run_update(dst, unsafe=unsafe)", "prediction_line": "        run_update(dst, unsafe=unsafe)", "ground_truth": "        run_update(dst, overwrite=True, unsafe=unsafe)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_update(", "prediction_line": "def test_update(", "ground_truth": "def test_copy_cli(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    if unsafe:", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from zntrack import dvc, zn", "prediction_line": "from zntrack import dvc, zn", "ground_truth": "from plumbum.cmd import git", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    src, dst = map(tmp_path_factory.mktemp, [\"src\", \"dst\"])", "prediction_line": "    src, dst = map(tmp_path_factory.mktemp, [\"src\", \"dst\"])", "ground_truth": "    src, dst = map(tmp_path_factory.mktemp, [\"src\", \"dst\"])", "line_class": "random", "zero_context": true}
{"original_prediction": "                ),\n            ),", "prediction_line": "                ),", "ground_truth": "                ),", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"template_name, expected_output\",", "prediction_line": "    \"template_name, expected_output\",", "ground_truth": "    (\"spec\", \"expected\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                UnsafeTemplateError, match=\"Template uses unsafe feature: tasks\"", "prediction_line": "                UnsafeTemplateError, match=\"Template uses unsafe feature: tasks\"", "ground_truth": "                UnsafeTemplateError, match=\"Template uses unsafe feature: tasks\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        git(\"commit\", \"-m\", \"Initial commit\")", "prediction_line": "        git(\"commit\", \"-m\", \"Initial commit\")", "ground_truth": "        git(\"commit\", \"-m1\")", "line_class": "random", "zero_context": true}
{"original_prediction": "    return ''.join(map(mangle_type_c, argtys))", "prediction_line": "    return ''.join(map(mangle_type_c, argtys))", "ground_truth": "    return ''.join([mangle_type_c(t) for t in argtys])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return ''.join([mangle_type_or_value(t) for t in argtys])", "prediction_line": "    return ''.join([mangle_type_or_value(t) for t in argtys])", "ground_truth": "    return ''.join([mangle_type_or_value(t) for t in argtys])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return (PREFIX + mangle_identifier(ident) + mangle_args_c(argtys))", "prediction_line": "    return (PREFIX + mangle_identifier(ident) + mangle_args_c(argtys))", "ground_truth": "    return PREFIX + mangle_identifier(ident) + mangle_args_c(argtys)", "line_class": "infile", "zero_context": true}
{"original_prediction": "mangle_identifier(ident, abi_tags=abi_tags, uid=uid),", "prediction_line": "mangle_identifier(ident, abi_tags=abi_tags, uid=uid),", "ground_truth": "                    mangle_identifier(ident, abi_tags=abi_tags, uid=uid),", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    mangle_args(argtys)])", "prediction_line": "                    mangle_args(argtys)])", "ground_truth": "                    mangle_args(argtys)])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            rc += \"U\" + str(typ.addrspace)", "prediction_line": "            rc += \"U\" + str(typ.addrspace)", "ground_truth": "            rc += \"U\" + itanium_mangler.mangle_identifier(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return mangle_type_or_value_numba(typ)", "prediction_line": "        return mangle_type_or_value_numba(typ)", "ground_truth": "        return mangle_type_or_value_numba(typ)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        ns_len = int(remaining[0])", "prediction_line": "        ns_len = int(remaining[0])", "ground_truth": "        ret = PREFIX + 'N' + mangle_identifier(ns) + remaining", "line_class": "infile", "zero_context": true}
{"original_prediction": "        ret = PREFIX + mangle_identifier(ns) + remaining", "prediction_line": "        ret = PREFIX + mangle_identifier(ns) + remaining", "ground_truth": "        head, tail = _split_mangled_ident(remaining)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        ret = PREFIX + mangle_identifier(ns) + 'N' + head + 'E' + tail", "prediction_line": "        ret = PREFIX + mangle_identifier(ns) + 'N' + head + 'E' + tail", "ground_truth": "        ret = PREFIX + 'N' + mangle_identifier(ns) + head + 'E' + tail", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return str(len(string)) + _fix_lead_digit(string)", "prediction_line": "    return str(len(string)) + _fix_lead_digit(string)", "ground_truth": "    string = _fix_lead_digit(string)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        + itanium_mangler.mangle_identifier(ident)", "prediction_line": "        + itanium_mangler.mangle_identifier(ident)", "ground_truth": "        + mangle_identifier(ident, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        + \"v\"", "prediction_line": "        + \"v\"", "ground_truth": "        + mangle_args(argtys)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Mangle abi tag.", "prediction_line": "    \"\"\"", "ground_truth": "    return \"B\" + _len_encoded(_escape_string(abi_tag))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if abi_tags:", "prediction_line": "    if abi_tags:", "ground_truth": "    parts = [_len_encoded(_escape_string(x)) for x in ident.split('.')]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if template_params:", "prediction_line": "    if template_params:", "ground_truth": "    enc_abi_tags = list(map(mangle_abi_tag, abi_tags))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return 'X' + _len_encoded(_escape_string(typ))", "prediction_line": "        return 'X' + _len_encoded(_escape_string(typ))", "ground_truth": "        return mangle_identifier(typ)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return mangle_type_c(N2C[typ])", "prediction_line": "            return mangle_type_c(N2C[typ])", "ground_truth": "            return mangle_type_c(N2C[typ])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return mangle_identifier(typ.name)", "prediction_line": "            return mangle_identifier(typ.name)", "ground_truth": "            return mangle_templated_ident(*typ.mangling_args)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        raise TypeError(\"Unsupported type %s\" % typ)", "prediction_line": "        raise TypeError(\"Unsupported type %s\" % typ)", "ground_truth": "        enc = _escape_string(str(typ))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return _len_encoded(enc)", "prediction_line": "        return _len_encoded(enc)", "ground_truth": "        return _len_encoded(enc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "for backward compatibility\nmangle_type_or_value = mangle_type_or_value_numba", "prediction_line": "for backward compatibility", "ground_truth": "mangle_type = mangle_type_or_value", "line_class": "infile", "zero_context": true}
{"original_prediction": "def mangle_templated_ident(ident, *args):", "prediction_line": "def mangle_templated_ident(ident, *args):", "ground_truth": "mangle_value = mangle_type_or_value", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return mangle_identifier(identifier, mangle_args(parameters))", "prediction_line": "    return mangle_identifier(identifier, mangle_args(parameters))", "ground_truth": "    template_params = ('I%sE' % ''.join(map(mangle_type_or_value, parameters))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return mangle_identifier(identifier, template_params)", "prediction_line": "    return mangle_identifier(identifier, template_params)", "ground_truth": "    return mangle_identifier(identifier, template_params)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        rc += itanium_mangler.mangle_type_or_value(typ.pointee)", "prediction_line": "        rc += itanium_mangler.mangle_type_or_value(typ.pointee)", "ground_truth": "        rc += mangle_type_or_value_numba(typ.dtype)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return _re_invalid_char.sub(repl, text)", "prediction_line": "    return _re_invalid_char.sub(repl, text)", "ground_truth": "    ret = re.sub(_re_invalid_char, repl, text)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "_ESCAPE_CHAR = \"_\"", "prediction_line": "_ESCAPE_CHAR = \"_\"", "ground_truth": "_re_invalid_char = re.compile(r'[^a-z0-9_]', re.I)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    'nullptr_t': 'u',", "prediction_line": "    'nullptr_t': 'u',", "ground_truth": "}", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        C type name", "prediction_line": "        C type name", "ground_truth": "        C type name", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    'unsigned char': 'h',", "prediction_line": "    'unsigned char': 'h',", "ground_truth": "    'unsigned char': 'h',", "line_class": "random", "zero_context": true}
{"original_prediction": "    'unsigned long': 'm',", "prediction_line": "    'unsigned long': 'm',", "ground_truth": "    'unsigned long': 'm',", "line_class": "random", "zero_context": true}
{"original_prediction": "for ch in m.group(0).encode('utf8'))", "prediction_line": "for ch in m.group(0).encode('utf8'))", "ground_truth": "                       for ch in m.group(0).encode('utf8'))", "line_class": "random", "zero_context": true}
{"original_prediction": "    types.int8: 'signed char',", "prediction_line": "    types.int8: 'signed char',", "ground_truth": "    types.int8: 'signed char',", "line_class": "random", "zero_context": true}
{"original_prediction": "    return mangled[:at], mangled[at:]", "prediction_line": "    return mangled[:at], mangled[at:]", "ground_truth": "    return mangled[:at], mangled[at:]", "line_class": "random", "zero_context": true}
{"original_prediction": "    run(dirname)", "prediction_line": "    run(dirname)", "ground_truth": "    run(dirname)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            newlist.extend(make_cpm_expr2b(e.args))", "prediction_line": "            newlist.extend(make_cpm_expr2b(e.args))", "ground_truth": "            newlist.extend(make_cpm_expr2b(e.args))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                unravel(e.flat)", "prediction_line": "                unravel(e.flat)", "ground_truth": "                unravel(e.flat)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                unravel(e.args)", "prediction_line": "                unravel(e.args)", "ground_truth": "                unravel(e.args)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist.extend(make_cpm_expr2b(e))", "prediction_line": "            newlist.extend(make_cpm_expr2b(e))", "ground_truth": "            newlist.extend(make_cpm_expr2b(e))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            unravel(e)", "prediction_line": "            unravel(e)", "ground_truth": "            unravel(e)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                newlist.extend(make_cpm_expr3(ee))", "prediction_line": "                newlist.extend(make_cpm_expr3(ee))", "ground_truth": "                newlist.extend(make_cpm_expr3(ee))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    unravel(cpm_expr)", "prediction_line": "    unravel(cpm_expr)", "ground_truth": "    unravel((cpm_expr,))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist.extend(make_cpm_expr2bb(e))", "prediction_line": "            newlist.extend(make_cpm_expr2bb(e))", "ground_truth": "            newlist.extend(make_cpm_expr2bb(e))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                model.solve()", "prediction_line": "                model.solve()", "ground_truth": "                newexp = make_cpm_expr2bf(cpm_cons)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist.extend(make_cpm_expr2bb(e.args))", "prediction_line": "            newlist.extend(make_cpm_expr2bb(e.args))", "ground_truth": "            newlist.extend(make_cpm_expr2bb(e.args))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                newexp2 = make_cpm_expr2bf(cpm_cons)", "prediction_line": "                newexp2 = make_cpm_expr2bf(cpm_cons)", "ground_truth": "                newexp2 = make_cpm_expr2bf(newexp)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist.extend(make_cpm_expr3b(e))", "prediction_line": "            newlist.extend(make_cpm_expr3b(e))", "ground_truth": "            newlist.extend(make_cpm_expr3(ee) for ee in e)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                newlist.extend(make_cpm_expr3(ee))", "prediction_line": "                newlist.extend(make_cpm_expr3(ee))", "ground_truth": "                newlist.extend(make_cpm_expr3(ee) for ee in e.args)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                # print(newexp2)", "prediction_line": "                # print(newexp2)", "ground_truth": "                newexp3 = make_cpm_expr2bf(newexp2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                newlist.extend(make_cpm_expr2bc(e))", "prediction_line": "                newlist.extend(make_cpm_expr2bc(e))", "ground_truth": "                newlist.extend(make_cpm_expr2bc(e.flat))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                newlist.extend(make_cpm_expr2bc(e.args))", "prediction_line": "                newlist.extend(make_cpm_expr2bc(e.args))", "ground_truth": "                newlist.extend(make_cpm_expr2bc(e.args))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist.extend(make_cpm_expr2bc(e))", "prediction_line": "            newlist.extend(make_cpm_expr2bc(e))", "ground_truth": "            newlist.extend(make_cpm_expr2bc(e))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist[i:i+1] = make_cpm_expr4(e)", "prediction_line": "            newlist[i:i+1] = make_cpm_expr4(e)", "ground_truth": "            newlist[i:i+1] = make_cpm_expr4(e)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return [make_cpm_expr1(e) for e in cpm_expr]", "prediction_line": "        return [make_cpm_expr1(e) for e in cpm_expr]", "ground_truth": "        expr = [make_cpm_expr1(e) for e in cpm_expr]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist[i:i+1] = make_cpm_expr4(e.args)", "prediction_line": "            newlist[i:i+1] = make_cpm_expr4(e.args)", "ground_truth": "            newlist[i:i+1] = make_cpm_expr4(e.args)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return [make_cpm_expr1(e) for e in cpm_expr.args]", "prediction_line": "        return [make_cpm_expr1(e) for e in cpm_expr.args]", "ground_truth": "        return make_cpm_expr1(cpm_expr.args)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                newlist.extend(make_cpm_expr2bd(e.flat))", "prediction_line": "                newlist.extend(make_cpm_expr2bd(e.flat))", "ground_truth": "                newlist.extend(make_cpm_expr2bd(e.flat))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                newlist.extend(make_cpm_expr2bd(e.args))", "prediction_line": "                newlist.extend(make_cpm_expr2bd(e.args))", "ground_truth": "                newlist.extend(make_cpm_expr2bd(e.args))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist.extend(make_cpm_expr2bd(e))", "prediction_line": "            newlist.extend(make_cpm_expr2bd(e))", "ground_truth": "            newlist.extend(make_cpm_expr2bd(e))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return make_cpm_expr1b(cpm_expr.args)", "prediction_line": "        return make_cpm_expr1b(cpm_expr.args)", "ground_truth": "        return [sl for e in cpm_expr.args for sl in make_cpm_expr1b(e)]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return [sl for e in cpm_expr for sl in make_cpm_expr1b(e)]", "prediction_line": "        return [sl for e in cpm_expr for sl in make_cpm_expr1b(e)]", "ground_truth": "        return [sl for e in cpm_expr for sl in make_cpm_expr1b(e)]", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    unravel(ee)", "prediction_line": "                    unravel(ee)", "ground_truth": "                    unravel(ee)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist.extend(make_cpm_expr2(e))", "prediction_line": "            newlist.extend(make_cpm_expr2(e))", "ground_truth": "            newlist.extend(make_cpm_expr2(e))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist.extend(make_cpm_expr2(e.args))", "prediction_line": "            newlist.extend(make_cpm_expr2(e.args))", "ground_truth": "            newlist.extend(make_cpm_expr2(e.args))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist.extend(make_cpm_expr2c(e.args))", "prediction_line": "            newlist.extend(make_cpm_expr2c(e.args))", "ground_truth": "            newlist.extend(make_cpm_expr2c(e.args))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            newlist.extend(make_cpm_expr2c(e))", "prediction_line": "            newlist.extend(make_cpm_expr2c(e))", "ground_truth": "            newlist.extend(make_cpm_expr2c(e))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    unravel(cpm_expr)", "prediction_line": "    unravel(cpm_expr)", "ground_truth": "    unravel(cpm_expr)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        elif e is False:", "prediction_line": "        elif e is False:", "ground_truth": "        elif isinstance(e, Operator) and e.name == \"and\":", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            newlist.append(BoolVal(e))", "prediction_line": "            newlist.append(BoolVal(e))", "ground_truth": "            newlist.append(BoolVal(e))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif is_any_list(e):", "prediction_line": "        elif is_any_list(e):", "ground_truth": "        elif is_any_list(e):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                cl = pickle.load(fpcl)", "prediction_line": "                cl = pickle.load(fpcl)", "ground_truth": "                model = pickle.loads(brotli.decompress(fpcl.read()))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if cpm_expr is False:", "prediction_line": "    if cpm_expr is False:", "ground_truth": "    if not is_any_list(cpm_expr):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if isinstance(e, Expression):", "prediction_line": "        if isinstance(e, Expression):", "ground_truth": "        if isinstance(e, Expression):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                times.append(t1)", "prediction_line": "                times.append(t1)", "ground_truth": "                if t1 > max(times):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            l[i] = BoolVal(e)", "prediction_line": "            l[i] = BoolVal(e)", "ground_truth": "            l[i] = BoolVal(e)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            newlist[i] = BoolVal(e)", "prediction_line": "            newlist[i] = BoolVal(e)", "ground_truth": "            newlist[i] = BoolVal(e)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   if isinstance(cpm_expr, Expression):", "prediction_line": "   if isinstance(cpm_expr, Expression):", "ground_truth": "    if is_any_list(cpm_expr):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return [BoolVal(False)]", "prediction_line": "        return [BoolVal(False)]", "ground_truth": "        return [BoolVal(cpm_expr)]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if isinstance(cpm_expr, Expression):", "prediction_line": "    if isinstance(cpm_expr, Expression):", "ground_truth": "    if isinstance(cpm_expr, Operator) and cpm_expr.name == \"and\":", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    elif isinstance(cpm_expr, Operator) and cpm_expr.name == \"and\":", "prediction_line": "    elif isinstance(cpm_expr, Operator) and cpm_expr.name == \"and\":", "ground_truth": "    elif isinstance(cpm_expr, Operator) and cpm_expr.name == \"and\":", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif e is not True:  # if True: pass", "prediction_line": "        elif e is not True:  # if True: pass", "ground_truth": "        elif e is not True:  # if True: pass", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# 0.38 total, 0.09 max", "prediction_line": "# 0.38 total, 0.09 max", "ground_truth": "# 0.27 total, 0.02 max  [not sure... something with the doulbe lists, e.g. for and]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# 0.11 total, 0.014 max  [faster but different scale...]", "prediction_line": "# 0.11 total, 0.014 max  [faster but different scale...]", "ground_truth": "def make_cpm_expr5(cpm_expr):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    unravels nested lists and top-level AND's and ensures every element returned is a CPMpy Expression", "prediction_line": "    unravels nested lists and top-level AND's and ensures every element returned is a CPMpy Expression", "ground_truth": "    unravels nested lists and top-level AND's and ensures every element returned is a CPMpy Expression", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ", do inline is_any_list", "prediction_line": ", do inline is_any_list", "ground_truth": "# 0.25 total, 0.02 max", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    l.extend(e[1:])", "prediction_line": "                    l.extend(e[1:])", "ground_truth": "                    l += e[1:].flatten()", "line_class": "random", "zero_context": true}
{"original_prediction": "    return newlist", "prediction_line": "    return newlist", "ground_truth": "    return newlist", "line_class": "random", "zero_context": true}
{"original_prediction": "        e = l[i]", "prediction_line": "        e = l[i]", "ground_truth": "        e = l[i]", "line_class": "random", "zero_context": true}
{"original_prediction": "            pass\n        elif isinstance(e, Operator) and e.name == \"and\":", "prediction_line": "            pass", "ground_truth": "            pass", "line_class": "random", "zero_context": true}
{"original_prediction": "                newlist.append(e)", "prediction_line": "                newlist.append(e)", "ground_truth": "                newlist.append(e)", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(cpm_model, subsolver)", "prediction_line": "        super().__init__(cpm_model, subsolver)", "ground_truth": "        super().__init__(name=\"exact\", cpm_model=cpm_model)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if my_status == xct.SAT:", "prediction_line": "        if my_status == xct.SAT:", "ground_truth": "        self.cpm_status.runtime = end - start", "line_class": "common", "zero_context": true}
{"original_prediction": "        if time_limit is not None:", "prediction_line": "        if time_limit is not None:", "ground_truth": "        start = time.time()", "line_class": "common", "zero_context": true}
{"original_prediction": "                        self._add_xct_reif_right(cond, xct_coefs,xct_vars,xct_rhs)", "prediction_line": "                        self._add_xct_reif_right(cond, xct_coefs,xct_vars,xct_rhs)", "ground_truth": "                        self._add_xct_reif_right(cond, xct_coefs,xct_vars,xct_rhs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        self._add_xct_reif_left(cond, xct_coefs,xct_vars,xct_rhs)", "prediction_line": "                        self._add_xct_reif_left(cond, xct_coefs,xct_vars,xct_rhs)", "ground_truth": "                        self._add_xct_reif_right(cond, [-x for x in xct_coefs],xct_vars,-xct_rhs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        self._add_xct_reif_left(cond, xct_coefs,xct_vars,1+xct_rhs)", "prediction_line": "                        self._add_xct_reif_left(cond, xct_coefs,xct_vars,1+xct_rhs)", "ground_truth": "                        self._add_xct_reif_left(cond, xct_coefs,xct_vars,1+xct_rhs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        self._add_xct_reif_left(cond, xct_coefs,xct_vars,1+xct_rhs)", "prediction_line": "                        self._add_xct_reif_left(cond, xct_coefs,xct_vars,1+xct_rhs)", "ground_truth": "                        self._add_xct_reif_left(cond, [-x for x in xct_coefs],xct_vars,1-xct_rhs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if cpm_expr.value:", "prediction_line": "                if cpm_expr.value:", "ground_truth": "                self._add_xct_constr([], [], True, 0 if cpm_expr.args[0] else 1, False, 0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.xct_solver.addConstraint(xct_coefs,xct_vars,uselb,lb,useub,ub)", "prediction_line": "            self.xct_solver.addConstraint(xct_coefs,xct_vars,uselb,lb,useub,ub)", "ground_truth": "            self.xct_solver.addConstraint([self.fix(x) for x in xct_coefs],xct_vars,uselb,self.fix(lb),useub,self.fix(ub))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.xct_solver.addReification(head,[self.fix(x) for x in xct_coefs],xct_vars,self.fix(lb))", "prediction_line": "            self.xct_solver.addReification(head,[self.fix(x) for x in xct_coefs],xct_vars,self.fix(lb))", "ground_truth": "            self.xct_solver.addReification(head,[self.fix(x) for x in xct_coefs],xct_vars,self.fix(lb))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.xct_solver.addRightReification(head,[self.fix(x) for x in xct_coefs],xct_vars,self.fix(xct_rhs))", "prediction_line": "            self.xct_solver.addRightReification(head,[self.fix(x) for x in xct_coefs],xct_vars,self.fix(xct_rhs))", "ground_truth": "            self.xct_solver.addRightReification(head,[self.fix(x) for x in xct_coefs],xct_vars,self.fix(xct_rhs))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.xct_solver.addLeftReification(head,[self.fix(x) for x in xct_coefs],xct_vars,self.fix(xct_rhs))", "prediction_line": "            self.xct_solver.addLeftReification(head,[self.fix(x) for x in xct_coefs],xct_vars,self.fix(xct_rhs))", "ground_truth": "            self.xct_solver.addLeftReification(head,[self.fix(x) for x in xct_coefs],xct_vars,self.fix(xct_rhs))", "line_class": "infile", "zero_context": true}
{"original_prediction": "to solver\n        if isinstance(flat_obj, _NumVarImpl):", "prediction_line": "to solver", "ground_truth": "        xct_coefs,xct_vars,xct_rhs = self._make_numexpr(flat_obj,0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    if callable(display):", "prediction_line": "                    if callable(display):", "ground_truth": "                    self._fillObjAndVars()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        super().__init__(cpm_model, subsolver)", "prediction_line": "        super().__init__(cpm_model, subsolver)", "ground_truth": "        if not self.supported():", "line_class": "infile", "zero_context": true}
{"original_prediction": "        cpm_cons = self.transform(cpm_expr_orig)", "prediction_line": "        cpm_cons = self.transform(cpm_expr_orig)", "ground_truth": "        for cpm_expr in self.transform(cpm_expr_orig):", "line_class": "infile", "zero_context": true}
{"original_prediction": "               xct_coefs, xct_vars, xct_rhs = self._make_numexpr(lhs,rhs)", "prediction_line": "               xct_coefs, xct_vars, xct_rhs = self._make_numexpr(lhs,rhs)", "ground_truth": "                xct_coefs, xct_vars, xct_rhs = self._make_numexpr(lhs,rhs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self._add_xct_constr(xct_coefs,xct_vars,True,xct_rhs,False,None)", "prediction_line": "                    self._add_xct_constr(xct_coefs,xct_vars,True,xct_rhs,False,None)", "ground_truth": "                    self._add_xct_constr(xct_coefs, xct_vars, False, 0, True, xct_rhs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self._add_xct_constr(xct_coefs, xct_vars, True, xct_rhs, False, 0)", "prediction_line": "                    self._add_xct_constr(xct_coefs, xct_vars, True, xct_rhs, False, 0)", "ground_truth": "                    self._add_xct_constr(xct_coefs, xct_vars, True, xct_rhs, False, 0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "()\n                    if isinstance(lhs, BoundedLinearExpression):", "prediction_line": "()", "ground_truth": "                    self._add_xct_constr(xct_coefs, xct_vars, True, xct_rhs, True, xct_rhs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            xvars += [self.solver_var(lhs)]", "prediction_line": "            xvars += [self.solver_var(lhs)]", "ground_truth": "            xvars += [self.solver_var(lhs)]", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    # negated Boolean variable", "prediction_line": "                    # negated Boolean variable", "ground_truth": "                    cond, bool_val = self.solver_var(cond._bv), False", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    cond, bool_val = self.solver_var(cond), True", "prediction_line": "                    cond, bool_val = self.solver_var(cond), True", "ground_truth": "                    cond, bool_val = self.solver_var(cond), True", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.cpm_status.exitstatus = ExitStatus.TIME_LIMIT", "prediction_line": "            self.cpm_status.exitstatus = ExitStatus.TIME_LIMIT", "ground_truth": "            self.cpm_status.exitstatus = ExitStatus.UNKNOWN", "line_class": "inproject", "zero_context": true}
{"original_prediction": "               self._add_xct_reif(self.solver_var(cond), xct_coefs, xct_vars, xct_rhs)", "prediction_line": "               self._add_xct_reif(self.solver_var(cond), xct_coefs, xct_vars, xct_rhs)", "ground_truth": "                if isinstance(cond, NegBoolView):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if call_from_model:", "prediction_line": "                    if call_from_model:", "ground_truth": "                    if isinstance(display, Expression):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            xvars += self.solver_vars(lhs.args[1])", "prediction_line": "            xvars += self.solver_vars(lhs.args[1])", "ground_truth": "            xvars += self.solver_vars(lhs.args[1])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if any(isinstance(x, float) for x in xct_coefs+[lb,ub]):", "prediction_line": "        if any(isinstance(x, float) for x in xct_coefs+[lb,ub]):", "ground_truth": "        maximum = max([abs(x) for x in xct_coefs]+[abs(lb),abs(ub)])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    elif callable(display):", "prediction_line": "                    elif callable(display):", "ground_truth": "                    elif isinstance(display, list):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for term in lhs.flat_tuple():", "prediction_line": "        for term in lhs.flat_tuple():", "ground_truth": "        if is_num(lhs):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"\n            Adds a constraint to the solver", "prediction_line": "        \"\"\"", "ground_truth": "        if any(not isinstance(x, numbers.Integral) for x in xct_coefs+[lb,ub]):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for i, cpm_var in enumerate(lst_vars):", "prediction_line": "        for i, cpm_var in enumerate(lst_vars):", "ground_truth": "        exact_vals = self.xct_solver.getLastSolutionFor(self.solver_vars(lst_vars))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            xvars = [self.solver_var(arg) for arg in lhs.args]", "prediction_line": "            xvars = [self.solver_var(arg) for arg in lhs.args]", "ground_truth": "            xvars = self.solver_vars(lhs.args)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.xct_solver.addVariable(revar,cpm_var.lb,cpm_var.ub)", "prediction_line": "            self.xct_solver.addVariable(revar,cpm_var.lb,cpm_var.ub)", "ground_truth": "            lb, ub = cpm_var.get_bounds()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if my_status == xct.SAT:", "prediction_line": "        if my_status == xct.SAT:", "ground_truth": "        self.cpm_status = SolverStatus(self.name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        maximum = max([abs(x) for x in xct_coefs]+[abs(xct_rhs)])", "prediction_line": "        maximum = max([abs(x) for x in xct_coefs]+[abs(xct_rhs)])", "ground_truth": "        maximum = max([abs(x) for x in xct_coefs]+[abs(xct_rhs)])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            elif isinstance(cpm_expr, _BoolVarImpl):", "prediction_line": "            elif isinstance(cpm_expr, _BoolVarImpl):", "ground_truth": "            elif isinstance(cpm_expr, BoolVal):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.cpm_status.exitstatus = ExitStatus.OPTIMAL", "prediction_line": "            self.cpm_status.exitstatus = ExitStatus.OPTIMAL", "ground_truth": "            self.cpm_status.exitstatus = ExitStatus.FEASIBLE", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        cpm_cons = linearize_constraint(cpm_cons, supported=frozenset([\"sum\", \"wsum\"]))  # supports only ==", "prediction_line": "        cpm_cons = linearize_constraint(cpm_cons, supported=frozenset([\"sum\", \"wsum\"]))  # supports only ==", "ground_truth": "        cpm_cons = linearize_constraint(cpm_cons, supported=frozenset({\"sum\",\"wsum\"}))  # the core of the MIP-linearization", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n            Whether the objective function is set", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            start = time.time()", "prediction_line": "            start = time.time()", "ground_truth": "            my_status = self.xct_solver.runFull(False,time_limit if time_limit is not None else 0)", "line_class": "random", "zero_context": true}
{"original_prediction": "        xvars = []", "prediction_line": "        xvars = []", "ground_truth": "        xvars = []", "line_class": "random", "zero_context": true}
{"original_prediction": "    def _make_numexpr(self, expr, rhs):", "prediction_line": "    def _make_numexpr(self, expr, rhs):", "ground_truth": "        self.solver_is_initialized = True", "line_class": "random", "zero_context": true}
{"original_prediction": "                break\n            else:", "prediction_line": "                break", "ground_truth": "                return solsfound", "line_class": "random", "zero_context": true}
{"original_prediction": "                    raise NotImplementedError(\"Exact does not support comparison {}\".format(cpm_expr.name))", "prediction_line": "                    raise NotImplementedError(\"Exact does not support comparison {}\".format(cpm_expr.name))", "ground_truth": "                    raise NotImplementedError(", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(cpm_model, subsolver)", "prediction_line": "        super().__init__(cpm_model, subsolver)", "ground_truth": "        super().__init__(name=\"pysdd\", cpm_model=cpm_model)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            # TODO: check if var is in model", "prediction_line": "            # TODO: check if var is in model", "ground_truth": "            self.pysdd_root &= self.solver_var(cpm_expr)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        super().__init__(cpm_model, subsolver)", "prediction_line": "        super().__init__(cpm_model, subsolver)", "ground_truth": "        if not self.supported():", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return -self.solver_var(cpm_var.var)", "prediction_line": "            return -self.solver_var(cpm_var.var)", "ground_truth": "            return -self.solver_var(cpm_var._bv)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if isinstance(cpm_var, _BoolVarImpl):", "prediction_line": "                if isinstance(cpm_var, _BoolVarImpl):", "ground_truth": "                lit = self.solver_var(cpm_var).literal", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._post_constraint(con)", "prediction_line": "            self._post_constraint(con)", "ground_truth": "            self._post_constraint(con)", "line_class": "infile", "zero_context": true}
{"original_prediction": ", Vtree\n            self.pysdd_vtree = Vtree(var_count=len(self.user_vars), vtree_type=\"balanced\")", "prediction_line": ", Vtree", "ground_truth": "            SddManager().true().dot()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        else:\n            self.pysdd_root.dot()", "prediction_line": "        else:", "ground_truth": "        return self.pysdd_root.dot()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # if we have a solution, we can enumerate it", "prediction_line": "        # if we have a solution, we can enumerate it", "ground_truth": "        self.cpm_status = SolverStatus(self.name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif isinstance(cpm_expr, Comparison):", "prediction_line": "        elif isinstance(cpm_expr, Comparison):", "ground_truth": "        elif isinstance(cpm_expr, Operator):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.cpm_status.exitstatus = ExitStatus.SAT", "prediction_line": "            self.cpm_status.exitstatus = ExitStatus.SAT", "ground_truth": "            self.cpm_status.exitstatus = ExitStatus.FEASIBLE", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.pysdd_root &= reduce(lambda x,y: x | y, [self.solver_var(v) for v in cpm_expr.args])", "prediction_line": "                self.pysdd_root &= reduce(lambda x,y: x | y, [self.solver_var(v) for v in cpm_expr.args])", "ground_truth": "                clause = reduce(self.pysdd_manager.disjoin, self.solver_vars(cpm_expr.args))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.cpm_status.exitstatus = ExitStatus.UNSATISFIABLE", "prediction_line": "            self.cpm_status.exitstatus = ExitStatus.UNSATISFIABLE", "ground_truth": "            self.cpm_status.exitstatus = ExitStatus.UNSATISFIABLE", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if isinstance(cpm_var, NegBoolView):", "prediction_line": "        if isinstance(cpm_var, NegBoolView):", "ground_truth": "        if isinstance(cpm_var, NegBoolView):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # get all solutions", "prediction_line": "        # get all solutions", "ground_truth": "        if display is None:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "of user variables\n        if is_any_list(cpm_con):", "prediction_line": "of user variables", "ground_truth": "        self.user_vars.update(get_variables(cpm_con))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # TODO: implement a faster version", "prediction_line": "            # TODO: implement a faster version", "ground_truth": "            solution_count = 0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # create new solver variable", "prediction_line": "            # create new solver variable", "ground_truth": "            if isinstance(cpm_var, _BoolVarImpl):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if is_any_list(cpm_con):", "prediction_line": "        if is_any_list(cpm_con):", "ground_truth": "        cpm_cons = to_cnf(cpm_con)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "call the display function\n                if callable(display):", "prediction_line": "call the display function", "ground_truth": "                if isinstance(display, Expression):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                elif callable(display):", "prediction_line": "                elif callable(display):", "ground_truth": "                elif isinstance(display, list):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # TODO: this is a bit of a hack, but it works...", "prediction_line": "        # TODO: this is a bit of a hack, but it works...", "ground_truth": "        if isinstance(cpm_expr, _BoolVarImpl):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        and then post them to the solver", "prediction_line": "        and then post them to the solver", "ground_truth": "        then post those primitive constraints directly to the native solver", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # check if already created", "prediction_line": "        # check if already created", "ground_truth": "        # create if it does not exit", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            self.cpm_status.solution = {v: sol[v] for v in self.user_variables}", "prediction_line": "            self.cpm_status.solution = {v: sol[v] for v in self.user_variables}", "ground_truth": "            # fill in variable values", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            Arguments:", "prediction_line": "            Arguments:", "ground_truth": "            or returns from cache if previously created", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    else:", "prediction_line": "                    else:", "ground_truth": "                    else:", "line_class": "random", "zero_context": true}
{"original_prediction": "        # translate exit status", "prediction_line": "        # translate exit status", "ground_truth": "        if self.pysdd_root is None:", "line_class": "random", "zero_context": true}
{"original_prediction": "            raise Exception(\"CPM_pysdd: time_limit not supported\")", "prediction_line": "            raise Exception(\"CPM_pysdd: time_limit not supported\")", "ground_truth": "            raise NotImplementedError(\"PySDD.solveAll(), time_limit not (yet?) supported\")", "line_class": "random", "zero_context": true}
{"original_prediction": "            for sol in self.pysdd_root.models():", "prediction_line": "            for sol in self.pysdd_root.models():", "ground_truth": "            for sol in self.pysdd_root.models():", "line_class": "random", "zero_context": true}
{"original_prediction": "        # call parent constructor", "prediction_line": "        # call parent constructor", "ground_truth": "        if cpm_model and cpm_model.objective_ is not None:", "line_class": "random", "zero_context": true}
{"original_prediction": "        return [c for c in cons if isinstance(c, Comparison)]", "prediction_line": "        return [c for c in cons if isinstance(c, Comparison)]", "ground_truth": "        cons = linearize_constraint(cons)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            simplied_args = [simplify(arg) for arg in lhs.args]", "prediction_line": "            simplied_args = [simplify(arg) for arg in lhs.args]", "ground_truth": "            simplied_args = [simplify(arg) for arg in lhs.args]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if isinstance(cond, _BoolVarImpl):", "prediction_line": "        if isinstance(cond, _BoolVarImpl):", "ground_truth": "        lin_comps = linearize_constraint(sub_expr)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return [linearize_constraint(e) for e in cpm_expr]", "prediction_line": "        return [linearize_constraint(e) for e in cpm_expr]", "ground_truth": "        lin_cons = [linearize_constraint(expr) for expr in cpm_expr]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        lin_cons = [only_positive_bv(expr) for expr in cpm_expr]", "prediction_line": "        lin_cons = [only_positive_bv(expr) for expr in cpm_expr]", "ground_truth": "        nn_cons = [only_positive_bv(expr) for expr in cpm_expr]", "line_class": "infile", "zero_context": true}
{"original_prediction": "           if lhs.name == \"sum\":", "prediction_line": "           if lhs.name == \"sum\":", "ground_truth": "            nn_subsexpr = only_positive_bv(subexpr)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                return [c1, c2]", "prediction_line": "                return [c1, c2]", "ground_truth": "                return linearize_constraint([c1,c2])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return [Comparison(cpm_expr.name, new_lhs, new_rhs)]", "prediction_line": "            return [Comparison(cpm_expr.name, new_lhs, new_rhs)]", "ground_truth": "            return [Comparison(cpm_expr.name, new_lhs, new_rhs)]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                lhs = Operator(\"wsum\", [weights, vars])", "prediction_line": "                lhs = Operator(\"wsum\", [weights, vars])", "ground_truth": "                new_lhs = Operator(\"wsum\", [weights, vars])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Boolean variables", "prediction_line": "        # Boolean variables", "ground_truth": "        sigma = boolvar(shape=n)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   if isinstance(cpm_expr, Comparison):", "prediction_line": "   if isinstance(cpm_expr, Comparison):", "ground_truth": "    if is_any_list(cpm_expr):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if isinstance(arg, NegBoolView):", "prediction_line": "                    if isinstance(arg, NegBoolView):", "ground_truth": "                    if isinstance(arg, NegBoolView):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if len(nn_subsexpr) == 1:", "prediction_line": "            if len(nn_subsexpr) == 1:", "ground_truth": "            return linearize_constraint([cond.implies(nn_expr) for nn_expr in nn_subsexpr])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                lhs = Operator(\"wsum\", [[1]*len(lhs.args), lhs.args])", "prediction_line": "                lhs = Operator(\"wsum\", [[1]*len(lhs.args), lhs.args])", "ground_truth": "                lhs = Operator(\"wsum\", [[1] * len(lhs.args), lhs.args])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                return [negated_normal(lhs) <= rhs, lhs >= rhs]", "prediction_line": "                return [negated_normal(lhs) <= rhs, lhs >= rhs]", "ground_truth": "                c1 = (~rhs).implies(negated_normal(lhs))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    new_lhs = Operator(\"sum\", [arg + (-1) * rhs for arg in lhs.args])", "prediction_line": "                    new_lhs = Operator(\"sum\", [arg + (-1) * rhs for arg in lhs.args])", "ground_truth": "                    new_lhs = Operator(\"wsum\", [[1]*len(lhs.args) + [-1], lhs.args + [rhs]])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                var_cons.append(new_lhs >= 0)", "prediction_line": "                var_cons.append(new_lhs >= 0)", "ground_truth": "                lin_exprs += [Comparison(l_expr.name, new_lhs, 0)]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            var, constraints += get_or_make_var(var * arg)", "prediction_line": "            var, constraints += get_or_make_var(var * arg)", "ground_truth": "            var, cons = get_or_make_var(var * arg)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if isinstance(lhs, NegBoolView) and isinstance(rhs, _NumVarImpl):", "prediction_line": "            if isinstance(lhs, NegBoolView) and isinstance(rhs, _NumVarImpl):", "ground_truth": "            if isinstance(lhs, NegBoolView):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            lhs, rhs = rhs, lhs", "prediction_line": "            lhs, rhs = rhs, lhs", "ground_truth": "            if isinstance(lhs, NegBoolView) and isinstance(rhs, NegBoolView):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if all(arg.is_bool() for arg in cpm_expr.args):", "prediction_line": "        if all(arg.is_bool() for arg in cpm_expr.args):", "ground_truth": "        if all(arg.is_bool() for arg in cpm_expr.args):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if isinstance(cond, NegBoolView):", "prediction_line": "        if isinstance(cond, NegBoolView):", "ground_truth": "        assert isinstance(cond, _BoolVarImpl), f\"Left hand side of implication {cpm_expr} should be boolvar\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "Django settings for mysite project.", "prediction_line": "Django settings for mysite project.", "ground_truth": "Transformations regarding linearization of constraints.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        lhs, rhs = cpm_expr.args", "prediction_line": "        lhs, rhs = cpm_expr.args", "ground_truth": "        # TODO: this can be optimized, see https://github.com/CPMpy/cpmpy/issues/97", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        if all(isinstance(arg, _BoolVarImpl) for arg in cpm_expr.args):", "prediction_line": "        \"\"\"", "ground_truth": "            This method avoids bounds computation", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        - add               (len(Operator.args) == 2)", "prediction_line": "        - add               (len(Operator.args) == 2)", "ground_truth": "        - sum", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       if rhs.is_bool() and not isinstance(rhs, _BoolVarImpl) and isinstance(lhs, _BoolVarImpl):", "prediction_line": "       if rhs.is_bool() and not isinstance(rhs, _BoolVarImpl) and isinstance(lhs, _BoolVarImpl):", "ground_truth": "    if cpm_expr.name == \"alldifferent\":", "line_class": "random", "zero_context": true}
{"original_prediction": "        assert len(arr.shape) == 1", "prediction_line": "        assert len(arr.shape) == 1", "ground_truth": "        assert len(arr.shape) == 1, f\"Only support 1-d element constraints, not {cpm_expr} which has shape {cpm_expr.shape}\"", "line_class": "random", "zero_context": true}
{"original_prediction": "            if isinstance(rhs, _BoolVarImpl):", "prediction_line": "            if isinstance(rhs, _BoolVarImpl):", "ground_truth": "            new_lhs = lhs + -1 * rhs", "line_class": "random", "zero_context": true}
{"original_prediction": "            # BV1 >=< BV2 => BV1 + BV2 >=< 2", "prediction_line": "            # BV1 >=< BV2 => BV1 + BV2 >=< 2", "ground_truth": "            return [cpm_expr]", "line_class": "random", "zero_context": true}
{"original_prediction": "        if lhs.name == \"wsum\":", "prediction_line": "        if lhs.name == \"wsum\":", "ground_truth": "        if lhs.name == \"wsum\":", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(cpm_model)", "prediction_line": "        super().__init__(cpm_model)", "ground_truth": "        super().__init__(name=\"z3\", cpm_model=cpm_model)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            # post to solver", "prediction_line": "            # post to solver", "ground_truth": "            self._post_constraint(con)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.solver_var(cpm_var.var)", "prediction_line": "            return self.solver_var(cpm_var.var)", "ground_truth": "            return z3.Not(self.solver_var(cpm_var._bv))", "line_class": "infile", "zero_context": true}
{"original_prediction": "to solver\n        if minimize:", "prediction_line": "to solver", "ground_truth": "        obj = self._make_numexpr(flat_obj)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                # get the z3 variable", "prediction_line": "                # get the z3 variable", "ground_truth": "                sol_var = self.solver_var(cpm_var)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.z3_solver.add(self.solver_var(cpm_con))", "prediction_line": "            self.z3_solver.add(self.solver_var(cpm_con))", "ground_truth": "            self.z3_solver.add(self.solver_var(cpm_con))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.solver_var(cpm_expr)", "prediction_line": "            return self.solver_var(cpm_expr)", "ground_truth": "            return self.solver_var(cpm_expr)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        super().__init__(cpm_model, subsolver)", "prediction_line": "        super().__init__(cpm_model, subsolver)", "ground_truth": "        if not self.supported():", "line_class": "infile", "zero_context": true}
{"original_prediction": "of user vars\n        self.user_vars.update(get_variables(cpm_con))", "prediction_line": "of user vars", "ground_truth": "        self.user_vars.update(get_variables(cpm_con))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        expr = flatten_constraint(expr)", "prediction_line": "        expr = flatten_constraint(expr)", "ground_truth": "        (flat_obj, flat_cons) = flatten_objective(expr)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if isinstance(cpm_var, NegBoolView):", "prediction_line": "        if isinstance(cpm_var, NegBoolView):", "ground_truth": "        if isinstance(cpm_var, NegBoolView):", "line_class": "inproject", "zero_context": true}
{"original_prediction": ".exitstatus\n        return self.cpm_status.exitstatus.is_feasible()", "prediction_line": ".exitstatus", "ground_truth": "        has_sol = self._solve_return(self.cpm_status)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if minimize:", "prediction_line": "        if minimize:", "ground_truth": "        if minimize:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            elif is_num(cpm_var):", "prediction_line": "            elif is_num(cpm_var):", "ground_truth": "            elif isinstance(cpm_var, _IntVarImpl):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.cpm_status.exitstatus = ExitStatus.SAT", "prediction_line": "            self.cpm_status.exitstatus = ExitStatus.SAT", "ground_truth": "            self.cpm_status.exitstatus = ExitStatus.FEASIBLE", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.cpm_status.exitstatus = ExitStatus.UNSATISFIABLE", "prediction_line": "            self.cpm_status.exitstatus = ExitStatus.UNSATISFIABLE", "ground_truth": "            self.cpm_status.exitstatus = ExitStatus.UNSATISFIABLE", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        import z3", "prediction_line": "        import z3", "ground_truth": "        if isinstance(cpm_con, _BoolVarImpl):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.z3_solver.set(**kwargs)", "prediction_line": "        self.z3_solver.set(**kwargs)", "ground_truth": "        for (key,value) in kwargs.items():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        import z3", "prediction_line": "        import z3", "ground_truth": "        if is_num(cpm_expr):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if my_status == \"sat\":", "prediction_line": "        if my_status == \"sat\":", "ground_truth": "        self.cpm_status = SolverStatus(self.name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.cpm_status.exitstatus = ExitStatus.UNKNOWN", "prediction_line": "            self.cpm_status.exitstatus = ExitStatus.UNKNOWN", "ground_truth": "            self.cpm_status.exitstatus = ExitStatus.UNKNOWN", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.z3_solver.set(key, value)", "prediction_line": "            self.z3_solver.set(key, value)", "ground_truth": "            self.z3_solver.set(key, value)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # TODO: add assumptions?", "prediction_line": "        # TODO: add assumptions?", "ground_truth": "        cpm_cons = flatten_constraint(cpm_con)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            >>> import z3", "prediction_line": "            >>> import z3", "ground_truth": "            ```", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       if my_status == \"sat\":", "prediction_line": "       if my_status == \"sat\":", "ground_truth": "        # new status, translate runtime", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        # if a list of constraints is given, post them all", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "yet\n        if cpm_var not in self.solver_var_map:", "prediction_line": "yet", "ground_truth": "        if cpm_var not in self._varmap:", "line_class": "random", "zero_context": true}
{"original_prediction": "        elif isinstance(cpm_con, Comparison):", "prediction_line": "        elif isinstance(cpm_con, Comparison):", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "            # no solution, fill in default values", "prediction_line": "            # no solution, fill in default values", "ground_truth": "            for cpm_var in self.user_vars:", "line_class": "random", "zero_context": true}
{"original_prediction": "        return self._varmap[cpm_var]", "prediction_line": "        return self._varmap[cpm_var]", "ground_truth": "        return self._varmap[cpm_var]", "line_class": "random", "zero_context": true}
{"original_prediction": "        if my_status == \"sat\":", "prediction_line": "        if my_status == \"sat\":", "ground_truth": "        if my_status == \"sat\":", "line_class": "random", "zero_context": true}
{"original_prediction": "        if not(csiobjectfunc.check_scaleoperatorobject_is_deployed()):", "prediction_line": "        if not(csiobjectfunc.check_scaleoperatorobject_is_deployed()):", "ground_truth": "        if not(csiobjectfunc.check_scaleoperatorobject_is_deployed()):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        csiobjectfunc.check_scaleoperatorobject_statefulsets_state(", "prediction_line": "        csiobjectfunc.check_scaleoperatorobject_statefulsets_state(", "ground_truth": "        csiobjectfunc.check_scaleoperatorobject_statefulsets_state(", "line_class": "commited", "zero_context": true}
{"original_prediction": "           csiobjectfunc.create_custom_object(self.temp[\"custom_object_body\"])", "prediction_line": "           csiobjectfunc.create_custom_object(self.temp[\"custom_object_body\"])", "ground_truth": "            csiobjectfunc.create_custom_object(self.temp[\"custom_object_body\"], self.stateful_set_not_created)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            csiobjectfunc.delete_custom_object()", "prediction_line": "            csiobjectfunc.delete_custom_object()", "ground_truth": "            csiobjectfunc.delete_custom_object()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            csiobjectfunc.check_scaleoperatorobject_is_deleted()", "prediction_line": "            csiobjectfunc.check_scaleoperatorobject_is_deleted()", "ground_truth": "            csiobjectfunc.check_scaleoperatorobject_is_deleted()", "line_class": "commited", "zero_context": true}
{"original_prediction": "       csiobjectfunc.check_scaleoperatorobject_is_deployed()", "prediction_line": "       csiobjectfunc.check_scaleoperatorobject_is_deployed()", "ground_truth": "        is_deployed = csiobjectfunc.check_scaleoperatorobject_is_deployed(csiscaleoperator_name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.operator_yaml = operator_yaml", "prediction_line": "        self.operator_yaml = operator_yaml", "ground_truth": "        csiobjectfunc.set_namespace_value(namespace_value)", "line_class": "commited", "zero_context": true}
{"original_prediction": "       csiobjectfunc.delete_custom_object()", "prediction_line": "       csiobjectfunc.delete_custom_object()", "ground_truth": "        if csiobjectfunc.check_scaleoperatorobject_is_deployed():", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if \"stateful_set_not_deleted\" in test_dict:", "prediction_line": "        if \"stateful_set_not_deleted\" in test_dict:", "ground_truth": "        csiobjectfunc.set_namespace_value(self.namespace)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        csiobjectfunc.check_scaleoperatorobject_statefulsets_state(", "prediction_line": "        csiobjectfunc.check_scaleoperatorobject_statefulsets_state(", "ground_truth": "        val, self.desired_number_scheduled = csiobjectfunc.check_scaleoperatorobject_daemonsets_state(csiscaleoperator_name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        created_objects = get_cleanup_dict()", "prediction_line": "        created_objects = get_cleanup_dict()", "ground_truth": "        created_objects = get_cleanup_dict()", "line_class": "infile", "zero_context": true}
{"original_prediction": "       api_instance = client.CustomObjectsApi()", "prediction_line": "       api_instance = client.CustomObjectsApi()", "ground_truth": "        body = self.get_operator_body()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.operator_yaml_file = open(self.operator_yaml_file_path, 'r')", "prediction_line": "        self.operator_yaml_file = open(self.operator_yaml_file_path, 'r')", "ground_truth": "        crd_body = self.get_operator_body()", "line_class": "infile", "zero_context": true}
{"original_prediction": "           csistoragefunc.create_snapshot(snapshot_name, fileset_name, self.cluster_id, created_objects)", "prediction_line": "           csistoragefunc.create_snapshot(snapshot_name, fileset_name, self.cluster_id, created_objects)", "ground_truth": "            FSUID = filesetfunc.get_FSUID()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       if value_clone_passed is None:", "prediction_line": "       if value_clone_passed is None:", "ground_truth": "        if \"permissions\" in value_sc.keys() and not(filesetfunc.feature_available(\"permissions\")):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                csistoragefunc.create_vs(vs_name+\"-\"+str(num), vs_content_name, fileset_name, created_objects)", "prediction_line": "                csistoragefunc.create_vs(vs_name+\"-\"+str(num), vs_content_name, fileset_name, created_objects)", "ground_truth": "                filesetfunc.create_snapshot(snapshot_name+\"-\"+str(num), fileset_name, created_objects)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                csistoragefunc.check_snapshot(snapshot_name+\"-\"+str(num), fileset_name, created_objects)", "prediction_line": "                csistoragefunc.check_snapshot(snapshot_name+\"-\"+str(num), fileset_name, created_objects)", "ground_truth": "                if filesetfunc.check_snapshot_exists(snapshot_name+\"-\"+str(num), fileset_name):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       if root_volume is True:", "prediction_line": "       if root_volume is True:", "ground_truth": "        mount_point = filesetfunc.get_mount_point()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            filesetfunc.create_directory(dir_name)", "prediction_line": "            filesetfunc.create_directory(dir_name)", "ground_truth": "            filesetfunc.create_dir(dir_name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for num in range(0, number_of_snapshots):", "prediction_line": "            for num in range(0, number_of_snapshots):", "ground_truth": "            if not(filesetfunc.feature_available(\"snapshot\")):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        LOGGER.info(100*\"-\")", "prediction_line": "                        LOGGER.info(100*\"-\")", "ground_truth": "                        csistoragefunc.clone_and_check_pvc(sc_name, value_sc, pvc_name, pod_name, value_pod_passed[num2], value_clone_passed, created_objects)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            csistoragefunc.check_pvc_deleted(pvc_name, vol_name, created_objects)", "prediction_line": "            csistoragefunc.check_pvc_deleted(pvc_name, vol_name, created_objects)", "ground_truth": "            csistoragefunc.check_pvc_deleted(pvc_name, vol_name, created_objects)", "line_class": "random", "zero_context": true}
{"original_prediction": "            kubeobjectfunc.check_configmap_is_deleted(self.temp[\"local_cacert_name\"])", "prediction_line": "            kubeobjectfunc.check_configmap_is_deleted(self.temp[\"local_cacert_name\"])", "ground_truth": "            kubeobjectfunc.check_configmap_is_deleted(self.temp[\"local_cacert_name\"])", "line_class": "random", "zero_context": true}
{"original_prediction": "            csistoragefunc.create_storage_class(value_sc, sc_name, created_objects)", "prediction_line": "            csistoragefunc.create_storage_class(value_sc, sc_name, created_objects)", "ground_truth": "            csistoragefunc.create_storage_class(value_sc, sc_name, created_objects)", "line_class": "random", "zero_context": true}
{"original_prediction": "                    pod_name = csistoragefunc.get_random_name(\"pod\")", "prediction_line": "                    pod_name = csistoragefunc.get_random_name(\"pod\")", "ground_truth": "                    pod_name = csistoragefunc.get_random_name(\"pod\")", "line_class": "random", "zero_context": true}
{"original_prediction": "                    assert False", "prediction_line": "                    assert False", "ground_truth": "                    assert False", "line_class": "random", "zero_context": true}
{"original_prediction": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc, value_clone_passed=value_clone_passed)", "prediction_line": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc, value_clone_passed=value_clone_passed)", "ground_truth": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc, value_clone_passed=value_clone_passed)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    kubeconfig_value, data = scaleop.read_driver_data()", "prediction_line": "    kubeconfig_value, data = scaleop.read_driver_data()", "ground_truth": "    kubeconfig_value, clusterconfig_value, operator_namespace, test_namespace, runslow_val, operator_yaml = scaleop.get_cmd_values(request)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   data = scaleop.read_driver_data()", "prediction_line": "   data = scaleop.read_driver_data()", "ground_truth": "    data = scaleop.read_driver_data(clusterconfig_value, test_namespace, operator_namespace, kubeconfig_value)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"}] * 2", "prediction_line": "    value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"}] * 2", "ground_truth": "    driver_object.test_dynamic(value_sc, value_pod_passed=value_pod)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc)", "prediction_line": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc)", "ground_truth": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    driver_object = scaleop.ScaleOperator(kubeconfig_value, operator_namespace)", "prediction_line": "    driver_object = scaleop.ScaleOperator(kubeconfig_value, operator_namespace)", "ground_truth": "    driver_object = scaleop.Driver(kubeconfig_value, value_pvc, value_pod, data[\"id\"],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    scaleop.get_cluster_details(data)", "prediction_line": "    scaleop.get_cluster_details(data)", "ground_truth": "    scaleop.filesetfunc.get_scale_version(data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@pytest.mark.regression", "prediction_line": "@pytest.mark.regression", "ground_truth": "    scaleop.get_kubernetes_version(kubeconfig_value)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@pytest.mark.regression", "prediction_line": "@pytest.mark.regression", "ground_truth": "    scaleop.csioperatorfunc.get_operator_image()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@pytest.mark.regression", "prediction_line": "@pytest.mark.regression", "ground_truth": "    scaleop.csiobjectfunc.get_driver_image()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_cg_create_delete_cg_snapshot_cg_snapshot_delete():", "prediction_line": "def test_cg_create_delete_cg_snapshot_cg_snapshot_delete():", "ground_truth": "def test_get_version():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_driver_cg_compression_6():", "prediction_line": "def test_driver_cg_compression_6():", "ground_truth": "def test_driver_cg_compression_6():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    driver_object = scaleop.ScaleOperator(kubeconfig_value, operator_namespace)", "prediction_line": "    driver_object = scaleop.ScaleOperator(kubeconfig_value, operator_namespace)", "ground_truth": "    keep_objects = data[\"keepobjects\"]", "line_class": "random", "zero_context": true}
{"original_prediction": "                     {\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"},", "prediction_line": "                     {\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"},", "ground_truth": "                     {\"access_modes\": \"ReadWriteOnce\", \"storage\": \"1Gi\"},", "line_class": "random", "zero_context": true}
{"original_prediction": "    value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"}] * 2", "prediction_line": "    value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"}] * 2", "ground_truth": "    value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\", \"reason\": \"InvalidArgument desc = invalid compression algorithm\"}] * 2", "line_class": "random", "zero_context": true}
{"original_prediction": "    value_sc = {\"volBackendFs\": data[\"primaryFs\"], \"version\": \"2\", \"permissions\": \"777\"}", "prediction_line": "    value_sc = {\"volBackendFs\": data[\"primaryFs\"], \"version\": \"2\", \"permissions\": \"777\"}", "ground_truth": "    value_pod = [{\"mount_path\": \"/usr/share/nginx/html/scale\", \"read_only\": \"False\", \"sub_path\": [\"sub_path_mnt\"], \"volumemount_readonly\":[False]},", "line_class": "random", "zero_context": true}
{"original_prediction": "    value_sc = {\"volBackendFs\": data[\"primaryFs\"], \"version\": \"2\", \"inodeLimit\": \"100000000000000000000000000000000000000000000000000000000000000000000", "prediction_line": "    value_sc = {\"volBackendFs\": data[\"primaryFs\"], \"version\": \"2\", \"inodeLimit\": \"100000000000000000000000000000000000000000000000000000000000000000000", "ground_truth": "    value_sc = {\"volBackendFs\": data[\"primaryFs\"], \"version\": \"2\", \"volDirBasePath\": data[\"volDirBasePath\"]}", "line_class": "random", "zero_context": true}
{"original_prediction": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc,", "prediction_line": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc,", "ground_truth": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    data = data_fixture['values']", "prediction_line": "    data = data_fixture['values']", "ground_truth": "    data = data_fixture[\"driver_data\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    remote_data = data_fixture[\"remote_data\"]", "prediction_line": "    remote_data = data_fixture[\"remote_data\"]", "ground_truth": "    remote_data = data_fixture[\"remote_data\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    driver_object = remote_cluster_fixture", "prediction_line": "    driver_object = remote_cluster_fixture", "ground_truth": "    kubeconfig_value = data_fixture[\"cmd_values\"][\"kubeconfig_value\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    driver_object = baseclass.VolumeDriver(kubeconfig_value)", "prediction_line": "    driver_object = baseclass.VolumeDriver(kubeconfig_value)", "ground_truth": "    driver_object = data_fixture[\"remote_driver_object\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    LOGGER.info(\"Cluster Name: %s\", remote_data[\"cluster_name\"])", "prediction_line": "    LOGGER.info(\"Cluster Name: %s\", remote_data[\"cluster_name\"])", "ground_truth": "    baseclass.filesetfunc.get_scale_version(remote_data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    baseclass.filesetfunc.get_scale_version(data)", "prediction_line": "    baseclass.filesetfunc.get_scale_version(data)", "ground_truth": "    baseclass.filesetfunc.get_scale_version(data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@pytest.mark.regression", "prediction_line": "@pytest.mark.regression", "ground_truth": "    baseclass.kubeobjectfunc.get_kubernetes_version(kubeconfig_value)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@pytest.mark.regression", "prediction_line": "@pytest.mark.regression", "ground_truth": "    baseclass.kubeobjectfunc.get_operator_image()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@pytest.mark.regression", "prediction_line": "@pytest.mark.regression", "ground_truth": "    baseclass.kubeobjectfunc.get_driver_image()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    value_clone_passed = {\"clone_pvc\": [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\", \"reason\": \"same storage class for cloning\"}],", "prediction_line": "    value_clone_passed = {\"clone_pvc\": [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\", \"reason\": \"same storage class for cloning\"}],", "ground_truth": "    value_clone_passed = {\"clone_pvc\": [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\", \"reason\": \"Volume cloning for directories for remote file system is not supported\"},", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import os\nimport sys", "prediction_line": "import os", "ground_truth": "import pytest", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def values(request):", "prediction_line": "def values(request):", "ground_truth": "def values(data_fixture, check_csi_operator, remote_cluster_fixture):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    value_clone_passed = {\"clone_pvc\": [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\", \"reason\": \"same storage class for cloning\"}],", "prediction_line": "    value_clone_passed = {\"clone_pvc\": [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\", \"reason\": \"same storage class for cloning\"}],", "ground_truth": "    value_clone_passed = {\"clone_pvc\": [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\", \"reason\": \"same storage class for cloning\"}],", "line_class": "random", "zero_context": true}
{"original_prediction": "                          \"clone_sc\": {\"volBackendFs\": data[\"remoteFs\"], \"volDirBasePath\": data[\"volDirBasePath\"]}}", "prediction_line": "                          \"clone_sc\": {\"volBackendFs\": data[\"remoteFs\"], \"volDirBasePath\": data[\"volDirBasePath\"]}}", "ground_truth": "                          \"clone_sc\": {\"volBackendFs\": data[\"remoteFs\"], \"r_volDirBasePath\": data[\"volDirBasePath\"]}}", "line_class": "random", "zero_context": true}
{"original_prediction": "                          \"number_of_clones\": 5, \"chain_clone\": True}", "prediction_line": "                          \"number_of_clones\": 5, \"chain_clone\": True}", "ground_truth": "                          \"clone_chain\": 1}", "line_class": "random", "zero_context": true}
{"original_prediction": "\"reason\": \"same storage class for cloning\"}],", "prediction_line": "\"reason\": \"same storage class for cloning\"}],", "ground_truth": "                                         \"reason\": \"new PVC request must be greater than or equal in size\"}]}", "line_class": "random", "zero_context": true}
{"original_prediction": "    value_sc = {\"volBackendFs\": data[\"remoteFs\"], \"clusterId\": data[\"remoteid\"]}", "prediction_line": "    value_sc = {\"volBackendFs\": data[\"remoteFs\"], \"clusterId\": data[\"remoteid\"]}", "ground_truth": "    value_sc = {\"volBackendFs\": data[\"remoteFs\"],", "line_class": "random", "zero_context": true}
{"original_prediction": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc)", "prediction_line": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc)", "ground_truth": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    kubeconfig_value, data, remote_data, driver_object = check_csi_operator", "prediction_line": "    kubeconfig_value, data, remote_data, driver_object = check_csi_operator", "ground_truth": "    kubeconfig_value, clusterconfig_value, operator_namespace, test_namespace, runslow_val, operator_yaml = scaleop.get_cmd_values(request)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc, value_clone_passed=value_clone_passed)", "prediction_line": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc, value_clone_passed=value_clone_passed)", "ground_truth": "    driver_object.test_dynamic(value_sc, value_pvc_passed=value_pvc, value_clone_passed=value_clone_passed)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   data = scaleop.read_driver_data(clusterconfig_value, test_namespace)", "prediction_line": "   data = scaleop.read_driver_data(clusterconfig_value, test_namespace)", "ground_truth": "    data = scaleop.read_driver_data(clusterconfig_value, test_namespace, operator_namespace, kubeconfig_value)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   remote_data = data[\"remote\"]", "prediction_line": "   remote_data = data[\"remote\"]", "ground_truth": "    remote_data = scaleop.get_remote_data(data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    driver_object = scaleop.get_driver_object(kubeconfig_value)", "prediction_line": "    driver_object = scaleop.get_driver_object(kubeconfig_value)", "ground_truth": "    scaleop.filesetfunc.cred_check(remote_data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    driver_object = scaleop.ScaleOperator(kubeconfig_value, operator_namespace)", "prediction_line": "    driver_object = scaleop.ScaleOperator(kubeconfig_value, operator_namespace)", "ground_truth": "    scaleop.filesetfunc.set_data(remote_data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"}] * 2", "prediction_line": "    value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"}] * 2", "ground_truth": "    driver_object.test_dynamic(value_sc, value_pod_passed=value_pod)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    driver_object = scaleop.ScaleOperator(kubeconfig_value, operator_namespace)", "prediction_line": "    driver_object = scaleop.ScaleOperator(kubeconfig_value, operator_namespace)", "ground_truth": "    driver_object = scaleop.Driver(kubeconfig_value, value_pvc, value_pod,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if not check_csi_operator(operator_namespace, data[\"image_name\"], operator_yaml):", "prediction_line": "    if not check_csi_operator(operator_namespace, data[\"image_name\"], operator_yaml):", "ground_truth": "    scaleop.filesetfunc.create_dir(remote_data[\"volDirBasePath\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    LOGGER.info(\"Remote Cluster ID: %s\", remote_data[\"id\"])", "prediction_line": "    LOGGER.info(\"Remote Cluster ID: %s\", remote_data[\"id\"])", "ground_truth": "    scaleop.filesetfunc.get_scale_version(remote_data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    scaleop.filesetfunc.get_scale_version(data)", "prediction_line": "    scaleop.filesetfunc.get_scale_version(data)", "ground_truth": "    scaleop.filesetfunc.get_scale_version(data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@pytest.mark.regression", "prediction_line": "@pytest.mark.regression", "ground_truth": "    scaleop.get_kubernetes_version(kubeconfig_value)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@pytest.mark.regression", "prediction_line": "@pytest.mark.regression", "ground_truth": "    scaleop.csioperatorfunc.get_operator_image()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@pytest.mark.regression", "prediction_line": "@pytest.mark.regression", "ground_truth": "    scaleop.csiobjectfunc.get_driver_image()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_driver_cg_cloning_2():", "prediction_line": "def test_driver_cg_cloning_2():", "ground_truth": "def test_driver_cg_cloning_2():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def setup(request):", "prediction_line": "def setup(request):", "ground_truth": "def values(request, check_csi_operator):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"}] * 2", "prediction_line": "    value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"}] * 2", "ground_truth": "    value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"}] * 2", "line_class": "random", "zero_context": true}
{"original_prediction": "    remote_data = scaleop.read_driver_data(clusterconfig_value, test_namespace, operator_namespace, kubeconfig_value, remote=True)", "prediction_line": "    remote_data = scaleop.read_driver_data(clusterconfig_value, test_namespace, operator_namespace, kubeconfig_value, remote=True)", "ground_truth": "    keep_objects = data[\"keepobjects\"]", "line_class": "random", "zero_context": true}
{"original_prediction": "        value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"},", "prediction_line": "        value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"},", "ground_truth": "        value_pvc = [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"}]", "line_class": "random", "zero_context": true}
{"original_prediction": "    value_pod = [{\"mount_path\": \"/usr/share/nginx/html/scale\", \"read_only\": \"False\"}]", "prediction_line": "    value_pod = [{\"mount_path\": \"/usr/share/nginx/html/scale\", \"read_only\": \"False\"}]", "ground_truth": "    value_clone_passed = {\"clone_pvc\": [{\"access_modes\": \"ReadWriteMany\", \"storage\": \"1Gi\"}, {\"access_modes\": \"ReadWriteOnce\", \"storage\": \"1Gi\"}]}", "line_class": "random", "zero_context": true}
{"original_prediction": "                 {\"mount_path\": \"/usr/share/nginx/html\", \"read_only\": \"False\", \"sub_path\": [\"sub_path_mnt\"], \"volumemount_readonly\":[False]}]", "prediction_line": "                 {\"mount_path\": \"/usr/share/nginx/html\", \"read_only\": \"False\", \"sub_path\": [\"sub_path_mnt\"], \"volumemount_readonly\":[False]}]", "ground_truth": "                 {\"mount_path\": \"/usr/share/nginx/html/scale\", \"read_only\": \"False\", \"sub_path\": [\"sub_path_mnt\"], \"volumemount_readonly\":[True],", "line_class": "random", "zero_context": true}
{"original_prediction": "import os\nimport sys", "prediction_line": "import os", "ground_truth": "from kubernetes import client", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"\n    try:", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    Checks statefulsets state", "prediction_line": "    Checks statefulsets state", "ground_truth": "    Checks statefulset exists or not", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    Set the namespace value", "prediction_line": "    Set the namespace value", "ground_truth": "    Make namespace as global to be used in later functions", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "           num += 1", "prediction_line": "           num += 1", "ground_truth": "            time.sleep(20)", "line_class": "random", "zero_context": true}
{"original_prediction": "        LOGGER.info(\"Custom object created successfully\")", "prediction_line": "        LOGGER.info(\"Custom object created successfully\")", "ground_truth": "        LOGGER.debug(custom_object_api_response)", "line_class": "random", "zero_context": true}
{"original_prediction": "        LOGGER.info(\"SpectrumScale CSI custom object does not exist\")", "prediction_line": "        LOGGER.info(\"SpectrumScale CSI custom object does not exist\")", "ground_truth": "        LOGGER.info(\"SpectrumScale CSI custom object does not exist\")", "line_class": "random", "zero_context": true}
{"original_prediction": "            LOGGER.info(\"waiting for daemonsets\")", "prediction_line": "            LOGGER.info(\"waiting for daemonsets\")", "ground_truth": "            LOGGER.info(\"waiting for daemonsets\")", "line_class": "random", "zero_context": true}
{"original_prediction": "            group=\"csi.ibm.com\",", "prediction_line": "            group=\"csi.ibm.com\",", "ground_truth": "            group=\"csi.ibm.com\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    unittest.main()", "prediction_line": "    unittest.main()", "ground_truth": "    unittest.main()", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.assertEqual(d[\"success\"], True)", "prediction_line": "        self.assertEqual(d[\"success\"], True)", "ground_truth": "        self._check_equivalent_inputs(\"mol.qin\", \"mol.qin.error2\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        h = QChemErrorHandler(", "prediction_line": "        h = QChemErrorHandler(", "ground_truth": "        self._check_equivalent_inputs(\"mol.qin\", \"mol.qin.error5\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._check_equivalent_inputs(\"mol.qin\", \"mol.qin.error3\")", "prediction_line": "        self._check_equivalent_inputs(\"mol.qin\", \"mol.qin.error3\")", "ground_truth": "        self._check_equivalent_inputs(\"mol.qin\", \"mol.qin.error3\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._check_equivalent_inputs(\"mol.qin\", \"mol.qin.freq_0\")", "prediction_line": "        self._check_equivalent_inputs(\"mol.qin\", \"mol.qin.freq_0\")", "ground_truth": "        self._check_equivalent_inputs(\"mol.qin\", \"mol.qin.freq_0\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._check_equivalent_inputs(\"mol.qin\", \"mol.qin.opt_0\")", "prediction_line": "        self._check_equivalent_inputs(\"mol.qin\", \"mol.qin.opt_0\")", "ground_truth": "        self._check_equivalent_inputs(\"mol.qin\", \"mol.qin.opt_0\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        h.check()", "prediction_line": "        h.check()", "ground_truth": "        h.check()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        d = h.correct()", "prediction_line": "        d = h.correct()", "ground_truth": "        d = h.correct()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        h = QChemErrorHandler(", "prediction_line": "        h = QChemErrorHandler(", "ground_truth": "        h = QChemErrorHandler(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        d = h.correct()", "prediction_line": "        d = h.correct()", "ground_truth": "        self.assertFalse(h.check())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    @patch(\"custodian.qchem.jobs.QCJob.run\")", "prediction_line": "    @patch(\"custodian.qchem.jobs.QCJob.run\")", "ground_truth": "        expected_next = QCJob(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.assertEqual(QCinput1.get(key), QCinput2.get(key))", "prediction_line": "            self.assertEqual(QCinput1.get(key), QCinput2.get(key))", "ground_truth": "            self.assertEqual(QCinput1.as_dict().get(key), QCinput2.as_dict().get(key))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            backup=False,", "prediction_line": "            backup=False,", "ground_truth": "            backup=False,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ).as_dict()", "prediction_line": "        ).as_dict()", "ground_truth": "        ).as_dict()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(next(myjob).as_dict(), expected_next)", "prediction_line": "        self.assertEqual(next(myjob).as_dict(), expected_next)", "ground_truth": "        self.assertEqual(next(myjob).as_dict(), expected_next)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Test that the input file is correctly modified for the first optimization", "prediction_line": "        # Test that the input file is correctly modified for the first optimization", "ground_truth": "        myjob = QCJob.opt_with_frequency_flattener(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            linked=True,", "prediction_line": "            linked=True,", "ground_truth": "            backup=True,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "except ImportError:", "prediction_line": "except ImportError:", "ground_truth": "except ImportError:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    from mock import patch  # type: ignore", "prediction_line": "    from mock import patch  # type: ignore", "ground_truth": "    from unittest.mock import patch  # type: ignore", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def tearDown(self):", "prediction_line": "    def tearDown(self):", "ground_truth": "    def tearDown(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            max_cores=40,", "prediction_line": "            max_cores=40,", "ground_truth": "            max_cores=40,", "line_class": "random", "zero_context": true}
{"original_prediction": "            input_file=\"mol.qin.opt_0\",", "prediction_line": "            input_file=\"mol.qin.opt_0\",", "ground_truth": "            input_file=\"mol.qin\",", "line_class": "random", "zero_context": true}
{"original_prediction": "__maintainer__ = \"Samuel Blau\"", "prediction_line": "__maintainer__ = \"Samuel Blau\"", "ground_truth": "__maintainer__ = \"Samuel Blau\"", "line_class": "random", "zero_context": true}
{"original_prediction": "            input_file=\"mol.qin.opt_0\",", "prediction_line": "            input_file=\"mol.qin.opt_0\",", "ground_truth": "            multimode=\"openmp\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                errors = outdata.get(\"errors\")", "prediction_line": "                errors = outdata.get(\"errors\")", "ground_truth": "                errors = outdata.get(\"errors\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                    opt_rem[\"cpscf_nseg\"] = freq_indata.rem[\"cpscf_nseg\"]", "prediction_line": "                    opt_rem[\"cpscf_nseg\"] = freq_indata.rem[\"cpscf_nseg\"]", "ground_truth": "                errors = freq_outdata.get(\"errors\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                    freq_0 = outdata.get(\"frequencies\")[0]", "prediction_line": "                    freq_0 = outdata.get(\"frequencies\")[0]", "ground_truth": "                    freq_0 = outdata.get(\"frequencies\")[0]", "line_class": "common", "zero_context": true}
{"original_prediction": "                    freq_1 = outdata.get(\"frequencies\")[1]", "prediction_line": "                    freq_1 = outdata.get(\"frequencies\")[1]", "ground_truth": "                    freq_1 = outdata.get(\"frequencies\")[1]", "line_class": "common", "zero_context": true}
{"original_prediction": "                   if freq_outdata.get(\"final_energy\") is None:", "prediction_line": "                   if freq_outdata.get(\"final_energy\") is None:", "ground_truth": "                    freq_list = freq_outdata.get(\"frequencies\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                        break\n                    if abs(freq_0) < 15.0 and freq_1 > 0.0:", "prediction_line": "                        break", "ground_truth": "                        if opt_outdata.get(\"final_energy\") > orig_energy:", "line_class": "common", "zero_context": true}
{"original_prediction": "                    if len(freq_list) > 2:", "prediction_line": "                    if len(freq_list) > 2:", "ground_truth": "                    freq_0 = freq_outdata.get(\"frequencies\")[0]", "line_class": "common", "zero_context": true}
{"original_prediction": "                    freq_2 = outdata.get(\"frequencies\")[2]", "prediction_line": "                    freq_2 = outdata.get(\"frequencies\")[2]", "ground_truth": "                    freq_2 = outdata.get(\"frequencies\")[2]", "line_class": "common", "zero_context": true}
{"original_prediction": "                        opt_rem[\"scf_algorithm\"] = opt_scf_alg", "prediction_line": "                        opt_rem[\"scf_algorithm\"] = opt_scf_alg", "ground_truth": "                        if opt_indata.rem.get(\"gen_scfman_hybrid_algo\", \"false\") == \"true\":", "line_class": "common", "zero_context": true}
{"original_prediction": "                        if freq_rem.get(\"gen_scfman_hybrid_algo\", \"false\") == \"true\":", "prediction_line": "                        if freq_rem.get(\"gen_scfman_hybrid_algo\", \"false\") == \"true\":", "ground_truth": "                        if freq_rem.get(\"gen_scfman_hybrid_algo\", \"false\") == \"true\":", "line_class": "common", "zero_context": true}
{"original_prediction": "                    molecule=opt_outdata.get(\"molecule_from_optimized_geometry\"),", "prediction_line": "                    molecule=opt_outdata.get(\"molecule_from_optimized_geometry\"),", "ground_truth": "                    molecule=opt_outdata.get(\"molecule_from_optimized_geometry\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "                hist[\"species\"] = copy.deepcopy(outdata.get(\"species\"))", "prediction_line": "                hist[\"species\"] = copy.deepcopy(outdata.get(\"species\"))", "ground_truth": "                hist[\"molecule\"] = copy.deepcopy(outdata.get(\"initial_molecule\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "                hist[\"energy\"] = copy.deepcopy(outdata.get(\"final_energy\"))", "prediction_line": "                hist[\"energy\"] = copy.deepcopy(outdata.get(\"final_energy\"))", "ground_truth": "                hist[\"geometry\"] = copy.deepcopy(outdata.get(\"initial_geometry\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "                hist[\"energy\"] = copy.deepcopy(outdata.get(\"final_energy\"))", "prediction_line": "                hist[\"energy\"] = copy.deepcopy(outdata.get(\"final_energy\"))", "ground_truth": "                hist[\"frequencies\"] = copy.deepcopy(outdata.get(\"frequencies\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "                hist[\"energy\"] = copy.deepcopy(outdata.get(\"final_energy\"))", "prediction_line": "                hist[\"energy\"] = copy.deepcopy(outdata.get(\"final_energy\"))", "ground_truth": "                hist[\"frequency_mode_vectors\"] = copy.deepcopy(outdata.get(\"frequency_mode_vectors\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "                hist[\"energy\"] = copy.deepcopy(outdata.get(\"final_energy\"))", "prediction_line": "                hist[\"energy\"] = copy.deepcopy(outdata.get(\"final_energy\"))", "ground_truth": "                hist[\"num_neg_freqs\"] = sum(1 for freq in outdata.get(\"frequencies\") if freq < 0)", "line_class": "common", "zero_context": true}
{"original_prediction": "                hist[\"energy\"] = copy.deepcopy(outdata.get(\"final_energy\"))", "prediction_line": "                hist[\"energy\"] = copy.deepcopy(outdata.get(\"final_energy\"))", "ground_truth": "                hist[\"energy\"] = copy.deepcopy(opt_outdata.get(\"final_energy\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "                    if freq_0 > 0.0:", "prediction_line": "                    if freq_0 > 0.0:", "ground_truth": "                    freq_1 = freq_outdata.get(\"frequencies\")[1]", "line_class": "common", "zero_context": true}
{"original_prediction": "                    if freq_0 > 0.0:", "prediction_line": "                    if freq_0 > 0.0:", "ground_truth": "                    freq_2 = freq_outdata.get(\"frequencies\")[2]", "line_class": "common", "zero_context": true}
{"original_prediction": "                    else:", "prediction_line": "                    else:", "ground_truth": "                energy_history.append(opt_outdata.get(\"final_energy\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "                    opt_indata = QCInput.from_file(input_file + f\".{opt_method}_\" + str(ii))", "prediction_line": "                    opt_indata = QCInput.from_file(input_file + f\".{opt_method}_\" + str(ii))", "ground_truth": "                    orig_species = copy.deepcopy(opt_outdata.get(\"species\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "                    first = False", "prediction_line": "                    first = False", "ground_truth": "                    orig_charge = copy.deepcopy(opt_outdata.get(\"charge\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "                    orig_mult = copy.deepcopy(opt_outdata.get(\"mult\"))", "prediction_line": "                    orig_mult = copy.deepcopy(opt_outdata.get(\"mult\"))", "ground_truth": "                    orig_multiplicity = copy.deepcopy(opt_outdata.get(\"multiplicity\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "                    orig_molecule = copy.deepcopy(opt_outdata.get(\"molecule_from_optimized_geometry\"))", "prediction_line": "                    orig_molecule = copy.deepcopy(opt_outdata.get(\"molecule_from_optimized_geometry\"))", "ground_truth": "                    orig_energy = copy.deepcopy(opt_outdata.get(\"final_energy\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "            qcinp.rem.jobtype == \"opt\"", "prediction_line": "            qcinp.rem.jobtype == \"opt\"", "ground_truth": "            qcinp.rem.get(\"run_nbo6\", \"none\").lower() == \"true\"", "line_class": "common", "zero_context": true}
{"original_prediction": "            or qcinp.rem.get(\"run_nbo7\", \"none\").lower() == \"true\"", "prediction_line": "            or qcinp.rem.get(\"run_nbo7\", \"none\").lower() == \"true\"", "ground_truth": "            or qcinp.rem.get(\"nbo_external\", \"none\").lower() == \"true\"", "line_class": "common", "zero_context": true}
{"original_prediction": "                    QCJob(", "prediction_line": "                    QCJob(", "ground_truth": "                    QCJob(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        backup=first,", "prediction_line": "                        backup=first,", "ground_truth": "                        backup=first,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            opt_rem.pop(\"scf_algorithm\", None)", "prediction_line": "                            opt_rem.pop(\"scf_algorithm\", None)", "ground_truth": "                            opt_rem.pop(\"scf_algorithm\", None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            freq_rem.pop(\"scf_algorithm\", None)", "prediction_line": "                            freq_rem.pop(\"scf_algorithm\", None)", "ground_truth": "                            freq_rem.pop(\"scf_algorithm\", None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        os.environ[\"QCSCRATCH\"] = os.getcwd()", "prediction_line": "        os.environ[\"QCSCRATCH\"] = os.getcwd()", "ground_truth": "        if self.backup:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            opt_rem[\"link1\"] = \"freq\"", "prediction_line": "            opt_rem[\"link1\"] = \"freq\"", "ground_truth": "            opt_rem.pop(\"geom_opt2\", None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        scratch_dir=None,", "prediction_line": "        scratch_dir=None,", "ground_truth": "        backup=True,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                    good_child[\"energy\"] > parent_hist[\"energy\"]", "prediction_line": "                                    good_child[\"energy\"] > parent_hist[\"energy\"]", "ground_truth": "                                    vector_list_diff(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if check_connectivity:", "prediction_line": "                    if check_connectivity:", "ground_truth": "                    new_coords = perturb_coordinates(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.backup = backup", "prediction_line": "        self.backup = backup", "ground_truth": "        self.backup = backup", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Args:", "prediction_line": "        Args:", "ground_truth": "        Args:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        imaginary frequency, it is treated as a transition state.", "prediction_line": "        imaginary frequency, it is treated as a transition state.", "ground_truth": "        imaginary frequency, it is still treated as a transition-state.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Returns the current command.", "prediction_line": "        Returns the current command.", "ground_truth": "        The command to run QChem", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                            \"ERROR: Could not find parent for iteration \"", "prediction_line": "                            \"ERROR: Could not find parent for iteration \"", "ground_truth": "                            \"ERROR: your parent should always be one or two iterations behind you! Exiting...\"", "line_class": "random", "zero_context": true}
{"original_prediction": "                if freq_outdata[\"completion\"]:", "prediction_line": "                if freq_outdata[\"completion\"]:", "ground_truth": "                if not transition_state:", "line_class": "random", "zero_context": true}
{"original_prediction": "                                else:", "prediction_line": "                                else:", "ground_truth": "                                else:", "line_class": "random", "zero_context": true}
{"original_prediction": "        opt_rem[\"job_type\"] = opt_method", "prediction_line": "        opt_rem[\"job_type\"] = opt_method", "ground_truth": "        opt_rem[\"job_type\"] = opt_method", "line_class": "random", "zero_context": true}
{"original_prediction": "        if self.calc_loc:", "prediction_line": "        if self.calc_loc:", "ground_truth": "        if self.calc_loc is not None:", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(tracer, epid)", "prediction_line": "        super().__init__(tracer, epid)", "ground_truth": "        super().__init__(tracer, epid)", "line_class": "commited", "zero_context": true}
{"original_prediction": "sio_tracer.start()", "prediction_line": "sio_tracer.start()", "ground_truth": "sio_tracer.start(dart_sio_tracer.dart)", "line_class": "common", "zero_context": true}
{"original_prediction": "spi_tracer.start()", "prediction_line": "spi_tracer.start()", "ground_truth": "spi_tracer.start()", "line_class": "common", "zero_context": true}
{"original_prediction": "dart_sio_tracer.start()", "prediction_line": "dart_sio_tracer.start()", "ground_truth": "dart_sio_tracer.start()", "line_class": "common", "zero_context": true}
{"original_prediction": "        0x1a: SIOEp,", "prediction_line": "        0x1a: SIOEp,", "ground_truth": "        0x20: SIOEp", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def __init__(self, ep, state):", "prediction_line": "    def __init__(self, ep, state):", "ground_truth": "    BASE_MESSAGE = SIOMessage", "line_class": "infile", "zero_context": true}
{"original_prediction": "   def __init__(self, hv, verbose=0):", "prediction_line": "   def __init__(self, hv, verbose=0):", "ground_truth": "sio_tracer = SIOTracer(hv, \"/arm-io/sio\", verbose=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       self.state.iova = msg.DATA", "prediction_line": "       self.state.iova = msg.DATA", "ground_truth": "    @msg(3, DIR.TX, SIOSetup)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.state.dumpfile = open(f\"sio.spi3.{msg.TAG:02x}.bin\", \"wb\")", "prediction_line": "            self.state.dumpfile = open(f\"sio.spi3.{msg.TAG:02x}.bin\", \"wb\")", "ground_truth": "            buf = struct.unpack(\"<I\", self.tracer.ioread(self.state.iova + 0xa8, 4))[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.state.iova = msg.DATA", "prediction_line": "        self.state.iova = msg.DATA", "ground_truth": "        self.log(\"Start SIO\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       self.state.dumpfile_cfg = None", "prediction_line": "       self.state.dumpfile_cfg = None", "ground_truth": "    @msg(2, DIR.TX, SIOStart)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.state.dumpfile.write(pkt.data[:min(246, pkt.length)])", "prediction_line": "            self.state.dumpfile.write(pkt.data[:min(246, pkt.length)])", "ground_truth": "            dump = f\"{label}: flags:{pkt.flags:#2x} dev:{pkt.dev:#2x} length:{pkt.length:4d}  {pkt.data[:min(246, pkt.length)].hex()}\\n\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    TYPE = 23, 16, Constant(3)", "prediction_line": "    TYPE = 23, 16, Constant(3)", "ground_truth": "    TYPE = 23, 16, Constant(3)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            size = struct.unpack(\"<I\", self.tracer.ioread(self.state.iova + 0x50, 4))[0]", "prediction_line": "            size = struct.unpack(\"<I\", self.tracer.ioread(self.state.iova + 0x50, 4))[0]", "ground_truth": "            size = struct.unpack(\"<I\", self.tracer.ioread(self.state.iova + 0x50, 4))[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if self.state.iova_cfg is None:", "prediction_line": "        if self.state.iova_cfg is None:", "ground_truth": "        if msg.EP == 0x1a:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.log(f\"SetupIO: {buf:08x} {size:08x}\")", "prediction_line": "            self.log(f\"SetupIO: {buf:08x} {size:08x}\")", "ground_truth": "            self.log_spihid_pkt(\"SPI3 TX\", self.tracer.ioread(buf, size))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.log(\"Setup SIO\")", "prediction_line": "        self.log(\"Setup SIO\")", "ground_truth": "        if msg.EP == 0 and msg.PARAM == 0x1:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        iomon.poll()", "prediction_line": "        iomon.poll()", "ground_truth": "        iomon.poll()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       if self.state.iova is not None and self.tracer.verbose > 1:", "prediction_line": "       if self.state.iova is not None and self.tracer.verbose > 1:", "ground_truth": "    @msg(6, DIR.TX, SIOSetupIO)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif msg.EP == 0 and msg.PARAM == 0x3:", "prediction_line": "        elif msg.EP == 0 and msg.PARAM == 0x3:", "ground_truth": "        elif msg.EP == 0 and msg.PARAM == 0xb:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "?\n            self.state.iova_cfg = msg.DATA << 12", "prediction_line": "?", "ground_truth": "            self.state.iova_cfg = msg.DATA << 12", "line_class": "inproject", "zero_context": true}
{"original_prediction": "#spi_tracer = SPITracer(hv, \"/arm-io/spi3\", verbose=0)", "prediction_line": "#spi_tracer = SPITracer(hv, \"/arm-io/spi3\", verbose=0)", "ground_truth": "spi_tracer = SPITracer(hv, \"/arm-io/\" + spi_node.name, verbose=1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": ",\n    }", "prediction_line": ",", "ground_truth": "    }", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from m1n1.hv.trace import Trace", "prediction_line": "from m1n1.hv.trace import Trace", "ground_truth": "from m1n1.proxyutils import RegMonitor", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class SPIHIDTracer(Tracer):", "prediction_line": "class SPIHIDTracer(Tracer):", "ground_truth": "spi_pins_nub = {", "line_class": "random", "zero_context": true}
{"original_prediction": "    except Exception as e:", "prediction_line": "    except Exception as e:", "ground_truth": "    except Exception as e:", "line_class": "random", "zero_context": true}
{"original_prediction": "                        break\n                except AttributeError:", "prediction_line": "                        break", "ground_truth": "                        break", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"data\"      / Prefixed(Int16ul, GreedyBytes),", "prediction_line": "    \"data\"      / Prefixed(Int16ul, GreedyBytes),", "ground_truth": "    \"data\"      / Bytes(246),", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.state = EPState.IDLE", "prediction_line": "        self.state = EPState.IDLE", "ground_truth": "        self.state.iova = None", "line_class": "random", "zero_context": true}
{"original_prediction": "    DeviceControl_17,", "prediction_line": "    DeviceControl_17,", "ground_truth": "    DeviceControl_17,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    DeviceControl_19,", "prediction_line": "    DeviceControl_19,", "ground_truth": "    DeviceControl_19,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    DeviceControl_1e,", "prediction_line": "    DeviceControl_1e,", "ground_truth": "    DeviceControl_23,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    DeviceControl_1e,", "prediction_line": "    DeviceControl_1e,", "ground_truth": "    UnknownMsg,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            ringbuffer = [UnknownMsg()] * 256,", "prediction_line": "            ringbuffer = [UnknownMsg()] * 256,", "ground_truth": "            ringbuffer = [UnknownMsg()] * 256,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"Return3\" / ChannelInfo(UnknownMsg),", "prediction_line": "        \"Return3\" / ChannelInfo(UnknownMsg),", "ground_truth": "        \"Return3\" / ChannelInfo(UnknownMsg),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"notify_cmdqueue_work\" / Array(12, NotifyCmdQueueWork),", "prediction_line": "        \"notify_cmdqueue_work\" / Array(12, NotifyCmdQueueWork),", "ground_truth": "        *[ channelNames[i] / ChannelInfo(NotifyCmdQueueWork) for i in range(12)],", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"DevCtrl\" / ChannelInfo(DeviceControlMsg),", "prediction_line": "        \"DevCtrl\" / ChannelInfo(DeviceControlMsg),", "ground_truth": "        \"DevCtrl\" / ChannelInfo(DeviceControlMsg),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        *[ channelNames[i] / ChannelInfo(NotifyCmdQueueWork) for i in range(12, 16)],", "prediction_line": "        *[ channelNames[i] / ChannelInfo(NotifyCmdQueueWork) for i in range(12, 16)],", "ground_truth": "        \"Return0\" / ChannelInfo(Bytes(0x38)),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"Return1\" / ChannelInfo(Bytes(0x38)),", "prediction_line": "        \"Return1\" / ChannelInfo(Bytes(0x38)),", "ground_truth": "        \"Return1\" / ChannelInfo(UnknownMsg),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"Return2\" / ChannelInfo(UnknownMsg),", "prediction_line": "        \"Return2\" / ChannelInfo(UnknownMsg),", "ground_truth": "        \"Return2\" / ChannelInfo(UnknownMsg),", "line_class": "infile", "zero_context": true}
{"original_prediction": "heap, shared_heap))", "prediction_line": "heap, shared_heap))", "ground_truth": "                state_addr = shared_heap.malloc(ChannelState.sizeof()),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                ringbuffer_addr = heap.malloc(0x1000),", "prediction_line": "                ringbuffer_addr = heap.malloc(0x1000),", "ground_truth": "                ringbuffer_addr = heap.malloc(256 * NotifyCmdQueueWork.sizeof()),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            ringbuffer_addr = heap.malloc(256 * DeviceControlMsg.sizeof()),", "prediction_line": "            ringbuffer_addr = heap.malloc(256 * DeviceControlMsg.sizeof()),", "ground_truth": "            ringbuffer_addr = heap.malloc(256 * UnknownMsg.sizeof()),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            state_addr = shared_heap.malloc(ChannelState.sizeof()),", "prediction_line": "            state_addr = shared_heap.malloc(ChannelState.sizeof()),", "ground_truth": "            state_addr = heap.malloc(ChannelState.sizeof()),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            ringbuffer_addr = heap.malloc(256 * UnknownMsg.sizeof()),", "prediction_line": "            ringbuffer_addr = heap.malloc(256 * UnknownMsg.sizeof()),", "ground_truth": "            ringbuffer_addr = heap.malloc(256 * 0x38),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            pass\n\n        if self.queue_type == 0:", "prediction_line": "            pass", "ground_truth": "            self.workItems = self.cmdqueue.getSubmittedWork(self.head)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"msg_addr\" / Int64ul,", "prediction_line": "        \"msg_addr\" / Int64ul,", "ground_truth": "        \"state\" / Pointer(this.state_addr, ChannelState),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"ringbuffer\" / Pointer(this.ringbuffer_addr, msg_cls),", "prediction_line": "        \"ringbuffer\" / Pointer(this.ringbuffer_addr, msg_cls),", "ground_truth": "        \"ringbuffer\" / Pointer(this.ringbuffer_addr, Array(256, msg_cls)),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return f\"UnknownMsg(0x{self.msg_type:x})\"", "prediction_line": "        return f\"UnknownMsg(0x{self.msg_type:x})\"", "ground_truth": "        return f\"Unknown(type={self.msg_type:x}, data={hexdump32(self.data)})\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "class DeviceControl_1a(ConstructClass):", "prediction_line": "class DeviceControl_1a(ConstructClass):", "ground_truth": "class DeviceControl_1e(ConstructClass):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __repr__(self):", "prediction_line": "    def __repr__(self):", "ground_truth": "    def __repr__(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#     )", "prediction_line": "#     )", "ground_truth": "#     )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class NotifyCmdQueue(ConstructClass):", "prediction_line": "class NotifyCmdQueue(ConstructClass):", "ground_truth": "class DeviceControl_17(ConstructClass):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        return \"<%s: %s>\" % (self.TYPE, self.get_workitems())", "prediction_line": "        return \"<%s: %s>\" % (self.TYPE, self.get_workitems())", "ground_truth": "        if (self.cmdqueue_addr == 0):", "line_class": "random", "zero_context": true}
{"original_prediction": "        Padding(0x2c)", "prediction_line": "        Padding(0x2c)", "ground_truth": "        \"data\" / Bytes(0x2c),", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"size\" / Default(Int32ul, 0),", "prediction_line": "    \"size\" / Default(Int32ul, 0),", "ground_truth": "    \"gpu_head\" / Default(Int32ul, 0),", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"unk_4\" / Int32ul,", "prediction_line": "        \"unk_4\" / Int32ul,", "ground_truth": "        Padding(0x2c)", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"unk_0\" / Default(Int32ul, 0),", "prediction_line": "        \"unk_0\" / Default(Int32ul, 0),", "ground_truth": "        \"msg_type\" / Const(0x17, Int32ul),", "line_class": "random", "zero_context": true}
{"original_prediction": "        im.save(args.output)", "prediction_line": "        im.save(args.output)", "ground_truth": "        im.save(args.output)", "line_class": "common", "zero_context": true}
{"original_prediction": "reset_block()", "prediction_line": "reset_block()", "ground_truth": "reset_block()", "line_class": "infile", "zero_context": true}
{"original_prediction": "   jpeg.MODE.val = 0x100", "prediction_line": "   jpeg.MODE.val = 0x100", "ground_truth": "    set_default_regs()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # 16x16 macroblocks?", "prediction_line": "    # 16x16 macroblocks?", "ground_truth": "    surface_W = divroundup(jpeg_W, macroblock_W) * macroblock_W", "line_class": "infile", "zero_context": true}
{"original_prediction": "    surface_H = divroundup(jpeg_H, macroblock_H) * macroblock_H", "prediction_line": "    surface_H = divroundup(jpeg_H, macroblock_H) * macroblock_H", "ground_truth": "    surface_H = divroundup(jpeg_H, macroblock_H) * macroblock_H", "line_class": "infile", "zero_context": true}
{"original_prediction": "    jpeg.REG_0x100.val = 0", "prediction_line": "    jpeg.REG_0x100.val = 0", "ground_truth": "    jpeg.ENCODE_PIXEL_FORMAT.val = 0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "y*surface_stride + x*BYTESPP:y*surface_stride + (x+1)*BYTESPP]", "prediction_line": "y*surface_stride + x*BYTESPP:y*surface_stride + (x+1)*BYTESPP]", "ground_truth": "                    y*surface_stride + x*BYTESPP:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    jpeg.REG_0x20c.val = 0", "prediction_line": "    jpeg.REG_0x20c.val = 0", "ground_truth": "    jpeg.REG_0x214.val = 0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        v = jpeg.REG_0x1004.val", "prediction_line": "        v = jpeg.REG_0x1004.val", "ground_truth": "        v = jpeg.RST_INTERVAL.val", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    jpeg.ENCODE_COMPONENT0_SIZE.val = 0", "prediction_line": "    jpeg.ENCODE_COMPONENT0_SIZE.val = 0", "ground_truth": "    jpeg.CONVERT_COLOR_SPACE.val = 0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    jpeg.PX_PLANE0_HEIGHT.val = 1", "prediction_line": "    jpeg.PX_PLANE0_HEIGHT.val = 1", "ground_truth": "    jpeg.PX_PLANE0_HEIGHT.val = 1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    jpeg.PX_PLANE1_WIDTH.val = 1", "prediction_line": "    jpeg.PX_PLANE1_WIDTH.val = 1", "ground_truth": "    jpeg.PX_PLANE0_TILING_H.val = 1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def encode_jpeg(jpeg_data, jpeg_W, jpeg_H, jpeg_MODE, surface_W, surface_H, surface_stride, input_mem_sz, output_mem_sz):", "prediction_line": "def encode_jpeg(jpeg_data, jpeg_W, jpeg_H, jpeg_MODE, surface_W, surface_H, surface_stride, input_mem_sz, output_mem_sz):", "ground_truth": "input_buf_phys = u.heap.memalign(0x4000, input_mem_sz)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    jpeg.REG_0x21c.val = 0", "prediction_line": "    jpeg.REG_0x21c.val = 0", "ground_truth": "    jpeg.REG_0x21c.val = 0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    jpeg.REG_0x224.val = 0", "prediction_line": "    jpeg.REG_0x224.val = 0", "ground_truth": "    jpeg.REG_0x224.val = 0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    jpeg.MODE.val = 0x100", "prediction_line": "    jpeg.MODE.val = 0x100", "ground_truth": "    if (v := jpeg.REG_0x1004.val) != 0:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "               im.putpixel((x, y), tuple(block))", "prediction_line": "               im.putpixel((x, y), tuple(block))", "ground_truth": "                r, g, b, a = block", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    jpeg.REG_0x1fc.val = 0", "prediction_line": "    jpeg.REG_0x1fc.val = 0", "ground_truth": "    jpeg.RGBA_ORDER.val = 1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "# Allocate memory for the JPEG block", "prediction_line": "# Allocate memory for the JPEG block", "ground_truth": "p.pmgr_adt_clocks_enable(f'/arm-io/{args.which_jpeg}')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def encode_jpeg(jpeg_data, output_buf_iova):", "prediction_line": "def encode_jpeg(jpeg_data, output_buf_iova):", "ground_truth": "iface.writemem(input_buf_phys, b'\\xAA' * input_mem_sz)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "parser = argparse.ArgumentParser()", "prediction_line": "parser = argparse.ArgumentParser()", "ground_truth": "from enum import IntEnum", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "parser = argparse.ArgumentParser()", "prediction_line": "parser = argparse.ArgumentParser()", "ground_truth": "import time", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        print(f\"reset 2 -- {v}\")", "prediction_line": "        print(f\"reset 2 -- {v}\")", "ground_truth": "        print(f\"reset 1 failed! -- {v}\")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                found_sof0 = True", "prediction_line": "                found_sof0 = True", "ground_truth": "                found_sof0 = True", "line_class": "random", "zero_context": true}
{"original_prediction": "    surface_size = surface_W * surface_H", "prediction_line": "    surface_size = surface_W * surface_H", "ground_truth": "    BYTESPP = 4", "line_class": "random", "zero_context": true}
{"original_prediction": "    elif jpeg_MODE == '422':", "prediction_line": "    elif jpeg_MODE == '422':", "ground_truth": "    elif jpeg_MODE == '422':", "line_class": "random", "zero_context": true}
{"original_prediction": "                found_sof0 = True", "prediction_line": "                found_sof0 = True", "ground_truth": "                assert not found_sof0", "line_class": "random", "zero_context": true}
{"original_prediction": "    # jpeg.REG_0x1004.val = 0x1", "prediction_line": "    # jpeg.REG_0x1004.val = 0x1", "ground_truth": "    jpeg.REG_0x1004 = 0x1", "line_class": "random", "zero_context": true}
{"original_prediction": "apr.QUANT_LUMA_PROXY[6].val     = 0x811810", "prediction_line": "apr.QUANT_LUMA_PROXY[6].val     = 0x811810", "ground_truth": "apr.QUANT_LUMA_PROXY[6].val     = 0x83f80e", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.DC_QUANT_SCALE[104].val     = 0x391c4", "prediction_line": "apr.DC_QUANT_SCALE[104].val     = 0x391c4", "ground_truth": "apr.DC_QUANT_SCALE[104].val     = 0x391c4", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.DC_QUANT_SCALE[74].val      = 0x1b0d4", "prediction_line": "apr.DC_QUANT_SCALE[74].val      = 0x1b0d4", "ground_truth": "apr.DC_QUANT_SCALE[74].val      = 0x1b0d4", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.DC_QUANT_SCALE[18].val      = 0x4c25", "prediction_line": "apr.DC_QUANT_SCALE[18].val      = 0x4c25", "ground_truth": "apr.DC_QUANT_SCALE[18].val      = 0x4c25", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.REG_0x2b0 = apr.REG_0x2b0.val & ~0x800F3FFF | 0x800204FF", "prediction_line": "apr.REG_0x2b0 = apr.REG_0x2b0.val & ~0x800F3FFF | 0x800204FF", "ground_truth": "apr.REG_0x2b0 = apr.REG_0x2b0.val & ~0x800F3FFF | 0x800204FF", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.QUANT_LUMA_NQ[12].val       = 0x805805", "prediction_line": "apr.QUANT_LUMA_NQ[12].val       = 0x805805", "ground_truth": "apr.QUANT_LUMA_NQ[12].val       = 0x805805", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.QUANT_LUMA_HQ[10].val       = 0x804804", "prediction_line": "apr.QUANT_LUMA_HQ[10].val       = 0x804804", "ground_truth": "apr.QUANT_LUMA_HQ[10].val       = 0x804804", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.QUANT_LUMA_LT[14].val       = 0x80f80d", "prediction_line": "apr.QUANT_LUMA_LT[14].val       = 0x80f80d", "ground_truth": "apr.QUANT_LUMA_LT[14].val       = 0x80f80d", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.DC_QUANT_SCALE[4].val       = 0x1409", "prediction_line": "apr.DC_QUANT_SCALE[4].val       = 0x1409", "ground_truth": "apr.DC_QUANT_SCALE[4].val       = 0x1409", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.QUANT_CHROMA_NQ[28].val     = 0x807807", "prediction_line": "apr.QUANT_CHROMA_NQ[28].val     = 0x807807", "ground_truth": "apr.QUANT_CHROMA_NQ[28].val     = 0x807807", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.QUANT_CHROMA_HQ[6].val      = 0x804804", "prediction_line": "apr.QUANT_CHROMA_HQ[6].val      = 0x804804", "ground_truth": "apr.QUANT_CHROMA_HQ[6].val      = 0x804804", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.DC_QUANT_SCALE[89].val      = 0x2a14c", "prediction_line": "apr.DC_QUANT_SCALE[89].val      = 0x2a14c", "ground_truth": "apr.DC_QUANT_SCALE[89].val      = 0x2a14c", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.QUANT_CHROMA_HQ[25].val     = 0x804804", "prediction_line": "apr.QUANT_CHROMA_HQ[25].val     = 0x804804", "ground_truth": "apr.QUANT_CHROMA_HQ[25].val     = 0x804804", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.DC_QUANT_SCALE[40].val      = 0xa451", "prediction_line": "apr.DC_QUANT_SCALE[40].val      = 0xa451", "ground_truth": "apr.DC_QUANT_SCALE[40].val      = 0xa451", "line_class": "inproject", "zero_context": true}
{"original_prediction": "apr.QUANT_CHROMA_PROXY[3].val   = 0xfff83f", "prediction_line": "apr.QUANT_CHROMA_PROXY[3].val   = 0xfff83f", "ground_truth": "apr.QUANT_CHROMA_PROXY[3].val   = 0xfff83f", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    pix_surface_h_byteswap_=0x8007, # hack", "prediction_line": "    pix_surface_h_byteswap_=0x8007, # hack", "ground_truth": "    pix_surface_h_byteswap_=0x3804, # hack", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "print(f\"ST1 = {apr.ST1}\")", "prediction_line": "print(f\"ST1 = {apr.ST1}\")", "ground_truth": "print(f\"ST1 = {apr.ST1}\")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# print(f\"Output buffer @ phys {out_buf_phys:016X} iova {out_buf_iova:016X}\")", "prediction_line": "# print(f\"Output buffer @ phys {out_buf_phys:016X} iova {out_buf_iova:016X}\")", "ground_truth": "print(f\"ST0 = {apr.ST0}\")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "print(f\"ST2 = {apr.ST2}\")", "prediction_line": "print(f\"ST2 = {apr.ST2}\")", "ground_truth": "print(f\"REG_0x1c = {apr.REG_0x1c}\")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    pix_plane2_iova=0,", "prediction_line": "    pix_plane2_iova=0,", "ground_truth": "    pix_plane2_iova=in_buf_iova,", "line_class": "random", "zero_context": true}
{"original_prediction": "    pix_plane1_tileheader_thing_=0,", "prediction_line": "    pix_plane1_tileheader_thing_=0,", "ground_truth": "    pix_plane1_tileheader_thing_=0,", "line_class": "random", "zero_context": true}
{"original_prediction": "    in_buf_iova=in_buf_iova,", "prediction_line": "    in_buf_iova=in_buf_iova,", "ground_truth": "    output_iova=out_buf_iova,", "line_class": "random", "zero_context": true}
{"original_prediction": "    unk_0x100_1_=0x880080,", "prediction_line": "    unk_0x100_1_=0x880080,", "ground_truth": "    unk_0x100_1_=0x4e00c5,", "line_class": "random", "zero_context": true}
{"original_prediction": "    unk_0x110_13_=0x400200,", "prediction_line": "    unk_0x110_13_=0x400200,", "ground_truth": "    unk_0x110_13_=0x400200,", "line_class": "random", "zero_context": true}
{"original_prediction": "        return f\"WorkCommand_3(context_id={self.context_id})\"", "prediction_line": "        return f\"WorkCommand_3(context_id={self.context_id})\"", "ground_truth": "        str = super().__str__(ignore=['magic', 'controllist_ptr', 'controllist_size'])", "line_class": "commited", "zero_context": true}
{"original_prediction": "        for i in range(self.Ringbuffer_count):", "prediction_line": "        for i in range(self.Ringbuffer_count):", "ground_truth": "        orig_tail = tail = self.getTail()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # 0x0 - 0x3", "prediction_line": "        # 0x0 - 0x3", "ground_truth": "        WorkCommand_0,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        WorkCommand_1,", "prediction_line": "        WorkCommand_1,", "ground_truth": "        WorkCommand_1,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        WorkCommand_3,", "prediction_line": "        WorkCommand_3,", "ground_truth": "        WorkCommand_3,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        WorkCommand_4,", "prediction_line": "        WorkCommand_4,", "ground_truth": "        WorkCommand_4,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        WorkCommand_6,", "prediction_line": "        WorkCommand_6,", "ground_truth": "        WorkCommand_6,", "line_class": "infile", "zero_context": true}
{"original_prediction": "           work = CmdBufWork.parse_stream(stream)", "prediction_line": "           work = CmdBufWork.parse_stream(stream)", "ground_truth": "            Work.append(CmdBufWork.parse_stream(stream))", "line_class": "infile", "zero_context": true}
{"original_prediction": "       UnknownWorkCommand,", "prediction_line": "       UnknownWorkCommand,", "ground_truth": "        UnknownWorkCommand", "line_class": "infile", "zero_context": true}
{"original_prediction": "            stream.seek(self.RingBuffer_addr + tail * 0x4ff)", "prediction_line": "            stream.seek(self.RingBuffer_addr + tail * 0x4ff)", "ground_truth": "            stream.seek(self.RingBuffer_addr + tail * 8, 0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            stream.seek(pointer, 0)", "prediction_line": "            stream.seek(pointer, 0)", "ground_truth": "            stream.seek(pointer, 0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"controllist_unk_1c\" / Hex(Int32ul),", "prediction_line": "        \"controllist_unk_1c\" / Hex(Int32ul),", "ground_truth": "        \"controllist\" / Pointer(this.controllist_ptr, ControlList),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def getSubmittedWork_old(self, head):", "prediction_line": "    def getSubmittedWork_old(self, head):", "ground_truth": "CommandQueueInfo = CommandQueueInfo._reloadcls()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"\"\"\n    def __init__(self, *args, **kwargs):", "prediction_line": "    \"\"\"", "ground_truth": "    00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"unk_80\" / Hex(Int32ul), # 0", "prediction_line": "        \"unk_80\" / Hex(Int32ul), # 0", "ground_truth": "        \"unk_84\" / Hex(Int32ul), # Set to 1 by gpu after work complete. Reset to zero by cpu", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"unk_10\" / Hex(Int32ul), # 0", "prediction_line": "        \"unk_10\" / Hex(Int32ul), # 0", "ground_truth": "        \"unk_10\" / Hex(Int32ul), # 0x30", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"offset4\" / Hex(Int32ul), # controled by gpu", "prediction_line": "        \"offset4\" / Hex(Int32ul), # controled by gpu", "ground_truth": "        \"unk_2c\" / Int32sl, # touched by both cpu and gpu, cpu likes -1, gpu likes 3. Might be a return value?", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    subcon = Struct(", "prediction_line": "    subcon = Struct(", "ground_truth": "    subcon = Select(", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"unk_14\" / Hex(Int32ul),", "prediction_line": "        \"unk_14\" / Hex(Int32ul),", "ground_truth": "        \"unk_14\" / Hex(Int32ul),", "line_class": "random", "zero_context": true}
{"original_prediction": "            work = CmdBufWork.parse_stream(stream)", "prediction_line": "            work = CmdBufWork.parse_stream(stream)", "ground_truth": "            pointer = Hex(Int64ul).parse_stream(stream)", "line_class": "random", "zero_context": true}
{"original_prediction": "        return str", "prediction_line": "        return str", "ground_truth": "        return str", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"controllist_ptr\" / Hex(Int64ul), # Command list", "prediction_line": "        \"controllist_ptr\" / Hex(Int64ul), # Command list", "ground_truth": "        \"unkptr_c\" / Hex(Int64ul),", "line_class": "random", "zero_context": true}
{"original_prediction": "        options: Dict[str, PackSelectOption],", "prediction_line": "        options: Dict[str, PackSelectOption],", "ground_truth": "        select_options: Optional[PackSelectOption] = None,", "line_class": "infile", "zero_context": true}
{"original_prediction": "       return re.compile(source, flags)", "prediction_line": "       return re.compile(source, flags)", "ground_truth": "        return re.compile(source, flags)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            files_regex, match_spec = select_options.compile(template)", "prediction_line": "            files_regex, match_spec = select_options.compile(template)", "ground_truth": "            return PackSelector(*select_options.compile(template))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            files_regex = self.files.compile_regex(template)", "prediction_line": "            files_regex = self.files.compile_regex(template)", "ground_truth": "            files_regex = self.files.compile_regex(template)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return cls.from_dict(values, template)", "prediction_line": "        return cls.from_dict(values, template)", "ground_truth": "        return PackSelector(*PackSelectOption.parse_obj(values).compile(template))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        else selector.select_files(pack, *extensions)", "prediction_line": "        else selector.select_files(pack, *extensions)", "ground_truth": "        else selector.select_files(pack, *extensions)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       if isinstance(self.__root__, RegexFlagsOption):", "prediction_line": "       if isinstance(self.__root__, RegexFlagsOption):", "ground_truth": "        if isinstance(self.__root__, RegexFlagsOption):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    __root__: Union[ListOption[str], RegexOption, PathSpecOption] = ListOption()", "prediction_line": "    __root__: Union[ListOption[str], RegexOption, PathSpecOption] = ListOption()", "ground_truth": "    files: RegexOption = RegexOption()", "line_class": "infile", "zero_context": true}
{"original_prediction": ") -> PackSelection[File[Any, Any]]:", "prediction_line": ") -> PackSelection[File[Any, Any]]:", "ground_truth": ") -> PackSelection[File[Any, Any]]:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        template: Optional[TemplateManager] = None,", "prediction_line": "        template: Optional[TemplateManager] = None,", "ground_truth": "        template: Optional[TemplateManager] = None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"\"\"A model for a regex flags option.\"\"\"", "prediction_line": "    \"\"\"A model for a regex flags option.\"\"\"", "ground_truth": "    regex: ListOption[str] = ListOption()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            if spec.match_file(path):", "prediction_line": "                            if spec.match_file(path):", "ground_truth": "                            if spec.match_file(path):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    __root__: Union[ListOption[str], RegexOption] = ListOption()", "prediction_line": "    __root__: Union[ListOption[str], RegexOption] = ListOption()", "ground_truth": "    __root__: ListOption[str] = ListOption()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        selector.select_files(pack, *extensions, extend=extend)", "prediction_line": "        selector.select_files(pack, *extensions, extend=extend)", "ground_truth": "        selector.select_files(pack, *extensions, extend=extend)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if group not in group_map:", "prediction_line": "                    if group not in group_map:", "ground_truth": "                    if file_type := group_map.get(group):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if match:", "prediction_line": "        if match:", "ground_truth": "        if match:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if origin is not Union:", "prediction_line": "            if origin is not Union:", "ground_truth": "            extend = origin", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if self.match:", "prediction_line": "        if self.match:", "ground_truth": "        if isinstance(self.match, PathSpecOption):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                (filename, file_instance)", "prediction_line": "                (filename, file_instance)", "ground_truth": "                pack.list_files(*extensions, extend=extend)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for flag in self.__root__.flags:", "prediction_line": "            for flag in self.__root__.flags:", "ground_truth": "            patterns = self.__root__.regex.entries()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return PackSelector.from_options(", "prediction_line": "    return PackSelector.from_options(", "ground_truth": "    selector = PackSelector.from_options(files=files, match=match, template=template)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if group_map[singular] in file_types:", "prediction_line": "                    if group_map[singular] in file_types:", "ground_truth": "                    group_map.setdefault(f\"{singular}s\", group_map[singular])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        if self.match_spec.match_file(path):", "prediction_line": "                        if self.match_spec.match_file(path):", "ground_truth": "                        if self.match_spec.match_file(path):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"__version__\",", "prediction_line": "    \"__version__\",", "ground_truth": "    \"select_files\",", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                key: value.compile_spec(template)", "prediction_line": "                key: value.compile_spec(template)", "ground_truth": "                group_name: spec", "line_class": "random", "zero_context": true}
{"original_prediction": "            match_spec = {}", "prediction_line": "            match_spec = {}", "ground_truth": "            match_spec = {", "line_class": "random", "zero_context": true}
{"original_prediction": "                for file_type in file_types:", "prediction_line": "                for file_type in file_types:", "ground_truth": "                for file_type in file_types:", "line_class": "random", "zero_context": true}
{"original_prediction": ") -> PackSelection[File[Any, Any]]:", "prediction_line": ") -> PackSelection[File[Any, Any]]:", "ground_truth": "    files: Optional[Any] = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "        return PathSpec.from_lines(patterns)", "prediction_line": "        return PathSpec.from_lines(patterns)", "ground_truth": "        return PathSpec.from_lines(\"gitwildmatch\", patterns)", "line_class": "random", "zero_context": true}
{"original_prediction": "    params['baud_rate'] = trx_params['baud_rate']", "prediction_line": "    params['baud_rate'] = trx_params['baud_rate']", "ground_truth": "    params.update(trx_params)", "line_class": "common", "zero_context": true}
{"original_prediction": "        assert (req.initial_spectrum[0].delta_p[amp] == deltap).all()", "prediction_line": "        assert (req.initial_spectrum[0].delta_p[amp] == deltap).all()", "ground_truth": "        expected_amp = next(n for n in ref_network() if n.uid == amp)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"roll_off\": 0.15,", "prediction_line": "        \"roll_off\": 0.15,", "ground_truth": "        \"slot_width\": slot_width,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    f_max = f_max_from_si if f_max_from_si else 191.0e12 + 100.0e9", "prediction_line": "    f_max = f_max_from_si if f_max_from_si else 191.0e12 + 100.0e9", "ground_truth": "    params['nb_channel'] = automatic_nch(f_min, f_max_from_si, params['spacing'])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "mode, slot_width, deltap)", "prediction_line": "mode, slot_width, deltap)", "ground_truth": "                             mode, slot_width, deltap)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    pref = Pref(p_span0=0, p_spani=-20, ref_carrier=ref_carrier)", "prediction_line": "    pref = Pref(p_span0=0, p_spani=-20, ref_carrier=ref_carrier)", "ground_truth": "    pref = Pref(p_span0=0, p_spani=-20, ref_carrier=ref_carrier)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    req = PathRequest(**params)", "prediction_line": "    req = PathRequest(**params)", "ground_truth": "    params['power'] = dbm2watt(power_dbm) if power_dbm else dbm2watt(equipment['SI']['default'].power_dbm)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                               pref=pref, pch_out_dbm=0, psd_out_mWperGHz=0)", "prediction_line": "                                               pref=pref, pch_out_dbm=0, psd_out_mWperGHz=0)", "ground_truth": "                                               delta_pdb_per_channel=delta_pdb_per_channel,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if isinstance(el, Roadm):", "prediction_line": "        if isinstance(el, Roadm):", "ground_truth": "        if isinstance(el, Roadm):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    si = create_input_spectral_information(p_db=p_db, p_total_db=p_total_db,", "prediction_line": "    si = create_input_spectral_information(p_db=p_db, p_total_db=p_total_db,", "ground_truth": "    build_network(network, equipment, p_db, p_total_db)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_initial_spectrum_not_identical_2():", "prediction_line": "def test_initial_spectrum_not_identical_2():", "ground_truth": "    assert_raises(AssertionError, assert_array_equal, infos_expected.baud_rate, infos_actual.baud_rate)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    roadm_config = {", "prediction_line": "    roadm_config = {", "ground_truth": "    setattr(equipment['Roadm']['default'], 'target_psd_out_mWperGHz', power_dbm_to_psd_mw_ghz(-20, 32e9))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    nch = 1", "prediction_line": "    nch = 1", "ground_truth": "    baud_rate = array([32e9, 42e9, 64e9, 42e9, 32e9])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    infos_expected = propagate(path, req, equipment)", "prediction_line": "    infos_expected = propagate(path, req, equipment)", "ground_truth": "    _ = propagate(path, req, equipment)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"f_max\": 191.35e12 + 2 * slot_width,", "prediction_line": "        \"f_max\": 191.35e12 + 2 * slot_width,", "ground_truth": "        \"f_max\": 196.15e12 - slot_width,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                               signal=signal, baud_rate=baud_rate, roll_off=0.15,", "prediction_line": "                                               signal=signal, baud_rate=baud_rate, roll_off=0.15,", "ground_truth": "                                               signal=signal, baud_rate=baud_rate, roll_off=0.15,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert_array_equal(infos_expected.nli, infos_actual.nli)", "prediction_line": "    assert_array_equal(infos_expected.nli, infos_actual.nli)", "ground_truth": "    assert_array_equal(infos_expected.nli, infos_actual.nli)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"\"\" create a path request for voyager", "prediction_line": "    \"\"\" create a path request for voyager", "ground_truth": "    \"\"\" create the usual request list according to parameters", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    network = network_from_json(json_data, equipment)", "prediction_line": "    network = network_from_json(json_data, equipment)", "ground_truth": "    # json_data is changed (type is popped from json_data with network_from_json_function). Create a new one:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_initial_spectrum_not_identical_2(with_initial_spectrum):", "prediction_line": "def test_initial_spectrum_not_identical_2(with_initial_spectrum):", "ground_truth": "def test_target_psd_out_mwperghz(with_initial_spectrum):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"check that ROADM correctly equalizes on small examples, assumes p_span_0 = 0", "prediction_line": "    \"\"\"check that ROADM correctly equalizes on small examples, assumes p_span_0 = 0", "ground_truth": "    \"\"\"check that ROADM correctly equalizes on small examples, assumes p_span_0 = 0", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"\n    network = load_network(NETWORK_FILENAME, equipment)", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                              'mode 1', 50e9, 0)", "prediction_line": "                              'mode 1', 50e9, 0)", "ground_truth": "                              'mode 1', 50e9, 0)", "line_class": "random", "zero_context": true}
{"original_prediction": "        }]\n        req.initial_spectrum = _spectrum_from_json(temp)", "prediction_line": "        }]", "ground_truth": "        }]", "line_class": "random", "zero_context": true}
{"original_prediction": "    roadm = [n for n in network.nodes()][0]", "prediction_line": "    roadm = [n for n in network.nodes()][0]", "ground_truth": "    roadm = [n for n in network.nodes()][0]", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"city\": \"Brest_KLA\",", "prediction_line": "                \"city\": \"Brest_KLA\",", "ground_truth": "                \"city\": \"Brest_KLA\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        }\n    }", "prediction_line": "        }", "ground_truth": "        }", "line_class": "random", "zero_context": true}
{"original_prediction": "scala_types.update(scala_common_generic_types)", "prediction_line": "scala_types.update(scala_common_generic_types)", "ground_truth": "scala_types.update(scala_common_generic_types)", "line_class": "common", "zero_context": true}
{"original_prediction": "        actions.user.code_insert_function(result, None)", "prediction_line": "        actions.user.code_insert_function(result, None)", "ground_truth": "        actions.user.code_insert_function(result, None)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.insert(\"protected\")", "prediction_line": "        actions.insert(\"protected\")", "ground_truth": "        actions.user.code_private_function()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.auto_insert(\"//\")", "prediction_line": "        actions.auto_insert(\"//\")", "ground_truth": "        actions.auto_insert('// ')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.auto_insert(\" += \")", "prediction_line": "        actions.auto_insert(\" += \")", "ground_truth": "        actions.auto_insert(\" += \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "text)\n        actions.user.code_insert_function(result, None)", "prediction_line": "text)", "ground_truth": "            actions.user.formatted_text(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.auto_insert(\" != null\")", "prediction_line": "        actions.auto_insert(\" != null\")", "ground_truth": "        actions.auto_insert(\" != null\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.auto_insert('false')", "prediction_line": "        actions.auto_insert('false')", "ground_truth": "        actions.auto_insert('false')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.auto_insert(\" <<= \")", "prediction_line": "        actions.auto_insert(\" <<= \")", "ground_truth": "        actions.auto_insert(\" <<= \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.insert(' */')", "prediction_line": "        actions.insert(' */')", "ground_truth": "        actions.key('enter')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.key(\"left\")", "prediction_line": "        actions.key(\"left\")", "ground_truth": "        actions.key(\"enter\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.key(\"left\")", "prediction_line": "        actions.key(\"left\")", "ground_truth": "        actions.key(\"left\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.auto_insert(\" < \")", "prediction_line": "        actions.auto_insert(\" < \")", "ground_truth": "        actions.auto_insert(\" < \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.auto_insert(\" &= \")", "prediction_line": "        actions.auto_insert(\" &= \")", "ground_truth": "        actions.auto_insert(' &= ')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.auto_insert('continue')", "prediction_line": "        actions.auto_insert('continue')", "ground_truth": "        actions.auto_insert('continue')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.auto_insert(\"++\")", "prediction_line": "        actions.auto_insert(\"++\")", "ground_truth": "        actions.auto_insert('++')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            text = selection", "prediction_line": "            text = selection", "ground_truth": "            text = text + \"({})\".format(selection)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "# Scala Common Functions", "prediction_line": "# Scala Common Functions", "ground_truth": "mod.list(\"scala_common_types\", desc=\"Scala Common Types\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "ctx.matches = r\"\"\"", "prediction_line": "ctx.matches = r\"\"\"", "ground_truth": "mod = Module()", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# Scala Common Types", "prediction_line": "# Scala Common Types", "ground_truth": "# Scala Common Generic Types", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def code_break():", "prediction_line": "    def code_break():", "ground_truth": "    def code_break():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "@mod.action_class", "prediction_line": "@mod.action_class", "ground_truth": "ctx.tags = [\"user.code_operators\", \"user.code_generic\"]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        actions.insert(\"else if () \")", "prediction_line": "        actions.insert(\"else if () \")", "ground_truth": "        actions.insert(\"else if () \")", "line_class": "random", "zero_context": true}
{"original_prediction": "ctx.lists[\"self.scala_common_generic_types\"] = scala_common_generic_types", "prediction_line": "ctx.lists[\"self.scala_common_generic_types\"] = scala_common_generic_types", "ground_truth": "ctx.lists[\"self.scala_common_generic_types\"] = scala_common_generic_types", "line_class": "random", "zero_context": true}
{"original_prediction": "        actions.insert(\"private def \")", "prediction_line": "        actions.insert(\"private def \")", "ground_truth": "        actions.insert(\"private\")", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"List\": \"List\",", "prediction_line": "    \"List\": \"List\",", "ground_truth": "    \"seq\": \"Seq\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"Long\": \"Long\",", "prediction_line": "    \"Long\": \"Long\",", "ground_truth": "    \"Double\": \"Double\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        actions.edit.left()", "prediction_line": "        actions.edit.left()", "ground_truth": "        formatter = settings.get('user.code_private_function_formatter')", "line_class": "common", "zero_context": true}
{"original_prediction": "        formatter = settings.get('user.code_public_function_formatter')", "prediction_line": "        formatter = settings.get('user.code_public_function_formatter')", "ground_truth": "        formatter = settings.get('user.code_public_function_formatter')", "line_class": "common", "zero_context": true}
{"original_prediction": "        formatter = settings.get('user.code_protected_function_formatter')", "prediction_line": "        formatter = settings.get('user.code_protected_function_formatter')", "ground_truth": "        formatter = settings.get('user.code_protected_function_formatter')", "line_class": "common", "zero_context": true}
{"original_prediction": "        actions.user.code_insert_function(function_name, None)", "prediction_line": "        actions.user.code_insert_function(function_name, None)", "ground_truth": "        actions.user.code_insert_function(function_name, None)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if formatter == 'snake_case':", "prediction_line": "        if formatter == 'snake_case':", "ground_truth": "        function_name = actions.user.formatted_text(text, formatter)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "ctx.lists['user.code_type_primitive'] = {", "prediction_line": "ctx.lists['user.code_type_primitive'] = {", "ground_truth": "@ctx.action_class('user')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if selection:", "prediction_line": "        if selection:", "ground_truth": "        actions.edit.left()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.insert('fn ')", "prediction_line": "        actions.insert('fn ')", "ground_truth": "        actions.user.code_private_function(text)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.edit.left()", "prediction_line": "        actions.edit.left()", "ground_truth": "        actions.edit.left();", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def code_state_if():", "prediction_line": "    def code_state_if():", "ground_truth": "        actions.edit.up()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def code_state_if():", "prediction_line": "    def code_state_if():", "ground_truth": "        actions.key('tab')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if selection:", "prediction_line": "        if selection:", "ground_truth": "        actions.user.paste(f'{text}({selection or \"\"})')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def code_operator_bitwise_right_shift():", "prediction_line": "    def code_operator_bitwise_right_shift():", "ground_truth": "    def code_operator_bitwise_left_shift_assignment():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    'drop': 'drop',", "prediction_line": "    'drop': 'drop',", "ground_truth": "    'print line': 'println!',", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def code_operator_bitwise_and_assignment():", "prediction_line": "    def code_operator_bitwise_and_assignment():", "ground_truth": "    def code_operator_bitwise_or():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        actions.auto(' / ')", "prediction_line": "        actions.auto(' / ')", "ground_truth": "        actions.auto(' / ')", "line_class": "random", "zero_context": true}
{"original_prediction": "        actions.auto(' + ')", "prediction_line": "        actions.auto(' + ')", "ground_truth": "        actions.auto(' + ')", "line_class": "random", "zero_context": true}
{"original_prediction": "        actions.auto(f': {type}')", "prediction_line": "        actions.auto(f': {type}')", "ground_truth": "        actions.insert(f': {type}')", "line_class": "random", "zero_context": true}
{"original_prediction": "        actions.insert(f' -> {type}')", "prediction_line": "        actions.insert(f' -> {type}')", "ground_truth": "        actions.insert(f' -> {type}')", "line_class": "random", "zero_context": true}
{"original_prediction": "        actions.insert('use ')", "prediction_line": "        actions.insert('use ')", "ground_truth": "        actions.auto('use ')", "line_class": "random", "zero_context": true}
{"original_prediction": "    if setting_meta.get() == \"esc\":", "prediction_line": "    if setting_meta.get() == \"esc\":", "ground_truth": "    m = setting_meta.get()", "line_class": "common", "zero_context": true}
{"original_prediction": "        actions.user.emacs_meta(\"shift-e\")", "prediction_line": "        actions.user.emacs_meta(\"shift-e\")", "ground_truth": "        actions.user.emacs_meta(\"shift-e\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.key(meta(str(n)))", "prediction_line": "        actions.key(meta(str(n)))", "ground_truth": "        actions.user.emacs_meta(\" \".join(str(n)))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.user.emacs(\"set-mark-command\")", "prediction_line": "        actions.user.emacs(\"set-mark-command\")", "ground_truth": "        actions.edit.jump_line(line_start)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.user.emacs(\"set-mark-command\")", "prediction_line": "        actions.user.emacs(\"set-mark-command\")", "ground_truth": "        actions.edit.jump_line(line_end + 1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return meta(k[5:])", "prediction_line": "        return meta(k[5:])", "ground_truth": "        k = meta(k[len(\"meta-\") :])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            actions.user.emacs(\"goto-line\", n)", "prediction_line": "            actions.user.emacs(\"goto-line\", n)", "ground_truth": "            actions.edit.jump_line(n)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            actions.user.emacs(\"mark-whole-buffer\")", "prediction_line": "            actions.user.emacs(\"mark-whole-buffer\")", "ground_truth": "            actions.edit.line_start()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.user.emacs(\"set-mark-command\")", "prediction_line": "        actions.user.emacs(\"set-mark-command\")", "ground_truth": "        actions.edit.extend_line_end()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # TODO: use something like 'emacs-lisp-mode' instead of 'elisp'", "prediction_line": "        # TODO: use something like 'emacs-lisp-mode' instead of 'elisp'", "ground_truth": "        if \"*scratch*\" == actions.win.filename():", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.user.emacs(\"backward-word\")", "prediction_line": "        actions.user.emacs(\"backward-word\")", "ground_truth": "        actions.user.emacs_meta(\"shift-b\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "            before = actions.edit.selected_text()", "prediction_line": "            before = actions.edit.selected_text()", "ground_truth": "            actions.edit.extend_word_left()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.user.emacs_meta(\"shift-f\")", "prediction_line": "        actions.user.emacs_meta(\"shift-f\")", "ground_truth": "        actions.user.emacs_meta(\"shift-f\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.user.emacs_meta(\"shift-b\")", "prediction_line": "        actions.user.emacs_meta(\"shift-b\")", "ground_truth": "        actions.user.emacs_meta(\"shift-a\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.key(meta(\"x\"))", "prediction_line": "        actions.key(meta(\"x\"))", "ground_truth": "        actions.user.emacs_meta(\"x\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.key(\"ctrl-a ctrl-space ctrl-n\")", "prediction_line": "        actions.key(\"ctrl-a ctrl-space ctrl-n\")", "ground_truth": "        actions.user.emacs_key(\"ctrl-a meta-1 ctrl-k ctrl-y ctrl-y up meta-m\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def split_toggle():", "prediction_line": "    def split_toggle():", "ground_truth": "        actions.user.split_last()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return \" \".join(\"cmd-\" + k for k in keys.split())", "prediction_line": "        return \" \".join(\"cmd-\" + k for k in keys.split())", "ground_truth": "        return \" \".join(\"cmd-\" + k for k in keys.split())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def split_toggle():", "prediction_line": "    def split_toggle():", "ground_truth": "        actions.key(\"ctrl-x b enter ctrl-x o\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.user.emacs_meta(\"h\")", "prediction_line": "        actions.user.emacs_meta(\"h\")", "ground_truth": "        actions.key(\"f1\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return actions.key(\"alt:\" + keys)", "prediction_line": "        return actions.key(\"alt:\" + keys)", "ground_truth": "        return \" \".join(\"alt-\" + k for k in keys.split())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            after = actions.edit.selected_text()", "prediction_line": "            after = actions.edit.selected_text()", "ground_truth": "            after = actions.edit.selected_text()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   def dictation_insert(text):", "prediction_line": "   def dictation_insert(text):", "ground_truth": "@ctx.action_class(\"edit\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if left:", "prediction_line": "        if left:", "ground_truth": "        if left:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@mod.action_class", "prediction_line": "@mod.action_class", "ground_truth": "@mod.action_class", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   def find_everywhere(text: str = None):", "prediction_line": "   def find_everywhere(text: str = None):", "ground_truth": "@ctx.action_class(\"app\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            before = actions.edit.selected_text()", "prediction_line": "            before = actions.edit.selected_text()", "ground_truth": "            before = actions.edit.selected_text()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@mod.action_class", "prediction_line": "@mod.action_class", "ground_truth": "ctx = Context()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.key(\"ctrl-s\")", "prediction_line": "        actions.key(\"ctrl-s\")", "ground_truth": "        actions.key(\"ctrl-s\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.key(\"up ctrl-x ctrl-t down\")", "prediction_line": "        actions.key(\"up ctrl-x ctrl-t down\")", "ground_truth": "        actions.key(\"ctrl-x ctrl-t up:2\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.user.emacs(\"other-window\")", "prediction_line": "        actions.user.emacs(\"other-window\")", "ground_truth": "        actions.key(\"ctrl-x b enter ctrl-x o ctrl-x b enter\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if right:", "prediction_line": "        if right:", "ground_truth": "        if right:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def tab_close():", "prediction_line": "    def tab_close():", "ground_truth": "    def tab_close():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # can't use actions.user.emacs.", "prediction_line": "    # can't use actions.user.emacs.", "ground_truth": "    # deliberately don't use actions.user.emacs.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def paragraph_end():", "prediction_line": "    def paragraph_end():", "ground_truth": "    def paragraph_end():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class WinActions:", "prediction_line": "class WinActions:", "ground_truth": "class WinActions:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            return \"text\"", "prediction_line": "            return \"text\"", "ground_truth": "            return \"elisp\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        k = k.replace(\"meta-\", meta(\"\"))", "prediction_line": "        k = k.replace(\"meta-\", meta(\"\"))", "ground_truth": "        raise NotImplementedError(\"user.emacs_key(): please put meta- first\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        actions.user.emacs(\"save-buffer\")", "prediction_line": "        actions.user.emacs(\"save-buffer\")", "ground_truth": "        actions.user.emacs(\"save-buffer\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        actions.user.emacs(\"yank\")", "prediction_line": "        actions.user.emacs(\"yank\")", "ground_truth": "        actions.user.emacs(\"yank\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        actions.user.emacs(\"delete-other-windows\")", "prediction_line": "        actions.user.emacs(\"delete-other-windows\")", "ground_truth": "        actions.user.emacs(\"delete-other-windows\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        if settings.get(\"user.lua_version\") > 5.2:", "prediction_line": "        if settings.get(\"user.lua_version\") > 5.2:", "ground_truth": "        if settings.get(\"user.lua_version\") > 5.2:", "line_class": "common", "zero_context": true}
{"original_prediction": "        actions.user.code_insert_function(result, None)", "prediction_line": "        actions.user.code_insert_function(result, None)", "ground_truth": "        actions.user.code_insert_function(result, None)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return m.lua_functions", "prediction_line": "    return m.lua_functions", "ground_truth": "    return m.lua_functions", "line_class": "infile", "zero_context": true}
{"original_prediction": "        actions.user.insert_between(\"while \", \" do\")", "prediction_line": "        actions.user.insert_between(\"while \", \" do\")", "ground_truth": "        actions.user.insert_between(\"while \", \" do\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                text, settings.get(\"user.code_public_function_formatter\")", "prediction_line": "                text, settings.get(\"user.code_public_function_formatter\")", "ground_truth": "                text, settings.get(\"user.code_public_function_formatter\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.insert(\"-- \")", "prediction_line": "        actions.insert(\"-- \")", "ground_truth": "        actions.insert(\"-- \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                text, settings.get(\"user.code_private_function_formatter\")", "prediction_line": "                text, settings.get(\"user.code_private_function_formatter\")", "ground_truth": "                text, settings.get(\"user.code_private_function_formatter\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            actions.insert(\" bit.rshift() \")", "prediction_line": "            actions.insert(\" bit.rshift() \")", "ground_truth": "            actions.insert(\" bit.rshift() \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            actions.user.formatted_text(", "prediction_line": "            actions.user.formatted_text(", "ground_truth": "            actions.user.formatted_text(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            actions.insert(\" ~ \")", "prediction_line": "            actions.insert(\" ~ \")", "ground_truth": "            actions.insert(\" ~ \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ##\n    # code_comment_block", "prediction_line": "    ##", "ground_truth": "        actions.edit.up()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.insert(\" <= \")", "prediction_line": "        actions.insert(\" <= \")", "ground_truth": "        actions.insert(\" <= \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            text = text + \"()\"", "prediction_line": "            text = text + \"()\"", "ground_truth": "            text = text + \"()\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            actions.insert(\" bit.bxor() \")", "prediction_line": "            actions.insert(\" bit.bxor() \")", "ground_truth": "            actions.insert(\" bit.xor() \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.insert(\" + \")", "prediction_line": "        actions.insert(\" + \")", "ground_truth": "        actions.insert(\" + \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.insert(\" >= \")", "prediction_line": "        actions.insert(\" >= \")", "ground_truth": "        actions.insert(\" >= \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.insert(\"return \")", "prediction_line": "        actions.insert(\"return \")", "ground_truth": "        actions.insert(\"return \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        actions.insert(\"break\")", "prediction_line": "        actions.insert(\"break\")", "ground_truth": "        actions.insert(\"break \")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def code_state_switch():", "prediction_line": "    def code_state_switch():", "ground_truth": "    def code_try_catch():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    ##\n    def code_gui_import():", "prediction_line": "    ##", "ground_truth": "    ##", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def code_comment_line():", "prediction_line": "    def code_comment_line():", "ground_truth": "    def code_comment_line_prefix():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ")\n\n\n@mod.action_class", "prediction_line": ")", "ground_truth": ")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"table concat\": \"table.concat\",", "prediction_line": "    \"table concat\": \"table.concat\",", "ground_truth": "    \"table unpack\": \"table.unpack\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"table remove\": \"table.remove\",", "prediction_line": "    \"table remove\": \"table.remove\",", "ground_truth": "    \"tabel sort\": \"table.sort\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        else:\n            actions.insert(\" bit.band \")", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"http request\": \"http.request\",", "prediction_line": "    \"http request\": \"http.request\",", "ground_truth": "    \"H T T P get\": \"http.get\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.instances: List[Instance] = []", "prediction_line": "        self.instances: List[Instance] = []", "ground_truth": "        self.instructions = get_raft_instructions(subset)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.load_prompt_construction_settings()", "prediction_line": "        self.load_prompt_construction_settings()", "ground_truth": "        self.load_prompt_construction_settings()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            field_ordering, instructions = map(json.loads, f.read().split(\"\\n\"))", "prediction_line": "            field_ordering, instructions = map(json.loads, f.read().split(\"\\n\"))", "ground_truth": "            FIELD_ORDERING, _ = map(json.loads, f.read().split(\"\\n\"))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ensure_file_downloaded(", "prediction_line": "        ensure_file_downloaded(", "ground_truth": "        ensure_file_downloaded(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            instructions = json.load(f)", "prediction_line": "            instructions = json.load(f)", "ground_truth": "            field_ordering, instructions = map(json.loads, f.read().split(\"\\n\"))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return instructions[subset]", "prediction_line": "    return instructions[subset]", "ground_truth": "    assert subset in instructions, \"Unknown subset: {}\".format(subset)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    url = \"https://huggingface.co/datasets/ought/raft\"", "prediction_line": "    url = \"https://huggingface.co/datasets/ought/raft\"", "ground_truth": "    tags = [\"text_classification\", \"robustness\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    reference=Reference(", "prediction_line": "                    reference=Reference(", "ground_truth": "                    references=[Reference(output=class_label_to_string(x[\"Label\"]), tags=[CORRECT_TAG])],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for split_tag, dataset in dataset_splits.items():", "prediction_line": "        for split_tag, dataset in dataset_splits.items():", "ground_truth": "        for tag, subset in dataset_splits.items():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                label = class_label_to_string(x[\"Label\"])", "prediction_line": "                label = class_label_to_string(x[\"Label\"])", "ground_truth": "                instance = Instance(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    tags=[tag],", "prediction_line": "                    tags=[tag],", "ground_truth": "                    tags=[tag],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "31. direct_debit_payment_wrong_exchange_rate", "prediction_line": "31. direct_debit_payment_wrong_exchange_rate", "ground_truth": "31. disposable_card_limits", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "36. expired_card", "prediction_line": "36. expired_card", "ground_truth": "36. extra_charge_on_statement", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "1. elementary\n2. intermediate", "prediction_line": "1. elementary", "ground_truth": "1. advanced", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "3. intermediate\"\"\",", "prediction_line": "3. intermediate\"\"\",", "ground_truth": "3. intermediate\"\"\",", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "4. bank_account_not_showing_up", "prediction_line": "4. bank_account_not_showing_up", "ground_truth": "4. apple_pay_or_google_pay", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            target_path=prompt_construction_settings_path,", "prediction_line": "            target_path=prompt_construction_settings_path,", "ground_truth": "            target_path=prompt_construction_settings_path,", "line_class": "random", "zero_context": true}
{"original_prediction": "            for instance in subset:", "prediction_line": "            for instance in subset:", "ground_truth": "            for x in subset:", "line_class": "random", "zero_context": true}
{"original_prediction": "        # Load dataset", "prediction_line": "        # Load dataset", "ground_truth": "        cache_dir = str(Path(self.output_path) / \"data\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        }\n\n        # Create instances", "prediction_line": "        }", "ground_truth": "        }", "line_class": "random", "zero_context": true}
{"original_prediction": "            return\n\n        # Load prompt construction settings", "prediction_line": "            return", "ground_truth": "            return", "line_class": "random", "zero_context": true}
{"original_prediction": "                    gold_rank = ranked_pids.index(gold_pid) + 1", "prediction_line": "                    gold_rank = ranked_pids.index(gold_pid) + 1", "ground_truth": "                    rank_gold = ranked_pids.index(gold_pid) + 1", "line_class": "common", "zero_context": true}
{"original_prediction": "            qid_to_gold_pid, qid_pid_logprob_dict = self.get_qid_dictionaries(validation_request_states)", "prediction_line": "            qid_to_gold_pid, qid_pid_logprob_dict = self.get_qid_dictionaries(validation_request_states)", "ground_truth": "            qid_to_gold_pid, qid_pid_logprob_dict = self.get_qid_dictionaries(validation_request_states)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                ranked_pids = self.get_ranked_pid_list(qid_pid_logprob_dict, qid)", "prediction_line": "                ranked_pids = self.get_ranked_pid_list(qid_pid_logprob_dict, qid)", "ground_truth": "                ranked_pids = self.get_ranked_pid_list(qid_pid_logprob_dict, qid)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            \"mean_reciprocal_rank\": self.reciprocal_rank,", "prediction_line": "            \"mean_reciprocal_rank\": self.reciprocal_rank,", "ground_truth": "            \"mean_reciprocal_rank\": self.reciprocal_rank", "line_class": "infile", "zero_context": true}
{"original_prediction": "            qid, pid, gold = self.flatten_id(instance_id)", "prediction_line": "            qid, pid, gold = self.flatten_id(instance_id)", "ground_truth": "            qid, pid, is_gold = self.flatten_id(instance_id)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                answer = self.get_answer(is_yes)", "prediction_line": "                answer = self.get_answer(is_yes)", "ground_truth": "                answer = self.get_answer(is_yes)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    stat.add(rr)", "prediction_line": "                    stat.add(rr)", "ground_truth": "                    stat.add(rr)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Get the qid_to_gold_pid and qid_pid_logprob_dict dictionaries", "prediction_line": "        # Get the qid_to_gold_pid and qid_pid_logprob_dict dictionaries", "ground_truth": "        topk_to_stat = {k: Stat(name=f\"RR@{k}\") for k in self.topk_list}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            topk_list: The list of top-k values to be used.", "prediction_line": "            topk_list: The list of top-k values to be used.", "ground_truth": "            topk_list: The number of top rankings we should consider when computing", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "istic\nfrom common.utils import get_logger", "prediction_line": "istic", "ground_truth": "from .adapter import ScenarioState, RequestState", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Args:", "prediction_line": "        Args:", "ground_truth": "            * We add the value we found to a Stat with name \"RR@k\", depending on", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                where qid is the query id, pid is the passage id, and logprob is the", "prediction_line": "                where qid is the query id, pid is the passage id, and logprob is the", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        qid = int(qid_str.split('_')[1])", "prediction_line": "        qid = int(qid_str.split('_')[1])", "ground_truth": "        qid = int(qid_str.split('_')[1])", "line_class": "random", "zero_context": true}
{"original_prediction": "    ANSWER_TEXT_NONE = \"NONE\"", "prediction_line": "    ANSWER_TEXT_NONE = \"NONE\"", "ground_truth": "    YES_ANSWER = \"yes\"", "line_class": "random", "zero_context": true}
{"original_prediction": "            topk_list = [10, 20, 50, 100]", "prediction_line": "            topk_list = [10, 20, 50, 100]", "ground_truth": "            topk_list = [10]", "line_class": "random", "zero_context": true}
{"original_prediction": "Dict[int, int], Dict[int, int]]:", "prediction_line": "Dict[int, int], Dict[int, int]]:", "ground_truth": "                                                                            Dict[int, int],", "line_class": "random", "zero_context": true}
{"original_prediction": "            raise ValueError(", "prediction_line": "            raise ValueError(", "ground_truth": "            raise ValueError(", "line_class": "random", "zero_context": true}
{"original_prediction": "                depth_counter[self.opening_parentheses.index(sequence[i])] += 1", "prediction_line": "                depth_counter[self.opening_parentheses.index(sequence[i])] += 1", "ground_truth": "                index = self.opening_parentheses.index(sequence[i])", "line_class": "common", "zero_context": true}
{"original_prediction": "                depth_counter[index] += 1", "prediction_line": "                depth_counter[index] += 1", "ground_truth": "                depth_counter[index] -= 1", "line_class": "common", "zero_context": true}
{"original_prediction": "                index = self.closing_parentheses.index(sequence[i])", "prediction_line": "                index = self.closing_parentheses.index(sequence[i])", "ground_truth": "                index = self.closing_parentheses.index(sequence[i])", "line_class": "common", "zero_context": true}
{"original_prediction": "                depth_counter[index] += 1", "prediction_line": "                depth_counter[index] += 1", "ground_truth": "                depth_counter[index] += 1", "line_class": "common", "zero_context": true}
{"original_prediction": "            # Pick a random index for the opening parenthesis", "prediction_line": "            # Pick a random index for the opening parenthesis", "ground_truth": "            index = np.random.randint(self.num_parenthesis_pairs)", "line_class": "common", "zero_context": true}
{"original_prediction": "            return [self.opening_parentheses[index]] + infix + [self.closing_parentheses[index]]", "prediction_line": "            return [self.opening_parentheses[index]] + infix + [self.closing_parentheses[index]]", "ground_truth": "            sequence = [self.opening_parentheses[index]] + infix + [self.closing_parentheses[index]]", "line_class": "common", "zero_context": true}
{"original_prediction": "                stack.append(elt)", "prediction_line": "                stack.append(elt)", "ground_truth": "                stack.append(self.closing_parentheses[self.opening_parentheses.index(elt)])", "line_class": "common", "zero_context": true}
{"original_prediction": "        \"\"\" Creates the instances for the task. \"\"\"", "prediction_line": "        \"\"\" Creates the instances for the task. \"\"\"", "ground_truth": "        train_inputs, train_instances = self.create_corpus(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            sequence = self.generate_dyck_sequence(max_length=max_length)", "prediction_line": "            sequence = self.generate_dyck_sequence(max_length=max_length)", "ground_truth": "            sequence = self.generate_dyck_sequence(current_recursive_depth=0, max_length=max_length)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        test_inputs, test_instances = self.create_corpus(", "prediction_line": "        test_inputs, test_instances = self.create_corpus(", "ground_truth": "        test_inputs, test_instances = self.create_corpus(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                input_seq = self.get_input(sequence, depth_n)", "prediction_line": "                input_seq = self.get_input(sequence, depth_n)", "ground_truth": "                input = self.get_input(sequence, depth_n)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    output = self.get_output(input)", "prediction_line": "                    output = self.get_output(input)", "ground_truth": "                    output = self.get_output(input)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return [self.opening_parentheses[index]] + self.generate_dyck_sequence(", "prediction_line": "            return [self.opening_parentheses[index]] + self.generate_dyck_sequence(", "ground_truth": "            infix = self.generate_dyck_sequence(current_recursive_depth + 1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            input, output = self.create_input_output(min_length, max_length)", "prediction_line": "            input, output = self.create_input_output(min_length, max_length)", "ground_truth": "            input, output = self.create_input_output(min_length, max_length)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            infix = self.generate_dyck_sequence(current_recursive_depth + 1)", "prediction_line": "            infix = self.generate_dyck_sequence(current_recursive_depth + 1)", "ground_truth": "            left_exp = self.generate_dyck_sequence(current_recursive_depth)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            right_exp = self.generate_dyck_sequence(current_recursive_depth)", "prediction_line": "            right_exp = self.generate_dyck_sequence(current_recursive_depth)", "ground_truth": "            right_exp = self.generate_dyck_sequence(current_recursive_depth)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                instances.append(Instance(input, output, split))", "prediction_line": "                instances.append(Instance(input, output, split))", "ground_truth": "                instance = Instance(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    input=input,", "prediction_line": "                    input=input,", "ground_truth": "                    input=input, references=[Reference(output=output, tags=[CORRECT_TAG])], split=split,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def __init__(", "prediction_line": "    def __init__(", "ground_truth": "    description = \"Generate the closing parentheses of a Dyck-n prefix\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ) -> List[Instance]:", "prediction_line": "    ) -> List[Instance]:", "ground_truth": "    ) -> Tuple[List[str], List[Instance]]:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    Scenario for Dyck language.", "prediction_line": "    Scenario for Dyck language.", "ground_truth": "        \"Memory-Augmented Recurrent Neural Networks Can Learn Generalized Dyck Languages\" (Suzgun et al., 2019)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            train_size: Number of training instances.", "prediction_line": "            train_size: Number of training instances.", "ground_truth": "            max_recursive_depth: Maximum recursive depth that can be reached while genereating a sequence.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        if min_seq_train_length < 0 or min_seq_train_length > max_seq_train_length:", "prediction_line": "        if min_seq_train_length < 0 or min_seq_train_length > max_seq_train_length:", "ground_truth": "        # Fixing the random seeds", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       \"\"\"\n        if current_recursive_depth > self.max_recursive_depth:", "prediction_line": "       \"\"\"", "ground_truth": "        Returns:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            sequence = []", "prediction_line": "            sequence = []", "ground_truth": "            sequence = []", "line_class": "random", "zero_context": true}
{"original_prediction": "        max_seq_test_length: int = 100,", "prediction_line": "        max_seq_test_length: int = 100,", "ground_truth": "        max_seq_test_length: int = 100,", "line_class": "random", "zero_context": true}
{"original_prediction": "            sequence = left_exp + right_exp", "prediction_line": "            sequence = left_exp + right_exp", "ground_truth": "            sequence = left_exp + right_exp", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.max_seq_train_length = max_seq_train_length", "prediction_line": "        self.max_seq_train_length = max_seq_train_length", "ground_truth": "        self.max_seq_train_length = max_seq_train_length", "line_class": "random", "zero_context": true}
{"original_prediction": "        return inputs, instances", "prediction_line": "        return inputs, instances", "ground_truth": "        return inputs, instances", "line_class": "random", "zero_context": true}
{"original_prediction": "            short_ans = ans_json[\"short_answers\"]", "prediction_line": "            short_ans = ans_json[\"short_answers\"]", "ground_truth": "            long_ans = self._clean_text(html_bytes[long_ans[\"start_byte\"] : long_ans[\"end_byte\"]])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            prompt, answers = self.create_prompt(sample, split)", "prediction_line": "            prompt, answers = self.create_prompt(sample, split)", "ground_truth": "            prompt, answers = self.create_prompt(sample, split)", "line_class": "infile", "zero_context": true}
{"original_prediction": "           instances.extend(self.get_file_instances(target_file=target_path, splits=splits))", "prediction_line": "           instances.extend(self.get_file_instances(target_file=target_path, splits=splits))", "ground_truth": "            instances.extend(self.get_file_instances(target_path, splits=splits))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                short_ans = self._clean_text(short_ans)", "prediction_line": "                short_ans = self._clean_text(short_ans)", "ground_truth": "                short_ans = self._clean_text(short_ans)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        ensure_directory_exists(data_path)", "prediction_line": "        ensure_directory_exists(data_path)", "ground_truth": "        ensure_directory_exists(data_path)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       file_list = [os.path.join(base_url, f) for f in file_list]", "prediction_line": "       file_list = [os.path.join(base_url, f) for f in file_list]", "ground_truth": "        instances: List[Instance] = []", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            ensure_file_downloaded(source_url, target_path)", "prediction_line": "            ensure_file_downloaded(source_url, target_path)", "ground_truth": "            ensure_file_downloaded(source_url=source_url, target_path=target_path)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    supported_modes = [\"closed\", \"open_longans\", \"wiki\"]", "prediction_line": "    supported_modes = [\"closed\", \"open_longans\", \"wiki\"]", "ground_truth": "    tags = [\"question_answering\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # Create the instance", "prediction_line": "            # Create the instance", "ground_truth": "            instance = Instance(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                reference=Reference(answers=answers, correct_answer=CORRECT_TAG),", "prediction_line": "                reference=Reference(answers=answers, correct_answer=CORRECT_TAG),", "ground_truth": "                references=[Reference(output=ans, tags=[CORRECT_TAG]) for ans in answers],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    drilling wells, and extracting oil and gas from the ground'", "prediction_line": "    drilling wells, and extracting oil and gas from the ground'", "ground_truth": "    drilling exploratory wells, and subsequently drilling and operating the wells that recover and", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ".\n        Returns:", "prediction_line": ".", "ground_truth": "        Returns:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "navigation, search Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry", "prediction_line": "navigation, search Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry )  Upstream ( petroleum industry", "ground_truth": "    navigation, search For other uses, see Upstream (disambiguation).  The oil and gas industry", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "    Example (mode:wiki)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   Target completion:\n        '5.7 million'", "prediction_line": "   Target completion:", "ground_truth": "    Question: who is the largest supermarket chain in the uk", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       prompt += short_answers[ans_idx]", "prediction_line": "       prompt += short_answers[ans_idx]", "ground_truth": "        if split == \"train\":", "line_class": "random", "zero_context": true}
{"original_prediction": "                scenario=self.name,", "prediction_line": "                scenario=self.name,", "ground_truth": "                input=prompt,", "line_class": "random", "zero_context": true}
{"original_prediction": "            else:\n                context = long_answers[ans_idx]", "prediction_line": "            else:", "ground_truth": "                prompt += f\"Title: {sample['document_title']}\\n\\n\"", "line_class": "random", "zero_context": true}
{"original_prediction": "               prompt += f\"Title: {sample['document_title']}\\n\\n\"", "prediction_line": "               prompt += f\"Title: {sample['document_title']}\\n\\n\"", "ground_truth": "            prompt += f\"Context: {context}\\n\\n\"", "line_class": "random", "zero_context": true}
{"original_prediction": "                context = long_answers[ans_idx]", "prediction_line": "                context = long_answers[ans_idx]", "ground_truth": "                context = long_answers[ans_idx]", "line_class": "random", "zero_context": true}
{"original_prediction": "        perturbed_text = self.substitute_names(instance.text)", "prediction_line": "        perturbed_text = self.substitute_names(instance.text)", "ground_truth": "        return super().apply(instance, should_perturb_references)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return PersonNamePerturbation.Description(", "prediction_line": "        return PersonNamePerturbation.Description(", "ground_truth": "        return PersonNamePerturbation.Description(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        # If we want to preserve gender, we only substitute the name if the gender is the same", "prediction_line": "                        # If we want to preserve gender, we only substitute the name if the gender is the same", "ground_truth": "                        name_gender = self.get_name_gender(lowered_word)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        perturbed_text = self.substitute_names(text)", "prediction_line": "        perturbed_text = self.substitute_names(text)", "ground_truth": "        return self.substitute_names(text)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.name_file_path = self.download_name_file()", "prediction_line": "            self.name_file_path = self.download_name_file()", "ground_truth": "            self.name_file_path = self.download_name_file()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.source_names: Set[str] = self.get_names(self.source_class)", "prediction_line": "        self.source_names: Set[str] = self.get_names(self.source_class)", "ground_truth": "        self.mapping_dict: Dict[str, Dict[str, Set[str]]] = self.load_name_file(self.name_file_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.source_names: Set[str] = self.get_source_names()", "prediction_line": "        self.source_names: Set[str] = self.get_source_names()", "ground_truth": "        self.source_names: Set[str] = self.get_possible_names(source_class)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.target_names: Set[str] = self.get_possible_names(target_class)", "prediction_line": "        self.target_names: Set[str] = self.get_possible_names(target_class)", "ground_truth": "        self.target_names: Set[str] = self.get_possible_names(target_class)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                word, subs_dict, nonsubs = self.process_word(word, subs_dict, nonsubs)", "prediction_line": "                word, subs_dict, nonsubs = self.process_word(word, subs_dict, nonsubs)", "ground_truth": "                word, subs_dict, nonsubs = self.process_word(word, subs_dict, nonsubs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"\"\" Path to the person_names.txt file \"\"\"", "prediction_line": "    \"\"\" Path to the person_names.txt file \"\"\"", "ground_truth": "    SOURCE_URI: str = CODALAB_URI_TEMPLATE.format(bundle=CODALAB_BUNDLE)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for line in f:", "prediction_line": "            for line in f:", "ground_truth": "            for line in f.readlines():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        mapping_dict[category_type][category].add(name)", "prediction_line": "                        mapping_dict[category_type][category].add(name)", "ground_truth": "                        mapping_dict[category_type][category].add(name.strip().lower())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if word in self.source_names:", "prediction_line": "        if word in self.source_names:", "ground_truth": "        lowered_word = word.lower()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        else:", "prediction_line": "                        else:", "ground_truth": "                    word = match_case(word, self.random.choice(list(options)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    nonsubs.add(lowered_word)", "prediction_line": "                    nonsubs.add(lowered_word)", "ground_truth": "                    nonsubs.add(lowered_word)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            words = self.tokenizer.tokenize(line)", "prediction_line": "            words = self.tokenizer.tokenize(line)", "ground_truth": "            words, new_words = self.tokenizer.tokenize(line), []", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ensure_directory_exists(data_path)", "prediction_line": "        ensure_directory_exists(data_path)", "ground_truth": "        ensure_directory_exists(data_path)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ensure_file_downloaded(self.SOURCE_URI, file_path)", "prediction_line": "        ensure_file_downloaded(self.SOURCE_URI, file_path)", "ground_truth": "        ensure_file_downloaded(source_url=self.SOURCE_URI, target_path=file_path)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return word, subs_dict, nonsubs", "prediction_line": "            return word, subs_dict, nonsubs", "ground_truth": "            word = match_case(word, subs_dict[lowered_word])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def description(self) -> PerturbationDescription:", "prediction_line": "    def description(self) -> PerturbationDescription:", "ground_truth": "    def description(self) -> PerturbationDescription:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\" Tokenizer \"\"\"", "prediction_line": "    \"\"\" Tokenizer \"\"\"", "ground_truth": "    \"\"\" Information needed to download person_names.txt \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"\n    The probability of perturbing a person name.", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\" Line seperator \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    # If we randomly decide to substitute the word, we pick a random target word", "prediction_line": "                    # If we randomly decide to substitute the word, we pick a random target word", "ground_truth": "                    # Substitute the name", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "values\n                of the category.", "prediction_line": "values", "ground_truth": "                corresponding values. If more than one category is provided,", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    FIRST_NAME = \"first_name\"", "prediction_line": "    FIRST_NAME = \"first_name\"", "ground_truth": "    FIRST_NAME = \"first_name\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        gender: str", "prediction_line": "        gender: str", "ground_truth": "        preserve_gender: bool", "line_class": "random", "zero_context": true}
{"original_prediction": "        description: Description,", "prediction_line": "        description: Description,", "ground_truth": "        prob: float,", "line_class": "random", "zero_context": true}
{"original_prediction": "= \"person_name\"", "prediction_line": "= \"person_name\"", "ground_truth": "        prob: float", "line_class": "random", "zero_context": true}
{"original_prediction": "    NAME_TYPES = [FIRST_NAME, LAST_NAME]", "prediction_line": "    NAME_TYPES = [FIRST_NAME, LAST_NAME]", "ground_truth": "    ANY = \"any\"", "line_class": "random", "zero_context": true}
{"original_prediction": "   lb2 >> Edge(forward=True, reverse=True) >> d3", "prediction_line": "   lb2 >> Edge(forward=True, reverse=True) >> d3", "ground_truth": "    lb2 >> Edge(forward=True, reverse=True) >> d3", "line_class": "common", "zero_context": true}
{"original_prediction": "    lb2 >> Edge(forward=True, reverse=True) >> d4", "prediction_line": "    lb2 >> Edge(forward=True, reverse=True) >> d4", "ground_truth": "    lb2 >> Edge(forward=True, reverse=True) >> d4", "line_class": "common", "zero_context": true}
{"original_prediction": "    Edge(d1, d2, label=\"10.0.0.0/24\")", "prediction_line": "    Edge(d1, d2, label=\"10.0.0.0/24\")", "ground_truth": "    lb1 >> Edge(forward=True, reverse=True) >> d1", "line_class": "common", "zero_context": true}
{"original_prediction": "    lb1 >> Edge(forward=True, reverse=True) >> d2", "prediction_line": "    lb1 >> Edge(forward=True, reverse=True) >> d2", "ground_truth": "    lb1 >> Edge(forward=True, reverse=True) >> d2", "line_class": "common", "zero_context": true}
{"original_prediction": "        with Region(\"Region 1\"):", "prediction_line": "        with Region(\"Region 1\"):", "ground_truth": "        with ServerContents(\"chassis 1: Bastion host\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            Crio(\"Keepalived\")", "prediction_line": "            Crio(\"Keepalived\")", "ground_truth": "        with AvailabilityZone(\"chassis 2\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            Server(\"nyctea\")", "prediction_line": "            Server(\"nyctea\")", "ground_truth": "        with AvailabilityZone(\"chassis 3\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            Server(\"strix\")", "prediction_line": "            Server(\"strix\")", "ground_truth": "            with VirtualPrivateCloud(\"\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                with PublicSubnet(\"\"):", "prediction_line": "                with PublicSubnet(\"\"):", "ground_truth": "                with PrivateSubnet(\"Private\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    with SecurityGroup(\"web sg\"):", "prediction_line": "                    with SecurityGroup(\"web sg\"):", "ground_truth": "                    with SecurityGroup(\"web sg\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        with AutoScalling(\"\"):", "prediction_line": "                        with AutoScalling(\"\"):", "ground_truth": "                        with AutoScalling(\"\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                            with EC2Contents(\"B\"):", "prediction_line": "                            with EC2Contents(\"B\"):", "ground_truth": "                            with EC2Contents(\"A\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                            with ServerContents(\"A1\"):", "prediction_line": "                            with ServerContents(\"A1\"):", "ground_truth": "                            with ServerContents(\"A1\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                           with ServerContents(\"A2\"):", "prediction_line": "                           with ServerContents(\"A2\"):", "ground_truth": "                    with PublicSubnet(\"Public\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    with SecurityGroup(\"elb sg\"):", "prediction_line": "                    with SecurityGroup(\"elb sg\"):", "ground_truth": "                    with SecurityGroup(\"elb sg\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _icon = PrivateSubnet", "prediction_line": "    _icon = PrivateSubnet", "ground_truth": "    _icon = PrivateSubnet", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _icon = PublicSubnet", "prediction_line": "    _icon = PublicSubnet", "ground_truth": "    _icon = PublicSubnet", "line_class": "infile", "zero_context": true}
{"original_prediction": "    }\n    _icon = Server", "prediction_line": "    }", "ground_truth": "    }", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class Subnet(Cluster):", "prediction_line": "class Subnet(Cluster):", "ground_truth": "class VirtualPrivateCloud(Cluster):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "under the License.", "prediction_line": "under the License.", "ground_truth": "under the License.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            Custom(\"Chassis\", \"./resources/ovn.png\")", "prediction_line": "            Custom(\"Chassis\", \"./resources/ovn.png\")", "ground_truth": "            Server(\"tyto\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"fontsize\": \"12\",", "prediction_line": "        \"fontsize\": \"12\",", "ground_truth": "        \"fontsize\": \"12\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            with PrivateSubnet(\"Private subnet\"):", "prediction_line": "            with PrivateSubnet(\"Private subnet\"):", "ground_truth": "            Custom(\"Chassis\", \"./resources/ovn.png\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"labeljust\": \"l\",", "prediction_line": "        \"labeljust\": \"l\",", "ground_truth": "        \"labeljust\": \"l\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            Server(\"strix\")", "prediction_line": "            Server(\"strix\")", "ground_truth": "            Server(\"otus\")", "line_class": "random", "zero_context": true}
{"original_prediction": "   lb2 >> Edge(forward=True, reverse=True) >> d3", "prediction_line": "   lb2 >> Edge(forward=True, reverse=True) >> d3", "ground_truth": "    lb2 >> Edge(forward=True, reverse=True) >> d3", "line_class": "common", "zero_context": true}
{"original_prediction": "    lb2 >> Edge(forward=True, reverse=True) >> d4", "prediction_line": "    lb2 >> Edge(forward=True, reverse=True) >> d4", "ground_truth": "    lb2 >> Edge(forward=True, reverse=True) >> d4", "line_class": "common", "zero_context": true}
{"original_prediction": "    Edge(d1, d2, label=\"10.0.0.0/24\")", "prediction_line": "    Edge(d1, d2, label=\"10.0.0.0/24\")", "ground_truth": "    lb1 >> Edge(forward=True, reverse=True) >> d1", "line_class": "common", "zero_context": true}
{"original_prediction": "    lb1 >> Edge(forward=True, reverse=True) >> d2", "prediction_line": "    lb1 >> Edge(forward=True, reverse=True) >> d2", "ground_truth": "    lb1 >> Edge(forward=True, reverse=True) >> d2", "line_class": "common", "zero_context": true}
{"original_prediction": "        with Region(\"Region 1\"):", "prediction_line": "        with Region(\"Region 1\"):", "ground_truth": "        with ServerContents(\"chassis 1: Bastion host\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            Crio(\"Keepalived\")", "prediction_line": "            Crio(\"Keepalived\")", "ground_truth": "        with AvailabilityZone(\"chassis 2\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            Server(\"nyctea\")", "prediction_line": "            Server(\"nyctea\")", "ground_truth": "        with AvailabilityZone(\"chassis 3\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            with VirtualPrivateCloud(\"\"):", "prediction_line": "            with VirtualPrivateCloud(\"\"):", "ground_truth": "            with VirtualPrivateCloud(\"\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                with PrivateSubnet(\"\"):", "prediction_line": "                with PrivateSubnet(\"\"):", "ground_truth": "                with PrivateSubnet(\"Private\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    with SecurityGroup(\"\"):", "prediction_line": "                    with SecurityGroup(\"\"):", "ground_truth": "                    with SecurityGroup(\"web sg\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        with AutoScalling(\"\"):", "prediction_line": "                        with AutoScalling(\"\"):", "ground_truth": "                        with AutoScalling(\"\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                            with EC2Contents(\"B\"):", "prediction_line": "                            with EC2Contents(\"B\"):", "ground_truth": "                            with EC2Contents(\"A\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                            with ServerContents(\"A1\"):", "prediction_line": "                            with ServerContents(\"A1\"):", "ground_truth": "                            with ServerContents(\"A1\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                           with ServerContents(\"A2\"):", "prediction_line": "                           with ServerContents(\"A2\"):", "ground_truth": "                    with PublicSubnet(\"Public\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        with ELB(\"\"):", "prediction_line": "                        with ELB(\"\"):", "ground_truth": "                        with SecurityGroup(\"elb sg\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _icon = PrivateSubnet", "prediction_line": "    _icon = PrivateSubnet", "ground_truth": "    _icon = PrivateSubnet", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _icon = PublicSubnet", "prediction_line": "    _icon = PublicSubnet", "ground_truth": "    _icon = PublicSubnet", "line_class": "infile", "zero_context": true}
{"original_prediction": "from diagrams.aws.storage import EBS, EFS, S3", "prediction_line": "from diagrams.aws.storage import EBS, EFS, S3", "ground_truth": "from diagrams.custom import Custom", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"Virtual private cloud.\"\"\"", "prediction_line": "    \"\"\"Virtual private cloud.\"\"\"", "ground_truth": "    \"\"\"Virtual private cloud.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "under the License.", "prediction_line": "under the License.", "ground_truth": "under the License.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    _default_graph_attrs = {", "prediction_line": "    _default_graph_attrs = {", "ground_truth": "    _default_graph_attrs = {", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"style\": \"dashed\",", "prediction_line": "        \"style\": \"dashed\",", "ground_truth": "        \"style\": \"dashed\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                                d2 = Crio(\"Container\")", "prediction_line": "                                d2 = Crio(\"Container\")", "ground_truth": "                                d2 = Crio(\"Container\")", "line_class": "random", "zero_context": true}
{"original_prediction": "                                EC2(\"A\")", "prediction_line": "                                EC2(\"A\")", "ground_truth": "                                d1 = Crio(\"Container\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"pencolor\": \"#FFB432\",", "prediction_line": "        \"pencolor\": \"#FFB432\",", "ground_truth": "        \"pencolor\": \"#A0A0A0\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            node, index = unvisited.pop()", "prediction_line": "            node, index = unvisited.pop()", "ground_truth": "            node, index = unvisited[-1]", "line_class": "common", "zero_context": true}
{"original_prediction": "            if index < len(node.value):", "prediction_line": "            if index < len(node.value):", "ground_truth": "            if index == len(node.value):", "line_class": "common", "zero_context": true}
{"original_prediction": "            value = node.value[index]", "prediction_line": "            value = node.value[index]", "ground_truth": "            for key, value in node.value[index:]:", "line_class": "common", "zero_context": true}
{"original_prediction": "                if isinstance(key, ScalarNode):", "prediction_line": "                if isinstance(key, ScalarNode):", "ground_truth": "                index += 1", "line_class": "common", "zero_context": true}
{"original_prediction": "                if not isinstance(key, ScalarNode):", "prediction_line": "                if not isinstance(key, ScalarNode):", "ground_truth": "                unvisited[-1] = (node, index)", "line_class": "common", "zero_context": true}
{"original_prediction": "        for line in source:", "prediction_line": "        for line in source:", "ground_truth": "        for linenum, line in enumerate(source.splitlines(), start=1):", "line_class": "common", "zero_context": true}
{"original_prediction": "                unvisited.append(node.remove_child())", "prediction_line": "                unvisited.append(node.remove_child())", "ground_truth": "                unvisited.append(node.remove_child())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        output_nodes = []", "prediction_line": "        output_nodes = []", "ground_truth": "        tree = TreeNode(None, comments)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            tree = self._parse_document(doc, comments)", "prediction_line": "            tree = self._parse_document(doc, comments)", "ground_truth": "            docs = self._generate_documentation(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        comments = self._get_comments(source, source_file)", "prediction_line": "        comments = self._get_comments(source, source_file)", "ground_truth": "        comments = self._get_comments(source, source_file)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self._parse_document(doc, comments))", "prediction_line": "                self._parse_document(doc, comments))", "ground_truth": "                self._parse_document(doc, comments)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                with open(location, 'r') as f:", "prediction_line": "                with open(location, 'r') as f:", "ground_truth": "                output_nodes.extend(self._parse_file(location))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                raise AutoYAMLException(", "prediction_line": "                raise AutoYAMLException(", "ground_truth": "                raise AutoYAMLException('Failed to parse YAML file: %s' % (location)) from e", "line_class": "infile", "zero_context": true}
{"original_prediction": "            logger.debug('[autoyaml] parsing directory: %s', location)", "prediction_line": "            logger.debug('[autoyaml] parsing directory: %s', location)", "ground_truth": "            raise AutoYAMLException('%s:%s: location \"%s\" is not a file.' % (", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if not isinstance(value, (MappingNode, ScalarNode)):", "prediction_line": "                if not isinstance(value, (MappingNode, ScalarNode)):", "ground_truth": "                subtree = tree.add_child(key)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            print(\"This path does not exist\")", "prediction_line": "            print(\"This path does not exist\")", "ground_truth": "            raise AutoYAMLException('location \"%s\" does not exists.' % (", "line_class": "infile", "zero_context": true}
{"original_prediction": "                comment.append(line, source_file, linenum)", "prediction_line": "                comment.append(line, source_file, linenum)", "ground_truth": "                line = line[len(self.config.autoyaml_comment):]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            source = f.read()", "prediction_line": "            source = f.read()", "ground_truth": "            source = f.read()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.state.nested_parse(node.comment, 0, node.comment)", "prediction_line": "                self.state.nested_parse(node.comment, 0, node.comment)", "ground_truth": "                definition = nodes.definition()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.state.document.note_implicit_target(", "prediction_line": "                self.state.document.note_implicit_target(", "ground_truth": "                node.comment = nodes.definition_list_item(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    nodes.term('', node.value.value),", "prediction_line": "                    nodes.term('', node.value.value),", "ground_truth": "                    nodes.term('', node.value.value),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if line.startswith('#'):", "prediction_line": "            if line.startswith('#'):", "ground_truth": "            if line.startswith(self.config.autoyaml_doc_delimiter):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    node.parent.comment = nodes.definition_list()", "prediction_line": "                    node.parent.comment = nodes.definition_list()", "ground_truth": "                    node.parent.comment = nodes.definition_list()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        len(value.value) > 0):", "prediction_line": "                        len(value.value) > 0):", "ground_truth": "                    len(unvisited) + 1 <= self.config.autoyaml_level", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                comment.parent = source_file", "prediction_line": "                comment.parent = source_file", "ground_truth": "            elif line.startswith(self.config.autoyaml_comment) \\", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        try:\n            output_nodes.extend(self.run_autoyaml())", "prediction_line": "        try:", "ground_truth": "        location = os.path.normpath(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        definition = nodes.definition()", "prediction_line": "                        definition = nodes.definition()", "ground_truth": "                        dlist = nodes.definition_list()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "self.arguments[0])", "prediction_line": "self.arguments[0])", "ground_truth": "                         self.config.autoyaml_root", "line_class": "inproject", "zero_context": true}
{"original_prediction": "s\n                ):\n                    unvisited.append((value, 0))", "prediction_line": "s", "ground_truth": "                    or self.config.autoyaml_level == 0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "nodes.definition_list):", "prediction_line": "nodes.definition_list):", "ground_truth": "                        nodes.definition_list):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                comment.append(line, source_file, linenum)", "prediction_line": "                comment.append(line, source_file, linenum)", "ground_truth": "                # strip preceding whitespace", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"AutoYAML exception.\"\"\"", "prediction_line": "    \"\"\"AutoYAML exception.\"\"\"", "ground_truth": "    \"\"\"Main plugin exception class.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __init__(self, key, value, parent=None):", "prediction_line": "    def __init__(self, key, value, parent=None):", "ground_truth": "    def __init__(self, value, comments, parent=None):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   optional_arguments = 0", "prediction_line": "   optional_arguments = 0", "ground_truth": "    def run(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            self.comment = self.value.comment", "prediction_line": "            self.comment = self.value.comment", "ground_truth": "            # Flow-style entries may attempt to incorrectly reuse comments", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    MappingNode,", "prediction_line": "    MappingNode,", "ground_truth": "    MappingNode,", "line_class": "random", "zero_context": true}
{"original_prediction": "                    continue\n                if not isinstance(value, (MappingNode, ScalarNode)):", "prediction_line": "                    continue", "ground_truth": "                    continue", "line_class": "random", "zero_context": true}
{"original_prediction": "            if node.parent.parent is None:", "prediction_line": "            if node.parent.parent is None:", "ground_truth": "            unvisited.pop()", "line_class": "random", "zero_context": true}
{"original_prediction": "                else:\n                    subtree.add_child(value)", "prediction_line": "                else:", "ground_truth": "        return tree", "line_class": "random", "zero_context": true}
{"original_prediction": "                comment.append(line, source_file, linenum)", "prediction_line": "                comment.append(line, source_file, linenum)", "ground_truth": "                comment.append(line, source_file, linenum)", "line_class": "random", "zero_context": true}
{"original_prediction": "    test_performance()", "prediction_line": "    test_performance()", "ground_truth": "    main()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        cmd = commands(platform)[\"basic\"]", "prediction_line": "        cmd = commands(platform)[\"basic\"]", "ground_truth": "        cmd = commands(platform)[\"config\"][0]", "line_class": "infile", "zero_context": true}
{"original_prediction": "@f_exec_time", "prediction_line": "@f_exec_time", "ground_truth": "@f_exec_time", "line_class": "infile", "zero_context": true}
{"original_prediction": "        remove_acl_cmd = \"no access-list netmiko_test_large_acl\"", "prediction_line": "        remove_acl_cmd = \"no access-list netmiko_test_large_acl\"", "ground_truth": "        base_acl_cmd = commands(platform)[\"config_long_acl\"][\"base_cmd\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ScrapliClass = globals()[driver]", "prediction_line": "    ScrapliClass = globals()[driver]", "ground_truth": "    cleanup_generic(driver, device, remove_acl_cmd)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        writer = csv.DictWriter(csv_file, fieldnames=field_names)", "prediction_line": "        writer = csv.DictWriter(csv_file, fieldnames=field_names)", "ground_truth": "        t_stamp = generate_csv_timestamp()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return wrapper_decorator", "prediction_line": "    return wrapper_decorator", "ground_truth": "    return wrapper_decorator", "line_class": "infile", "zero_context": true}
{"original_prediction": "       write_csv(dev_name, results)", "prediction_line": "       write_csv(dev_name, results)", "ground_truth": "        write_csv(dev_name, results)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        command = commands(platform)[\"show_version\"]", "prediction_line": "        command = commands(platform)[\"show_version\"]", "ground_truth": "        cmd = commands(platform)[\"basic\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "   devices = read_devices()", "prediction_line": "   devices = read_devices()", "ground_truth": "    devices = read_devices()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        conn.send_command(\"show version\")", "prediction_line": "        conn.send_command(\"show version\")", "ground_truth": "        conn.open()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with open(results_file, \"a\", newline=\"\") as f:", "prediction_line": "    with open(results_file, \"a\", newline=\"\") as f:", "ground_truth": "    with open(results_file, \"a\") as csv_file:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    f_path = path.join(PWD, f_name)", "prediction_line": "    f_path = path.join(PWD, f_name)", "ground_truth": "    with open(f_name) as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        output = conn.send_command(cmd)", "prediction_line": "        output = conn.send_command(cmd)", "ground_truth": "        output = conn.send_command(cmd)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    f_name = f\"commands_{test_platform}.yml\"", "prediction_line": "    f_name = f\"commands_{test_platform}.yml\"", "ground_truth": "    commands_yml = parse_yaml(PWD + \"/../etc/commands.yml\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "Main\n#", "prediction_line": "Main", "ground_truth": "#", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "import functools", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"Write the results to a CSV file.\"\"\"", "prediction_line": "    \"\"\"Write the results to a CSV file.\"\"\"", "ground_truth": "    results_file = \"netmiko_scrapli_performance.csv\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        response = conn.send_configs(command)", "prediction_line": "        response = conn.send_configs(command)", "ground_truth": "        response = conn.send_configs(command)", "line_class": "random", "zero_context": true}
{"original_prediction": "            entry[func_name] = exec_time", "prediction_line": "            entry[func_name] = exec_time", "ground_truth": "            entry[func_name] = exec_time", "line_class": "random", "zero_context": true}
{"original_prediction": "        ]\n        results = {}", "prediction_line": "        ]", "ground_truth": "        ]", "line_class": "random", "zero_context": true}
{"original_prediction": "    else:\n        remove_acl_cmd = \"no ip access-list test\"", "prediction_line": "    else:", "ground_truth": "    elif \"hp_procurve\" in platform:", "line_class": "random", "zero_context": true}
{"original_prediction": "    test_performance()", "prediction_line": "    test_performance()", "ground_truth": "    main()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        cmd = commands(platform)[\"basic\"]", "prediction_line": "        cmd = commands(platform)[\"basic\"]", "ground_truth": "        cmd = commands(platform)[\"config\"][0]", "line_class": "infile", "zero_context": true}
{"original_prediction": "def netmiko_connect(device):", "prediction_line": "def netmiko_connect(device):", "ground_truth": "@f_exec_time", "line_class": "infile", "zero_context": true}
{"original_prediction": "        remove_acl_cmd = \"no access-list netmiko_test_large_acl\"", "prediction_line": "        remove_acl_cmd = \"no access-list netmiko_test_large_acl\"", "ground_truth": "        base_acl_cmd = commands(platform)[\"config_long_acl\"][\"base_cmd\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ScrapliClass = globals()[driver]", "prediction_line": "    ScrapliClass = globals()[driver]", "ground_truth": "    cleanup_generic(driver, device, remove_acl_cmd)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        writer = csv.DictWriter(csv_file, fieldnames=field_names)", "prediction_line": "        writer = csv.DictWriter(csv_file, fieldnames=field_names)", "ground_truth": "        t_stamp = generate_csv_timestamp()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return wrapper_decorator", "prediction_line": "    return wrapper_decorator", "ground_truth": "    return wrapper_decorator", "line_class": "infile", "zero_context": true}
{"original_prediction": "       write_csv(dev_name, results)", "prediction_line": "       write_csv(dev_name, results)", "ground_truth": "        write_csv(dev_name, results)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        command = commands(platform)[\"show_version\"]", "prediction_line": "        command = commands(platform)[\"show_version\"]", "ground_truth": "        cmd = commands(platform)[\"basic\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "   devices = read_devices()", "prediction_line": "   devices = read_devices()", "ground_truth": "    devices = read_devices()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        conn.open()", "prediction_line": "        conn.open()", "ground_truth": "        conn.open()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with open(results_file, \"a\", newline=\"\") as f:", "prediction_line": "    with open(results_file, \"a\", newline=\"\") as f:", "ground_truth": "    with open(results_file, \"a\") as csv_file:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    f_path = path.join(PWD, f_name)", "prediction_line": "    f_path = path.join(PWD, f_name)", "ground_truth": "    with open(f_name) as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        output = conn.send_command(cmd)", "prediction_line": "        output = conn.send_command(cmd)", "ground_truth": "        output = conn.send_command(cmd)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    f_name = f\"commands_{test_platform}.yml\"", "prediction_line": "    f_name = f\"commands_{test_platform}.yml\"", "ground_truth": "    commands_yml = parse_yaml(PWD + \"/../etc/commands.yml\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from scrapli.driver.core import AristaDriver  # noqa", "prediction_line": "from scrapli.driver.core import AristaDriver  # noqa", "ground_truth": "from scrapli.driver.core import JunosDriver  # noqa", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import re\nimport sys", "prediction_line": "import re", "ground_truth": "from os import path", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "import functools", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            connect,\n            send_command_simple,", "prediction_line": "            connect,", "ground_truth": "            \"connect\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        remove_acl_cmd = base_acl_cmd.replace(\"netmiko_test_large_acl\", \"test_acl\")", "prediction_line": "        remove_acl_cmd = base_acl_cmd.replace(\"netmiko_test_large_acl\", \"test_acl\")", "ground_truth": "        remove_acl_cmd = f\"no {base_acl_cmd}\"", "line_class": "random", "zero_context": true}
{"original_prediction": "def print_debug(func):", "prediction_line": "def print_debug(func):", "ground_truth": "PWD = path.dirname(path.realpath(__file__))", "line_class": "random", "zero_context": true}
{"original_prediction": "    with open(path.join(PWD, \"devices.yml\")) as f:", "prediction_line": "    with open(path.join(PWD, \"devices.yml\")) as f:", "ground_truth": "    f_name = \"test_devices_scrapli.yml\"", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"IOSXRDriver\": \"cisco_xr\",", "prediction_line": "    \"IOSXRDriver\": \"cisco_xr\",", "ground_truth": "    \"IOSXRDriver\": \"cisco_xr\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(*args, **kwargs)", "prediction_line": "        super().__init__(*args, **kwargs)", "ground_truth": "        super().__init__(*args, **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        \"\"\"Initialize AudioCode driver.\"\"\"", "prediction_line": "        \"\"\"Initialize AudioCode driver.\"\"\"", "ground_truth": "        default_enter = kwargs.get(\"default_enter\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        strip_command: bool = False,", "prediction_line": "        strip_command: bool = False,", "ground_truth": "        strip_command: bool = False,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            strip_command=strip_command,", "prediction_line": "            strip_command=strip_command,", "ground_truth": "            strip_command=strip_command,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            strip_prompt=strip_prompt,", "prediction_line": "            strip_prompt=strip_prompt,", "ground_truth": "            strip_prompt=strip_prompt,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"Enter configuration mode.\"\"\"", "prediction_line": "        \"\"\"Enter configuration mode.\"\"\"", "ground_truth": "        return super().config_mode(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.write_channel(command)", "prediction_line": "            self.write_channel(command)", "ground_truth": "            return super().disable_paging(", "line_class": "infile", "zero_context": true}
{"original_prediction": "       if enter_config_mode and config_mode_command is None:", "prediction_line": "       if enter_config_mode and config_mode_command is None:", "ground_truth": "        return super().send_config_set(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            exit_config_mode=exit_config_mode,", "prediction_line": "            exit_config_mode=exit_config_mode,", "ground_truth": "            exit_config_mode=exit_config_mode,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.set_base_prompt()", "prediction_line": "        self.set_base_prompt()", "ground_truth": "        self.set_base_prompt()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.disable_paging(command=\"set length 0\")", "prediction_line": "        self.disable_paging(command=\"set length 0\")", "ground_truth": "        self.disable_paging()", "line_class": "infile", "zero_context": true}
{"original_prediction": "       \"\"\"Checks if the device is in configuration mode or not.\"\"\"", "prediction_line": "       \"\"\"Checks if the device is in configuration mode or not.\"\"\"", "ground_truth": "        return super().check_config_mode(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.write_channel(self.normalize_cmd(cmd))", "prediction_line": "        self.write_channel(self.normalize_cmd(cmd))", "ground_truth": "        self.enable()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return super().exit_config_mode(exit_config=exit_config, pattern=pattern)", "prediction_line": "        return super().exit_config_mode(exit_config=exit_config, pattern=pattern)", "ground_truth": "        return super().exit_config_mode(exit_config=exit_config, pattern=pattern)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Sets self.base_prompt", "prediction_line": "        \"\"\"", "ground_truth": "        return super().set_base_prompt(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for command in command_list:", "prediction_line": "        for command in command_list:", "ground_truth": "        return self.send_config_set(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Find prompt", "prediction_line": "        \"\"\"", "ground_truth": "        return super().find_prompt(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"Saves the running configuration.\"\"\"", "prediction_line": "        \"\"\"Saves the running configuration.\"\"\"", "ground_truth": "        return super().save_config(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if reload_save:", "prediction_line": "        if reload_save:", "ground_truth": "        return super()._reload_device(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.exit_config_mode()", "prediction_line": "            self.exit_config_mode()", "ground_truth": "            self._enable_paging()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return super().check_enable_mode(check_string=check_string)", "prediction_line": "        return super().check_enable_mode(check_string=check_string)", "ground_truth": "        return super().check_enable_mode(check_string=check_string)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.exit_config_mode()", "prediction_line": "            self.exit_config_mode()", "ground_truth": "            if self.check_config_mode():", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.exit_config_mode()", "prediction_line": "                self.exit_config_mode()", "ground_truth": "                self.exit_config_mode()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return output", "prediction_line": "        return output", "ground_truth": "        return super().strip_command(command_string=command_string, output=output)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return super().strip_prompt(a_string=a_string)", "prediction_line": "        return super().strip_prompt(a_string=a_string)", "ground_truth": "        return super().strip_prompt(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return super().set_base_prompt(", "prediction_line": "        return super().set_base_prompt(", "ground_truth": "        prompt = self.find_prompt(delay_factor=delay_factor, pattern=pattern)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"Enter enable mode.\"\"\"", "prediction_line": "        \"\"\"Enter enable mode.\"\"\"", "ground_truth": "        return super().enable(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        exit_config_mode: bool = False,", "prediction_line": "        exit_config_mode: bool = False,", "ground_truth": "        exit_config_mode: bool = True,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if self.check_config_mode():", "prediction_line": "                if self.check_config_mode():", "ground_truth": "                if not self.check_config_mode():", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ) -> str:", "prediction_line": "    ) -> str:", "ground_truth": "        strip_prompt: bool = False,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        output = \"\"", "prediction_line": "        output = \"\"", "ground_truth": "        return super().exit_enable_mode(exit_command=exit_command)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._test_channel_read(pattern=r\"[>#]\")", "prediction_line": "        self._test_channel_read(pattern=r\"[>#]\")", "ground_truth": "        self._test_channel_read(pattern=r\"[>#]\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        time.sleep(0.3 * self.global_delay_factor)", "prediction_line": "        time.sleep(0.3 * self.global_delay_factor)", "ground_truth": "        self.clear_buffer()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            delay_factor = self.select_delay_factor(delay_factor)", "prediction_line": "            delay_factor = self.select_delay_factor(delay_factor)", "ground_truth": "            delay_factor = self.select_delay_factor(delay_factor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.write_channel(self.normalize_cmd(cmd))", "prediction_line": "            self.write_channel(self.normalize_cmd(cmd))", "ground_truth": "            output = self._send_command_timing_str(command_string=cmd)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                output += self._send_command_timing_str(", "prediction_line": "                output += self._send_command_timing_str(", "ground_truth": "                output += self._send_command_timing_str(confirm_response)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                output += self._send_command_timing_str(self.RETURN)", "prediction_line": "                output += self._send_command_timing_str(self.RETURN)", "ground_truth": "                output += self._send_command_timing_str(self.RETURN)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if self.ansi_escape_codes:", "prediction_line": "            if self.ansi_escape_codes:", "ground_truth": "            output = self._send_command_str(command_string=cmd)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.write_channel(self.normalize_cmd(cmd))", "prediction_line": "        self.write_channel(self.normalize_cmd(cmd))", "ground_truth": "        return self._send_command_timing_str(command_string=cmd)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self._test_channel_read(pattern=r\"[>#]\")", "prediction_line": "        self._test_channel_read(pattern=r\"[>#]\")", "ground_truth": "        self.write_channel(self.RETURN)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.set_base_prompt()", "prediction_line": "        self.set_base_prompt()", "ground_truth": "        self._test_channel_read(pattern=r\"/>\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.write_channel(command + self.RETURN)", "prediction_line": "        self.write_channel(command + self.RETURN)", "ground_truth": "        self.write_channel(command + self.RETURN)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                output += self.send_command_expect(exit_config)", "prediction_line": "                output += self.send_command_expect(exit_config)", "ground_truth": "                self.write_channel(self.normalize_cmd(exit_config))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    output += self.read_until_prompt_or_pattern(", "prediction_line": "                    output += self.read_until_prompt_or_pattern(", "ground_truth": "                    output += self.read_until_pattern(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    output += self.read_until_pattern(pattern=pattern)", "prediction_line": "                    output += self.read_until_pattern(pattern=pattern)", "ground_truth": "                    output += self.read_until_pattern(pattern=pattern)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    output += self.read_until_prompt()", "prediction_line": "                    output += self.read_until_prompt()", "ground_truth": "                    output += self.read_until_prompt(read_entire_line=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def check_config_mode(self, check_string: str = \")#\", pattern: str = r\"[#>]\") -> bool:", "prediction_line": "    def check_config_mode(self, check_string: str = \")#\", pattern: str = r\"[#>]\") -> bool:", "ground_truth": "    def find_prompt(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class Audiocode66Telnet(AudiocodeBase66):", "prediction_line": "class Audiocode66Telnet(AudiocodeBase66):", "ground_truth": "class Audiocode66Telnet(AudiocodeBase66):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def session_preparation(self) -> None:", "prediction_line": "    def session_preparation(self) -> None:", "ground_truth": "    def __init__(self, *args: Any, **kwargs: Any) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            output += self.send_command_expect(exit_config)", "prediction_line": "            output += self.send_command_expect(exit_config)", "ground_truth": "            # Keep \"exitting\" until out of config mode", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                if self.check_config_mode():", "prediction_line": "                if self.check_config_mode():", "ground_truth": "                else:", "line_class": "random", "zero_context": true}
{"original_prediction": "            delay_factor=delay_factor,", "prediction_line": "            delay_factor=delay_factor,", "ground_truth": "            delay_factor=delay_factor,", "line_class": "random", "zero_context": true}
{"original_prediction": "        if re.search(pattern, output, re.M):", "prediction_line": "        if re.search(pattern, output, re.M):", "ground_truth": "        output = re.sub(pattern, \"\", output, flags=re.M)", "line_class": "random", "zero_context": true}
{"original_prediction": "            pattern=pattern,", "prediction_line": "            pattern=pattern,", "ground_truth": "            pattern=pattern,", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"cli-terminal\",", "prediction_line": "            \"cli-terminal\",", "ground_truth": "            \"cli-terminal\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            Cuba(years=2018),", "prediction_line": "            Cuba(years=2018),", "ground_truth": "            Cuba(years=2018),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=2008),", "prediction_line": "            Cuba(years=2008),", "ground_truth": "            Cuba(years=2008),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=2007),", "prediction_line": "            Cuba(years=2007),", "ground_truth": "            Cuba(years=2007),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=1997),", "prediction_line": "            Cuba(years=1997),", "ground_truth": "            Cuba(years=1997),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.holidays = Cuba()", "prediction_line": "        self.holidays = Cuba()", "ground_truth": "        self.holidays = Cuba()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=2022),", "prediction_line": "            Cuba(years=2022),", "ground_truth": "            Cuba(years=2022),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.holidays,", "prediction_line": "            self.holidays,", "ground_truth": "            Cuba(years=1968),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=2011),", "prediction_line": "            Cuba(years=2011),", "ground_truth": "            Cuba(years=2011),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=2023),", "prediction_line": "            Cuba(years=2023),", "ground_truth": "            Cuba(years=2023),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=2021),", "prediction_line": "            Cuba(years=2021),", "ground_truth": "            Cuba(years=2021),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=2020),", "prediction_line": "            Cuba(years=2020),", "ground_truth": "            Cuba(years=2020),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=2012),", "prediction_line": "            Cuba(years=2012),", "ground_truth": "            Cuba(years=2012),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=1998),", "prediction_line": "            Cuba(years=1998),", "ground_truth": "            Cuba(years=1998),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=1996),", "prediction_line": "            Cuba(years=1996),", "ground_truth": "            Cuba(years=1996),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Cuba(years=2006),", "prediction_line": "            Cuba(years=2006),", "ground_truth": "            Cuba(years=2006),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def test_2023(self):", "prediction_line": "    def test_2023(self):", "ground_truth": "    def test_2023(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class TestCuba(TestCase):", "prediction_line": "class TestCuba(TestCase):", "ground_truth": "class TestCuba(TestCase):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#  Repository: https://github.com/dr-prodigy/python-holidays", "prediction_line": "#  Repository: https://github.com/dr-prodigy/python-holidays", "ground_truth": "#           ryanss <ryanssdev@icloud.com> (c) 2014-2017", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_2022(self):", "prediction_line": "    def test_2022(self):", "ground_truth": "    def test_2022(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_1998(self):", "prediction_line": "    def test_1998(self):", "ground_truth": "    def test_1998(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            \"2023-07-27\",", "prediction_line": "            \"2023-07-27\",", "ground_truth": "            \"2023-07-27\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"2020-12-25\",", "prediction_line": "            \"2020-12-25\",", "ground_truth": "            \"2020-12-25\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        )\n\n    def test_2009(self):", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"1969-10-10\",", "prediction_line": "            \"1969-10-10\",", "ground_truth": "            \"1969-10-10\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"1997-07-26\",", "prediction_line": "            \"1997-07-26\",", "ground_truth": "            \"1997-07-26\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        s_holidays = holidays.BO(subdiv=\"S\")", "prediction_line": "        s_holidays = holidays.BO(subdiv=\"S\")", "ground_truth": "        s_holidays = holidays.BO(subdiv=\"S\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        oru_holidays = holidays.BO(subdiv=\"ORU\")", "prediction_line": "        oru_holidays = holidays.BO(subdiv=\"ORU\")", "ground_truth": "        o_holidays = holidays.BO(subdiv=\"O\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        p_holidays = holidays.BO(subdiv=\"P\")", "prediction_line": "        p_holidays = holidays.BO(subdiv=\"P\")", "ground_truth": "        p_holidays = holidays.BO(subdiv=\"P\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        p_holidays = holidays.BO(subdiv=\"P\")", "prediction_line": "        p_holidays = holidays.BO(subdiv=\"P\")", "ground_truth": "        n_holidays = holidays.BO(subdiv=\"N\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       self.assertIn(date(2017, 4, 15), self.holidays)", "prediction_line": "       self.assertIn(date(2017, 4, 15), self.holidays)", "ground_truth": "        t_holidays = holidays.BO(subdiv=\"T\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.holidays = holidays.BO(observed=True)", "prediction_line": "        self.holidays = holidays.BO(observed=True)", "ground_truth": "        self.holidays = holidays.BO(observed=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def test_2018(self):", "prediction_line": "    def test_2018(self):", "ground_truth": "        self.holidays_observed = holidays.BO(observed=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        c_holidays = holidays.BO(subdiv=\"C\")", "prediction_line": "        c_holidays = holidays.BO(subdiv=\"C\")", "ground_truth": "        h_holidays = holidays.BO(subdiv=\"H\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        lp_holidays = holidays.BO(subdiv=\"LP\")", "prediction_line": "        lp_holidays = holidays.BO(subdiv=\"LP\")", "ground_truth": "        l_holidays = holidays.BO(subdiv=\"L\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        b_holidays = holidays.BO(subdiv=\"B\")", "prediction_line": "        b_holidays = holidays.BO(subdiv=\"B\")", "ground_truth": "        b_holidays = holidays.BO(subdiv=\"B\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        c_holidays = holidays.BO(subdiv=\"C\")", "prediction_line": "        c_holidays = holidays.BO(subdiv=\"C\")", "ground_truth": "        c_holidays = holidays.BO(subdiv=\"C\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "#  given date is a holiday as easy as possible.", "prediction_line": "#  given date is a holiday as easy as possible.", "ground_truth": "#  specific date is a holiday as fast and flexible as possible.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_columbus_day(self):", "prediction_line": "    def test_columbus_day(self):", "ground_truth": "    def test_santa_cruz_day(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_may_day(self):", "prediction_line": "    def test_may_day(self):", "ground_truth": "    def test_la_tablada_and_viernes_santo(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.assertNotIn(date(2020, 11, 20), self.holidays)", "prediction_line": "        self.assertNotIn(date(2020, 11, 20), self.holidays)", "ground_truth": "        self.assertNotIn(date(2020, 11, 10), self.holidays)", "line_class": "random", "zero_context": true}
{"original_prediction": "        for dt in (date(2010, 5, 1), date(2022, 5, 1)):", "prediction_line": "        for dt in (date(2010, 5, 1), date(2022, 5, 1)):", "ground_truth": "        for dt in (date(2021, 5, 1), date(2022, 5, 1)):", "line_class": "random", "zero_context": true}
{"original_prediction": "            )\n\n    def test_easter(self):", "prediction_line": "            )", "ground_truth": "            )", "line_class": "random", "zero_context": true}
{"original_prediction": "        for dt in (date(2020, 2, 24), date(2021, 2, 15)):", "prediction_line": "        for dt in (date(2020, 2, 24), date(2021, 2, 15)):", "ground_truth": "        for dt in (date(2020, 2, 24), date(2023, 2, 20)):", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.assertIn(dt, b_holidays)", "prediction_line": "            self.assertIn(dt, b_holidays)", "ground_truth": "            self.assertIn(dt, b_holidays)", "line_class": "random", "zero_context": true}
{"original_prediction": "       self.assertHoliday(", "prediction_line": "       self.assertHoliday(", "ground_truth": "        self.assertNoHolidayName(name, Thailand(years=1947))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertHolidaysName(", "prediction_line": "        self.assertHolidaysName(", "ground_truth": "        self.assertNoHolidayName(name, Thailand(years=1973))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertNoHolidays(self.holidays_no_observed, [2017])", "prediction_line": "        self.assertNoHolidays(self.holidays_no_observed, [2017])", "ground_truth": "        self.assertNoHolidays(Thailand(years=1940))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertNoHolidayName(name, Thailand(years=range(1910, 1940)))", "prediction_line": "        self.assertNoHolidayName(name, Thailand(years=range(1910, 1940)))", "ground_truth": "        self.assertNoHolidayName(name, Thailand(years=[1910, 1940]))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertNoHolidayName(name, Thailand(years=1960))", "prediction_line": "        self.assertNoHolidayName(name, Thailand(years=1960))", "ground_truth": "        self.assertNoHolidayName(name, Thailand(years=1960))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.holidays = TH()", "prediction_line": "        self.holidays = TH()", "ground_truth": "        self.holidays = Thailand()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertNoHolidayName(name_x, Thailand(years=range(2017, 2020)))", "prediction_line": "        self.assertNoHolidayName(name_x, Thailand(years=range(2017, 2020)))", "ground_truth": "        self.assertNoHolidayName(name_x, Thailand(years=range(1941, 2017)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertNoHoliday(", "prediction_line": "        self.assertNoHoliday(", "ground_truth": "        self.assertNoHolidayName(name_ix, Thailand(years=range(2017, 2058)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(self.holidays.country_name, \"Thailand\")", "prediction_line": "        self.assertEqual(self.holidays.country_name, \"Thailand\")", "ground_truth": "        self.assertCountryAliases(Thailand, TH, THA)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertHoliday(f\"{year}-05-04\" for year in range(2018, 2058))", "prediction_line": "        self.assertHoliday(f\"{year}-05-04\" for year in range(2018, 2058))", "ground_truth": "        self.assertNoHolidayName(name, Thailand(years=range(2017, 2020)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertNoHolidayName(name, Thailand(years=1959))", "prediction_line": "        self.assertNoHolidayName(name, Thailand(years=1959))", "ground_truth": "        self.assertNoHolidayName(name, Thailand(years=1979))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertNoHolidayName(name, Thailand(years=2018))", "prediction_line": "        self.assertNoHolidayName(name, Thailand(years=2018))", "ground_truth": "        self.assertNoHolidayName(name, Thailand(years=2018))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.assertHolidayName(name, f\"{year}-04-13\")", "prediction_line": "            self.assertHolidayName(name, f\"{year}-04-13\")", "ground_truth": "        self.assertNoHolidayName(name, Thailand(years=range(1954, 1957)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertNoHolidayName(name, Thailand(years=1959))", "prediction_line": "        self.assertNoHolidayName(name, Thailand(years=1959))", "ground_truth": "        self.assertNoHolidayName(name, Thailand(years=1959))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertNoHolidayName(name, Thailand(years=2058))", "prediction_line": "        self.assertNoHolidayName(name, Thailand(years=2058))", "ground_truth": "        self.assertNoHolidayName(name, Thailand(years=[1956, 1999]))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def test_constitution_day(self):", "prediction_line": "    def test_constitution_day(self):", "ground_truth": "    def test_constitution_day(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#\n#  Released under the MIT License.", "prediction_line": "#", "ground_truth": "#  Website: https://github.com/dr-prodigy/python-holidays", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            \"2030-07-29\",", "prediction_line": "            \"2030-07-29\",", "ground_truth": "            \"2030-07-29\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"2017-02-10\",", "prediction_line": "            \"2017-02-10\",", "ground_truth": "            \"2017-02-11\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            [\n                (2022, 1, 1, \"New Year's Day\"),", "prediction_line": "            [", "ground_truth": "            (\"2022-01-01\", \"New Year's Day\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.holidays_no_observed,", "prediction_line": "            self.holidays_no_observed,", "ground_truth": "            self.holidays_no_observed,", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"2019-10-14\",", "prediction_line": "            \"2019-10-14\",", "ground_truth": "            \"2019-10-14\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.assertNotIn(dt, self.holidays)", "prediction_line": "            self.assertNotIn(dt, self.holidays)", "ground_truth": "            self.assertEqual(self.holidays_full.get(dt)[:11], \"Вихідний за\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.holidays = holidays.UA()", "prediction_line": "        self.holidays = holidays.UA()", "ground_truth": "        self.holidays = holidays.UA(observed=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def test_2018(self):", "prediction_line": "    def test_2018(self):", "ground_truth": "        self.holidays_full = holidays.UA(observed=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "Monday\n            date(2000, 4, 24),", "prediction_line": "Monday", "ground_truth": "            date(1995, 4, 24),", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            date(1996, 6, 10),", "prediction_line": "            date(1996, 6, 10),", "ground_truth": "            date(1996, 6, 3),", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_2022(self):", "prediction_line": "    def test_2022(self):", "ground_truth": "    def test_2022(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       self.assertIn(date(1918, 3, 30), self.holidays)", "prediction_line": "       self.assertIn(date(1918, 3, 30), self.holidays)", "ground_truth": "    def test_observed(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       self.assertIn(date(2020, 8, 25), self.holidays_full)", "prediction_line": "       self.assertIn(date(2020, 8, 25), self.holidays_full)", "ground_truth": "    def test_2021(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            date(2006, 4, 17),", "prediction_line": "            date(2006, 4, 17),", "ground_truth": "            date(2006, 4, 24),", "line_class": "random", "zero_context": true}
{"original_prediction": "            date(2003, 6, 9),", "prediction_line": "            date(2003, 6, 9),", "ground_truth": "            date(2003, 6, 16),", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.assertIn(date(2018, 11, 1), self.holidays)", "prediction_line": "        self.assertIn(date(2018, 11, 1), self.holidays)", "ground_truth": "        self.assertIn(date(2018, 10, 14), self.holidays)", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.assertIn(date(2020, 1, 6), self.holidays)", "prediction_line": "        self.assertIn(date(2020, 1, 6), self.holidays)", "ground_truth": "        self.assertIn(date(2020, 1, 7), self.holidays)", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.assertIn(date(2019, 5, 27), self.holidays)", "prediction_line": "        self.assertIn(date(2019, 5, 27), self.holidays)", "ground_truth": "        self.assertIn(date(2019, 6, 16), self.holidays)", "line_class": "random", "zero_context": true}
{"original_prediction": "                    year_province_days[(eid_al_fitr_current_year, 1)] = {", "prediction_line": "                    year_province_days[(eid_al_fitr_current_year, 1)] = {", "ground_truth": "                    year_province_days.update(", "line_class": "common", "zero_context": true}
{"original_prediction": "                    year_province_days.update({(9, 15): {\"ML\"}})", "prediction_line": "                    year_province_days.update({(9, 15): {\"ML\"}})", "ground_truth": "                    eid_al_fitr_current_year = _islamic_to_gre(year, 10, 1)[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    year_province_days[(eid_al_fitr_current_year, 1)] = {", "prediction_line": "                    year_province_days[(eid_al_fitr_current_year, 1)] = {", "ground_truth": "                    eid_al_adha_current_year = _islamic_to_gre(year, 12, 10)[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.holidays = holidays.ES(observed=True)", "prediction_line": "        self.holidays = holidays.ES(observed=True)", "ground_truth": "        self.holidays = holidays.ES(observed=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def test_2018(self):", "prediction_line": "    def test_2018(self):", "ground_truth": "        self.holidays_observed = holidays.ES()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"AN\": holidays.ES(prov=\"AN\", observed=False),", "prediction_line": "            \"AN\": holidays.ES(prov=\"AN\", observed=False),", "ground_truth": "            prov: holidays.ES(observed=False, subdiv=prov)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for prov in holidays.ES.subdivisions", "prediction_line": "            for prov in holidays.ES.subdivisions", "ground_truth": "            for prov in holidays.ES.subdivisions", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"AN\": holidays.ES(years=[2022], subdiv=\"AN\", observed=True),", "prediction_line": "            \"AN\": holidays.ES(years=[2022], subdiv=\"AN\", observed=True),", "ground_truth": "            prov: holidays.ES(observed=True, subdiv=prov)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "holidays.\n#  https://github.com/dr-prodigy/python-holidays", "prediction_line": "holidays.", "ground_truth": "#  specific sets of holidays on the fly. It aims to make determining whether a", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#\n#  Author:  Jason Pellerin", "prediction_line": "#", "ground_truth": "#", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_variable_days(self):", "prediction_line": "    def test_variable_days(self):", "ground_truth": "    def test_fixed_holidays_observed(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            (8, 15): {\"CB\"},", "prediction_line": "            (8, 15): {\"CB\"},", "ground_truth": "            (9, 2): {\"CE\"},", "line_class": "random", "zero_context": true}
{"original_prediction": "            (6, 9): {\"CT\"},", "prediction_line": "            (6, 9): {\"CT\"},", "ground_truth": "            (6, 9): {\"MC\", \"RI\"},", "line_class": "random", "zero_context": true}
{"original_prediction": "                    )", "prediction_line": "                    )", "ground_truth": "                    )", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.assertIn(date(2013, 10, 25), prov_holidays)", "prediction_line": "        self.assertIn(date(2013, 10, 25), prov_holidays)", "ground_truth": "        self.assertIn(date(2013, 10, 25), prov_holidays)", "line_class": "random", "zero_context": true}
{"original_prediction": "            (8, 15),", "prediction_line": "            (8, 15),", "ground_truth": "            (8, 15),", "line_class": "random", "zero_context": true}
{"original_prediction": "        return super().__call__(*args, **kwargs)", "prediction_line": "        return super().__call__(*args, **kwargs)", "ground_truth": "        return super().__call__(*args, **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(*args, name=name, **kwargs)", "prediction_line": "        super().__init__(*args, name=name, **kwargs)", "ground_truth": "        super().__init__(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return mapping.get(if_exists, if_exists)", "prediction_line": "        return mapping.get(if_exists, if_exists)", "ground_truth": "        return mapping.get(if_exists, if_exists)", "line_class": "common", "zero_context": true}
{"original_prediction": "            if_exists=self._map_if_exists(self.if_exists),", "prediction_line": "            if_exists=self._map_if_exists(self.if_exists),", "ground_truth": "            if_exists=self._map_if_exists(self.if_exists),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.gen_flow()", "prediction_line": "        self.gen_flow()", "ground_truth": "        self.gen_flow()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        df_to_csv_task.bind(", "prediction_line": "        df_to_csv_task.bind(", "ground_truth": "        df_to_csv_task.bind(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "class TestSftpToDF:", "prediction_line": "class TestSftpToDF:", "ground_truth": "upload_to_adls = AzureDataLakeUpload()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_sftp_to_df_task_runs(monkeypatch):", "prediction_line": "def test_sftp_to_df_task_runs(monkeypatch):", "ground_truth": "create_table_task = AzureSQLCreateTable()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_sftp_to_df_task(monkeypatch):", "prediction_line": "def test_sftp_to_df_task(monkeypatch):", "ground_truth": "bulk_insert_task = BCPTask()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        df.set_upstream(df_to_csv_task, flow=self)", "prediction_line": "        df.set_upstream(df_to_csv_task, flow=self)", "ground_truth": "        df_to_csv_task.set_upstream(df, flow=self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        df_to_csv_task.set_upstream(df_with_metadata, flow=self)", "prediction_line": "        df_to_csv_task.set_upstream(df_with_metadata, flow=self)", "ground_truth": "        df_to_csv_task.set_upstream(df_with_metadata, flow=self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        create_table_task.set_upstream(df_to_csv_task, flow=self)", "prediction_line": "        create_table_task.set_upstream(df_to_csv_task, flow=self)", "ground_truth": "        create_table_task.set_upstream(df_to_csv_task, flow=self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        upload_df.set_upstream(df_to_csv_task, flow=self)", "prediction_line": "        upload_df.set_upstream(df_to_csv_task, flow=self)", "ground_truth": "        upload_df.set_upstream(df_to_csv_task, flow=self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        df_to_csv = df_to_csv_task.bind(", "prediction_line": "        df_to_csv = df_to_csv_task.bind(", "ground_truth": "        df_with_metadata = add_ingestion_metadata_task.bind(df, flow=self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def gen_flow(self) -> Flow:", "prediction_line": "    def gen_flow(self) -> Flow:", "ground_truth": "    def gen_flow(self) -> Flow:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Args:", "prediction_line": "        Args:", "ground_truth": "        This task also creates the table if it doesn't exist.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            from_path (str, optional): The path to the file on the SFTP server.", "prediction_line": "            from_path (str, optional): The path to the file on the SFTP server.", "ground_truth": "            from_path (str): Path to the file in SFTP server.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.overwrite = overwrite", "prediction_line": "        self.overwrite = overwrite", "ground_truth": "        self.sp_credentials_secret = sp_credentials_secret", "line_class": "random", "zero_context": true}
{"original_prediction": "        adls_credentials_secret: Dict[str, Any] = None,", "prediction_line": "        adls_credentials_secret: Dict[str, Any] = None,", "ground_truth": "        sqldb_credentials_secret: str = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "        from_path: str = None,", "prediction_line": "        from_path: str = None,", "ground_truth": "        from_path: str = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "        )\n\n        upload_to_adls.bind(", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "            try:\n                self.credentials = local_config.get(\"CUSTOMER_GAUGE\")", "prediction_line": "            try:", "ground_truth": "            self.credentials = local_config.get(\"CustomerGauge\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        headers = {", "prediction_line": "        headers = {", "ground_truth": "        client_id = self.credentials.get(\"client_id\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "        client_secret = self.credentials.get(\"client_secret\", None)", "prediction_line": "        client_secret = self.credentials.get(\"client_secret\", None)", "ground_truth": "        client_secret = self.credentials.get(\"client_secret\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "        headers = {\"Authorization\": f\"Bearer {self.get_token()}\"}", "prediction_line": "        headers = {\"Authorization\": f\"Bearer {self.get_token()}\"}", "ground_truth": "        header = {\"Authorization\": f\"Bearer {self.get_token()}\"}", "line_class": "infile", "zero_context": true}
{"original_prediction": "        df = pd.DataFrame(response_json)", "prediction_line": "        df = pd.DataFrame(response_json)", "ground_truth": "        clean_json = list(map(self.properties_cleaning, response_json))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        flatten_json = list(map(self.flatten_json, clean_json))", "prediction_line": "        flatten_json = list(map(self.flatten_json, clean_json))", "ground_truth": "        df = pd.DataFrame(list(map(self.flatten_json, clean_json)))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    flattify(x[a], key + a + \"_\")", "prediction_line": "                    flattify(x[a], key + a + \"_\")", "ground_truth": "                    flattify(x[a], key + a + \"_\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        flattify(json_response)", "prediction_line": "        flattify(json_response)", "ground_truth": "        flattify(json_response)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        api_response = handle_api_response(", "prediction_line": "        api_response = handle_api_response(", "ground_truth": "        api_response = handle_api_response(url=url, headers=header, params=params)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if api_response.status_code == 200:", "prediction_line": "        if api_response.status_code == 200:", "ground_truth": "        response = api_response.json()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise APIError(\"No response from API call.\")", "prediction_line": "            raise APIError(\"No response from API call.\")", "ground_truth": "            raise APIError(\"No response.\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        response = handle_api_response(", "prediction_line": "        response = handle_api_response(", "ground_truth": "        api_response = handle_api_response(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if api_response.status_code == 200:", "prediction_line": "        if api_response.status_code == 200:", "ground_truth": "        token = api_response.json().get(\"access_token\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise APIError(\"Token not returned.\")", "prediction_line": "            raise APIError(\"Token not returned.\")", "ground_truth": "            raise APIError(\"Token is None. Check your credentials.\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                raise CredentialError(", "prediction_line": "                raise CredentialError(", "ground_truth": "                raise CredentialError(\"Credentials not provided.\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        https://docs.customergauge.com/docs/api-gateways", "prediction_line": "        https://docs.customergauge.com/docs/api-gateways", "ground_truth": "            Responses gateway https://support.customergauge.com/support/solutions/articles/5000875861-get-responses", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ".\n        \"\"\"\n        url = f\"{self.API_URL}oauth/token\"", "prediction_line": ".", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            self.credentials = credentials", "prediction_line": "            self.credentials = credentials", "ground_truth": "            self.credentials = credentials", "line_class": "random", "zero_context": true}
{"original_prediction": "                params[\"period[end]\"] = (end_date,)", "prediction_line": "                params[\"period[end]\"] = (end_date,)", "ground_truth": "                params[\"period[end]\"] = end_date", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"client_id\": client_id,", "prediction_line": "            \"client_id\": client_id,", "ground_truth": "            \"client_id\": client_id,", "line_class": "random", "zero_context": true}
{"original_prediction": "                    f\"Incorrect endpoint provided. Please choose between 'responses' or 'non-responses'\"", "prediction_line": "                    f\"Incorrect endpoint provided. Please choose between 'responses' or 'non-responses'\"", "ground_truth": "                    \"Incorrect endpoint name. Choose: 'responses' or 'non-responses'\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        date_from: datetime = None,", "prediction_line": "        date_from: datetime = None,", "ground_truth": "        start_date: datetime = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.host = credentials.get(\"host\")", "prediction_line": "        self.host = credentials.get(\"host\")", "ground_truth": "        super().__init__(*args, credentials=credentials, **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self._cursor = None", "prediction_line": "        self._cursor = None", "ground_truth": "        DEFAULT_CREDENTIALS = local_config.get(\"SAP\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Resolve a column name to its alias if it exists.", "prediction_line": "        \"\"\"", "ground_truth": "        return self.aliases_keyed_by_columns.get(column, column)", "line_class": "common", "zero_context": true}
{"original_prediction": "        result = self.con.call(\"RFC_READ_TABLE\", **params)", "prediction_line": "        result = self.con.call(\"RFC_READ_TABLE\", **params)", "ground_truth": "        delimiter = self._query.get(\"DELIMITER\")", "line_class": "common", "zero_context": true}
{"original_prediction": "       self.extract_values(sql)", "prediction_line": "       self.extract_values(sql)", "ground_truth": "        self.extract_values(sql)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.table_name = self._get_table_name(sql)", "prediction_line": "        self.table_name = self._get_table_name(sql)", "ground_truth": "        table_name = self._get_table_name(sql)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    where_uppercased = get_where_uppercased(where)", "prediction_line": "    where_uppercased = get_where_uppercased(where)", "ground_truth": "    where = get_where_uppercased(where)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.query_dict = {", "prediction_line": "        self.query_dict = {", "ground_truth": "        limit = self._get_limit(sql)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        offset = self._get_offset(sql)", "prediction_line": "        offset = self._get_offset(sql)", "ground_truth": "        offset = self._get_offset(sql)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return where", "prediction_line": "        return where", "ground_truth": "        where_sanitized = remove_whitespaces(where)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return where_sanitized", "prediction_line": "        return where_sanitized", "ground_truth": "        where_trimmed, client_side_filters = trim_where(where_sanitized)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.con.call(func, *args, **kwargs)", "prediction_line": "        return self.con.call(func, *args, **kwargs)", "ground_truth": "        return self.con.call(func, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "clause until it's 75 characters or less", "prediction_line": "clause until it's 75 characters or less", "ground_truth": "        where_trimmed, removed_condition = remove_last_condition(where_trimmed)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        keyword = get_keyword_for_condition(where, removed_condition)", "prediction_line": "        keyword = get_keyword_for_condition(where, removed_condition)", "ground_truth": "        keyword = get_keyword_for_condition(where, removed_condition)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                continue\n            keyword, condition = f", "prediction_line": "                continue", "ground_truth": "                query = f[1]", "line_class": "infile", "zero_context": true}
{"original_prediction": "                query = f\"{query} AND {f[1]}\"", "prediction_line": "                query = f\"{query} AND {f[1]}\"", "ground_truth": "                query += \" \" + f[0] + \" \" + f[1]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if filter_column_name.upper() == \"LIKE\":", "prediction_line": "            if filter_column_name.upper() == \"LIKE\":", "ground_truth": "            resolved_column_name = self._resolve_col_name(filter_column_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if resolved_column_name != filter_column_name:", "prediction_line": "            if resolved_column_name != filter_column_name:", "ground_truth": "        query = query.replace(\"=\", \"==\").replace(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return query", "prediction_line": "        return query", "ground_truth": "        return query", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.logger.info(\"Extracting values...\")", "prediction_line": "        self.logger.info(\"Extracting values...\")", "ground_truth": "        self.where = self._get_where_condition(sql)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.table_name = self._get_table_name(sql)", "prediction_line": "        self.table_name = self._get_table_name(sql)", "ground_truth": "        self.select_columns = self._get_columns(sql, aliased=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.table_name = self._get_table_name(sql)", "prediction_line": "        self.table_name = self._get_table_name(sql)", "ground_truth": "        self.select_columns_aliased = self._get_columns(sql, aliased=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    result = self.con.call(\"RFC_READ_TABLE\", **self._query)", "prediction_line": "                    result = self.con.call(\"RFC_READ_TABLE\", **self._query)", "ground_truth": "                    response = self.call(\"RFC_READ_TABLE\", **params)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            # In case the WHERE clause is > 75 characters long, we execute the rest of the filters", "prediction_line": "            # In case the WHERE clause is > 75 characters long, we execute the rest of the filters", "ground_truth": "            filter_query = self._build_pandas_filter_query(self.client_side_filters)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            df = df.query(filter_query)", "prediction_line": "            df = df.query(filter_query)", "ground_truth": "            df.query(filter_query, inplace=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self._get_alias(col) for col in self._get_client_side_filter_cols()", "prediction_line": "                self._get_alias(col) for col in self._get_client_side_filter_cols()", "ground_truth": "                self._get_alias(col) for col in self._get_client_side_filter_cols()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._con = pyrfc.Connection(**self.credentials)", "prediction_line": "        self._con = pyrfc.Connection(**self.credentials)", "ground_truth": "        con = pyrfc.Connection(**self.credentials)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._con = con", "prediction_line": "        self._con = con", "ground_truth": "        self._con = con", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return con", "prediction_line": "        return con", "ground_truth": "        return con", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.con.ping()", "prediction_line": "        self.con.ping()", "ground_truth": "        self.con.ping()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Get the parameters of a function.", "prediction_line": "        \"\"\"", "ground_truth": "        descr = self.con.get_function_description(function_name, *args)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            raise CredentialError(", "prediction_line": "            raise CredentialError(", "ground_truth": "            raise CredentialError(\"Missing credentials.\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return parsed.tables[0]", "prediction_line": "        return parsed.tables[0]", "ground_truth": "        if len(parsed.tables) > 1:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return parsed.tables[0]", "prediction_line": "        return parsed.tables[0]", "ground_truth": "        return parsed.tables[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def _get_client_side_filter_query(self):", "prediction_line": "    def _get_client_side_filter_query(self):", "ground_truth": "    def to_df(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.table_name = table_name", "prediction_line": "        self.table_name = table_name", "ground_truth": "        # this has to be called before checking client_side_filters", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def _resolve_col_name(self, col_name: str) -> str:", "prediction_line": "    def _resolve_col_name(self, col_name: str) -> str:", "ground_truth": "    def extract_values(self, sql: str) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        where_trimmed, condition_to_remove = remove_last_condition(where_trimmed)", "prediction_line": "        where_trimmed, condition_to_remove = remove_last_condition(where_trimmed)", "ground_truth": "        # trim the where", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Parameters\n        ----------", "prediction_line": "        Parameters", "ground_truth": "        Args:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            return \"\"", "prediction_line": "            return \"\"", "ground_truth": "            return None", "line_class": "random", "zero_context": true}
{"original_prediction": "            else:\n                raise ValueError(", "prediction_line": "            else:", "ground_truth": "            else:", "line_class": "random", "zero_context": true}
{"original_prediction": "       self.extract_values(sql)", "prediction_line": "       self.extract_values(sql)", "ground_truth": "        if not sql.strip().upper().startswith(\"SELECT\"):", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"direction\": param[\"direction\"],", "prediction_line": "                \"direction\": param[\"direction\"],", "ground_truth": "                \"optional\": param[\"optional\"],", "line_class": "random", "zero_context": true}
{"original_prediction": "        if self._con is None:", "prediction_line": "        if self._con is None:", "ground_truth": "        if self._con is not None:", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(*args, **kwargs)", "prediction_line": "        super().__init__(*args, **kwargs)", "ground_truth": "        super().__init__(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return self.run(*args, **kwargs)", "prediction_line": "        return self.run(*args, **kwargs)", "ground_truth": "        return super().__call__(*args, **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    item_params_dict.update(item_parameter)", "prediction_line": "                    item_params_dict.update(item_parameter)", "ground_truth": "                    item_params_dict.update(item_parameter)", "line_class": "common", "zero_context": true}
{"original_prediction": "                almost_full.update(item_params_dict)", "prediction_line": "                almost_full.update(item_params_dict)", "ground_truth": "                almost_full.update(item_params_dict)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    ship_dict.update(ship_parameter)", "prediction_line": "                    ship_dict.update(ship_parameter)", "ground_truth": "                    ship_dict.update(ship_parameter)", "line_class": "common", "zero_context": true}
{"original_prediction": "                result_shipto = ShipToAddress(**ship_dict)", "prediction_line": "                result_shipto = ShipToAddress(**ship_dict)", "ground_truth": "                almost_full.update(ship_dict)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    invoice_dict.update(invoice_parameter)", "prediction_line": "                    invoice_dict.update(invoice_parameter)", "ground_truth": "                    invoice_dict.update(invoice_parameter)", "line_class": "common", "zero_context": true}
{"original_prediction": "                almost_full.update(invoice_dict)", "prediction_line": "                almost_full.update(invoice_dict)", "ground_truth": "                almost_full.update(invoice_dict)", "line_class": "common", "zero_context": true}
{"original_prediction": "                header_params_dict.update(header_parameter)", "prediction_line": "                header_params_dict.update(header_parameter)", "ground_truth": "                header_params_dict.update(header_parameter)", "line_class": "common", "zero_context": true}
{"original_prediction": "            almost_full.update(header_params_dict)", "prediction_line": "            almost_full.update(header_params_dict)", "ground_truth": "            almost_full.update(header_params_dict)", "line_class": "common", "zero_context": true}
{"original_prediction": "                ship_dict[header.tag] = result_numbers", "prediction_line": "                ship_dict[header.tag] = result_numbers", "ground_truth": "                almost_full.update(result_numbers)", "line_class": "common", "zero_context": true}
{"original_prediction": "    InvoiceDueDate: Optional[str]", "prediction_line": "    InvoiceDueDate: Optional[str]", "ground_truth": "    ShipToAddress: Optional[List[Any]]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    BillToAddress: Optional[List[Any]]", "prediction_line": "    BillToAddress: Optional[List[Any]]", "ground_truth": "    TrackingNumbers: Optional[List[Any]]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ShipToAddressDescription: Optional[str]", "prediction_line": "    ShipToAddressDescription: Optional[str]", "ground_truth": "    InvoiceTotals: Optional[List[Any]]", "line_class": "infile", "zero_context": true}
{"original_prediction": "                ship_dict[header.find(\"ShippingWarehouse\").text] = numbers", "prediction_line": "                ship_dict[header.find(\"ShippingWarehouse\").text] = numbers", "ground_truth": "                result_numbers = TrackingNumbers(TrackingNumber=numbers)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                for invoice_param in InvoiceTotals.__dict__.get(\"__annotations__\"):", "prediction_line": "                for invoice_param in InvoiceTotals.__dict__.get(\"__annotations__\"):", "ground_truth": "                for invoice_param in InvoiceTotals.__dict__.get(\"__annotations__\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        df = parse_orders_xml(data)", "prediction_line": "        df = parse_orders_xml(data)", "ground_truth": "        df = parse_orders_xml(data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for header_param in HeaderInformation.__dict__.get(\"__annotations__\"):", "prediction_line": "            for header_param in HeaderInformation.__dict__.get(\"__annotations__\"):", "ground_truth": "            for header_param in HeaderInformation.__dict__.get(\"__annotations__\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    LineItemDetail: Optional[List[LineItemDetail]]", "prediction_line": "    LineItemDetail: Optional[List[LineItemDetail]]", "ground_truth": "    LineItemDetail: Optional[LineItemDetail]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    HeaderInformation: Optional[HeaderInformation]", "prediction_line": "    HeaderInformation: Optional[HeaderInformation]", "ground_truth": "    HeaderInformation: Optional[HeaderInformation]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ShipToAddress: Optional[ShipToAddress]", "prediction_line": "    ShipToAddress: Optional[ShipToAddress]", "ground_truth": "    LineItemDetails: Optional[LineItemDetails]", "line_class": "infile", "zero_context": true}
{"original_prediction": "                for item_param in LineItemDetail.__dict__.get(\"__annotations__\"):", "prediction_line": "                for item_param in LineItemDetail.__dict__.get(\"__annotations__\"):", "ground_truth": "                for item_param in LineItemDetail.__dict__.get(\"__annotations__\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                ship_to_number = \"\"", "prediction_line": "                ship_to_number = \"\"", "ground_truth": "                for ship_param in ShipToAddress.__dict__.get(\"__annotations__\"):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    Order: Optional[Order]", "prediction_line": "    Order: Optional[Order]", "ground_truth": "    Order: Optional[List[Any]]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            base_url (str, required):", "prediction_line": "            base_url (str, required):", "ground_truth": "            name (str): The name of the flow.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    @defaults_from_attrs(", "prediction_line": "    @defaults_from_attrs(", "ground_truth": "    def __call__(self, *args, **kwargs):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            filters_xml (str, required): XML string containing filters for Epicor Orders.", "prediction_line": "            filters_xml (str, required): XML string containing filters for Epicor Orders.", "ground_truth": "            filters_xml (str, required): Filters in form of XML. The date filter is necessary.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class InvoiceTotals(BaseModel):", "prediction_line": "class InvoiceTotals(BaseModel):", "ground_truth": "class TrackingNumbers(BaseModel):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    except:", "prediction_line": "                    except:", "ground_truth": "                    except:", "line_class": "random", "zero_context": true}
{"original_prediction": "    CustomerAddress1: Optional[str]", "prediction_line": "    CustomerAddress1: Optional[str]", "ground_truth": "    CustomerPurchaseOrderNumber: Optional[str]", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.filters_xml = filters_xml", "prediction_line": "        self.filters_xml = filters_xml", "ground_truth": "        self.filters_xml = filters_xml", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.base_url = base_url", "prediction_line": "        self.base_url = base_url", "ground_truth": "        self.base_url = base_url", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.start_date_field = start_date_field", "prediction_line": "        self.start_date_field = start_date_field", "ground_truth": "        self.start_date_field = start_date_field", "line_class": "random", "zero_context": true}
{"original_prediction": "        if self.params:", "prediction_line": "        if self.params:", "ground_truth": "        super().__init__(*args, **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    data_dictionary[\"label\"], name=\"label\"", "prediction_line": "                    data_dictionary[\"label\"], name=\"label\"", "ground_truth": "                    str(data_dictionary[\"label\"]), index=data_frame.index, name=\"label\"", "line_class": "common", "zero_context": true}
{"original_prediction": "                    index=data_frame.index,", "prediction_line": "                    index=data_frame.index,", "ground_truth": "                    index=data_frame.index,", "line_class": "common", "zero_context": true}
{"original_prediction": "                for signal_index, signal_label in zip(", "prediction_line": "                for signal_index, signal_label in zip(", "ground_truth": "                index = str(", "line_class": "common", "zero_context": true}
{"original_prediction": "                geo = col_label", "prediction_line": "                geo = col_label", "ground_truth": "                if index in eurostat_dictionary[\"value\"].keys():", "line_class": "common", "zero_context": true}
{"original_prediction": "                    col_signal_temp.append(col_label)", "prediction_line": "                    col_signal_temp.append(col_label)", "ground_truth": "                    index_list.append(index)", "line_class": "common", "zero_context": true}
{"original_prediction": "                self.logger.error(", "prediction_line": "                self.logger.error(", "ground_truth": "                self.make_params_validation()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                data_frame = self.eurostat_dictionary_to_df(", "prediction_line": "                data_frame = self.eurostat_dictionary_to_df(", "ground_truth": "                data_frame = self.eurostat_dictionary_to_df(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            # get the list of keys for the signal", "prediction_line": "            # get the list of keys for the signal", "ground_truth": "            signal_struct = T_SIGNAL()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            # Validation of keys", "prediction_line": "            # Validation of keys", "ground_truth": "            key_codes = self.get_parameters_codes()", "line_class": "infile", "zero_context": true}
{"original_prediction": "response\n            response = self.get_response(self.url)", "prediction_line": "response", "ground_truth": "            response = handle_api_response(self.url)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                data_dictionary = response.json()", "prediction_line": "                data_dictionary = response.json()", "ground_truth": "                data_dictionary = response.json()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.make_params_validation()", "prediction_line": "                self.make_params_validation()", "ground_truth": "                response = handle_api_response(self.url, params=self.params)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # get list of parameters", "prediction_line": "            # get list of parameters", "ground_truth": "            data = response.json()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "The parameters that we would like to use to filter the data.", "prediction_line": "The parameters that we would like to use to filter the data.", "ground_truth": "                A dictionary with optional URL parameters. The key represents the parameter id, while the value is the code", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        self.dataset_code = dataset_code", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "           params_codes = {}", "prediction_line": "           params_codes = {}", "ground_truth": "            # Assigning list of available codes to specific parameters", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        table_code: str,", "prediction_line": "        table_code: str,", "ground_truth": "        params: dict = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "            signal_time_list: list", "prediction_line": "            signal_time_list: list", "ground_truth": "            signal_name: str", "line_class": "random", "zero_context": true}
{"original_prediction": "       self.dataset_code = dataset_code", "prediction_line": "       self.dataset_code = dataset_code", "ground_truth": "        self.dataset_code = dataset_code", "line_class": "random", "zero_context": true}
{"original_prediction": "                for k, v in key_codes.items()", "prediction_line": "                for k, v in key_codes.items()", "ground_truth": "                for k, v in key_codes.items()", "line_class": "random", "zero_context": true}
{"original_prediction": "                last_updated__col = pd.Series(", "prediction_line": "                last_updated__col = pd.Series(", "ground_truth": "                last_updated__col = pd.Series(", "line_class": "random", "zero_context": true}
{"original_prediction": "       self.download_live_image(os.path.join(consts.BASE_IMAGE_FOLDER, EMBED_IMAGE_NAME))", "prediction_line": "       self.download_live_image(os.path.join(consts.BASE_IMAGE_FOLDER, EMBED_IMAGE_NAME))", "ground_truth": "        self.download_live_image(f\"{BUILD_DIR}/installer-image.iso\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "                lambda: self.all_operators_up(),", "prediction_line": "                lambda: self.all_operators_up(),", "ground_truth": "                self.all_operators_up, sleep_seconds=20, timeout_seconds=60 * 60, waiting_for=\"all operators to get up\"", "line_class": "infile", "zero_context": true}
{"original_prediction": "        logging.info(\"Filling install-config.yaml\")", "prediction_line": "        logging.info(\"Filling install-config.yaml\")", "ground_truth": "        yaml.add_representer(str, self.str_presenter)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.log_collection(vm_ip)", "prediction_line": "            self.log_collection(vm_ip)", "ground_truth": "            self.log_collection(vm_ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.installer_gather(vm_ip, os.environ[\"SSH_PRIVATE_KEY\"], INSTALLER_GATHER_DIR)", "prediction_line": "            self.installer_gather(vm_ip, os.environ[\"SSH_PRIVATE_KEY\"], INSTALLER_GATHER_DIR)", "ground_truth": "            self.installer_gather(ip=vm_ip, ssh_key=consts.DEFAULT_SSH_PRIVATE_KEY_PATH, out_dir=INSTALLER_GATHER_DIR)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.installer_generate(openshift_release_image)", "prediction_line": "        self.installer_generate(openshift_release_image)", "ground_truth": "        self.installer_generate(openshift_release_image)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        utils.run_command_with_output(", "prediction_line": "        utils.run_command_with_output(", "ground_truth": "        utils.run_command_with_output(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            worker_memory=45 * 1024,  # in megabytes", "prediction_line": "            worker_memory=45 * 1024,  # in megabytes", "ground_truth": "            bootstrap_in_place=True,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        utils.run_command_with_output(", "prediction_line": "        utils.run_command_with_output(", "ground_truth": "        os.remove(embedded_image) if os.path.exists(embedded_image) else None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.fill_install_config(", "prediction_line": "        self.fill_install_config(", "ground_truth": "        self.fill_install_config(os.environ[\"PULL_SECRET\"], os.environ[\"SSH_PUB_KEY\"], net_asset, cluster_name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        os.makedirs(IBIP_DIR, exist_ok=True)", "prediction_line": "        os.makedirs(IBIP_DIR, exist_ok=True)", "ground_truth": "        utils.recreate_folder(consts.BASE_IMAGE_FOLDER, force_recreate=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        utils.recreate_folder(IBIP_DIR, force_recreate=True)", "prediction_line": "        utils.recreate_folder(IBIP_DIR, force_recreate=True)", "ground_truth": "        utils.recreate_folder(IBIP_DIR, with_chmod=False, force_recreate=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        controller.start_all_nodes()", "prediction_line": "        controller.start_all_nodes()", "ground_truth": "        controller.start_all_nodes()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        cluster_name = ClusterName(request.node.name)", "prediction_line": "        cluster_name = ClusterName(request.node.name)", "ground_truth": "        return ClusterConfig(cluster_name=ClusterName(prefix=\"test-infra-cluster\", suffix=\"\"))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        shutil.copy(embedded_image, image_path)", "prediction_line": "        shutil.copy(embedded_image, image_path)", "ground_truth": "        shutil.move(embedded_image, image_path)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        controller.start_all_nodes()", "prediction_line": "        controller.start_all_nodes()", "ground_truth": "        controller.image_path = image_path", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        logging.info(\"Waiting for installation to complete\")", "prediction_line": "        logging.info(\"Waiting for installation to complete\")", "ground_truth": "        vm_ip = controller.master_ips[0][0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.embed(", "prediction_line": "        self.embed(", "ground_truth": "        image_path = self.embed(\"installer-image.iso\", \"bootstrap-in-place-for-live-iso.ign\", EMBED_IMAGE_NAME)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    @JunitTestCase()", "prediction_line": "    @JunitTestCase()", "ground_truth": "        os.remove(bundle_file_path) if os.path.exists(bundle_file_path) else None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            workers_count=0,", "prediction_line": "            workers_count=0,", "ground_truth": "            workers_count=0,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            utils.configure_etc_hosts(vm_ip, consts.TEST_INFRA_CLUSTER_NAME)", "prediction_line": "            utils.configure_etc_hosts(vm_ip, consts.TEST_INFRA_CLUSTER_NAME)", "ground_truth": "            utils.config_etc_hosts(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        utils.run_command_with_output(", "prediction_line": "        utils.run_command_with_output(", "ground_truth": "        # TODO: enable fetching the appropriate rhcos image", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def create_cluster(self, cluster_name: str, cluster_config: ClusterConfig, terraform_config: TerraformConfig):", "prediction_line": "    def create_cluster(self, cluster_name: str, cluster_config: ClusterConfig, terraform_config: TerraformConfig):", "ground_truth": "    def embed(self, image_name: str, ignition_file: str, embed_image_name: str) -> str:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import sys\nimport time", "prediction_line": "import sys", "ground_truth": "import re", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            f\"--ignition-file {ignition_file} \"", "prediction_line": "            f\"--ignition-file {ignition_file} \"", "ground_truth": "            f\"-f --ignition-file /data/{IBIP_DIR}/{ignition_file} -o /data/{embedded_image}\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        return dumper.represent_str(data)", "prediction_line": "        return dumper.represent_str(data)", "ground_truth": "        return dumper.represent_scalar(\"tag:yaml.org,2002:str\", data)", "line_class": "random", "zero_context": true}
{"original_prediction": "                return False\n            return all(status.available for status in statuses)", "prediction_line": "                return False", "ground_truth": "                logging.debug(\"No operator has been found currently...\")", "line_class": "random", "zero_context": true}
{"original_prediction": "            raise Exception(\"Failed to find logs captured here in installer gather output\")", "prediction_line": "            raise Exception(\"Failed to find logs captured here in installer gather output\")", "ground_truth": "            logging.warning(f\"It seems like installer-gather didn't generate any bundles, stderr: {stderr}\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        )\n\n    @JunitTestCase()", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "            lambda: wait_till_all_hosts_are_in_status(", "prediction_line": "            lambda: wait_till_all_hosts_are_in_status(", "ground_truth": "            lambda: self.are_libvirt_nodes_in_cluster_hosts(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        nodes = self.get_ocp_cluster_nodes(kubeconfig)", "prediction_line": "        nodes = self.get_ocp_cluster_nodes(kubeconfig)", "ground_truth": "        csrs = self.get_ocp_cluster_csrs(kubeconfig)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Wait for day2 nodes to be in installed status", "prediction_line": "        # Wait for day2 nodes to be in installed status", "ground_truth": "        self.set_nodes_hostnames_if_needed(tf_network_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            lambda: self.get_ocp_cluster_ready_nodes_num(kubeconfig) == ocp_ready_nodes + num_nodes_to_wait,", "prediction_line": "            lambda: self.get_ocp_cluster_ready_nodes_num(kubeconfig) == ocp_ready_nodes + num_nodes_to_wait,", "ground_truth": "            lambda: self.wait_nodes_join_ocp_cluster(ocp_ready_nodes, self.config.day2_workers_count, kubeconfig),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        tfvars[\"libvirt_network_if\"] = self.config.libvirt_network_if", "prediction_line": "        tfvars[\"libvirt_network_if\"] = self.config.libvirt_network_if", "ground_truth": "        self.configure_terraform_workers_nodes(tfvars, num_worker_nodes)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       self.set_cluster_hostnames(cluster.id)", "prediction_line": "       self.set_cluster_hostnames(cluster.id)", "ground_truth": "        self.config_etc_hosts(api_vip_ip, api_vip_dnsname)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        tfvars[\"libvirt_worker_memory\"] = self.config.libvirt_worker_memory", "prediction_line": "        tfvars[\"libvirt_worker_memory\"] = self.config.libvirt_worker_memory", "ground_truth": "        self.set_workers_addresses_by_type(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.config.tf_folder = os.path.join(self.config.tf_folder, self.config.cluster_id)", "prediction_line": "        self.config.tf_folder = os.path.join(self.config.tf_folder, self.config.cluster_id)", "ground_truth": "        self.configure_terraform(self.config.tf_folder, self.config.day2_workers_count, api_vip_ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.api_client.install_all(self.config.cluster_id, kubeconfig)", "prediction_line": "        self.api_client.install_all(self.config.cluster_id, kubeconfig)", "ground_truth": "        ocp_ready_nodes = self.get_ocp_cluster_ready_nodes_num(kubeconfig)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        ocp_nodes = self.get_ocp_cluster_nodes(kubeconfig)", "prediction_line": "        ocp_nodes = self.get_ocp_cluster_nodes(kubeconfig)", "ground_truth": "        self.approve_workers_on_ocp_cluster(kubeconfig)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        ocp_ready_nodes = self.get_ocp_cluster_ready_nodes_num(kubeconfig)", "prediction_line": "        ocp_ready_nodes = self.get_ocp_cluster_ready_nodes_num(kubeconfig)", "ground_truth": "        return self.get_ocp_cluster_ready_nodes_num(kubeconfig) == num_orig_nodes + num_new_nodes", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.set_hosts_roles()", "prediction_line": "        self.set_hosts_roles()", "ground_truth": "        utils.recreate_folder(consts.IMAGE_FOLDER, force_recreate=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            worker_ips_list = []", "prediction_line": "            worker_ips_list = []", "ground_truth": "            worker_ips_list = old_worker_ips_list + utils.create_empty_nested_list(num_worker_nodes)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ingress_vip_dnsname = \"ingress.\" + self.config.day1_cluster_name + \".\" + cluster.base_dns_domain", "prediction_line": "        ingress_vip_dnsname = \"ingress.\" + self.config.day1_cluster_name + \".\" + cluster.base_dns_domain", "ground_truth": "        api_vip_ip = cluster.api_vip", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.generate_image(", "prediction_line": "        self.generate_image(", "ground_truth": "        infra_env = self.api_client.create_infra_env(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for node in libvirt_nodes:", "prediction_line": "            for node in libvirt_nodes:", "ground_truth": "            utils.update_hosts(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.config.day2_cluster_id = cluster.id", "prediction_line": "        self.config.day2_cluster_id = cluster.id", "ground_truth": "        self.config.cluster_id = cluster.id", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.api_client.install_all(self.config.cluster_id)", "prediction_line": "        self.api_client.install_all(self.config.cluster_id)", "ground_truth": "        kubeconfig = utils.get_kubeconfig_path(self.config.day1_cluster_name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       tf_network_cidr = tfvars[\"libvirt_network_cidr\"]", "prediction_line": "       tf_network_cidr = tfvars[\"libvirt_network_cidr\"]", "ground_truth": "        config = TerraformConfig()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        utils.download_file(iso_download_url, image_path)", "prediction_line": "        utils.download_file(iso_download_url, image_path)", "ground_truth": "        log.info(f\"Downloading image {iso_download_url} to {image_path}\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        worker_mac_addresses = old_worker_mac_addresses + utils.create_mac_addresses_nested_list(num_worker_nodes)", "prediction_line": "        worker_mac_addresses = old_worker_mac_addresses + utils.create_mac_addresses_nested_list(num_worker_nodes)", "ground_truth": "        tfvars[worker_mac_type] = old_worker_mac_addresses + static_network.generate_macs(num_worker_nodes)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        config.platform = consts.Platforms.BARE_METAL", "prediction_line": "        config.platform = consts.Platforms.BARE_METAL", "ground_truth": "        config.nodes_count = num_nodes_to_wait", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.config.libvirt_controller.start_cluster(cluster_name)", "prediction_line": "                self.config.libvirt_controller.start_cluster(cluster_name)", "ground_truth": "                utils.run_command(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.config.day2_cluster_id = cluster.get(\"id\")", "prediction_line": "        self.config.day2_cluster_id = cluster.get(\"id\")", "ground_truth": "        self.config.day1_cluster_name = cluster.name", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.api_client = api_client", "prediction_line": "        self.api_client = api_client", "ground_truth": "        self.api_client = api_client", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return len([node for node in nodes if self.is_ocp_node_ready(node[\"status\"])])", "prediction_line": "        return len([node for node in nodes if self.is_ocp_node_ready(node[\"status\"])])", "ground_truth": "        return len([node for node in nodes if self.is_ocp_node_ready(node[\"status\"])])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def are_libvirt_nodes_in_cluster_hosts(self):", "prediction_line": "    def are_libvirt_nodes_in_cluster_hosts(self):", "ground_truth": "    def get_ocp_cluster_nodes(self, kubeconfig: str):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from assisted_service_client import ApiClient, InventoryClient, models", "prediction_line": "from assisted_service_client import ApiClient, InventoryClient, models", "ground_truth": "from assisted_test_infra.test_infra import utils", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def configure_terraform_workers_nodes(self, tfvars: dict, num_worker_nodes: int):", "prediction_line": "    def configure_terraform_workers_nodes(self, tfvars: dict, num_worker_nodes: int):", "ground_truth": "    def configure_terraform_workers_nodes(self, tfvars: Any, num_worker_nodes: int):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        log.info(f\"Starting installation of {cluster_name}\")", "prediction_line": "        log.info(f\"Starting installation of {cluster_name}\")", "ground_truth": "        # Running twice as a workaround for an issue with terraform not spawning a new node on first apply.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def set_nodes_hostnames_if_needed(self, network_name: str):", "prediction_line": "    def set_nodes_hostnames_if_needed(self, network_name: str):", "ground_truth": "    def config_etc_hosts(self, api_vip_ip: str, api_vip_dnsname: str):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        )\n        self.config.infra_env_id = infra_env.id", "prediction_line": "        )", "ground_truth": "            pull_secret=self.config.pull_secret,", "line_class": "random", "zero_context": true}
{"original_prediction": "    ):\n        master_ips = tfvars[master_ip_type]", "prediction_line": "    ):", "ground_truth": "    ):", "line_class": "random", "zero_context": true}
{"original_prediction": "        hosts = self.api_client.get_cluster_hosts(self.config.cluster_id)", "prediction_line": "        hosts = self.api_client.get_cluster_hosts(self.config.cluster_id)", "ground_truth": "        try:", "line_class": "random", "zero_context": true}
{"original_prediction": "            )\n\n        self.config.day2_cluster_config = ClusterConfig(", "prediction_line": "            )", "ground_truth": "            )", "line_class": "random", "zero_context": true}
{"original_prediction": "        with open(\"/etc/hosts\", \"w\") as f:", "prediction_line": "        with open(\"/etc/hosts\", \"w\") as f:", "ground_truth": "        with open(\"/etc/hosts\", \"w\") as f:", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(config, cluster_config)", "prediction_line": "        super().__init__(config, cluster_config)", "ground_truth": "        super().__init__(config, cluster_config)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return self._get_vm(node_name)[\"attributes\"][\"memory_size_mib\"]", "prediction_line": "        return self._get_vm(node_name)[\"attributes\"][\"memory_size_mib\"]", "ground_truth": "        return self._get_vm(node_name)[\"attributes\"][\"memory_size_mib\"] * 1024", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.set_boot_order(node, self._entity_config.boot_order)", "prediction_line": "            self.set_boot_order(node, self._entity_config.boot_order)", "ground_truth": "            self.set_boot_order(node.name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        vm = self._get_nutanix_vm(node_name)", "prediction_line": "        vm = self._get_nutanix_vm(node_name)", "ground_truth": "        vm = self._get_nutanix_vm(tf_vm_name=node_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        vm = self._get_vm(node_name)", "prediction_line": "        vm = self._get_vm(node_name)", "ground_truth": "        vm_attributes = self._get_vm(node_name)[\"attributes\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.start_node(node.name, check_ips=False)", "prediction_line": "            self.start_node(node.name, check_ips=False)", "ground_truth": "            self.start_node(node.name, check_ips=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return nodes", "prediction_line": "        return nodes", "ground_truth": "        return self.list_nodes()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._get_vm(node_name)", "prediction_line": "        self._get_vm(node_name)", "ground_truth": "        vm = self._get_nutanix_vm(node_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        tf_vms = self._get_tf_vms()", "prediction_line": "        tf_vms = self._get_tf_vms()", "ground_truth": "        return next((vm for vm in self._get_tf_vms() if vm[\"attributes\"][\"name\"] == node_name), None)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.shutdown_node(node.name)", "prediction_line": "            self.shutdown_node(node.name)", "ground_truth": "            self.shutdown_node(node.name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        tf_vms = self._tf.get_all_vms()", "prediction_line": "        tf_vms = self._tf.get_all_vms()", "ground_truth": "        tf_vms = self._get_tf_vms()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        vm = self._get_nutanix_vm(node_name)", "prediction_line": "        vm = self._get_nutanix_vm(node_name)", "ground_truth": "        return self._get_vm(node_name)[\"attributes\"][\"num_sockets\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._tf.init_and_apply(config)", "prediction_line": "        self._tf.init_and_apply(config)", "ground_truth": "        self._nutanix_client = self._create_nutanix_client()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if mac in macs:", "prediction_line": "                if mac in macs:", "ground_truth": "                if mac in macs:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return (\n            [ipaddress.ip_address(ip) for ip in vm_attributes[\"ip_addresses\"]],", "prediction_line": "        return (", "ground_truth": "        ips = []", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        macs = []", "prediction_line": "        macs = []", "ground_truth": "        macs = []", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def list_nodes(self) -> List[Node]:", "prediction_line": "    def list_nodes(self) -> List[Node]:", "ground_truth": "        return nodes", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise ValueError(\"No VMs found in terraform state\")", "prediction_line": "            raise ValueError(\"No VMs found in terraform state\")", "ground_truth": "            return list()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "           macs.append(nic[\"mac_address\"])", "prediction_line": "           macs.append(nic[\"mac_address\"])", "ground_truth": "            macs.append(nic[\"mac_address\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "self._config.base_dns_domain, \"api\", api_ip)", "prediction_line": "self._config.base_dns_domain, \"api\", api_ip)", "ground_truth": "            cluster_name=self.cluster_name,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        pass\n\n    def set_boot_order(self, node_name: str, boot_order: List[str] = None) -> None:", "prediction_line": "        pass", "ground_truth": "        utils.add_dns_record(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self._config = config", "prediction_line": "        self._config = config", "ground_truth": "        self.cluster_name = cluster_config.cluster_name.get()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.terraform = TerraformControllerUtil(folder, self.config.terraform_config_path)", "prediction_line": "        self.terraform = TerraformControllerUtil(folder, self.config.terraform_config_path)", "ground_truth": "        self._tf = terraform_utils.TerraformUtils(working_dir=folder, terraform_init=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return [self._nutanix_vm_to_node(vm) for vm in tf_vms]", "prediction_line": "        return [self._nutanix_vm_to_node(vm) for vm in tf_vms]", "ground_truth": "        return list(map(self._nutanix_vm_to_node, tf_vms))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                ips.append(ips_list[\"ip\"])", "prediction_line": "                ips.append(ips_list[\"ip\"])", "ground_truth": "                ips.append(ips_list[\"ip\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for nutanix_vm in nutanix_vms:", "prediction_line": "        for nutanix_vm in nutanix_vms:", "ground_truth": "        _, macs = self.get_node_ips_and_macs(tf_vm_name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self._tf.destroy()", "prediction_line": "        self._tf.destroy()", "ground_truth": "        self._tf.destroy(force=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self._tf.init()", "prediction_line": "        self._tf.init()", "ground_truth": "        config = {**self._config.get_all(), **self._entity_config.get_all(), \"cluster_name\": self.cluster_name}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def delete_network(self, network_name: str):", "prediction_line": "    def delete_network(self, network_name: str):", "ground_truth": "    def get_network_by_name(self, network_name: str):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def get_node_macs(self, node_name: str) -> List[str]:", "prediction_line": "    def get_node_macs(self, node_name: str) -> List[str]:", "ground_truth": "    def create_network(self, network_xml: str):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def set_boot_order(self, node_name: str, boot_order: List[str] = None) -> None:", "prediction_line": "    def set_boot_order(self, node_name: str, boot_order: List[str] = None) -> None:", "ground_truth": "    def set_boot_order(self, node_name, cd_first=False) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            ingress_ip=ingress_ip,", "prediction_line": "            ingress_ip=ingress_ip,", "ground_truth": "            ingress_ip=ingress_ip,", "line_class": "random", "zero_context": true}
{"original_prediction": "        vm.power_on()", "prediction_line": "        vm.power_on()", "ground_truth": "        vm.power_on()", "line_class": "random", "zero_context": true}
{"original_prediction": "        raise NotImplementedError", "prediction_line": "        raise NotImplementedError", "ground_truth": "        raise NotImplementedError", "line_class": "random", "zero_context": true}
{"original_prediction": "        for ip in nutanix_subnet.free_ip_list:", "prediction_line": "        for ip in nutanix_subnet.free_ip_list:", "ground_truth": "        max_ping_attempts = 30", "line_class": "random", "zero_context": true}
{"original_prediction": "            log.warning(", "prediction_line": "            log.warning(", "ground_truth": "            log.warning(", "line_class": "random", "zero_context": true}
{"original_prediction": "        return self._get_resources_by_kind(name, \"v1\")", "prediction_line": "        return self._get_resources_by_kind(name, \"v1\")", "ground_truth": "        return self.mapping_resources.get(name)", "line_class": "common", "zero_context": true}
{"original_prediction": "        \"\"\"Verify resource replicas count", "prediction_line": "        \"\"\"Verify resource replicas count", "ground_truth": "        resource = self._get_obj_resources_by_name(resource_type, resource_name, exact_match)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.wait_for_pod_change(deployment_name, replicas_count)", "prediction_line": "        self.wait_for_pod_change(deployment_name, replicas_count)", "ground_truth": "        self.wait_for_pod_change(deployment_name, replicas_count)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            logging.info(f\"Rollout assisted service to last configuration {request_node_name}\")", "prediction_line": "            logging.info(f\"Rollout assisted service to last configuration {request_node_name}\")", "ground_truth": "            logging.debug(f\"configmap data {self.configmap_name} changed during {request_node_name} - restoring\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._restart_deployment(self.assisted_service_name)", "prediction_line": "            self._restart_deployment(self.assisted_service_name)", "ground_truth": "            self._restart_deployment(self.assisted_service_name, request_node_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.resource_kind(self.Resources.DEPLOYMENT.value).patch(", "prediction_line": "        self.resource_kind(self.Resources.DEPLOYMENT.value).patch(", "ground_truth": "        self.change_deployment_scale(deployment_name, 0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._restart_deployment(deployment_name)", "prediction_line": "            self._restart_deployment(deployment_name)", "ground_truth": "            self._restart_deployment(deployment_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.change_deployment_scale(deployment_name, 1)", "prediction_line": "        self.change_deployment_scale(deployment_name, 1)", "ground_truth": "        self.change_deployment_scale(deployment_name, 1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       body_value = body_data[body_key]", "prediction_line": "       body_value = body_data[body_key]", "ground_truth": "        resource_obj = self._get_obj_resources_by_name(resource_kind_name, obj_resource_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            logging.debug(f\"configmap data {self.configmap_name} not changed during {request_node_name}\")", "prediction_line": "            logging.debug(f\"configmap data {self.configmap_name} not changed during {request_node_name}\")", "ground_truth": "            logging.info(f\"configmap {self.configmap_name} was not changed during the test {request_node_name}\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "            lambda: self._verify_resource_replicas(resource_name, name, exact_match=True, count=replicas_count),", "prediction_line": "            lambda: self._verify_resource_replicas(resource_name, name, exact_match=True, count=replicas_count),", "ground_truth": "            lambda: self._get_obj_resources_by_name(resource_name, name)[0].spec.replicas == replicas_count,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                pods_are_running,", "prediction_line": "                pods_are_running,", "ground_truth": "                lambda: pods_are_running() is True,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.global_variables.ai_base_version", "prediction_line": "        return self.global_variables.ai_base_version", "ground_truth": "        return self.global_variables.ai_base_version", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.global_variables.get_ingress_namespace()", "prediction_line": "        return self.global_variables.get_ingress_namespace()", "ground_truth": "        return self.global_variables.namespace", "line_class": "infile", "zero_context": true}
{"original_prediction": "        resource_kind = self.resource_kind(resource_kind_name)", "prediction_line": "        resource_kind = self.resource_kind(resource_kind_name)", "ground_truth": "        all_resources = self.resource_kind(resource_kind_name).get(namespace=self.namespace, name=None)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if resource_kind_name == self.Resources.CONFIGMAP.value:", "prediction_line": "        if resource_kind_name == self.Resources.CONFIGMAP.value:", "ground_truth": "        assert self.verify_resource_data_exists(resource_kind_name, name, body), f\"Patch {str(body)} could not found\"", "line_class": "infile", "zero_context": true}
{"original_prediction": "        logging.info(f\"change_deployment_scale deployment_name={deployment_name} replicas_count={replicas_count}\")", "prediction_line": "        logging.info(f\"change_deployment_scale deployment_name={deployment_name} replicas_count={replicas_count}\")", "ground_truth": "        self._verify_resource_replicas(self.Resources.DEPLOYMENT.value, deployment_name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Patch change configuration", "prediction_line": "        # Patch change configuration", "ground_truth": "        self.patch_resource(self.Resources.CONFIGMAP.value, self.configmap_name, body)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self.k8s_client.resources.get(", "prediction_line": "        return self.k8s_client.resources.get(", "ground_truth": "        return self._get_resources_by_kind(self.Resources.CONFIGMAP.value, \"v1\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                pods = self._get_obj_resources_by_name(self.Resources.POD.value, name)", "prediction_line": "                pods = self._get_obj_resources_by_name(self.Resources.POD.value, name)", "ground_truth": "                pods = self._get_obj_resources_by_name(self.Resources.POD.value, name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.wait_for_scale_config_change(self.Resources.REPLICASET.value, deployment_name, replicas_count)", "prediction_line": "        self.wait_for_scale_config_change(self.Resources.REPLICASET.value, deployment_name, replicas_count)", "ground_truth": "        self.wait_for_scale_config_change(self.Resources.REPLICASET.value, deployment_name, replicas_count)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self._get_resources_by_kind(self.Resources.DEPLOYMENT.value, \"apps/v1\")", "prediction_line": "        return self._get_resources_by_kind(self.Resources.DEPLOYMENT.value, \"apps/v1\")", "ground_truth": "        return self._get_resources_by_kind(self.Resources.DEPLOYMENT.value, \"apps/v1\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self.resource_kind(resource_kind_name).patch(name=name, namespace=self.namespace, body=body)", "prediction_line": "        return self.resource_kind(resource_kind_name).patch(name=name, namespace=self.namespace, body=body)", "ground_truth": "        patch = self.resource_kind(resource_kind_name).patch(namespace=self.namespace, name=name, body=body)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        deployments = self.deployment_resource.get(namespace=self.namespace, name=None)", "prediction_line": "        deployments = self.deployment_resource.get(namespace=self.namespace, name=None)", "ground_truth": "        deployments = self.resource_kind(self.Resources.DEPLOYMENT.value).get().items", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                return all(list(map(lambda pod: pod.status.phase == \"Running\", pods)))", "prediction_line": "                return all(list(map(lambda pod: pod.status.phase == \"Running\", pods)))", "ground_truth": "                running = list(map(lambda pod: hasattr(pod.status, \"phase\") and pod.status.phase == \"Running\", pods))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return resource_obj == body", "prediction_line": "        return resource_obj == body", "ground_truth": "        result = all(list(map(lambda key: body[key] == resource_obj[key], body)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        root_key = list(body_data.keys())[0]", "prediction_line": "        root_key = list(body_data.keys())[0]", "ground_truth": "        body_key = list(body_data.keys())[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "for a resource object and verify", "prediction_line": "for a resource object and verify", "ground_truth": "        self.patch_resource(self.Resources.DEPLOYMENT.value, deployment_name, body)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            lambda: self._verify_resource_replicas(self.Resources.POD.value, name, exact_match=False, count=replicas_count),", "prediction_line": "            lambda: self._verify_resource_replicas(self.Resources.POD.value, name, exact_match=False, count=replicas_count),", "ground_truth": "            lambda: len(self._get_obj_resources_by_name(self.Resources.POD.value, name)) == replicas_count,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return patch", "prediction_line": "        return patch", "ground_truth": "        return patch", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self._get_obj_resources_by_name(self.configmap_name).data", "prediction_line": "        return self._get_obj_resources_by_name(self.configmap_name).data", "ground_truth": "        config_map_store = self._get_obj_resources_by_name(self.Resources.CONFIGMAP.value, self.configmap_name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        In case we delete pods (replicas) need to wait for a deleted state", "prediction_line": "        In case we delete pods (replicas) need to wait for a deleted state", "ground_truth": "        :param name: lookup name begins with assisted-service", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        logging.info(f\"wait_for_scale_config_change resource_name={resource_name} name={name} replicas_count={replicas_count}\")", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        :param sleep: interval time to check pods", "prediction_line": "        :param sleep: interval time to check pods", "ground_truth": "        :param sleep: sleep between interval", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"Get resource by api_version and kind", "prediction_line": "        \"\"\"Get resource by api_version and kind", "ground_truth": "        \"\"\"Get object by resource obj by namespace and begins name.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       for deployment in deployments:", "prediction_line": "       for deployment in deployments:", "ground_truth": "        def check_ready_replicas(deployment):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        assert len(resource) == count, f\"{resource_type} {resource_name} should be {count}\"", "prediction_line": "        assert len(resource) == count, f\"{resource_type} {resource_name} should be {count}\"", "ground_truth": "        assert len(resource) == count, f\"{resource_type} repeated {len(resource)} times expected {count}\"", "line_class": "random", "zero_context": true}
{"original_prediction": "                configuration=kubernetes.client.Configuration()", "prediction_line": "                configuration=kubernetes.client.Configuration()", "ground_truth": "                configuration=kubernetes.config.load_kube_config(),", "line_class": "random", "zero_context": true}
{"original_prediction": "    @property\n    def ai_base_image(self) -> str:", "prediction_line": "    @property", "ground_truth": "    @property", "line_class": "random", "zero_context": true}
{"original_prediction": "                sleep_seconds=sleep,", "prediction_line": "                sleep_seconds=sleep,", "ground_truth": "                sleep_seconds=sleep,", "line_class": "random", "zero_context": true}
{"original_prediction": "                f\" name_begins_with={name_begins_with} exact_match={exact_match}\"", "prediction_line": "                f\" name_begins_with={name_begins_with} exact_match={exact_match}\"", "ground_truth": "                f\" name_begins_with={name_begins_with} exact_match={exact_match}\"", "line_class": "random", "zero_context": true}
{"original_prediction": "                encoding=encoding,", "prediction_line": "                encoding=encoding,", "ground_truth": "                encoding={v: encoding.get(v, {})},", "line_class": "common", "zero_context": true}
{"original_prediction": "            fn_out = join(outdir, f\"era5_{var}_{year}_daily.nc\")", "prediction_line": "            fn_out = join(outdir, f\"era5_{var}_{year}_daily.nc\")", "ground_truth": "            fns0 = resample_year(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                fn_out = fn.replace(outdir, ddir)", "prediction_line": "                fn_out = fn.replace(outdir, ddir)", "ground_truth": "                move_replace(fn, join(ddir, var, basename(fn)))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    update_daily_nc(", "prediction_line": "    update_daily_nc(", "ground_truth": "    update_daily_nc(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            move_replace(fn, join(ddir_day, var, basename(fn)))", "prediction_line": "            move_replace(fn, join(ddir_day, var, basename(fn)))", "ground_truth": "            move_replace(fn, join(ddir_day, var, basename(fn)))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    update_hourly_nc(", "prediction_line": "    update_hourly_nc(", "ground_truth": "    update_hourly_nc(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            t0 = get_last_timestep_nc(fns)", "prediction_line": "            t0 = get_last_timestep_nc(fns)", "ground_truth": "            t0 = get_last_timestep_nc(fns)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        update_zarr(", "prediction_line": "        update_zarr(", "ground_truth": "        update_zarr(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if isfile(fn_out):", "prediction_line": "            if isfile(fn_out):", "ground_truth": "            job = dask.delayed(download_era5_year)(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            t1 = get_last_timestep_nc(fns)", "prediction_line": "            t1 = get_last_timestep_nc(fns)", "ground_truth": "            t1 = get_last_timestep_nc(fns)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                            append_zarr(fn_zarr, ds_nc, chunks, **kwargs)", "prediction_line": "                            append_zarr(fn_zarr, ds_nc, chunks, **kwargs)", "ground_truth": "                            append_zarr(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            flatten_era5_temp(fn, nodata=-9999, chunks={\"time\": 30, \"latitude\": 250})", "prediction_line": "            flatten_era5_temp(fn, nodata=-9999, chunks={\"time\": 30, \"latitude\": 250})", "ground_truth": "            flatten_era5_temp(fn, dask_kwargs=dask_kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                dims=_da0.dims,", "prediction_line": "                dims=_da0.dims,", "ground_truth": "                dims=_da0.dims,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "/ 86400", "prediction_line": "/ 86400", "ground_truth": "        dvars[\"tp\"].attrs.update(daily_attrs.get(\"tp\", {}))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                arr.resize(shape)", "prediction_line": "                arr.resize(shape)", "ground_truth": "                zgroup[v].resize(shape)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    for i, dim in enumerate(ds_zarr[var0].dims)", "prediction_line": "                    for i, dim in enumerate(ds_zarr[var0].dims)", "ground_truth": "                    for i, dim in enumerate(ds_zarr[var0].dims)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        dvars[\"tmax\"].attrs.update(daily_attrs.get(\"tmax\", {}))", "prediction_line": "        dvars[\"tmax\"].attrs.update(daily_attrs.get(\"tmax\", {}))", "ground_truth": "        dvars[\"tmax\"].attrs.update(daily_attrs.get(\"tmax\", {}))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                shape[0] = dates.size", "prediction_line": "                shape[0] = dates.size", "ground_truth": "                shape[0] = dates.size", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                arr.resize((dates.size,) + arr.shape[1:])", "prediction_line": "                arr.resize((dates.size,) + arr.shape[1:])", "ground_truth": "                shape = list(arr.shape)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if var in ds_zarr:", "prediction_line": "                if var in ds_zarr:", "ground_truth": "                var0 = var if var in ds_zarr else list(ds_zarr.data_vars.keys())[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    zarr_day = join(root, \"era5_daily.zarr\")", "prediction_line": "    zarr_day = join(root, \"era5_daily.zarr\")", "ground_truth": "    zarr_day = join(root, \"era5_daily.zarr\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                dims=_da0.dims,", "prediction_line": "                dims=_da0.dims,", "ground_truth": "                coords=_da0.coords,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if var in ds_nc:", "prediction_line": "                if var in ds_nc:", "ground_truth": "                if ds_nc[\"time\"].size > 0:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            zgroup[v].resize((ds0[v].size + offset,) + ds0[v].shape[1:])", "prediction_line": "            zgroup[v].resize((ds0[v].size + offset,) + ds0[v].shape[1:])", "ground_truth": "            if append_dim in ds0[v].dims:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ddir_hour = join(root, \"hourly\")", "prediction_line": "    ddir_hour = join(root, \"hourly\")", "ground_truth": "    ddir_hour = join(root, \"era5\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        dvars[\"tmin\"].attrs.update(daily_attrs.get(\"tmin\", {}))", "prediction_line": "        dvars[\"tmin\"].attrs.update(daily_attrs.get(\"tmin\", {}))", "ground_truth": "        dvars[\"tmin\"].attrs.update(daily_attrs.get(\"tmin\", {}))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            ds0[v] = ds[v].chunk(chunks_out)", "prediction_line": "            ds0[v] = ds[v].chunk(chunks_out)", "ground_truth": "            _da0 = ds0[list(ds0.data_vars.keys())[0]]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    variables : list", "prediction_line": "    variables : list", "ground_truth": "    variables : list", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        end date in YYYYMMDD format, by default None and read from last timestep of nc files", "prediction_line": "        end date in YYYYMMDD format, by default None and read from last timestep of nc files", "ground_truth": "        end date in YYYYMMDD format, by default None and read from last timestep of the nc files", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import rioxarray", "prediction_line": "import rioxarray", "ground_truth": "import time", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Download a single year of ERA5 data.", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"Download single ERA5 variable for single year from CDS.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        time period of ERA5T data which is overwritten by new data, by default dt_era5t", "prediction_line": "        time period of ERA5T data which is overwritten by new data, by default dt_era5t", "ground_truth": "        time period of ERA5T data which is overwritten by new data, by default dt_era5t", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            fns.append(fn)", "prediction_line": "            fns.append(fn)", "ground_truth": "            fns.append(fn)", "line_class": "random", "zero_context": true}
{"original_prediction": "            fn_zarr=zarr_day,", "prediction_line": "            fn_zarr=zarr_day,", "ground_truth": "            fn_zarr=zarr_day,", "line_class": "random", "zero_context": true}
{"original_prediction": "            fn_lst.extend(fns0)", "prediction_line": "            fn_lst.extend(fns0)", "ground_truth": "            fn_lst.extend(fns0)", "line_class": "random", "zero_context": true}
{"original_prediction": "    if start_year is None:", "prediction_line": "    if start_year is None:", "ground_truth": "    if end_year:", "line_class": "random", "zero_context": true}
{"original_prediction": "    ddir_hour: str,", "prediction_line": "    ddir_hour: str,", "ground_truth": "    ddir: str,", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(path, driver=driver, crs=crs, nodata=nodata, rename=rename, unit_mult=unit_mult, unit_add=unit_add, units=units, meta=meta, placeholders=placeholders, **kwargs)", "prediction_line": "        super().__init__(path, driver=driver, crs=crs, nodata=nodata, rename=rename, unit_mult=unit_mult, unit_add=unit_add, units=units, meta=meta, placeholders=placeholders, **kwargs)", "ground_truth": "        super().__init__(", "line_class": "commited", "zero_context": true}
{"original_prediction": "                kwargs.pop(\"preprocess\")", "prediction_line": "                kwargs.pop(\"preprocess\")", "ground_truth": "                preprocess = PREPROCESSORS.get(kwargs[\"preprocess\"], None)", "line_class": "common", "zero_context": true}
{"original_prediction": "                if preprocess is None:", "prediction_line": "                if preprocess is None:", "ground_truth": "                kwargs.update(preprocess=preprocess)", "line_class": "common", "zero_context": true}
{"original_prediction": "            mult = self.unit_mult.get(name, 1)", "prediction_line": "            mult = self.unit_mult.get(name, 1)", "ground_truth": "            m = self.unit_mult.get(name, 1)", "line_class": "common", "zero_context": true}
{"original_prediction": "            if time_tuple is None:", "prediction_line": "            if time_tuple is None:", "ground_truth": "            dt = self.unit_add.get(\"time\", 0)", "line_class": "common", "zero_context": true}
{"original_prediction": "                encoding = {", "prediction_line": "                encoding = {", "ground_truth": "                kwargs.update(encoding={k: {\"zlib\": True} for k in dvars})", "line_class": "common", "zero_context": true}
{"original_prediction": "            a = self.unit_add.get(name, 0)", "prediction_line": "            a = self.unit_add.get(name, 0)", "ground_truth": "            a = self.unit_add.get(name, 0)", "line_class": "common", "zero_context": true}
{"original_prediction": "            fn_out = join(data_root, f\"{data_name}.tif\")", "prediction_line": "            fn_out = join(data_root, f\"{data_name}.tif\")", "ground_truth": "            ext = gis_utils.GDAL_EXT_CODE_MAP.get(driver)", "line_class": "common", "zero_context": true}
{"original_prediction": "            # TODO: check if this is the right way to do it", "prediction_line": "            # TODO: check if this is the right way to do it", "ground_truth": "            obj = self.get_data(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if nodata_isnan:", "prediction_line": "            if nodata_isnan:", "ground_truth": "            nodata = np.nan if nodata_isnan else da.raster.nodata", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    ds_out = ds_out.raster.clip(geom, buffer=buffer, align=align)", "prediction_line": "                    ds_out = ds_out.raster.clip(geom, buffer=buffer, align=align)", "ground_truth": "                    ds_out = ds_out.raster.clip_geom(geom, buffer=buffer, align=align)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                ds_out[\"time\"] = ds_out[\"time\"] + np.timedelta64(dt, \"s\")", "prediction_line": "                ds_out[\"time\"] = ds_out[\"time\"] + np.timedelta64(dt, \"s\")", "ground_truth": "                ds_out[\"time\"] = ds_out[\"time\"] + pd.to_timedelta(dt, unit=\"s\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ds_out.attrs.update(self.meta)", "prediction_line": "        ds_out.attrs.update(self.meta)", "ground_truth": "        ds_out.attrs.update(self.meta)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        y_dim = ds_out.raster.y_dim", "prediction_line": "        y_dim = ds_out.raster.y_dim", "ground_truth": "        y_dim = ds_out.raster.y_dim", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            ds_out = io.open_raster_tindex(fns, **kwargs)", "prediction_line": "            ds_out = io.open_raster_tindex(fns, **kwargs)", "ground_truth": "            ds_out = io.open_raster_from_tindex(fns[0], bbox=bbox, geom=geom, **kwargs)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        else:\n            rm = self.rename", "prediction_line": "        else:", "ground_truth": "            if rm.keys() != rm.values():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if x_dim in ds_out.dims and y_dim in ds_out.dims:", "prediction_line": "        if x_dim in ds_out.dims and y_dim in ds_out.dims:", "ground_truth": "        ds_out = ds_out.transpose(..., y_dim, x_dim)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if m != 1 or a != 0:", "prediction_line": "            if m != 1 or a != 0:", "ground_truth": "            data_bool = ~np.isnan(da) if nodata_isnan else da != nodata", "line_class": "inproject", "zero_context": true}
{"original_prediction": "and align\n        if bbox is not None or geom is not None:", "prediction_line": "and align", "ground_truth": "        epsg = ds_out.raster.crs.to_epsg()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "time_tuple is not None) and (time_tuple != ds_out.raster.time_slice):", "prediction_line": "time_tuple is not None) and (time_tuple != ds_out.raster.time_slice):", "ground_truth": "            \"time\" in ds_out.dims", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            geom = gpd.GeoDataFrame(geometry=[box(*bbox)], crs=4326)", "prediction_line": "            geom = gpd.GeoDataFrame(geometry=[box(*bbox)], crs=4326)", "ground_truth": "            w, e = np.asarray(ds_out.raster.bounds)[[0, 2]]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            bbox = gis_utils.reproject_bbox(bbox, epsg, 4326)", "prediction_line": "            bbox = gis_utils.reproject_bbox(bbox, epsg, 4326)", "ground_truth": "            geom = gpd.GeoDataFrame(geometry=[box(*bbox)], crs=4326)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        preprocessors=None,", "prediction_line": "        preprocessors=None,", "ground_truth": "        crs=None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            and time_tuple is not None", "prediction_line": "            and time_tuple is not None", "ground_truth": "            and ds_out[\"time\"].size > 1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Parameters", "prediction_line": "        Parameters", "ground_truth": "        In addition it keeps meta data to be able to reproduce which data is used.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        # TODO: add support for time_tuple", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        ----------", "prediction_line": "        ----------", "ground_truth": "        ----------", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        if driver == \"netcdf\":", "prediction_line": "        if driver == \"netcdf\":", "ground_truth": "        # write using various writers", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            Path to the raster file.", "prediction_line": "            Path to the raster file.", "ground_truth": "            Path to data source. If the dataset consists of multiple files, the path may", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                raise ValueError(", "prediction_line": "                raise ValueError(", "ground_truth": "                raise ValueError(", "line_class": "random", "zero_context": true}
{"original_prediction": "                logger.warning(err)", "prediction_line": "                logger.warning(err)", "ground_truth": "                raise IndexError(err)", "line_class": "random", "zero_context": true}
{"original_prediction": "data?\n        if self.units:", "prediction_line": "data?", "ground_truth": "        for k in self.units:", "line_class": "random", "zero_context": true}
{"original_prediction": "    _DEFAULT_GEO_MAP_COORD = GEO_MAP_COORD", "prediction_line": "    _DEFAULT_GEO_MAP_COORD = GEO_MAP_COORD", "ground_truth": "    _DRIVERS = {", "line_class": "random", "zero_context": true}
{"original_prediction": "        if time_tuple is not None:", "prediction_line": "        if time_tuple is not None:", "ground_truth": "        if (", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(path, driver=driver, crs=crs, nodata=nodata, rename=rename, unit_mult=unit_mult, unit_add=unit_add, units=units, meta=meta, **kwargs)", "prediction_line": "        super().__init__(path, driver=driver, crs=crs, nodata=nodata, rename=rename, unit_mult=unit_mult, unit_add=unit_add, units=units, meta=meta, **kwargs)", "ground_truth": "        super().__init__(", "line_class": "commited", "zero_context": true}
{"original_prediction": "                kwargs[\"driver\"] = self.driver", "prediction_line": "                kwargs[\"driver\"] = self.driver", "ground_truth": "                kwargs.update(driver=self.driver)", "line_class": "common", "zero_context": true}
{"original_prediction": "columns\n                mult = self.unit_mult.get(name, 1)", "prediction_line": "columns", "ground_truth": "                m = self.unit_mult.get(name, 1)", "line_class": "common", "zero_context": true}
{"original_prediction": "            fn_out = join(data_root, f\"{data_name}{driver_extensions.get(driver, '')}\")", "prediction_line": "            fn_out = join(data_root, f\"{data_name}{driver_extensions.get(driver, '')}\")", "ground_truth": "            ext = driver_extensions.get(driver, driver).lower()", "line_class": "common", "zero_context": true}
{"original_prediction": "                a = self.unit_add.get(name, 0)", "prediction_line": "                a = self.unit_add.get(name, 0)", "ground_truth": "                a = self.unit_add.get(name, 0)", "line_class": "common", "zero_context": true}
{"original_prediction": "        kwargs.pop(\"time_range\", None)", "prediction_line": "        kwargs.pop(\"time_range\", None)", "ground_truth": "        gdf = self.get_data(bbox=bbox, variables=variables, logger=logger)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            gdf.to_file(fn_out, driver=driver, **kwargs)", "prediction_line": "            gdf.to_file(fn_out, driver=driver, **kwargs)", "ground_truth": "            gdf.to_file(fn_out, driver=driver, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for c in cols:", "prediction_line": "            for c in cols:", "ground_truth": "            unit_names = list(self.unit_mult.keys()) + list(self.unit_add.keys())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            geom = box(*bbox).to_crs(epsg=4326)", "prediction_line": "            geom = box(*bbox).to_crs(epsg=4326)", "ground_truth": "            geom = gpd.GeoDataFrame(geometry=[box(*bbox)], crs=4326)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if self.nodata:", "prediction_line": "            if self.nodata:", "ground_truth": "            if self.nodata is not None and len(cols) > 0:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            gdf.to_csv(fn_out, index=False)", "prediction_line": "            gdf.to_csv(fn_out, index=False)", "ground_truth": "            gdf[\"x\"], gdf[\"y\"] = gdf.geometry.x, gdf.geometry.y", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    nodata = {c: self.nodata[c] for c in cols if c in self.nodata}", "prediction_line": "                    nodata = {c: self.nodata[c] for c in cols if c in self.nodata}", "ground_truth": "                    nodata = self.nodata", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    self.nodata = {k: self.nodata for k in cols}", "prediction_line": "                    self.nodata = {k: self.nodata for k in cols}", "ground_truth": "                    nodata = {c: self.nodata for c in cols}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        crs=None,", "prediction_line": "        crs=None,", "ground_truth": "        crs=None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        encoding=None,", "prediction_line": "        encoding=None,", "ground_truth": "        nodata=None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            nodata=nodata,", "prediction_line": "            nodata=nodata,", "ground_truth": "            nodata=nodata,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                geom = geom.to_crs(epsg=3857)", "prediction_line": "                geom = geom.to_crs(epsg=3857)", "ground_truth": "                geom = geom.to_crs(3857)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            gdf = io.open_vector_from_table(self.path, geom=geom, predicate=predicate, **kwargs)", "prediction_line": "            gdf = io.open_vector_from_table(self.path, geom=geom, predicate=predicate, **kwargs)", "ground_truth": "            gdf = io.open_vector(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if c in nodata:", "prediction_line": "                    if c in nodata:", "ground_truth": "                    mv = nodata.get(c, None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            gdf.to_csv(fn_out, index=False)", "prediction_line": "            gdf.to_csv(fn_out, index=False)", "ground_truth": "            if not np.all(gdf.geometry.type == \"Point\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            crs=crs,", "prediction_line": "            crs=crs,", "ground_truth": "            crs=crs,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if self.nodata:", "prediction_line": "        if self.nodata:", "ground_truth": "        if gdf.index.size == 0:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            'title', 'description', 'source', 'license', 'version', 'date', 'contact',", "prediction_line": "            'title', 'description', 'source', 'license', 'version', 'date', 'contact',", "ground_truth": "            {'source_version', 'source_url', 'source_license', 'paper_ref', 'paper_doi', 'category'}", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        if bbox is None and geom is None:", "prediction_line": "        if bbox is None and geom is None:", "ground_truth": "        # If variable is string, convert to list", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Parameters", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"Initiates data adapter for geospatial vector data.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            or a :py:class:`pyproj.crs.CRS` object.", "prediction_line": "            or a :py:class:`pyproj.crs.CRS` object.", "ground_truth": "            or wkt (str). Only used if the data has no native CRS.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                for c in unit_names:", "prediction_line": "                for c in unit_names:", "ground_truth": "            for name in list(set(unit_names)):  # unique", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        crs=None,", "prediction_line": "        crs=None,", "ground_truth": "        logger=logger,", "line_class": "random", "zero_context": true}
{"original_prediction": "self, filename, driver=None, **kwargs):", "prediction_line": "self, filename, driver=None, **kwargs):", "ground_truth": "        self,", "line_class": "random", "zero_context": true}
{"original_prediction": "            if len(unit_names) > 0:", "prediction_line": "            if len(unit_names) > 0:", "ground_truth": "            if len(unit_names) > 0:", "line_class": "random", "zero_context": true}
{"original_prediction": "        return fn_out, driver", "prediction_line": "        return fn_out, driver", "ground_truth": "        return fn_out, driver", "line_class": "random", "zero_context": true}
{"original_prediction": "            )\n        else:", "prediction_line": "            )", "ground_truth": "            )", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert \"extremes_rate\" in da_params.coords, \"da_params should have a 'extremes_rate' coordinate\"", "prediction_line": "    assert \"extremes_rate\" in da_params.coords, \"da_params should have a 'extremes_rate' coordinate\"", "ground_truth": "    distributions = da_params[\"distribution\"].load()", "line_class": "common", "zero_context": true}
{"original_prediction": "    rates = da_params[\"extremes_rate\"].load()", "prediction_line": "    rates = da_params[\"extremes_rate\"].load()", "ground_truth": "    extremes_rate = da_params[\"extremes_rate\"].load()", "line_class": "common", "zero_context": true}
{"original_prediction": "in output\n        return np.concatenate([[d], params])", "prediction_line": "in output", "ground_truth": "        return np.concatenate([params, [distributions.index(d)]])", "line_class": "common", "zero_context": true}
{"original_prediction": "    return getattr(stats, _DISTS.get(distribution, distribution))", "prediction_line": "    return getattr(stats, _DISTS.get(distribution, distribution))", "ground_truth": "    distribution = _DISTS.get(distribution, distribution)", "line_class": "common", "zero_context": true}
{"original_prediction": "    if ev_type.upper() not in _DISTS.keys():", "prediction_line": "    if ev_type.upper() not in _DISTS.keys():", "ground_truth": "    distributions = _DISTS.get(ev_type.upper(), None)", "line_class": "common", "zero_context": true}
{"original_prediction": "        rvs_fit = _get_return_values(params, distribution, rps=rps, extremes_rate=extremes_rate)", "prediction_line": "        rvs_fit = _get_return_values(params, distribution, rps=rps, extremes_rate=extremes_rate)", "ground_truth": "        rvs_sim = _get_return_values(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    da_peaks = get_peaks(", "prediction_line": "    da_peaks = get_peaks(", "ground_truth": "    da_bm = get_peaks(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return _fitopt(x, distributions=distributions, criterium=criterium)", "prediction_line": "        return _fitopt(x, distributions=distributions, criterium=criterium)", "ground_truth": "        params, d = lmoment_fitopt(x, distributions=distributions, criterium=criterium)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if x_scale == \"gumbel\":", "prediction_line": "    if x_scale == \"gumbel\":", "ground_truth": "    rps_obs = _get_return_periods(rvs_obs, a=a, extremes_rate=extremes_rate)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    n = x.size", "prediction_line": "    n = x.size", "ground_truth": "    nll = get_frozen_dist(params, distribution).logpdf(x).sum()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    lmom = get_lmom(x, 4)", "prediction_line": "    lmom = get_lmom(x, 4)", "ground_truth": "    lmom = get_lmom(x, 4)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    da_params = fit_extremes(", "prediction_line": "    da_params = fit_extremes(", "ground_truth": "    da_params = fit_extremes(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _fitopt_1d,", "prediction_line": "        _fitopt_1d,", "ground_truth": "        _fitopt_1d,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    params = _lmomentfit(lmom, distribution)", "prediction_line": "    params = _lmomentfit(lmom, distribution)", "ground_truth": "    params = _lmomentfit(lmom, distribution)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    da_return_values = get_return_value(", "prediction_line": "    da_return_values = get_return_value(", "ground_truth": "    da_rps = get_return_value(da_params, rps=rps)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if ev_type.upper() == \"BM\":", "prediction_line": "        if ev_type.upper() == \"BM\":", "ground_truth": "        return local_max_1d(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    n = x.size", "prediction_line": "    n = x.size", "ground_truth": "    aic = _aic(x, params, distribution)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for j in range(0, len(B) - (i + 1)):", "prediction_line": "        for j in range(0, len(B) - (i + 1)):", "ground_truth": "        Coeff = np.concatenate([Spc, legendre_shift_poly(i)])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        rvs_sim_ci = lmoment_ci(", "prediction_line": "        rvs_sim_ci = lmoment_ci(", "ground_truth": "        urvs = lmoment_ci(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    da_peaks = duck.map_blocks(func, da.data, dtype=np.float32)", "prediction_line": "    da_peaks = duck.map_blocks(func, da.data, dtype=np.float32)", "ground_truth": "    lmax = duck.apply_along_axis(func, da.get_axis_num(\"time\"), da)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    frozen_dist = get_frozen_dist(params, distribution)", "prediction_line": "    frozen_dist = get_frozen_dist(params, distribution)", "ground_truth": "    return get_frozen_dist(params, distribution).isf(q)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    dist = get_dist(distribution)", "prediction_line": "    dist = get_dist(distribution)", "ground_truth": "    dist = get_dist(distribution)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return dist.isf(q, *x)", "prediction_line": "        return dist.isf(q, *x)", "ground_truth": "        p = lmoment_fit(x, distribution)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        elif d == \"gev\" and len(p) == 4:", "prediction_line": "        elif d == \"gev\" and len(p) == 4:", "ground_truth": "        return _get_return_values(p, d, rps=rps, extremes_rate=r)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    x_sample = x_sample.reshape([nsample, x.size])", "prediction_line": "    x_sample = x_sample.reshape([nsample, x.size])", "ground_truth": "    xrv = np.apply_along_axis(func, 1, x_sample)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _return_values_1d,", "prediction_line": "        _return_values_1d,", "ground_truth": "        _return_values_1d,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if ev_type == \"BM\":", "prediction_line": "    if ev_type == \"BM\":", "ground_truth": "    da_peaks = get_peaks(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    assert criterium in [\"AIC\", \"AICc\", \"BIC\"]", "prediction_line": "    assert criterium in [\"AIC\", \"AICc\", \"BIC\"]", "ground_truth": "    fgof = {\"AIC\": _aic, \"AICC\": _aicc, \"BIC\": _bic}.get(criterium.upper())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        dist = get_dist(distribution)", "prediction_line": "        dist = get_dist(distribution)", "ground_truth": "        params[distribution] = _lmomentfit(lmom, distribution)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    dist = get_dist(distribution)", "prediction_line": "    dist = get_dist(distribution)", "ground_truth": "    return get_dist(distribution)(*params[:-2], loc=params[-2], scale=params[-1])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if ev_type.upper() == \"BM\":", "prediction_line": "    if ev_type.upper() == \"BM\":", "ground_truth": "        np.unique(bins).size", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        vectorize=True,", "prediction_line": "        vectorize=True,", "ground_truth": "        vectorize=True,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    da_params[\"distribution\"] = xr.IndexVariable(\"dparams\", distributions)", "prediction_line": "    da_params[\"distribution\"] = xr.IndexVariable(\"dparams\", distributions)", "ground_truth": "    dist_dims = list([d for d in da_params.dims if d != \"dparams\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return ax.figure", "prediction_line": "    return ax.figure", "ground_truth": "    ax.grid()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert ev_type in [\"POT\", \"BM\"], \"ev_type must be either 'POT' or 'BM'\"", "prediction_line": "    assert ev_type in [\"POT\", \"BM\"], \"ev_type must be either 'POT' or 'BM'\"", "ground_truth": "    if ev_type.upper() not in _DISTS.keys():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    for i, a in enumerate(arr):", "prediction_line": "    for i, a in enumerate(arr):", "ground_truth": "    out = np.array([bool(0) for _ in range(arr.size)])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    da_params = da_params.assign_coords(coords)", "prediction_line": "    da_params = da_params.assign_coords(coords)", "ground_truth": "    da_params = da_params.assign_coords(coords)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ds = xr.Dataset(", "prediction_line": "    ds = xr.Dataset(", "ground_truth": "    return xr.merge([da_peaks, da_params, da_rps])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return xr.merge([da_bm, da_params, da_rps])", "prediction_line": "    return xr.merge([da_bm, da_params, da_rps])", "ground_truth": "    return xr.merge([da_bm, da_params, da_rps])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # np.random.seed(12456)", "prediction_line": "    # np.random.seed(12456)", "ground_truth": "    x_sample = np.random.choice(x, size=[nsample, x.size], replace=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        distribution=xr.IndexVariable(\"distribution\", distributions),", "prediction_line": "        distribution=xr.IndexVariable(\"distribution\", distributions),", "ground_truth": "        distribution=xr.DataArray(dims=dist_dims, data=distributions),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            f\"Unknown ev_type {ev_type.upper()}, select from {_DISTS.keys()}.\"", "prediction_line": "            f\"Unknown ev_type {ev_type.upper()}, select from {_DISTS.keys()}.\"", "ground_truth": "            f\"Unknown ev_type {ev_type.upper()}, select from {_DISTS.keys()}.\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    for i, a in enumerate(arr):", "prediction_line": "    for i, a in enumerate(arr):", "ground_truth": "    for i in range(arr.size):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return dask.array.apply_along_axis(", "prediction_line": "    return dask.array.apply_along_axis(", "ground_truth": "    assert \"dparams\" in da_params.dims, \"da_params should have a 'dparams' dimension\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    da_params = da_params.assign_coords(", "prediction_line": "    da_params = da_params.assign_coords(", "ground_truth": "    coords = dict(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    Lmomentfit routine derive parameters of a distribution function", "prediction_line": "    Lmomentfit routine derive parameters of a distribution function", "ground_truth": "    Lmomentfit routine derive parameters of a distribution function", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    # fit distribution using lmom", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Figure of EVA fit and empirical data.", "prediction_line": "        Figure of EVA fit and empirical data.", "ground_truth": "        Figure of EVA fit and empirical data", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Timeseries data, must have a regular spaced 'time' dimension.", "prediction_line": "        Timeseries data, must have a regular spaced 'time' dimension.", "ground_truth": "        Timeseries data, must have a regular spaced 'time' dimension.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    distribution : str, optional", "prediction_line": "    distribution : str, optional", "ground_truth": "    distribution : str, optional", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"get_block_maxima\",", "prediction_line": "    \"get_block_maxima\",", "ground_truth": "    \"get_return_value\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            x,\n            bins=bins,", "prediction_line": "            x,", "ground_truth": "            x, min_dist=min_dist, bins=bins, min_sample_size=min_sample_size", "line_class": "random", "zero_context": true}
{"original_prediction": "        c2 = 2.0 / (3.0 + tau3) - np.log(2.0) / np.log(3.0)", "prediction_line": "        c2 = 2.0 / (3.0 + tau3) - np.log(2.0) / np.log(3.0)", "ground_truth": "        m1 = lmom[0] - (s1 / k1) * (1.0 - math.gamma(1.0 + k1))", "line_class": "random", "zero_context": true}
{"original_prediction": "        bb[r - 1] = (r - 1) * (r - 1) / n", "prediction_line": "        bb[r - 1] = (r - 1) * (r - 1) / n", "ground_truth": "        Num1 = np.kron(np.ones((r, 1)), np.arange(r + 1, n + 1))", "line_class": "random", "zero_context": true}
{"original_prediction": "        da,\n        ev_type=ev_type,", "prediction_line": "        da,", "ground_truth": "        da,", "line_class": "random", "zero_context": true}
{"original_prediction": "    ts_fit = extremes.fit_extremes(ts_extremes, ev_type=\"BM\")", "prediction_line": "    ts_fit = extremes.fit_extremes(ts_extremes, ev_type=\"BM\")", "ground_truth": "    bm_peaks = extremes.get_peaks(ts_extremes, ev_type=\"BM\", period=\"182.625D\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    # Testing if EVA is the same as the peaks", "prediction_line": "    # Testing if EVA is the same as the peaks", "ground_truth": "    da_params = extremes.fit_extremes(bm_peaks, ev_type=\"BM\", distribution=\"gumb\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    da_rps = extremes.get_return_value(da_params, rps=rps)", "prediction_line": "    da_rps = extremes.get_return_value(da_params, rps=rps)", "ground_truth": "    da_rps = extremes.get_return_value(da_params, rps=rps)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    peaks = extremes.peaks(ts_extremes, window=6, freq=\"M\")", "prediction_line": "    peaks = extremes.peaks(ts_extremes, window=6, freq=\"M\")", "ground_truth": "    ts_bm = extremes.get_peaks(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    ts_pot = extremes.get_peaks(", "prediction_line": "    ts_pot = extremes.get_peaks(", "ground_truth": "    ts_pot = extremes.get_peaks(ts_extremes, ev_type=\"POT\", qthresh=0.996)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    pot_peaks = extremes.get_peaks(ts_extremes, ev_type=\"POT\", qthresh=0.996)", "prediction_line": "    pot_peaks = extremes.get_peaks(ts_extremes, ev_type=\"POT\", qthresh=0.996)", "ground_truth": "    pot_peaks = extremes.get_peaks(ts_extremes, ev_type=\"POT\", qthresh=0.996)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    da_params = extremes.fit_extremes(pot_peaks, ev_type=\"POT\", distribution=\"gpd\")", "prediction_line": "    da_params = extremes.fit_extremes(pot_peaks, ev_type=\"POT\", distribution=\"gpd\")", "ground_truth": "    da_params = extremes.fit_extremes(pot_peaks, ev_type=\"POT\", distribution=\"gpd\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    bm_peaks = extremes.get_peaks(ts_extremes, ev_type=\"BM\", period=\"182.625D\")", "prediction_line": "    bm_peaks = extremes.get_peaks(ts_extremes, ev_type=\"BM\", period=\"182.625D\")", "ground_truth": "    bm_eva = extremes.eva(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    da_rps = extremes.get_return_value(da_params)", "prediction_line": "    da_rps = extremes.get_return_value(da_params)", "ground_truth": "    da_rps = extremes.get_return_value(da_params)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    pot_eva = extremes.eva(", "prediction_line": "    pot_eva = extremes.eva(", "ground_truth": "    pot_eva = extremes.eva(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    da_params = extremes.fit_extremes(bm_peaks, ev_type=\"BM\", distribution=\"gev\")", "prediction_line": "    da_params = extremes.fit_extremes(bm_peaks, ev_type=\"BM\", distribution=\"gev\")", "ground_truth": "    da_params = extremes.fit_extremes(bm_peaks, ev_type=\"BM\", distribution=\"gev\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "rps\n    assert da_rps.shape == (len(rps),)", "prediction_line": "rps", "ground_truth": "    assert da_rps.shape == (len(da_params[\"stations\"]), len(rps))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # Testing if values are the same as from the function", "prediction_line": "    # Testing if values are the same as from the function", "ground_truth": "    bm_test = xr.merge([bm_peaks, da_params, da_rps])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    pot_test = xr.merge([pot_peaks, da_params, da_rps])", "prediction_line": "    pot_test = xr.merge([pot_peaks, da_params, da_rps])", "ground_truth": "    pot_test = xr.merge([pot_peaks, da_params, da_rps])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "import pytest", "prediction_line": "import pytest", "ground_truth": "import xarray as xr", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    # Testing expected number of peaks", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # Fitting BM-Pareto to Pareto generated data", "prediction_line": "    # Fitting BM-Pareto to Pareto generated data", "ground_truth": "    # Fitting BM-GEV to Gumbel generated data", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # testing if we get the value from the function", "prediction_line": "    # testing if we get the value from the function", "ground_truth": "    # testing if we get the value from the function", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from xclim.core.calendar import convert_calendar", "prediction_line": "from xclim.core.calendar import convert_calendar", "ground_truth": "from hydromt.stats import extremes", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        np.testing.assert_approx_equal(", "prediction_line": "        np.testing.assert_approx_equal(", "ground_truth": "        np.testing.assert_approx_equal(", "line_class": "random", "zero_context": true}
{"original_prediction": "            da_params.sel(dparams=\"loc\").isel(stations=i).values, mom_alpha, decimal=2", "prediction_line": "            da_params.sel(dparams=\"loc\").isel(stations=i).values, mom_alpha, decimal=2", "ground_truth": "            da_params.isel(stations=i).sel(dparams=\"loc\"), mom_alpha, significant=2", "line_class": "random", "zero_context": true}
{"original_prediction": "    np.testing.assert_array_almost_equal(", "prediction_line": "    np.testing.assert_array_almost_equal(", "ground_truth": "    np.testing.assert_array_almost_equal(", "line_class": "random", "zero_context": true}
{"original_prediction": "        da_param_loc = float(da_params.isel(stations=i).sel(dparams=\"loc\").values)", "prediction_line": "        da_param_loc = float(da_params.isel(stations=i).sel(dparams=\"loc\").values)", "ground_truth": "        gumb_loc = float(da_params.isel(stations=i)[1])", "line_class": "random", "zero_context": true}
{"original_prediction": "        )\n        np.testing.assert_approx_equal(", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "    payload = process_new_granules_worker.get_jobs_for_granule(subscription, granule, mock_granules)", "prediction_line": "    payload = process_new_granules_worker.get_jobs_for_granule(subscription, granule, mock_granules)", "ground_truth": "    with patch('process_new_granules_worker.get_neighbors', lambda x, y, z: mock_granules):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with patch('asf_search.stack_from_product', mock_stack_from_product):", "prediction_line": "    with patch('asf_search.stack_from_product', mock_stack_from_product):", "ground_truth": "    with patch('asf_search.baseline_search.stack_from_product', mock_stack_from_product):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        with patch('process_new_granules_worker.get_jobs_for_granule', mock_get_jobs_for_granule):", "prediction_line": "        with patch('process_new_granules_worker.get_jobs_for_granule', mock_get_jobs_for_granule):", "ground_truth": "        with patch('process_new_granules_worker.get_jobs_for_granule', mock_get_jobs_for_granule):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_get_jobs_for_subscription_with_limit():", "prediction_line": "def test_get_jobs_for_subscription_with_limit():", "ground_truth": "            result = process_new_granules_worker.get_jobs_for_subscription(subscription={}, limit=0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with patch('asf_search.search', mock_search):", "prediction_line": "    with patch('asf_search.search', mock_search):", "ground_truth": "    with patch('asf_search.search', mock_search):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        neighbors = process_new_granules_worker.get_neighbors(granule, 2, 'S1B')", "prediction_line": "        neighbors = process_new_granules_worker.get_neighbors(granule, 2, 'S1B')", "ground_truth": "        neighbors = process_new_granules_worker.get_neighbors(granule, 5, 'S1B')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    job_ids = [", "prediction_line": "    job_ids = [", "ground_truth": "    payload = process_new_granules_worker.get_jobs_for_granule(subscription, granule)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        results = process_new_granules_worker.get_neighbors(granule)", "prediction_line": "        results = process_new_granules_worker.get_neighbors(granule)", "ground_truth": "        neighbors = process_new_granules_worker.get_neighbors(granule, 1, 'S1')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        neighbors = process_new_granules_worker.get_neighbors(granule, 3, 'S1')", "prediction_line": "        neighbors = process_new_granules_worker.get_neighbors(granule, 3, 'S1')", "ground_truth": "        neighbors = process_new_granules_worker.get_neighbors(granule, 2, 'S1A')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        process_new_granules_worker.get_jobs_for_granule(subscription, granule)", "prediction_line": "        process_new_granules_worker.get_jobs_for_granule(subscription, granule)", "ground_truth": "        process_new_granules_worker.get_jobs_for_granule(subscription, granule)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with patch('process_new_granules_worker.get_unprocessed_granules', mock_get_unprocessed_granules):", "prediction_line": "    with patch('process_new_granules_worker.get_unprocessed_granules', mock_get_unprocessed_granules):", "ground_truth": "    with patch('process_new_granules_worker.get_unprocessed_granules', mock_get_unprocessed_granules):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "           jobs = process_new_granules_worker.get_jobs_for_subscription({})", "prediction_line": "           jobs = process_new_granules_worker.get_jobs_for_subscription({})", "ground_truth": "            result = process_new_granules_worker.get_jobs_for_subscription(subscription={}, limit=20)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert payload == {", "prediction_line": "    assert payload == {", "ground_truth": "    payload2 = process_new_granules_worker.get_jobs_for_granule(subscription, granule2)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_get_neighbors_no_baseline():", "prediction_line": "def test_get_neighbors_no_baseline():", "ground_truth": "        neighbors = process_new_granules_worker.get_neighbors(granule, 2, 'S1')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            result = process_new_granules_worker.get_jobs_for_subscription(subscription={}, limit=1)", "prediction_line": "            result = process_new_granules_worker.get_jobs_for_subscription(subscription={}, limit=1)", "ground_truth": "            result = process_new_granules_worker.get_jobs_for_subscription(subscription={}, limit=1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from django.test import TestCase", "prediction_line": "from django.test import TestCase", "ground_truth": "import asf_search", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "from unittest.mock import patch", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        ])\n\n    with patch('asf_search.stack_from_product', mock_stack_from_product):", "prediction_line": "        ])", "ground_truth": "        ])", "line_class": "random", "zero_context": true}
{"original_prediction": "    with pytest.raises(ValueError):", "prediction_line": "    with pytest.raises(ValueError):", "ground_truth": "    with pytest.raises(ValueError):", "line_class": "random", "zero_context": true}
{"original_prediction": "            {\n                'subscription_id': '51b576b0-a89b-4108-a9d8-7ecb52aee950',", "prediction_line": "            {", "ground_truth": "            {", "line_class": "random", "zero_context": true}
{"original_prediction": "   unprocessed_granules = process_new_granules_worker.get_unprocessed_granules(", "prediction_line": "   unprocessed_granules = process_new_granules_worker.get_unprocessed_granules(", "ground_truth": "    search_results = [", "line_class": "random", "zero_context": true}
{"original_prediction": "            'name': 'my_name',", "prediction_line": "            'name': 'my_name',", "ground_truth": "            'name': 'subscription1',", "line_class": "random", "zero_context": true}
{"original_prediction": "        reference_config = json.load(f)", "prediction_line": "        reference_config = json.load(f)", "ground_truth": "        reference_dict = json.load(f)[\"reference\"]", "line_class": "common", "zero_context": true}
{"original_prediction": "    balsamic_cache,", "prediction_line": "    balsamic_cache,", "ground_truth": "    analysis_dir,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    get_sample_dict_from_bam,", "prediction_line": "    get_sample_dict_from_bam,", "ground_truth": "    generate_graph,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    create_fastq_symlink(", "prediction_line": "    create_fastq_symlink(", "ground_truth": "    create_fastq_symlink(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        conda_env=CONTAINERS_CONDA_ENV_PATH,", "prediction_line": "        conda_env=CONTAINERS_CONDA_ENV_PATH,", "ground_truth": "        bioinfo_tools_version=get_bioinfo_tools_version(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        PANEL={", "prediction_line": "        PANEL={", "ground_truth": "        analysis={", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"analysis_dir\": analysis_dir,", "prediction_line": "            \"analysis_dir\": analysis_dir,", "ground_truth": "            \"analysis_dir\": analysis_dir,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        generate_graph(", "prediction_line": "        generate_graph(", "ground_truth": "        generate_graph(config_collection_dict, config_path)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    balsamic_cache,", "prediction_line": "    balsamic_cache,", "ground_truth": "    balsamic_cache,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    generate_graph(", "prediction_line": "    generate_graph(", "ground_truth": "    config_path = Path(analysis_dir) / case_id / (case_id + \"_QC.json\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        reference=reference_dict,", "prediction_line": "        reference=reference_dict,", "ground_truth": "        reference=reference_dict,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    get_sample_dict_from_file,", "prediction_line": "    get_sample_dict_from_file,", "ground_truth": "    get_panel_chrom,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        this will be used as the sample name in the output file\",", "prediction_line": "        this will be used as the sample name in the output file\",", "ground_truth": "         naming the analysis jobs, and analysis path\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"chromosomes\": get_panel_chrom(panel_bed),", "prediction_line": "            \"chromosomes\": get_panel_chrom(panel_bed),", "ground_truth": "            \"chrom\": get_panel_chrom(panel_bed),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        balsamic_cache, \"reference\", genome_version, \"config.json\"", "prediction_line": "        balsamic_cache, \"reference\", genome_version, \"config.json\"", "ground_truth": "        balsamic_cache, balsamic_version, genome_version, \"reference.json\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    get_balsamic_version,", "prediction_line": "    get_balsamic_version,", "ground_truth": "    create_fastq_symlink,", "line_class": "inproject", "zero_context": true}
{"original_prediction": ")\n@click.option(", "prediction_line": ")", "ground_truth": ")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from BALSAMIC.utils.constants import (", "prediction_line": "from BALSAMIC.utils.constants import (", "ground_truth": "from BALSAMIC.utils.cli import (", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import logging\nimport requests", "prediction_line": "import logging", "ground_truth": "import logging", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        panel_bed=panel_bed,", "prediction_line": "        panel_bed=panel_bed,", "ground_truth": "        panel={", "line_class": "random", "zero_context": true}
{"original_prediction": "    type=click.Choice([\"hg19\", \"hg38\"]),", "prediction_line": "    type=click.Choice([\"hg19\", \"hg38\"]),", "ground_truth": "    default=\"hg19\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            tumor_sample_name=tumor_sample_name,", "prediction_line": "            tumor_sample_name=tumor_sample_name,", "ground_truth": "            tumor_sample_name=tumor_sample_name,", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"--threads\",", "prediction_line": "    \"--threads\",", "ground_truth": "    \"--tumor\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        container_version = f\"v{container_version}\"", "prediction_line": "        container_version = f\"v{container_version}\"", "ground_truth": "        balsamic_version = container_version", "line_class": "random", "zero_context": true}
{"original_prediction": "    qc_config = json.load(open(Path(test_analysis_dir, case_id, case_id + qc_json)))", "prediction_line": "    qc_config = json.load(open(Path(test_analysis_dir, case_id, case_id + qc_json)))", "ground_truth": "    qc_config = json.load(open(Path(test_analysis_dir, case_id, case_id + qc_json)))", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert Path(qc_config[\"analysis\"][\"dag\"]).exists()", "prediction_line": "    assert Path(qc_config[\"analysis\"][\"dag\"]).exists()", "ground_truth": "    assert Path(qc_config[\"analysis\"][\"dag\"]).exists()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    result = invoke_cli(", "prediction_line": "    result = invoke_cli(", "ground_truth": "    case_result = invoke_cli(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    balsamic_cache,", "prediction_line": "    balsamic_cache,", "ground_truth": "    analysis_dir,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                balsamic_cache,", "prediction_line": "                balsamic_cache,", "ground_truth": "                balsamic_cache,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    balsamic_config,", "prediction_line": "    balsamic_config,", "ground_truth": "    panel_bed_file,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    invoke_cli,", "prediction_line": "    invoke_cli,", "ground_truth": "    invoke_cli,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    sample_fastq,", "prediction_line": "    sample_fastq,", "ground_truth": "    sample_fastq,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    tumor = sample_fastq[\"tumor\"]", "prediction_line": "    tumor = sample_fastq[\"tumor\"]", "ground_truth": "    tumor = sample_fastq[\"tumor\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    normal = sample_fastq[\"normal\"]", "prediction_line": "    normal = sample_fastq[\"normal\"]", "ground_truth": "    normal = sample_fastq[\"normal\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            no_write_perm_path,", "prediction_line": "            no_write_perm_path,", "ground_truth": "            no_write_perm_path,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # WHEN running the qc workflow", "prediction_line": "    # WHEN running the qc workflow", "ground_truth": "    result = invoke_cli(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "):\n    # GIVEN a case ID, fastq files, and an analysis dir", "prediction_line": "):", "ground_truth": "    sentieon_license,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "):\n    # GIVEN a case ID, fastq files, and an analysis dir", "prediction_line": "):", "ground_truth": "    sentieon_install_dir,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    invoke_cli, sample_fastq, analysis_dir, balsamic_cache, panel_bed_file", "prediction_line": "    invoke_cli, sample_fastq, analysis_dir, balsamic_cache, panel_bed_file", "ground_truth": "    invoke_cli, sample_fastq, analysis_dir, balsamic_cache, panel_bed_file", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"SENTIEON_LICENSE\": sentieon_license,", "prediction_line": "            \"SENTIEON_LICENSE\": sentieon_license,", "ground_truth": "            \"SENTIEON_LICENSE\": sentieon_license,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"SENTIEON_INSTALL_DIR\": sentieon_install_dir,", "prediction_line": "            \"SENTIEON_INSTALL_DIR\": sentieon_install_dir,", "ground_truth": "            \"SENTIEON_INSTALL_DIR\": sentieon_install_dir,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_qc_config_no_tumor(", "prediction_line": "def test_qc_config_no_tumor(", "ground_truth": "def test_config_qc_graph_failed(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from django.test import TestCase", "prediction_line": "from django.test import TestCase", "ground_truth": "from pathlib import Path", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # THEN the config file is created", "prediction_line": "    # THEN the config file is created", "ground_truth": "    # THEN a config should be created and exist", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # THEN a config should be created and exist", "prediction_line": "    # THEN a config should be created and exist", "ground_truth": "    # THEN a config should not be created and exit", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            \"qc_panel\",", "prediction_line": "            \"qc_panel\",", "ground_truth": "            \"qc_panel\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"--tumor-sample-name\",", "prediction_line": "                \"--tumor-sample-name\",", "ground_truth": "                \"--tumor-sample-name\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"-p\",", "prediction_line": "                \"-p\",", "ground_truth": "                \"-p\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            ]\n        )", "prediction_line": "            ]", "ground_truth": "            ],", "line_class": "random", "zero_context": true}
{"original_prediction": "    case_id = \"sample_tumor_only\"", "prediction_line": "    case_id = \"sample_tumor_only\"", "ground_truth": "    case_id = \"sample_tumor_only\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        # Exclusive count", "prediction_line": "        # Exclusive count", "ground_truth": "        self.stats.update(res)", "line_class": "common", "zero_context": true}
{"original_prediction": "        res.update(d)", "prediction_line": "        res.update(d)", "ground_truth": "        res.update(d)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.stats[i] = {", "prediction_line": "        self.stats[i] = {", "ground_truth": "        res = dict(zip([f\"table{i}_{n}\" for n in col_exprs], map(json_friendly_value, res)))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        exclusive_rows_count = db.query(exclusive_rows_query.select(Count()), tuple)", "prediction_line": "        exclusive_rows_count = db.query(exclusive_rows_query.select(Count()), tuple)", "ground_truth": "        with temp_table(db, exclusive_rows_query) as exclusive_rows:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        db = table1.database", "prediction_line": "        db = table1.database", "ground_truth": "        with self._run_in_background(self._test_null_or_duplicate_keys, table1, table2):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # TODO: sample", "prediction_line": "        # TODO: sample", "ground_truth": "        with self._run_in_background(self._sample_and_count_exclusive, db, diff_rows, a_cols, b_cols):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            yield from self._diff_rows(diff_rows, a_cols, b_cols)", "prediction_line": "            yield from self._diff_rows(diff_rows, a_cols, b_cols)", "ground_truth": "            with self._run_in_background(self._count_diff_per_column, db, diff_rows, is_diff_cols):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            with self._run_in_background(self._test_null_or_duplicate_keys, table2, table1):", "prediction_line": "            with self._run_in_background(self._test_null_or_duplicate_keys, table2, table1):", "ground_truth": "            with self._run_in_background(self._collect_stats, 1, table1):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                with self._run_in_background(self._collect_stats, 2, table2):", "prediction_line": "                with self._run_in_background(self._collect_stats, 2, table2):", "ground_truth": "                with self._run_in_background(self._collect_stats, 2, table2):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        q = table.select(", "prediction_line": "        q = table.select(", "ground_truth": "        col_exprs = merge_dicts(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    with self._run_in_background(self._diff_tables, table1, table2):", "prediction_line": "                    with self._run_in_background(self._diff_tables, table1, table2):", "ground_truth": "                    yield from self._outer_join(table1, table2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    yield DiffResult(", "prediction_line": "                    yield DiffResult(", "ground_truth": "                    is_diff, a_row, b_row = _slice_tuple(x, len(is_diff_cols), len(a_cols), len(b_cols))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                f\"min_{c}\": min_(c),", "prediction_line": "                f\"min_{c}\": min_(c),", "ground_truth": "                f\"avg_{c}\": avg(c),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        yield name\n    finally:", "prediction_line": "        yield name", "ground_truth": "        yield table(name, schema=expr.source_table.schema)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                yield from self._yield_diff_rows(db, diff_rows, a_cols, b_cols)", "prediction_line": "                yield from self._yield_diff_rows(db, diff_rows, a_cols, b_cols)", "ground_truth": "                for is_xa, is_xb, *x in db.query(diff_rows, list):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        b = table2._make_select()", "prediction_line": "        b = table2._make_select()", "ground_truth": "        b = table2._make_select()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.stats.update(", "prediction_line": "        self.stats.update(", "ground_truth": "        for name, count in safezip(is_diff_cols, is_diff_cols_counts):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                c.name: c", "prediction_line": "                c.name: c", "ground_truth": "                f\"sum_{c}\": sum_(c),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "           key_expr = Concat(*key_columns)", "prediction_line": "           key_expr = Concat(*key_columns)", "ground_truth": "            q = t.select(total=Count(), total_distinct=Count(Concat(key_columns), distinct=True))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    db.create_table(name, expr)", "prediction_line": "    db.create_table(name, expr)", "ground_truth": "    db.query(f\"create temporary table {c.quote(name)} as {c.compile(expr)}\", None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       is_diff_keys = {", "prediction_line": "       is_diff_keys = {", "ground_truth": "        a_cols = {f\"table1_{c}\": NormalizeAsString(a[c]) for c in cols1}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        res = db.query(", "prediction_line": "        res = db.query(", "ground_truth": "        is_diff_cols_counts = db.query(diff_rows.select(sum_(this[c]) for c in is_diff_cols), tuple)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"Finds the diff between two SQL tables using JOINs", "prediction_line": "        \"\"\"Finds the diff between two SQL tables using JOINs", "ground_truth": "        table1, table2 = self._threaded_call(\"with_schema\", [table1, table2])", "line_class": "inproject", "zero_context": true}
{"original_prediction": ": make this configurable", "prediction_line": ": make this configurable", "ground_truth": "    return table.order_by(Random()).limit(10)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            res = self._threaded_call(\"query\", [q])", "prediction_line": "            res = self._threaded_call(\"query\", [q])", "ground_truth": "            total, total_distinct = ts.database.query(q, tuple)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        )\n\n        # TODO: this is a hack to get around the fact that we can't use a subquery in the", "prediction_line": "        )", "ground_truth": "            .where(or_(this[c] == 1 for c in is_diff_cols))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        db.query(f\"drop table {c.quote(name)}\", None)", "prediction_line": "        db.query(f\"drop table {c.quote(name)}\", None)", "ground_truth": "        db.query(f\"drop table {c.quote(name)}\", None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        logger.info(\"Done querying for different rows\")", "prediction_line": "        logger.info(\"Done querying for different rows\")", "ground_truth": "    def _count_diff_per_column(self, db, diff_rows, is_diff_cols):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from sqlalchemy import (", "prediction_line": "from sqlalchemy import (", "ground_truth": "from .utils import safezip", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from __future__ import absolute_import", "prediction_line": "from __future__ import absolute_import", "ground_truth": "from decimal import Decimal", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # TODO: check that the columns are the same", "prediction_line": "        # TODO: check that the columns are the same", "ground_truth": "        if len(cols1) != len(cols2):", "line_class": "random", "zero_context": true}
{"original_prediction": "                raise ValueError(", "prediction_line": "                raise ValueError(", "ground_truth": "                raise ValueError(\"Duplicate primary keys\")", "line_class": "random", "zero_context": true}
{"original_prediction": "            [\n                {c.name: c for c in table.schema.columns},", "prediction_line": "            [", "ground_truth": "            {", "line_class": "random", "zero_context": true}
{"original_prediction": "    diff_count: int", "prediction_line": "    diff_count: int", "ground_truth": "    metrics: Dict[str, float]", "line_class": "random", "zero_context": true}
{"original_prediction": "    return res", "prediction_line": "    return res", "ground_truth": "    return res", "line_class": "random", "zero_context": true}
{"original_prediction": "    app.run(toml_path)", "prediction_line": "    app.run(toml_path)", "ground_truth": "    app.run(toml_path)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self._db = self._config.databases[self._db_name]", "prediction_line": "        self._db = self._config.databases[self._db_name]", "ground_truth": "        super().__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    if len(sys.argv) != 2:", "prediction_line": "    if len(sys.argv) != 2:", "ground_truth": "    main(sys.argv[1])", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.list_of_connections = ListOfConnections(self.config)", "prediction_line": "        self.list_of_connections = ListOfConnections(self.config)", "ground_truth": "        return super().run(**kw)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(**kw)", "prediction_line": "        super().__init__(**kw)", "ground_truth": "        super().__init__(**kw)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                self._config.add_database(self._db_name, connect_dict)", "prediction_line": "                self._config.add_database(self._db_name, connect_dict)", "ground_truth": "                self.save(connect_dict)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return connection_list.selected", "prediction_line": "        return connection_list.selected", "ground_truth": "        return connection_list.children[connection_list.index]", "line_class": "common", "zero_context": true}
{"original_prediction": "    def on_test_and_save(self, event: Button.Pressed) -> None:", "prediction_line": "    def on_test_and_save(self, event: Button.Pressed) -> None:", "ground_truth": "    async def on_button_pressed(self, event: Button.Pressed) -> None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.config_changed()", "prediction_line": "        self.config_changed()", "ground_truth": "        self.config_changed()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            connect_dict = self._get_connect_dict()", "prediction_line": "            connect_dict = self._get_connect_dict()", "ground_truth": "            connect_dict = self._get_connect_dict()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                test_connect(connect_dict)", "prediction_line": "                test_connect(connect_dict)", "ground_truth": "                test_connect(connect_dict)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    app = ConnectionEditor()", "prediction_line": "    app = ConnectionEditor()", "ground_truth": "    app = ConnectionEditor()", "line_class": "infile", "zero_context": true}
{"original_prediction": "class MainView(Vertical):", "prediction_line": "class MainView(Vertical):", "ground_truth": "        self.app.config_changed()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        yield Header(\"Edit connection\")", "prediction_line": "        yield Header(\"Edit connection\")", "ground_truth": "        self.params_container = ContentSwapper(id=\"params\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        )\n        self.driver_select.on_select(self.on_driver_select)", "prediction_line": "        )", "ground_truth": "            value=self._config.databases.get(self._db_name, {}).get(\"driver\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def on_driver_select(self, value):", "prediction_line": "    def on_driver_select(self, value):", "ground_truth": "        self.create_params()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.params_container.new_content(*self.create_params_for_driver(driver))", "prediction_line": "        self.params_container.new_content(*self.create_params_for_driver(driver))", "ground_truth": "        db_config = self._config.databases.get(self._db_name, {})", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.config = Config(toml.load(f))", "prediction_line": "                self.config = Config(toml.load(f))", "ground_truth": "                self.config = Config(toml.load(f))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.config = Config({})", "prediction_line": "            self.config = Config({})", "ground_truth": "            self.config = Config({})", "line_class": "infile", "zero_context": true}
{"original_prediction": "        with open(self.toml_path, \"w\") as f:", "prediction_line": "        with open(self.toml_path, \"w\") as f:", "ground_truth": "        self.list_swapper.new_content(ListOfConnections(self.config))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.params_container.new_content(*widgets)", "prediction_line": "        self.params_container.new_content(*widgets)", "ground_truth": "        self.params_container.new_content(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.list_swapper = ContentSwapper(id=\"conn_list\")", "prediction_line": "        self.list_swapper = ContentSwapper(id=\"conn_list\")", "ground_truth": "        self.list_swapper = ContentSwapper(ListOfConnections(self.config), id=\"conn_list\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.edit_swapper = ContentSwapper(id=\"edit_container\")", "prediction_line": "        self.edit_swapper = ContentSwapper(id=\"edit_container\")", "ground_truth": "        self.edit_swapper = ContentSwapper(id=\"edit_container\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.list_swapper.new_content(ListOfConnections(self.config))", "prediction_line": "        self.list_swapper.new_content(ListOfConnections(self.config))", "ground_truth": "        self.edit_swapper.new_content(EditConnection(\"New\", self.config))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        del self.config[\"database\"][name]", "prediction_line": "        del self.config[\"database\"][name]", "ground_truth": "        del self.config[\"database\"][name]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       self._config.add_database(self._db_name, connect_dict)", "prediction_line": "       self._config.add_database(self._db_name, connect_dict)", "ground_truth": "        name = self.query_one(\"#conn_name\").value", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self._config.add_database(name, connect_dict)", "prediction_line": "        self._config.add_database(name, connect_dict)", "ground_truth": "        self._config.add_database(name, connect_dict)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for w in self.params_container.container.children:", "prediction_line": "        for w in self.params_container.container.children:", "ground_truth": "        for p in self.query(\".param\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.app.show_edit_connection(h.item.name)", "prediction_line": "        self.app.show_edit_connection(h.item.name)", "ground_truth": "        name = h.item.name", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            t.submit(self._test_existing_db, name)", "prediction_line": "            t.submit(self._test_existing_db, name)", "ground_truth": "            t.submit(self._test_existing_db, name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        try:\n            test_connect(self.config.databases[name])", "prediction_line": "        try:", "ground_truth": "        label: Label = self.query_one(\"#list_label_\" + name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        label.text = f\"[yellow]Testing {name}...[/yellow]\"", "prediction_line": "        label.text = f\"[yellow]Testing {name}...[/yellow]\"", "ground_truth": "        label.update(f\"{name}🔃\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    conn.close()", "prediction_line": "    conn.close()", "ground_truth": "    assert conn.query(\"select 1+1\", int) == 2", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                connect_dict[p.name] = p.value", "prediction_line": "                connect_dict[p.name] = p.value", "ground_truth": "                connect_dict[p.name] = p.value", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for name in self.config.databases.keys():", "prediction_line": "        for name in self.config.databases.keys():", "ground_truth": "        for name in self.config.databases:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if p in db_config:", "prediction_line": "            if p in db_config:", "ground_truth": "            widgets.append(Input(id=\"input_\" + p, name=p, classes=\"param\", value=db_config.get(p)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        conn_name = self._selected_connection().name", "prediction_line": "        conn_name = self._selected_connection().name", "ground_truth": "        name = self._selected_connection().name", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.params_container.new_content(", "prediction_line": "        self.params_container.new_content(", "ground_truth": "        self.driver_select = Select(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.databases[name] = db", "prediction_line": "        self.databases[name] = db", "ground_truth": "        self.config[\"database\"][name] = db", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   def get_database(self, name):", "prediction_line": "   def get_database(self, name):", "ground_truth": "class EditConnection(Vertical):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def action_test_conn(self):", "prediction_line": "    def action_test_conn(self):", "ground_truth": "    def action_add_conn(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.list_swapper = ContentSwapper(id=\"list_container\")", "prediction_line": "        self.list_swapper = ContentSwapper(id=\"list_container\")", "ground_truth": "        \"\"\"Create child widgets for the app.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self._test_existing_db(name)", "prediction_line": "        self._test_existing_db(name)", "ground_truth": "        t = ThreadPoolExecutor()", "line_class": "random", "zero_context": true}
{"original_prediction": "        base_params = list(set(base_params))", "prediction_line": "        base_params = list(set(base_params))", "ground_truth": "        params = dict.fromkeys([p.lower() for p in base_params] + [k for k in db_config if k != \"driver\"])", "line_class": "random", "zero_context": true}
{"original_prediction": "        ]\n        self.list = ListView(", "prediction_line": "        ]", "ground_truth": "        ]", "line_class": "random", "zero_context": true}
{"original_prediction": "           try:\n                test_connect(connect_dict)", "prediction_line": "           try:", "ground_truth": "            result_container = self.query_one(\"#result\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        driver = self.driver_select.value", "prediction_line": "        driver = self.driver_select.value", "ground_truth": "        connect_dict = {\"driver\": self.driver_select.value}", "line_class": "random", "zero_context": true}
{"original_prediction": "                event_json = create_end_event_json(", "prediction_line": "                event_json = create_end_event_json(", "ground_truth": "                runtime = time.monotonic() - start", "line_class": "common", "zero_context": true}
{"original_prediction": "                event_json = create_end_event_json(", "prediction_line": "                event_json = create_end_event_json(", "ground_truth": "                table1_count = self.stats.get(\"table1_count\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                table2_count = self.stats.get(\"table2_count\")", "prediction_line": "                table2_count = self.stats.get(\"table2_count\")", "ground_truth": "                table2_count = self.stats.get(\"table2_count\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                diff_count = self.stats.get(\"diff_count\")", "prediction_line": "                diff_count = self.stats.get(\"diff_count\")", "ground_truth": "                diff_count = self.stats.get(\"diff_count\")", "line_class": "common", "zero_context": true}
{"original_prediction": "            yield from diff", "prediction_line": "            yield from diff", "ground_truth": "            self.stats[\"rows_downloaded\"] = self.stats.get(\"rows_downloaded\", 0) + max(len(rows1), len(rows2))", "line_class": "common", "zero_context": true}
{"original_prediction": "@dataclass", "prediction_line": "@dataclass", "ground_truth": "BENCHMARK = os.environ.get(\"BENCHMARK\", False)", "line_class": "common", "zero_context": true}
{"original_prediction": "            self.stats[\"table1_count\"] = count1", "prediction_line": "            self.stats[\"table1_count\"] = count1", "ground_truth": "            self.stats[\"table1_count\"] = self.stats.get(\"table1_count\", 0) + count1", "line_class": "common", "zero_context": true}
{"original_prediction": "            self.stats[\"table2_count\"] = self.stats.get(\"table2_count\", 0) + count2", "prediction_line": "            self.stats[\"table2_count\"] = self.stats.get(\"table2_count\", 0) + count2", "ground_truth": "            self.stats[\"table2_count\"] = self.stats.get(\"table2_count\", 0) + count2", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.stats[\"diff_time\"] = 0", "prediction_line": "        self.stats[\"diff_time\"] = 0", "ground_truth": "        start = time.monotonic()", "line_class": "common", "zero_context": true}
{"original_prediction": "            yield from diff_sets(rows1, rows2)", "prediction_line": "            yield from diff_sets(rows1, rows2)", "ground_truth": "            diff = list(diff_sets(rows1, rows2))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                rows1, rows2 = self._threaded_call(\"get_values\", [table1, table2])", "prediction_line": "                rows1, rows2 = self._threaded_call(\"get_values\", [table1, table2])", "ground_truth": "                return self._bisect_and_diff_tables(ti, table1, table2, level=level, max_rows=max_rows)", "line_class": "infile", "zero_context": true}
{"original_prediction": "for the other\n            key_range1 = next(key_ranges)", "prediction_line": "for the other", "ground_truth": "            min_key1, max_key1 = self._parse_key_range_result(key_type, next(key_ranges))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            # logger.warning(", "prediction_line": "            # logger.warning(", "ground_truth": "            return self._bisect_and_diff_tables(ti, table1, table2, level=level, max_rows=max(count1, count2))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            # We do this in a separate thread, so we can continue diffing the rest of the table", "prediction_line": "            # We do this in a separate thread, so we can continue diffing the rest of the table", "ground_truth": "            min_key2, max_key2 = self._parse_key_range_result(key_type, next(key_ranges))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if table1.schema != table2.schema:", "prediction_line": "            if table1.schema != table2.schema:", "ground_truth": "            self._validate_and_adjust_columns(table1, table2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if key_type != key_type2:", "prediction_line": "            if key_type != key_type2:", "ground_truth": "            if not isinstance(key_type, IKey):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if not isinstance(col2, NumericType):", "prediction_line": "                if not isinstance(col2, NumericType):", "ground_truth": "                if not isinstance(col2, NumericType):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                # We have a gap between the two tables.", "prediction_line": "                # We have a gap between the two tables.", "ground_truth": "                pre_tables = [t.new(min_key=min_key2, max_key=min_key1) for t in (table1, table2)]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if not isinstance(key_type2, IKey):", "prediction_line": "            if not isinstance(key_type2, IKey):", "ground_truth": "            if not isinstance(key_type2, IKey):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    table1_count,", "prediction_line": "                    table1_count,", "ground_truth": "                    table1.database.name,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # The first segment is always the full table, so we can skip it.", "prediction_line": "            # The first segment is always the full table, so we can skip it.", "ground_truth": "            ti.submit(self._bisect_and_diff_tables, ti, table1, table2)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        segmented2 = table2.segment_by_checkpoints(checkpoints)", "prediction_line": "        segmented2 = table2.segment_by_checkpoints(checkpoints)", "ground_truth": "        segmented2 = table2.segment_by_checkpoints(checkpoints)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if isinstance(col2, PrecisionType):", "prediction_line": "                if isinstance(col2, PrecisionType):", "ground_truth": "                if not isinstance(col2, PrecisionType):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            schema1 = table1.get_schema()", "prediction_line": "            schema1 = table1.get_schema()", "ground_truth": "            table1, table2 = self._threaded_call(\"with_schema\", [table1, table2])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "           min_key2, max_key2 = self._parse_key_range_result(key_type, next(key_ranges))", "prediction_line": "           min_key2, max_key2 = self._parse_key_range_result(key_type, next(key_ranges))", "ground_truth": "            table1, table2 = [t.new(min_key=min_key1, max_key=max_key1) for t in (table1, table2)]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            options.pop(\"table1\")", "prediction_line": "            options.pop(\"table1\")", "ground_truth": "            event_json = create_start_event_json(options)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            min_key1, max_key1 = self._threaded_call(\"min_max_key\", [table1])", "prediction_line": "            min_key1, max_key1 = self._threaded_call(\"min_max_key\", [table1])", "ground_truth": "            key_ranges = self._threaded_call_as_completed(\"query_key_range\", [table1, table2])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for s1, s2 in safezip(segmented1, segmented2):", "prediction_line": "        for s1, s2 in safezip(segmented1, segmented2):", "ground_truth": "        for i, (t1, t2) in enumerate(safezip(segmented1, segmented2)):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise ValueError(f\"Invalid key range: {mn}..{mx}\") from e", "prediction_line": "            raise ValueError(f\"Invalid key range: {mn}..{mx}\") from e", "ground_truth": "            raise type(e)(f\"Cannot apply {key_type} to {mn}, {mx}.\") from e", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Checksum the segments", "prediction_line": "        # Checksum the segments", "ground_truth": "        (count1, checksum1), (count2, checksum2) = self._threaded_call(\"count_and_checksum\", [table1, table2])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from .table_segment_manager import TableSegmentManager", "prediction_line": "from .table_segment_manager import TableSegmentManager", "ground_truth": "from .tracking import create_end_event_json, create_start_event_json, send_event_json, is_tracking_enabled", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    This class is threaded, and will spawn a thread for each table segment.", "prediction_line": "    This class is threaded, and will spawn a thread for each table segment.", "ground_truth": "    The algorithm uses hashing to quickly check if the tables are different, and then applies a", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "@dataclass\nclass TableDiffResult(DiffResult):", "prediction_line": "@dataclass", "ground_truth": "def diff_sets(a: set, b: set) -> Iterator:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "_cls()\n        return cls.from_db_value(mn), cls.from_db_value(mx)", "prediction_line": "_cls()", "ground_truth": "        # We add 1 because our ranges are exclusive of the end (like in Python)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # Get the relevant columns", "prediction_line": "        # Get the relevant columns", "ground_truth": "        self.stats[\"diff_count\"] = 0", "line_class": "random", "zero_context": true}
{"original_prediction": "        yield v", "prediction_line": "        yield v", "ground_truth": "        yield from v", "line_class": "random", "zero_context": true}
{"original_prediction": "                raise ValueError(f\"Column '{c2}' not found in schema for table {table2}\")", "prediction_line": "                raise ValueError(f\"Column '{c2}' not found in schema for table {table2}\")", "ground_truth": "                raise ValueError(f\"Column '{c2}' not found in schema for table {table2}\")", "line_class": "random", "zero_context": true}
{"original_prediction": "    for i in s2 - s1:", "prediction_line": "    for i in s2 - s1:", "ground_truth": "    for i in s2 - s1:", "line_class": "random", "zero_context": true}
{"original_prediction": "        except TypeError:", "prediction_line": "        except TypeError:", "ground_truth": "        except (TypeError, ValueError) as e:", "line_class": "random", "zero_context": true}
{"original_prediction": "    if thread_count is None:", "prediction_line": "    if thread_count is None:", "ground_truth": "    if issubclass(cls, ThreadedDatabase):", "line_class": "commited", "zero_context": true}
{"original_prediction": "    else:\n        kw = matcher.match_path(dsn)", "prediction_line": "    else:", "ground_truth": "        kw.update(dsn.query)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Matches a URI path to a database.", "prediction_line": "    \"\"\"", "ground_truth": "    database_cls: Type[Database]", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if dsn.path.startswith(self.params[0]):", "prediction_line": "        if dsn.path.startswith(self.params[0]):", "ground_truth": "        dsn_dict = dict(dsn.query)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return connect_with_dict(db_conf, thread_count)", "prediction_line": "        return connect_with_dict(db_conf, thread_count)", "ground_truth": "        return connect_with_dict(db_conf, thread_count)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"snowflake\": MatchUriPath(Snowflake, [\"database?\"], help_str=\"snowflake://<user>:<pass>@<host>/<database>\"),", "prediction_line": "    \"snowflake\": MatchUriPath(Snowflake, [\"database?\"], help_str=\"snowflake://<user>:<pass>@<host>/<database>\"),", "ground_truth": "    \"snowflake\": MatchUriPath(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        kw = matcher.match_path(dsn)", "prediction_line": "        kw = matcher.match_path(dsn)", "ground_truth": "        kw = matcher.match_path(dsn)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"databricks\": MatchUriPath(Databricks, [\"database\"], help_str=\"databricks://<user>:<pass>@<host>/<database>\"),", "prediction_line": "    \"databricks\": MatchUriPath(Databricks, [\"database\"], help_str=\"databricks://<user>:<pass>@<host>/<database>\"),", "ground_truth": "    \"databricks\": MatchUriPath(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return connect_to_uri(db_conf, thread_count)", "prediction_line": "        return connect_to_uri(db_conf, thread_count)", "ground_truth": "        return connect_to_uri(db_conf, thread_count)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    PostgreSQL: MatchUriPath(", "prediction_line": "    PostgreSQL: MatchUriPath(", "ground_truth": "    \"postgresql\": MatchUriPath(PostgreSQL, [\"database?\"], help_str=\"postgresql://<user>:<pass>@<host>/<database>\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"mysql\": MatchUriPath(MySQL, [\"database?\"], help_str=\"mysql://<user>:<pass>@<host>/<database>\"),", "prediction_line": "    \"mysql\": MatchUriPath(MySQL, [\"database?\"], help_str=\"mysql://<user>:<pass>@<host>/<database>\"),", "ground_truth": "    \"mysql\": MatchUriPath(MySQL, [\"database?\"], help_str=\"mysql://<user>:<pass>@<host>/<database>\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"oracle\": MatchUriPath(Oracle, [\"database?\"], help_str=\"oracle://<user>:<pass>@<host>/<database>\"),", "prediction_line": "    \"oracle\": MatchUriPath(Oracle, [\"database?\"], help_str=\"oracle://<user>:<pass>@<host>/<database>\"),", "ground_truth": "    \"oracle\": MatchUriPath(Oracle, [\"database?\"], help_str=\"oracle://<user>:<pass>@<host>/<database>\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"snowflake\": MatchUriPath(", "prediction_line": "    \"snowflake\": MatchUriPath(", "ground_truth": "    \"redshift\": MatchUriPath(Redshift, [\"database?\"], help_str=\"redshift://<user>:<pass>@<host>/<database>\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "Snowflake, [\"database?\"], help_str=\"snowflake://<user>:<pass>@<host>/<database>\"),", "prediction_line": "Snowflake, [\"database?\"], help_str=\"snowflake://<user>:<pass>@<host>/<database>\"),", "ground_truth": "        Snowflake,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"bigquery\": MatchUriPath(", "prediction_line": "    \"bigquery\": MatchUriPath(", "ground_truth": "    \"presto\": MatchUriPath(Presto, [\"catalog\", \"schema\"], help_str=\"presto://<user>@<host>/<catalog>/<schema>\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"databricks\": MatchUriPath(", "prediction_line": "    \"databricks\": MatchUriPath(", "ground_truth": "    \"bigquery\": MatchUriPath(BigQuery, [\"dataset\"], help_str=\"bigquery://<project>/<dataset>\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "Databricks, [\"database\"], help_str=\"databricks://<user>:<pass>@<host>/<database>\"),", "prediction_line": "Databricks, [\"database\"], help_str=\"databricks://<user>:<pass>@<host>/<database>\"),", "ground_truth": "        Databricks,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"trino\": MatchUriPath(Trino, [\"catalog\", \"schema\"], help_str=\"trino://<user>@<host>/<catalog>/<schema>\"),", "prediction_line": "    \"trino\": MatchUriPath(Trino, [\"catalog\", \"schema\"], help_str=\"trino://<user>@<host>/<catalog>/<schema>\"),", "ground_truth": "    \"duckdb\": MatchUriPath(DuckDB, ['database', 'dbpath'], help_str=\"duckdb://<database>@<dbpath>\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"trino\": MatchUriPath(Trino, [\"catalog\", \"schema\"], help_str=\"trino://<user>@<host>/<catalog>/<schema>\"),", "prediction_line": "    \"trino\": MatchUriPath(Trino, [\"catalog\", \"schema\"], help_str=\"trino://<user>@<host>/<catalog>/<schema>\"),", "ground_truth": "    \"trino\": MatchUriPath(Trino, [\"catalog\", \"schema\"], help_str=\"trino://<user>@<host>/<catalog>/<schema>\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"clickhouse\": MatchUriPath(Clickhouse, [\"database\"], help_str=\"clickhouse://<user>:<pass>@<host>/<database>\"),", "prediction_line": "    \"clickhouse\": MatchUriPath(Clickhouse, [\"database\"], help_str=\"clickhouse://<user>:<pass>@<host>/<database>\"),", "ground_truth": "    \"clickhouse\": MatchUriPath(Clickhouse, [\"database?\"], help_str=\"clickhouse://<user>:<pass>@<host>/<database>\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"vertica\": MatchUriPath(Vertica, [\"database?\"], help_str=\"vertica://<user>:<pass>@<host>/<database>\"),", "prediction_line": "    \"vertica\": MatchUriPath(Vertica, [\"database?\"], help_str=\"vertica://<user>:<pass>@<host>/<database>\"),", "ground_truth": "    \"vertica\": MatchUriPath(Vertica, [\"database?\"], help_str=\"vertica://<user>:<pass>@<host>/<database>\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from .redshift import Redshift", "prediction_line": "from .redshift import Redshift", "ground_truth": "from .redshift import Redshift", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    - clickhouse", "prediction_line": "    - clickhouse", "ground_truth": "    - clickhouse", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from .sqlite import SQLite", "prediction_line": "from .sqlite import SQLite", "ground_truth": "from .snowflake import Snowflake", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    - oracle\n    - redshift", "prediction_line": "    - oracle", "ground_truth": "    - oracle", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def connect_to_database(", "prediction_line": "def connect_to_database(", "ground_truth": "def connect_with_dict(d, thread_count):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class DatabaseFactory:", "prediction_line": "class DatabaseFactory:", "ground_truth": "    help_str: str", "line_class": "random", "zero_context": true}
{"original_prediction": "        return self.database_cls(**matches)", "prediction_line": "        return self.database_cls(**matches)", "ground_truth": "        return matches", "line_class": "random", "zero_context": true}
{"original_prediction": "        for param, kwparam in zip_longest(self.params, self.kwparams):", "prediction_line": "        for param, kwparam in zip_longest(self.params, self.kwparams):", "ground_truth": "        matches = {}", "line_class": "random", "zero_context": true}
{"original_prediction": "class DatabaseFactory:", "prediction_line": "class DatabaseFactory:", "ground_truth": "MATCH_URI_PATH = {", "line_class": "random", "zero_context": true}
{"original_prediction": "@dataclass\nclass Connection:", "prediction_line": "@dataclass", "ground_truth": "@dataclass", "line_class": "random", "zero_context": true}
{"original_prediction": "        num = num * len(base) + base.index(c)", "prediction_line": "        num = num * len(base) + base.index(c)", "ground_truth": "        num = num * len(base) + base.index(c)", "line_class": "common", "zero_context": true}
{"original_prediction": "    \"Split a space between start and end into count pieces\"", "prediction_line": "    \"Split a space between start and end into count pieces\"", "ground_truth": "    size = end - start", "line_class": "common", "zero_context": true}
{"original_prediction": "+ 1\n            return self.new(str=numberToAlphanum(num, alphanums))", "prediction_line": "+ 1", "ground_truth": "            return self.new(numberToAlphanum(num + 1))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert isinstance(other, ArithAlphanumeric)", "prediction_line": "        assert isinstance(other, ArithAlphanumeric)", "ground_truth": "        assert isinstance(other, ArithAlphanumeric)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            n1, n2 = alphanums_to_numbers(self._str, other._str)", "prediction_line": "            n1, n2 = alphanums_to_numbers(self._str, other._str)", "ground_truth": "            n1, n2 = alphanums_to_numbers(self._str, other._str)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.new(int=self.int - other)", "prediction_line": "            return self.new(int=self.int - other)", "ground_truth": "            return self.new(int=self.int - other)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return [self.new(numberToAlphanum(i)) for i in split]", "prediction_line": "        return [self.new(numberToAlphanum(i)) for i in split]", "ground_truth": "        return [self.new(numberToAlphanum(s)) for s in split]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self > other:", "prediction_line": "        if self > other:", "ground_truth": "        assert isinstance(other, ArithString)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return [self.new(int=i) for i in checkpoints]", "prediction_line": "        return [self.new(int=i) for i in checkpoints]", "ground_truth": "        return [self.new(int=i) for i in checkpoints]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if isinstance(other, int):", "prediction_line": "        if isinstance(other, int):", "ground_truth": "        if isinstance(other, ArithAlphanumeric):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.new(int=self.int + other)", "prediction_line": "            return self.new(int=self.int + other)", "ground_truth": "            return self.new(int=self.int + other)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    s1, s2 = justify_alphanums(s1, s2)", "prediction_line": "    s1, s2 = justify_alphanums(s1, s2)", "ground_truth": "    s1, s2 = justify_alphanums(s1, s2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return alphanumToNumber(s1), alphanumToNumber(s2)", "prediction_line": "    return alphanumToNumber(s1), alphanumToNumber(s2)", "ground_truth": "    n1 = alphanumToNumber(s1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    n2 = alphanumToNumber(s2)", "prediction_line": "    n2 = alphanumToNumber(s2)", "ground_truth": "    n2 = alphanumToNumber(s2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return CaseInsensitiveDict(self)", "prediction_line": "        return CaseInsensitiveDict(self)", "ground_truth": "        return CaseInsensitiveDict(self)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.new(s=self._str + alphanums[0])", "prediction_line": "            return self.new(s=self._str + alphanums[0])", "ground_truth": "            num = alphanumToNumber(self._str)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return \"\".join(base[i] for i in digits[::-1])", "prediction_line": "    return \"\".join(base[i] for i in digits[::-1])", "ground_truth": "    return \"\".join(base[i] for i in digits[::-1])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        checkpoints = split_space(n1, n2, count)", "prediction_line": "        checkpoints = split_space(n1, n2, count)", "ground_truth": "        split = split_space(n1, n2, count)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        assert self.is_numeric() and other.is_numeric()", "prediction_line": "        assert self.is_numeric() and other.is_numeric()", "ground_truth": "        checkpoints = split_space(self.int, other.int, count)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if size == 0:", "prediction_line": "    if size == 0:", "ground_truth": "    assert count <= size, (count, size)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if count == size:", "prediction_line": "    if count == size:", "ground_truth": "    return list(range(start, end, (size + 1) // (count + 1)))[1 : count + 1]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if not isinstance(other, type(self)):", "prediction_line": "        if not isinstance(other, type(self)):", "ground_truth": "        if not isinstance(other, type(self)):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return type(self)(*args, **kw)", "prediction_line": "        return type(self)(*args, **kw)", "ground_truth": "        return type(self)(*args, **kw, max_len=self._max_len)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def __init__(self, *args, **kwargs):", "prediction_line": "    def __init__(self, *args, **kwargs):", "ground_truth": "    def __init__(self, initial):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class CaseSensitiveDict(CaseAwareMapping):", "prediction_line": "class CaseSensitiveDict(CaseAwareMapping):", "ground_truth": "class CaseSensitiveDict(dict, CaseAwareMapping):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    millidx = max(0, min(len(millnames) - 1, int(math.floor(0 if n == 0 else math.log10(abs(n)) / 3))))", "prediction_line": "    millidx = max(0, min(len(millnames) - 1, int(math.floor(0 if n == 0 else math.log10(abs(n)) / 3))))", "ground_truth": "    millidx = max(", "line_class": "random", "zero_context": true}
{"original_prediction": "    return n1, n2", "prediction_line": "    return n1, n2", "ground_truth": "    return n1, n2", "line_class": "random", "zero_context": true}
{"original_prediction": "       elif isinstance(other, int):", "prediction_line": "       elif isinstance(other, int):", "ground_truth": "        return NotImplemented", "line_class": "random", "zero_context": true}
{"original_prediction": "    s2 = s2.ljust(max_len)", "prediction_line": "    s2 = s2.ljust(max_len)", "ground_truth": "    s2 = s2.ljust(max_len)", "line_class": "random", "zero_context": true}
{"original_prediction": "    return True", "prediction_line": "    return True", "ground_truth": "    return True", "line_class": "random", "zero_context": true}
{"original_prediction": "        for attr in ('run_id', 'run_i', 'config', 'deps',", "prediction_line": "        for attr in ('run_id', 'run_i', 'config', 'deps',", "ground_truth": "        plugin_copy.__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            start=start,", "prediction_line": "            start=start,", "ground_truth": "            start=start,", "line_class": "common", "zero_context": true}
{"original_prediction": "            result = strax.Chunk(", "prediction_line": "            result = strax.Chunk(", "ground_truth": "            if start is None:", "line_class": "common", "zero_context": true}
{"original_prediction": "            compute_pars.remove('chunk_i')", "prediction_line": "            compute_pars.remove('chunk_i')", "ground_truth": "            del compute_pars[compute_pars.index('chunk_i')]", "line_class": "common", "zero_context": true}
{"original_prediction": ", so it doesn't need to check", "prediction_line": ", so it doesn't need to check", "ground_truth": "            start, end = None, None", "line_class": "common", "zero_context": true}
{"original_prediction": "            del compute_pars[compute_pars.index('start')]", "prediction_line": "            del compute_pars[compute_pars.index('start')]", "ground_truth": "            del compute_pars[compute_pars.index('start')]", "line_class": "common", "zero_context": true}
{"original_prediction": "            # (This is not a hard requirement, but it is a useful check)", "prediction_line": "            # (This is not a hard requirement, but it is a useful check)", "ground_truth": "            tranges = {k: (v.start, v.end) for k, v in kwargs.items()}", "line_class": "common", "zero_context": true}
{"original_prediction": "            if len(set(tranges.values())) > 1:", "prediction_line": "            if len(set(tranges.values())) > 1:", "ground_truth": "            start, end = list(tranges.values())[0]", "line_class": "common", "zero_context": true}
{"original_prediction": "            del compute_pars[compute_pars.index('end')]", "prediction_line": "            del compute_pars[compute_pars.index('end')]", "ground_truth": "            del compute_pars[compute_pars.index('end')]", "line_class": "common", "zero_context": true}
{"original_prediction": "            kwargs['start'] = start", "prediction_line": "            kwargs['start'] = start", "ground_truth": "            kwargs['start'] = start", "line_class": "common", "zero_context": true}
{"original_prediction": "            if save_when == SaveWhen.TARGET:", "prediction_line": "            if save_when == SaveWhen.TARGET:", "ground_truth": "            if save_when > strax.SaveWhen.EXPLICIT:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Provide the data_kind of one of the provide arguments of the plugin.", "prediction_line": "        \"\"\"", "ground_truth": "        if self.multi_output:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return tuple([_return_hashable(attr) for attr in attributes])", "prediction_line": "        return tuple([_return_hashable(attr) for attr in attributes])", "ground_truth": "        res = {attr: _return_hashable(attr) for attr in attributes}", "line_class": "infile", "zero_context": true}
{"original_prediction": "            data_type=data_type,", "prediction_line": "            data_type=data_type,", "ground_truth": "            data_kind=self.data_kind_for(data_type),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if self._fetch_chunk(d, iters, check_end_not_before=_end):", "prediction_line": "            if self._fetch_chunk(d, iters, check_end_not_before=_end):", "ground_truth": "            self._fetch_chunk(d, iters)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            version=self.version(run_id),", "prediction_line": "            version=self.version(run_id),", "ground_truth": "            dtype=self.dtype_for(data_type),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            _dtype = self.dtype", "prediction_line": "            _dtype = self.dtype", "ground_truth": "            assert not self.multi_output", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self._auto_version", "prediction_line": "            return self._auto_version", "ground_truth": "            return self._auto_version", "line_class": "infile", "zero_context": true}
{"original_prediction": "            raise PluginGaveWrongOutput(", "prediction_line": "            raise PluginGaveWrongOutput(", "ground_truth": "            raise strax.PluginGaveWrongOutput(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if self.input_timeout is not None:", "prediction_line": "                if self.input_timeout is not None:", "ground_truth": "                while not self.is_ready(chunk_i):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    if time.time() - last_input_received > self.input_timeout:", "prediction_line": "                    if time.time() - last_input_received > self.input_timeout:", "ground_truth": "                    if self.source_finished():", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.__copy__(_deep_copy=True)", "prediction_line": "        return self.__copy__(_deep_copy=True)", "ground_truth": "        return self.__copy__(_deep_copy=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                            raise IterDone()", "prediction_line": "                            raise IterDone()", "ground_truth": "                            raise IterDone()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        raise InputTimeoutExceeded(", "prediction_line": "                        raise InputTimeoutExceeded(", "ground_truth": "                        raise InputTimeoutExceeded(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return {k: np.zeros(0, dtype=self.dtype_for(k))", "prediction_line": "            return {k: np.zeros(0, dtype=self.dtype_for(k))", "ground_truth": "            return {d: np.empty(0, self.dtype_for(d))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        self._fetch_chunk(pacemaker, iters,", "prediction_line": "                        self._fetch_chunk(pacemaker, iters,", "ground_truth": "                        if not self._fetch_chunk(pacemaker, iters):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.dtype = strax.infer_dtype(self.dtype)", "prediction_line": "            self.dtype = strax.infer_dtype(self.dtype)", "ground_truth": "            self.dtype = self.infer_dtype()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if save_when > strax.SaveWhen.EXPLICIT:", "prediction_line": "            if save_when > strax.SaveWhen.EXPLICIT:", "ground_truth": "            if save_when <= strax.SaveWhen.EXPLICIT:", "line_class": "infile", "zero_context": true}
{"original_prediction": "                                if not self._fetch_chunk(d, iters,", "prediction_line": "                                if not self._fetch_chunk(d, iters,", "ground_truth": "                                self._fetch_chunk(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # How many seconds to wait for input before crashing", "prediction_line": "    # How many seconds to wait for input before crashing", "ground_truth": "    save_when = SaveWhen.ALWAYS", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if d not in self.dtype:", "prediction_line": "            if d not in self.dtype:", "ground_truth": "            fieldnames = self.dtype_for(d).names", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Compute", "prediction_line": "        # Compute", "ground_truth": "        result = self.compute(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self.multi_output:", "prediction_line": "        if self.multi_output:", "ground_truth": "        return self._fix_output(result, start, end)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Fix the output of the compute function.", "prediction_line": "        \"\"\"", "ground_truth": "        if self.multi_output and _dtype is None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        for kind, deps_of_kind in self.dependencies_by_kind().items()}", "prediction_line": "                        for kind, deps_of_kind in self.dependencies_by_kind().items()}", "ground_truth": "                        for kind, deps_of_kind in self.dependencies_by_kind().items()}", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if not set(result.keys()) == set(self.provides):", "prediction_line": "            if not set(result.keys()) == set(self.provides):", "ground_truth": "            return {d: self._fix_output(result[d], start, end, _dtype=d)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        self.compute,", "prediction_line": "                        self.compute,", "ground_truth": "                        self.do_compute,", "line_class": "infile", "zero_context": true}
{"original_prediction": "inspect.signature(self.compute).parameters)", "prediction_line": "inspect.signature(self.compute).parameters)", "ground_truth": "            inspect.signature(self.compute).parameters.keys())", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    yield self.do_compute(", "prediction_line": "                    yield self.do_compute(", "ground_truth": "                    yield self.do_compute(chunk_i=chunk_i, **inputs_merged)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if not self.is_ready(chunk_i):", "prediction_line": "                if not self.is_ready(chunk_i):", "ground_truth": "                if self._fetch_chunk(d, iters):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        except IterDone:", "prediction_line": "        except IterDone:", "ground_truth": "        except IterDone:", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    f'dtype {self.dtype_for(_dtype)}.')", "prediction_line": "                    f'dtype {self.dtype_for(_dtype)}.')", "ground_truth": "                    f'dtype {self.dtype_for(_dtype)}.\\nSee '", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if result.dtype != self.dtype_for(_dtype):", "prediction_line": "        if result.dtype != self.dtype_for(_dtype):", "ground_truth": "            self._check_dtype(result, _dtype)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if start is not None:", "prediction_line": "        if start is not None:", "ground_truth": "            result = self.chunk(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            result = strax.Chunk(", "prediction_line": "            result = strax.Chunk(", "ground_truth": "            result = strax.dict_to_rec(result, dtype=self.dtype_for(_dtype))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # Fetch the chunk", "prediction_line": "            # Fetch the chunk", "ground_truth": "            self.input_buffer[d] = strax.Chunk.concatenate(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                return strax.deterministic_hash(obj)", "prediction_line": "                return strax.deterministic_hash(obj)", "ground_truth": "                return strax.deterministic_hash(obj)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                self.input_buffer[d].split(", "prediction_line": "                                self.input_buffer[d].split(", "ground_truth": "                                inputs[d].split(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    takes_config = False", "prediction_line": "    takes_config = False", "ground_truth": "    takes_config = immutabledict()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       if x.dtype != self.dtype_for(d):", "prediction_line": "       if x.dtype != self.dtype_for(d):", "ground_truth": "        expect = strax.remove_titles_from_dtype(self.dtype_for(d))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.dtype = strax.to_numpy_dtype(self.dtype)", "prediction_line": "            self.dtype = strax.to_numpy_dtype(self.dtype)", "ground_truth": "            self.dtype = strax.to_numpy_dtype(self.dtype)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            self.input_buffer[d], None", "prediction_line": "                            self.input_buffer[d], None", "ground_truth": "                            self.input_buffer[d].split(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                return self.config[name]", "prediction_line": "                return self.config[name]", "ground_truth": "                return self.takes_config[name].__get__(self)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "k: strax.Chunk.concatenate(", "prediction_line": "k: strax.Chunk.concatenate(", "ground_truth": "                        kind: strax.Chunk.merge([inputs[d] for d in deps_of_kind])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # Wait for all pending futures to finish", "prediction_line": "            # Wait for all pending futures to finish", "ground_truth": "            self.cleanup(wait_for=pending_futures)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "run_id, data_type).lineage_hash,", "prediction_line": "run_id, data_type).lineage_hash,", "ground_truth": "                run_id, data_type, self.lineage).lineage_hash,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    save_when: SaveWhen", "prediction_line": "    save_when: SaveWhen", "ground_truth": "    input_buffer: typing.Dict[str, strax.Chunk]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            version=self.version(run_id),", "prediction_line": "            version=self.version(run_id),", "ground_truth": "            lineage_hash=strax.DataKey(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if not isinstance(v, strax.Chunk):", "prediction_line": "            if not isinstance(v, strax.Chunk):", "ground_truth": "            if not isinstance(v, strax.Chunk):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "import numpy as np", "prediction_line": "import numpy as np", "ground_truth": "import numpy as np", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    ALWAYS = 3        # Save regardless of user's wishes", "prediction_line": "    ALWAYS = 3        # Save regardless of user's wishes", "ground_truth": "    ALWAYS = 3        # Save even if the user does not list it", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def compute(self, **kwargs):", "prediction_line": "    def compute(self, **kwargs):", "ground_truth": "    def compute(self, **kwargs):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from . import utils", "prediction_line": "from . import utils", "ground_truth": "import strax", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        if self.multi_output:", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        return self.data_kind", "prediction_line": "        return self.data_kind", "ground_truth": "        return self.data_kind", "line_class": "random", "zero_context": true}
{"original_prediction": "        else:\n            self._check_dtype(result.data, _dtype)", "prediction_line": "        else:", "ground_truth": "        return result", "line_class": "random", "zero_context": true}
{"original_prediction": "                            f\"inputs in {max_passes_left} passes\")", "prediction_line": "                            f\"inputs in {max_passes_left} passes\")", "ground_truth": "                            f\"inputs after ten passess. Inputs: \\n{inputs}\\n\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Fix the dtype of the plugin.", "prediction_line": "        \"\"\"", "ground_truth": "        try:", "line_class": "random", "zero_context": true}
{"original_prediction": "                           f\"ranges for inputs: {tranges}\")", "prediction_line": "                           f\"ranges for inputs: {tranges}\")", "ground_truth": "                           f\"ranges of inputs: {tranges}\")", "line_class": "random", "zero_context": true}
{"original_prediction": "    shell.run(", "prediction_line": "    shell.run(", "ground_truth": "    shell.run(", "line_class": "common", "zero_context": true}
{"original_prediction": "    shell.run(", "prediction_line": "    shell.run(", "ground_truth": "    shell.run([\"npm\", \"install\"], hide_output=hide_output)", "line_class": "common", "zero_context": true}
{"original_prediction": "        data = json.load(f)", "prediction_line": "        data = json.load(f)", "ground_truth": "        data = json.load(f)", "line_class": "common", "zero_context": true}
{"original_prediction": "    shell.run(", "prediction_line": "    shell.run(", "ground_truth": "    shell.run([\"npx\", \"compileProtos\", \"src\"], hide_output=hide_output)", "line_class": "common", "zero_context": true}
{"original_prediction": "    shell.run([\"npm\", \"run\", \"prelint\"], hide_output=hide_output, raise_on_fail=False)", "prediction_line": "    shell.run([\"npm\", \"run\", \"prelint\"], hide_output=hide_output, raise_on_fail=False)", "ground_truth": "    shell.run([\"npm\", \"run\", \"prelint\"], check=False, hide_output=hide_output)", "line_class": "common", "zero_context": true}
{"original_prediction": "    with open(Path(relative_dir, \".repo-metadata.json\").resolve()) as f:", "prediction_line": "    with open(Path(relative_dir, \".repo-metadata.json\").resolve()) as f:", "ground_truth": "    default_version = json.load(", "line_class": "common", "zero_context": true}
{"original_prediction": "    shell.run([\"npm\", \"run\", \"fix\"], hide_output=hide_output)", "prediction_line": "    shell.run([\"npm\", \"run\", \"fix\"], hide_output=hide_output)", "ground_truth": "    shell.run([\"npm\", \"run\", \"fix\"], hide_output=hide_output)", "line_class": "common", "zero_context": true}
{"original_prediction": "    )[\"default_version\"]", "prediction_line": "    )[\"default_version\"]", "ground_truth": "    ).get(\"default_version\")", "line_class": "common", "zero_context": true}
{"original_prediction": "    shell.run([\"npm\", \"run\", \"postprocess\"], hide_output=hide_output)", "prediction_line": "    shell.run([\"npm\", \"run\", \"postprocess\"], hide_output=hide_output)", "ground_truth": "    install(hide_output=hide_output)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    fix(hide_output=hide_output)", "prediction_line": "    fix(hide_output=hide_output)", "ground_truth": "    fix(hide_output=hide_output)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    compile_protos(hide_output=hide_output)", "prediction_line": "    compile_protos(hide_output=hide_output)", "ground_truth": "    compile_protos(hide_output=hide_output)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       postprocess_gapic_library_hermetic()", "prediction_line": "       postprocess_gapic_library_hermetic()", "ground_truth": "    library_version = template_metadata(str(Path(relative_dir))).get(\"version\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        metadata = read_metadata(relative_dir)", "prediction_line": "        metadata = read_metadata(relative_dir)", "ground_truth": "        metadata = read_metadata(relative_dir)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    install_hermetic(hide_output=hide_output)", "prediction_line": "    install_hermetic(hide_output=hide_output)", "ground_truth": "    fix_hermetic(hide_output=hide_output)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    postprocess: Callable[[Path], None] = _noop,", "prediction_line": "    postprocess: Callable[[Path], None] = _noop,", "ground_truth": "    patch_staging: Callable[[Path], None] = _noop,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # compose the content of src/index.ts", "prediction_line": "    # compose the content of src/index.ts", "ground_truth": "    clients = extract_clients(versioned_index_ts_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    compile_protos_hermetic(hide_output=hide_output)", "prediction_line": "    compile_protos_hermetic(hide_output=hide_output)", "ground_truth": "    compile_protos_hermetic(hide_output=hide_output)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Entrypoint for owlbot.py.", "prediction_line": "    \"\"\"", "ground_truth": "    owlbot_dirs = walk_through_owlbot_dirs(Path.cwd())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        owlbot_main(", "prediction_line": "        owlbot_main(", "ground_truth": "        owlbot_main(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    owlbot_entrypoint()", "prediction_line": "    owlbot_entrypoint()", "ground_truth": "    owlbot_entrypoint()", "line_class": "infile", "zero_context": true}
{"original_prediction": "def owlbot_main_hermetic(", "prediction_line": "def owlbot_main_hermetic(", "ground_truth": "        postprocess_gapic_library_hermetic()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    index_content = index_template.render(", "prediction_line": "    index_content = index_template.render(", "ground_truth": "    output_text = index_template.render(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            logger.info(f\"Copying files from ${library} to ${relative_dir}.\")", "prediction_line": "            logger.info(f\"Copying files from ${library} to ${relative_dir}.\")", "ground_truth": "            _tracked_paths.add(library)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    logger.debug(\"Running fix...\")", "prediction_line": "    logger.debug(\"Running fix...\")", "ground_truth": "    logger.debug(\"Copy eslint config\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        logger.info(f\"Collected versions ${versions} from ${src}\")", "prediction_line": "        logger.info(f\"Collected versions ${versions} from ${src}\")", "ground_truth": "        logger.info(f\"Collected versions ${versions} from ${src}\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": ".\n    quickstart_sample = next(", "prediction_line": ".", "ground_truth": "    quickstart_snippets = list(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    logger.debug(\"Copying protos\")", "prediction_line": "    logger.debug(\"Copying protos\")", "ground_truth": "    logger.debug(\"Compiling protos...\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # Add the quickstart sample to the list of samples", "prediction_line": "    # Add the quickstart sample to the list of samples", "ground_truth": "    metadata[\"samples\"] = list(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    shell.run(", "prediction_line": "    shell.run(", "ground_truth": "    logger.debug(\"Installing dependencies...\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        fh.write(output_text)", "prediction_line": "        fh.write(output_text)", "ground_truth": "        fh.write(output_text)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    logger.debug(\"Post-processing completed\")", "prediction_line": "    logger.debug(\"Post-processing completed\")", "ground_truth": "    logger.debug(\"Post-processing completed\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    metadata[\"quickstart\"] = snippets.read_snippet(", "prediction_line": "    metadata[\"quickstart\"] = snippets.read_snippet(", "ground_truth": "    all_samples = samples.all_samples([str(Path(relative_dir, \"samples/*.js\"))])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        logger.info(f\"Default version is {default_version}.  Ok.\")", "prediction_line": "        logger.info(f\"Default version is {default_version}.  Ok.\")", "ground_truth": "        logger.info(f\"Copying files from staging directory ${staging}.\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Generate samples for the default version.", "prediction_line": "        # Generate samples for the default version.", "ground_truth": "        common.update_library_version(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    logger.debug(\"Fixing formatting...\")", "prediction_line": "    logger.debug(\"Fixing formatting...\")", "ground_truth": "    logger.debug(\"Running prelint...\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            all_samples,", "prediction_line": "            all_samples,", "ground_truth": "            all_samples,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   \"\"\"\n    if staging_excludes is None:", "prediction_line": "   \"\"\"", "ground_truth": "    When there is no owlbot.py file, run this function instead.  Also, when an", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# You may obtain a copy of the License at", "prediction_line": "# You may obtain a copy of the License at", "ground_truth": "# You may obtain a copy of the License at", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Generate index.ts file for each version.", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ".\n    \"\"\"\n    logger.debug(\"Fixing formatting...\")", "prediction_line": ".", "ground_truth": "    for samples, but do not fail if it does not succeed.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "      relative_dir: the relative path of the client library.", "prediction_line": "      relative_dir: the relative path of the client library.", "ground_truth": "    Return:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # write index.ts file", "prediction_line": "    # write index.ts file", "ground_truth": "    with open(Path(relative_dir, \"src/index.ts\").resolve(), \"w\") as fh:", "line_class": "random", "zero_context": true}
{"original_prediction": "        hide_output=hide_output,", "prediction_line": "        hide_output=hide_output,", "ground_truth": "        hide_output=hide_output,", "line_class": "random", "zero_context": true}
{"original_prediction": "    for d in dir.iterdir():", "prediction_line": "    for d in dir.iterdir():", "ground_truth": "    for path_object in dir.glob(\"packages/**/.OwlBot.yaml\"):", "line_class": "random", "zero_context": true}
{"original_prediction": "def owlbot_main_hermetic(", "prediction_line": "def owlbot_main_hermetic(", "ground_truth": "if __name__ == \"__main__\":", "line_class": "random", "zero_context": true}
{"original_prediction": "    else:\n        logger.info(f\"Default version is {default_version}.\")", "prediction_line": "    else:", "ground_truth": "    elif staging.is_dir():", "line_class": "random", "zero_context": true}
{"original_prediction": "    node_mono_repo.owlbot_entrypoint(", "prediction_line": "    node_mono_repo.owlbot_entrypoint(", "ground_truth": "    node_mono_repo.owlbot_entrypoint(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        node_mono_repo.generate_index_ts(", "prediction_line": "        node_mono_repo.generate_index_ts(", "ground_truth": "        node_mono_repo.generate_index_ts(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        metadata = node_mono_repo.template_metadata(", "prediction_line": "        metadata = node_mono_repo.template_metadata(", "ground_truth": "        metadata = node_mono_repo.template_metadata(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        shell_run_mock.return_value = 0", "prediction_line": "        shell_run_mock.return_value = 0", "ground_truth": "        node_mono_repo.install()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        node_mono_repo.fix()", "prediction_line": "        node_mono_repo.fix()", "ground_truth": "        node_mono_repo.fix()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        node_mono_repo.compile_protos()", "prediction_line": "        node_mono_repo.compile_protos()", "ground_truth": "        node_mono_repo.compile_protos()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        s.owlbot_main(", "prediction_line": "        s.owlbot_main(", "ground_truth": "        node_mono_repo.owlbot_entrypoint(template_path=TEMPLATES)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        node_mono_repo.postprocess_gapic_library()", "prediction_line": "        node_mono_repo.postprocess_gapic_library()", "ground_truth": "        node_mono_repo.postprocess_gapic_library()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        metadata = node_mono_repo.template_metadata(FIXTURES)", "prediction_line": "        metadata = node_mono_repo.template_metadata(FIXTURES)", "ground_truth": "        metadata = node_mono_repo.template_metadata(FIXTURES)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        node_mono_repo.extract_clients(index_ts_path)", "prediction_line": "        node_mono_repo.extract_clients(index_ts_path)", "ground_truth": "        clients = node_mono_repo.extract_clients(index_ts_path)", "line_class": "commited", "zero_context": true}
{"original_prediction": "@patch(\"synthtool.languages.node_mono_repo.postprocess_gapic_library_hermetic\")", "prediction_line": "@patch(\"synthtool.languages.node_mono_repo.postprocess_gapic_library_hermetic\")", "ground_truth": "@patch(\"synthtool.languages.node_mono_repo.postprocess_gapic_library_hermetic\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @patch(\"synthtool.shell.run\")", "prediction_line": "    @patch(\"synthtool.shell.run\")", "ground_truth": "    @patch(\"synthtool.shell.run\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        patch_staging=patch,", "prediction_line": "        patch_staging=patch,", "ground_truth": "        patch_staging=patch,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    with util.chdir(FIXTURES / \"node_templates\" / \"standard\"):", "prediction_line": "    with util.chdir(FIXTURES / \"node_templates\" / \"standard\"):", "ground_truth": "    with util.chdir(FIXTURES / \"node_templates\" / \"standard\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with util.copied_fixtures_dir(", "prediction_line": "    with util.copied_fixtures_dir(", "ground_truth": "    with util.copied_fixtures_dir(FIXTURES / \"node_templates\" / \"no_version\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with util.chdir(FIXTURES):", "prediction_line": "    with util.chdir(FIXTURES):", "ground_truth": "    with util.chdir(FIXTURES / \"node_templates\" / \"index_samples\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_quickstart_metadata_without_snippet():", "prediction_line": "def test_quickstart_metadata_without_snippet():", "ground_truth": "        assert isinstance(metadata[\"samples\"], list)", "line_class": "inproject", "zero_context": true}
{"original_prediction": ".\n        assert \"quickstart.md\" in metadata[\"samples\"][0]", "prediction_line": ".", "ground_truth": "        sample_names = list(map(lambda sample: sample[\"file\"], metadata[\"samples\"]))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "list(filter(lambda name: \"quickstart\" in name, sample_names))) == 1", "prediction_line": "list(filter(lambda name: \"quickstart\" in name, sample_names))) == 1", "ground_truth": "                list(filter((re.compile(\"samples/quickstart.js$\")).match, sample_names))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with util.chdir(FIXTURES / \"python_templates\" / \"standard\"):", "prediction_line": "    with util.chdir(FIXTURES / \"python_templates\" / \"standard\"):", "ground_truth": "    with util.chdir(FIXTURES):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    node_mono_repo.owlbot_main()", "prediction_line": "    node_mono_repo.owlbot_main()", "ground_truth": "    with util.copied_fixtures_dir(FIXTURES / \"nodejs_mono_repo_with_staging\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with util.chdir(FIXTURES / \"node_templates\" / \"no_quickstart\"):", "prediction_line": "    with util.chdir(FIXTURES / \"node_templates\" / \"no_quickstart\"):", "ground_truth": "    with util.chdir(FIXTURES / \"node_templates\" / \"no_quickstart_snippet\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with util.copied_fixtures_dir(FIXTURES / \"nodejs_mono_repo_with_staging\") as tmp:", "prediction_line": "    with util.copied_fixtures_dir(FIXTURES / \"nodejs_mono_repo_with_staging\") as tmp:", "ground_truth": "    with util.copied_fixtures_dir(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "import shutil\nimport subprocess", "prediction_line": "import shutil", "ground_truth": "import re", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_generate_index_ts_no_index_ts():", "prediction_line": "def test_generate_index_ts_no_index_ts():", "ground_truth": "class TestPostprocess(TestCase):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    assert staging_text != text", "prediction_line": "    assert staging_text != text", "ground_truth": "    assert \"import * as v2\" in staging_text", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_compile_protos_with_path(self, shell_run_mock):", "prediction_line": "    def test_compile_protos_with_path(self, shell_run_mock):", "ground_truth": "    def test_postprocess_gapic_library(self, shell_run_mock):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        shell_run_mock.assert_called_once_with(\"npm install\")", "prediction_line": "        shell_run_mock.assert_called_once_with(\"npm install\")", "ground_truth": "        calls = shell_run_mock.call_args_list", "line_class": "random", "zero_context": true}
{"original_prediction": "        / \"dlp\"", "prediction_line": "        / \"dlp\"", "ground_truth": "        / \"dlp\"", "line_class": "random", "zero_context": true}
{"original_prediction": "/ \"nodejs_mono_repo_with_staging\" / \"src\" / \"v1\" / \"index.ts\"", "prediction_line": "/ \"nodejs_mono_repo_with_staging\" / \"src\" / \"v1\" / \"index.ts\"", "ground_truth": "        / \"nodejs_mono_repo_with_staging\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        assert (\n            len(", "prediction_line": "        assert (", "ground_truth": "        assert \"samples/quickstart.js\" not in sample_names", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert text == staging_text", "prediction_line": "    assert text == staging_text", "ground_truth": "    assert staging_text != text", "line_class": "random", "zero_context": true}
{"original_prediction": "        release_please_manifest_json = json.load(f)", "prediction_line": "        release_please_manifest_json = json.load(f)", "ground_truth": "        manifest_json = json.load(f)", "line_class": "common", "zero_context": true}
{"original_prediction": "        repo_metadata_path = Path(f\"{package_dir}/.repo-metadata.json\")", "prediction_line": "        repo_metadata_path = Path(f\"{package_dir}/.repo-metadata.json\")", "ground_truth": "        default_version = json.load(", "line_class": "common", "zero_context": true}
{"original_prediction": "        config_json = json.load(f)", "prediction_line": "        config_json = json.load(f)", "ground_truth": "        config_json = json.load(f)", "line_class": "common", "zero_context": true}
{"original_prediction": "        )[\"default_version\"]", "prediction_line": "        )[\"default_version\"]", "ground_truth": "        ).get(\"default_version\")", "line_class": "common", "zero_context": true}
{"original_prediction": "            s.nox.noxfile.run_nox_session(", "prediction_line": "            s.nox.noxfile.run_nox_session(", "ground_truth": "            s.shell.run([\"nox\", \"-s\", \"format\"], cwd=noxfile.parent, hide_output=False)", "line_class": "common", "zero_context": true}
{"original_prediction": "        create_gapic_version_py(package_dir)", "prediction_line": "        create_gapic_version_py(package_dir)", "ground_truth": "        create_gapic_version_py(package_dir)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    owlbot_dirs = walk_through_owlbot_dirs(Path(\".\"))", "prediction_line": "    owlbot_dirs = walk_through_owlbot_dirs(Path(\".\"))", "ground_truth": "    owlbot_dirs = walk_through_owlbot_dirs(Path.cwd())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    create_symlink_in_docs_dir(package_dir, \"CHANGELOG.md\")", "prediction_line": "    create_symlink_in_docs_dir(package_dir, \"CHANGELOG.md\")", "ground_truth": "    create_symlink_in_docs_dir(package_dir, \"CHANGELOG.md\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        create_symlink_docs_readme(package_dir)", "prediction_line": "        create_symlink_docs_readme(package_dir)", "ground_truth": "        create_symlink_docs_readme(package_dir)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    configure_release_please(owlbot_dirs)", "prediction_line": "    configure_release_please(owlbot_dirs)", "ground_truth": "    configure_release_please(owlbot_dirs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        owlbot_main(package_dir)", "prediction_line": "        owlbot_main(package_dir)", "ground_truth": "        owlbot_main(package_dir)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        create_changelog_and_symlink_to_docs_changelog(package_dir)", "prediction_line": "        create_changelog_and_symlink_to_docs_changelog(package_dir)", "ground_truth": "        create_changelog_and_symlink_to_docs_changelog(package_dir)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        update_url_in_setup_py(package_dir)", "prediction_line": "        update_url_in_setup_py(package_dir)", "ground_truth": "        update_url_in_setup_py(package_dir)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    create_symlink_in_docs_dir(package_dir, \"README.rst\")", "prediction_line": "    create_symlink_in_docs_dir(package_dir, \"README.rst\")", "ground_truth": "    create_symlink_in_docs_dir(package_dir, \"README.rst\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Copy the template files into the package directory.", "prediction_line": "    # Copy the template files into the package directory.", "ground_truth": "        templated_files = gcp.CommonTemplates().py_mono_repo_library(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            default_version=default_version,", "prediction_line": "            default_version=default_version,", "ground_truth": "            versions=gcp.common.detect_versions(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   os.chdir(package_dir)", "prediction_line": "   os.chdir(package_dir)", "ground_truth": "    os.chdir(f\"{package_dir}/docs\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        s.move(templated_files, package_dir)", "prediction_line": "        s.move(templated_files, package_dir)", "ground_truth": "        s.move([templated_files], package_dir)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            f.write(\"\")", "prediction_line": "            f.write(\"\")", "ground_truth": "            f.write(\"# Changelog\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    os.chdir(current_dir)", "prediction_line": "    os.chdir(current_dir)", "ground_truth": "    os.chdir(current_dir)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # run format nox session for all directories which have a noxfile", "prediction_line": "    # run format nox session for all directories which have a noxfile", "ground_truth": "    s.remove_staging_dirs()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "package_name)\n            if path_to_version_file not in config_json[\"package-configs\"]:", "prediction_line": "package_name)", "ground_truth": "                package_name.replace(\"-\", \"/\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Copy the staging directory into the current working directory.", "prediction_line": "        # Copy the staging directory into the current working directory.", "ground_truth": "        for library in s.get_staging_dirs(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            f.write(gapic_version_text)", "prediction_line": "            f.write(gapic_version_text)", "ground_truth": "            f.write(gapic_version_text)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    version_file = Path(package_dir) / \"gapic_version.py\"", "prediction_line": "    version_file = Path(package_dir) / \"gapic_version.py\"", "ground_truth": "    sub_directory_to_gapic = Path(package_dir).name.replace(\"-\", \"/\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                sample_json[\"path\"] = str(file)", "prediction_line": "                sample_json[\"path\"] = str(file)", "ground_truth": "                sample_json[\"path\"] = str(file).replace(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # Copy the generated samples into the samples directory.", "prediction_line": "            # Copy the generated samples into the samples directory.", "ground_truth": "            s.move([library], package_dir, excludes=[\"**/gapic_version.py\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "# Generated by generate_gapic_version.py", "prediction_line": "# Generated by generate_gapic_version.py", "ground_truth": "__version__ = \"0.0.0\"  # {x-release-please-version}", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            if f\"packages/{package_name}\" not in config_json:", "prediction_line": "            if f\"packages/{package_name}\" not in config_json:", "ground_truth": "            # if package_name not in config_json[\"packages\"]:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Runs owlbot on the package_dir specified.", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"Copies files from staging and template directories into current working dir.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Configure release-please for all packages in owlbot_dirs", "prediction_line": "    \"\"\"", "ground_truth": "    # add all packages to the .release-please-manifest.json", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            }\n\n    with open(release_please_config, \"w\") as f:", "prediction_line": "            }", "ground_truth": "            }", "line_class": "random", "zero_context": true}
{"original_prediction": "f\"{library}/samples\", ignore_errors=True)", "prediction_line": "f\"{library}/samples\", ignore_errors=True)", "ground_truth": "                    f\"{package_dir}/samples/generated_samples\", ignore_errors=True", "line_class": "random", "zero_context": true}
{"original_prediction": "   return owlbot_dirs", "prediction_line": "   return owlbot_dirs", "ground_truth": "    return owlbot_dirs", "line_class": "random", "zero_context": true}
{"original_prediction": "           if path_to_version_file not in config_json[\"package-configs\"]:", "prediction_line": "           if path_to_version_file not in config_json[\"package-configs\"]:", "ground_truth": "            output: List[Union[str, Dict[str, str]]] = []", "line_class": "random", "zero_context": true}
{"original_prediction": "            if package_name not in manifest_json:", "prediction_line": "            if package_name not in manifest_json:", "ground_truth": "            if f\"packages/{package_name}\" not in manifest_json:", "line_class": "random", "zero_context": true}
{"original_prediction": "    component = pp.Combine(pp.Literal(COMPONENT_CLASSIFIER) + generic_identifier)", "prediction_line": "    component = pp.Combine(pp.Literal(COMPONENT_CLASSIFIER) + generic_identifier)", "ground_truth": "    component = pp.Combine(pp.Suppress(COMPONENT_CLASSIFIER) + generic_identifier)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    component.set_parse_action(EvalComponent)", "prediction_line": "    component.set_parse_action(EvalComponent)", "ground_truth": "    component.set_parse_action(EvalComponent)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    helper_function << helper_function_name + lpar + helper_func_args + rpar", "prediction_line": "    helper_function << helper_function_name + lpar + helper_func_args + rpar", "ground_truth": "    helper_function << (", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return component", "prediction_line": "    return component", "ground_truth": "    return component", "line_class": "commited", "zero_context": true}
{"original_prediction": "   helper_function.set_parse_action(EvalFunction)", "prediction_line": "   helper_function.set_parse_action(EvalFunction)", "ground_truth": "    helper_function.set_parse_action(EvalFunction)", "line_class": "commited", "zero_context": true}
{"original_prediction": "   helper_function_name = generic_identifier.copy()", "prediction_line": "   helper_function_name = generic_identifier.copy()", "ground_truth": "    helper_function = pp.Forward()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return helper_function", "prediction_line": "    return helper_function", "ground_truth": "    return helper_function", "line_class": "commited", "zero_context": true}
{"original_prediction": "    number = pp.Combine(", "prediction_line": "    number = pp.Combine(", "ground_truth": "    number = pp.pyparsing_common.number | inf_kw", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return number, generic_identifier", "prediction_line": "    return number, generic_identifier", "ground_truth": "    number.set_parse_action(EvalNumber)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return number, generic_identifier", "prediction_line": "    return number, generic_identifier", "ground_truth": "    return number, generic_identifier", "line_class": "commited", "zero_context": true}
{"original_prediction": "        helper_function << helper_function_name + lpar + helper_function + rpar", "prediction_line": "        helper_function << helper_function_name + lpar + helper_function + rpar", "ground_truth": "        allowed_parser_elements_in_args.insert(0, pp.Group(helper_function))", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if test:", "prediction_line": "        if test:", "ground_truth": "        helper_function = self.name.eval(test=test, **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    Parsing grammar to process strings representing model components, e.g.", "prediction_line": "    Parsing grammar to process strings representing model components, e.g.", "ground_truth": "    Parse strings preppended with the YAML constraint component classifier.", "line_class": "commited", "zero_context": true}
{"original_prediction": "                \"helper_function\": helper_function,", "prediction_line": "                \"helper_function\": helper_function,", "ground_truth": "                \"function\": helper_function,", "line_class": "commited", "zero_context": true}
{"original_prediction": "            return helper_function(*args_, **kwargs_)", "prediction_line": "            return helper_function(*args_, **kwargs_)", "ground_truth": "            return helper_function(*args_, **kwargs_)", "line_class": "commited", "zero_context": true}
{"original_prediction": "self, test: bool = False, **kwargs) -> Union[Any, Dict]:", "prediction_line": "self, test: bool = False, **kwargs) -> Union[Any, Dict]:", "ground_truth": "        self, helper_func_dict: Dict[str, Callable], test: bool = False, **kwargs", "line_class": "common", "zero_context": true}
{"original_prediction": "        if test:", "prediction_line": "        if test:", "ground_truth": "        if test:", "line_class": "common", "zero_context": true}
{"original_prediction": "                args_.append(arg)", "prediction_line": "                args_.append(arg)", "ground_truth": "                args_.append(arg.eval(test=test, **kwargs))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                args_.append(arg.eval(test=test, **kwargs))", "prediction_line": "                args_.append(arg.eval(test=test, **kwargs))", "ground_truth": "                args_.append(arg[0].eval(test=test, **kwargs))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    indexed_param_or_var.set_parse_action(EvalIndexedParameterOrVariable)", "prediction_line": "    indexed_param_or_var.set_parse_action(EvalIndexedParameterOrVariable)", "ground_truth": "    indexed_param_or_var.set_parse_action(EvalIndexedParameterOrVariable)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                kwargs_[kwarg_name] = kwarg_val.eval(test=test, **kwargs)", "prediction_line": "                kwargs_[kwarg_name] = kwarg_val.eval(test=test, **kwargs)", "ground_truth": "                kwargs_[kwarg_name] = kwarg_val.eval(test=test, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    helper_function_name.set_parse_action(EvalHelperFuncName)", "prediction_line": "    helper_function_name.set_parse_action(EvalHelperFuncName)", "ground_truth": "    helper_function_name.set_parse_action(EvalHelperFuncName)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                kwargs_[kwarg_name] = kwarg_val[0].eval(test=test, **kwargs)", "prediction_line": "                kwargs_[kwarg_name] = kwarg_val[0].eval(test=test, **kwargs)", "ground_truth": "                kwargs_[kwarg_name] = kwarg_val[0].eval(test=test, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    unindexed_param_or_var.set_parse_action(EvalUnindexedParameterOrVariable)", "prediction_line": "    unindexed_param_or_var.set_parse_action(EvalUnindexedParameterOrVariable)", "ground_truth": "    unindexed_param_or_var.set_parse_action(EvalUnindexedParameterOrVariable)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.helper_function_name = tokens.helper_function_name", "prediction_line": "        self.helper_function_name = tokens.helper_function_name", "ground_truth": "        token_dict = tokens.as_dict()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    args = pp.delimited_list(arg_values, delim=\",\")", "prediction_line": "    args = pp.delimited_list(arg_values, delim=\",\")", "ground_truth": "    arglist = pp.delimitedList(arg_values.copy())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    unindexed_param_or_var = generic_identifier.copy()", "prediction_line": "    unindexed_param_or_var = generic_identifier.copy()", "ground_truth": "    unindexed_param_or_var = generic_identifier.copy()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Tuple[pp.ParserElement, pp.ParserElement]:", "prediction_line": "        Tuple[pp.ParserElement, pp.ParserElement]:", "ground_truth": "        number [pp.ParserElement]:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Parse action to process successfully parsed indexed parameter or variable strings.", "prediction_line": "        Parse action to process successfully parsed indexed parameter or variable strings.", "ground_truth": "        Parse action to process successfully parsed indexed parameters or decision variables", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,", "prediction_line": "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,", "ground_truth": "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from pyparsing import (", "prediction_line": "from pyparsing import (", "ground_truth": "import pyparsing as pp", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            Parser for numbers described as integers (1), floats (1.), or in scientific", "prediction_line": "            Parser for numbers described as integers (1), floats (1.), or in scientific", "ground_truth": "            Parser for numbers (integer, float, scientific notation, \"inf\"/\".inf\").", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        return float(self.value)", "prediction_line": "        return float(self.value)", "ground_truth": "        return float(self.value)", "line_class": "random", "zero_context": true}
{"original_prediction": "helper_func_dict: Dict[str, Callable]) -> pp.ParserElement:", "prediction_line": "helper_func_dict: Dict[str, Callable]) -> pp.ParserElement:", "ground_truth": "    generic_identifier: pp.ParserElement,", "line_class": "random", "zero_context": true}
{"original_prediction": "            Parser for valid python variables without leading underscore and not called \"inf\".", "prediction_line": "            Parser for valid python variables without leading underscore and not called \"inf\".", "ground_truth": "            Parser for valid python variables without leading underscore and not called \"inf\".", "line_class": "random", "zero_context": true}
{"original_prediction": "        if test:", "prediction_line": "        if test:", "ground_truth": "        if self.name not in helper_func_dict.keys():", "line_class": "random", "zero_context": true}
{"original_prediction": "    rpar = pp.Suppress(\")\")", "prediction_line": "    rpar = pp.Suppress(\")\")", "ground_truth": "    rpar = pp.Suppress(\")\")", "line_class": "random", "zero_context": true}
{"original_prediction": "    return identifier + equation_parser.UNINDEXED_PARAM", "prediction_line": "    return identifier + equation_parser.UNINDEXED_PARAM", "ground_truth": "    return equation_parser.unindexed_param_parser(identifier)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert parsed_[0].eval() == expected", "prediction_line": "        assert parsed_[0].eval() == expected", "ground_truth": "        assert parsed_[0].eval() == {", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return equation_parser.indexed_param_parser(identifier)", "prediction_line": "    return equation_parser.indexed_param_parser(identifier)", "ground_truth": "    return equation_parser.indexed_param_or_var_parser(identifier)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return equation_parser.component_parser(identifier)", "prediction_line": "    return equation_parser.component_parser(identifier)", "ground_truth": "    return equation_parser.component_parser(identifier)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return equation_parser.helper_function_parser(", "prediction_line": "    return equation_parser.helper_function_parser(", "ground_truth": "    return equation_parser.helper_function_parser(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return equation_parser.base_parser_elements", "prediction_line": "    return equation_parser.base_parser_elements", "ground_truth": "    number, identifier = equation_parser.setup_base_parser_elements()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            parsed_[0].eval(helper_func_dict=HELPER_FUNCS, test=True)", "prediction_line": "            parsed_[0].eval(helper_func_dict=HELPER_FUNCS, test=True)", "ground_truth": "            parsed_[0].eval(helper_func_dict=HELPER_FUNCS, test=True)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert parsed_[0] == expected", "prediction_line": "        assert parsed_[0] == expected", "ground_truth": "        assert parsed_[0].eval() == expected", "line_class": "commited", "zero_context": true}
{"original_prediction": "        getattr(request.getfixturevalue(parser_element), \"parseString\"),", "prediction_line": "        getattr(request.getfixturevalue(parser_element), \"parseString\"),", "ground_truth": "        equation_parser.helper_function_parser(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert parsed_[0].eval() == expected", "prediction_line": "        assert parsed_[0].eval() == expected", "ground_truth": "        assert parsed_[0].eval() == {\"component\": expected}", "line_class": "commited", "zero_context": true}
{"original_prediction": "            assert parsed_[0].name == string_val", "prediction_line": "            assert parsed_[0].name == string_val", "ground_truth": "            assert parsed_[0].eval() == {\"param_or_var_name\": string_val}", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert parsed_[0].eval() == expected", "prediction_line": "        assert parsed_[0].eval() == expected", "ground_truth": "        assert parsed_[0].eval(helper_func_dict=HELPER_FUNCS, test=True) == expected", "line_class": "commited", "zero_context": true}
{"original_prediction": "            component.parse_string(string_val, parse_all=True)", "prediction_line": "            component.parse_string(string_val, parse_all=True)", "ground_truth": "            component.parse_string(string_val, parse_all=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            number.parse_string(string_val)", "prediction_line": "            number.parse_string(string_val)", "ground_truth": "            number.parse_string(string_val, parse_all=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return number, identifier", "prediction_line": "    return number, identifier", "ground_truth": "    return number, identifier", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return base_parser_elements[0]", "prediction_line": "    return base_parser_elements[0]", "ground_truth": "    return base_parser_elements[0]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return base_parser_elements[1]", "prediction_line": "    return base_parser_elements[1]", "ground_truth": "    return base_parser_elements[1]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        parsed_ = helper_function.parse_string(string_val, parse_all=True)", "prediction_line": "        parsed_ = helper_function.parse_string(string_val, parse_all=True)", "ground_truth": "        parsed_ = helper_function.parse_string(string_val, parse_all=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        number, indexed_param, component, unindexed_param, identifier", "prediction_line": "        number, indexed_param, component, unindexed_param, identifier", "ground_truth": "        identifier,", "line_class": "infile", "zero_context": true}
{"original_prediction": "number, indexed_param, component, unindexed_param],", "prediction_line": "number, indexed_param, component, unindexed_param],", "ground_truth": "            indexed_param,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            component,\n            unindexed_param,", "prediction_line": "            component,", "ground_truth": "            component,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            unindexed_param,", "prediction_line": "            unindexed_param,", "ground_truth": "            unindexed_param,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            number,\n        ],", "prediction_line": "            number,", "ground_truth": "            number,", "line_class": "infile", "zero_context": true}
{"original_prediction": "number, indexed_param, component, unindexed_param, identifier):", "prediction_line": "number, indexed_param, component, unindexed_param, identifier):", "ground_truth": "    number, indexed_param, component, unindexed_param, identifier", "line_class": "infile", "zero_context": true}
{"original_prediction": "        parsed_ = indexed_param.parse_string(string_val, parse_all=True)", "prediction_line": "        parsed_ = indexed_param.parse_string(string_val, parse_all=True)", "ground_truth": "        parsed_ = indexed_param.parse_string(string_val, parse_all=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            helper_function.parse_string(string_val, parse_all=True)", "prediction_line": "            helper_function.parse_string(string_val, parse_all=True)", "ground_truth": "            helper_function.parse_string(string_val, parse_all=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "self, helper_function_no_nesting):", "prediction_line": "self, helper_function_no_nesting):", "ground_truth": "        self, helper_function_no_nesting", "line_class": "infile", "zero_context": true}
{"original_prediction": "        helper_function_no_nesting.parse_string(", "prediction_line": "        helper_function_no_nesting.parse_string(", "ground_truth": "        helper_function_no_nesting.parse_string(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self, helper_function_no_nesting, args", "prediction_line": "        self, helper_function_no_nesting, args", "ground_truth": "        self, helper_function_no_nesting, args", "line_class": "infile", "zero_context": true}
{"original_prediction": "            indexed_param.parse_string(string_val, parse_all=True)", "prediction_line": "            indexed_param.parse_string(string_val, parse_all=True)", "ground_truth": "            indexed_param.parse_string(string_val, parse_all=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self, helper_function_one_parser_in_args, helper_func_string", "prediction_line": "        self, helper_function_one_parser_in_args, helper_func_string", "ground_truth": "        self, helper_function_one_parser_in_args, helper_func_string", "line_class": "infile", "zero_context": true}
{"original_prediction": "        parser_, valid_string, invalid_string = helper_function_one_parser_in_args", "prediction_line": "        parser_, valid_string, invalid_string = helper_function_one_parser_in_args", "ground_truth": "        parser_, valid_string, invalid_string = helper_function_one_parser_in_args", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert number.parseString(string_val)[0] == expected", "prediction_line": "        assert number.parseString(string_val)[0] == expected", "ground_truth": "        parsed_ = number.parse_string(string_val, parse_all=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        parsed_ = component.parse_string(string_val, parse_all=True)", "prediction_line": "        parsed_ = component.parse_string(string_val, parse_all=True)", "ground_truth": "        parsed_ = component.parse_string(string_val, parse_all=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert \"not_a_helper_func\" in str(excinfo.value)", "prediction_line": "        assert \"not_a_helper_func\" in str(excinfo.value)", "ground_truth": "        assert check_error_or_warning(excinfo, \"Invalid helper function defined\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        assert check_error_or_warning(excinfo, \"Nested functions not allowed\")", "prediction_line": "        assert check_error_or_warning(excinfo, \"Nested functions not allowed\")", "ground_truth": "        assert check_error_or_warning(excinfo, \"Expected\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    )\n    def test_fail_indexed_param(self, indexed_param, string_val):", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def component_classifier(base_parser_elements):", "prediction_line": "def component_classifier(base_parser_elements):", "ground_truth": "def unindexed_param(identifier):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            \"1e\",", "prediction_line": "            \"1e\",", "ground_truth": "            \"1 2\",  # whitespace between valid characters", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_fail_function(self, helper_function, string_val):", "prediction_line": "    def test_fail_function(self, helper_function, string_val):", "ground_truth": "    def test_function_protected_name(self, string_val, helper_function):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                {\"function\": \"dummy_func_2\", \"args\": [1, 2], \"kwargs\": {}},", "prediction_line": "                {\"function\": \"dummy_func_2\", \"args\": [1, 2], \"kwargs\": {}},", "ground_truth": "                {\"function\": \"dummy_func_2\", \"args\": [1, 2], \"kwargs\": {}},", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"dummy_func_2(x=1, y=2)\",", "prediction_line": "                \"dummy_func_2(x=1, y=2)\",", "ground_truth": "                \"dummy_func_2(1, 2)\",", "line_class": "random", "zero_context": true}
{"original_prediction": "       parser_.parse_string(", "prediction_line": "       parser_.parse_string(", "ground_truth": "        parser_.parse_string(helper_func_string.format(valid_string), parse_all=True)", "line_class": "random", "zero_context": true}
{"original_prediction": "                        \"x\": {\"param_or_var_name\": \"foo\", \"dimensions\": [\"bar\"]}", "prediction_line": "                        \"x\": {\"param_or_var_name\": \"foo\", \"dimensions\": [\"bar\"]}", "ground_truth": "                        \"x\": {\"param_or_var_name\": \"foo\", \"dimensions\": [\"bar\"]}", "line_class": "random", "zero_context": true}
{"original_prediction": "            ),\n        ],", "prediction_line": "            ),", "ground_truth": "            ),", "line_class": "random", "zero_context": true}
{"original_prediction": "        f\"\"\"setup=\"{setup}\", number={number}));{py_after}\"\"\"", "prediction_line": "        f\"\"\"setup=\"{setup}\", number={number}));{py_after}\"\"\"", "ground_truth": "          f\"\"\"setup=\"{setup}\", number={number}));{py_after}\"\"\"", "line_class": "common", "zero_context": true}
{"original_prediction": "            # Remove the broken multibyte character", "prediction_line": "            # Remove the broken multibyte character", "ground_truth": "            faulty_idx_start = int(ude.start)", "line_class": "common", "zero_context": true}
{"original_prediction": "    command += _add_command(before)", "prediction_line": "    command += _add_command(before)", "ground_truth": "    command += _add_command([", "line_class": "infile", "zero_context": true}
{"original_prediction": "    command += _add_command(before)", "prediction_line": "    command += _add_command(before)", "ground_truth": "    command += _add_command(before)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    command += _add_command(cmd)", "prediction_line": "    command += _add_command(cmd)", "ground_truth": "    command += _add_command(cmd)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    command += _add_command(after)", "prediction_line": "    command += _add_command(after)", "ground_truth": "    command += _add_command(after)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            raise GdbAssertionError(\"Gef did not raise an exception\")", "prediction_line": "            raise GdbAssertionError(\"Gef did not raise an exception\")", "ground_truth": "            raise GdbAssertionError(\"GDB Exception expected, not raised\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        command += _add_command([", "prediction_line": "        command += _add_command([", "ground_truth": "        command += _add_command([\"pi cov.stop()\", \"pi cov.save()\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return gdb_run_cmd(cmd, before, after, target, strip_ansi)", "prediction_line": "    return gdb_run_cmd(cmd, before, after, target, strip_ansi)", "ground_truth": "    return gdb_run_cmd(cmd, before, after, target, strip_ansi)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return gdb_run_cmd_last_line(cmd, strip_ansi=strip_ansi)", "prediction_line": "    return gdb_run_cmd_last_line(cmd, strip_ansi=strip_ansi)", "ground_truth": "    return gdb_start_silent_cmd(cmd, target=target, strip_ansi=strip_ansi)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            raise GdbAssertionError(\"GDB Exception raised\")", "prediction_line": "            raise GdbAssertionError(\"GDB Exception raised\")", "ground_truth": "            raise GdbAssertionError(f\"Unexpected GDB Exception raised in {buf}\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return float(gdb_start_silent_cmd(cmd, before, after, target, strip_ansi))", "prediction_line": "    return float(gdb_start_silent_cmd(cmd, before, after, target, strip_ansi))", "ground_truth": "    lines = gdb_run_cmd(cmd, before=before, after=after,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        result = ansi_clean(result)", "prediction_line": "        result = ansi_clean(result)", "ground_truth": "        result = ansi_clean(result)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return http.read()", "prediction_line": "        return http.read()", "ground_truth": "        return http.read() if http.getcode() == 200 else None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def get_test_data_path() -> pathlib.Path:", "prediction_line": "def get_test_data_path() -> pathlib.Path:", "ground_truth": "ARCH = (os.getenv(\"GEF_CI_ARCH\") or platform.machine()).lower()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise GdbAssertionError(f\"Deprecated API used: {deprecated_api_names}\")", "prediction_line": "            raise GdbAssertionError(f\"Deprecated API used: {deprecated_api_names}\")", "ground_truth": "            warnings.warn(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def is_ci() -> bool:", "prediction_line": "def is_ci() -> bool:", "ground_truth": "COVERAGE_DIR = os.getenv(\"COVERAGE_DIR\", \"\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        command += [\"--coverage\", COVERAGE_DIR]", "prediction_line": "        command += [\"--coverage\", COVERAGE_DIR]", "ground_truth": "        coverage_file = pathlib.Path(COVERAGE_DIR) / os.getenv(\"PYTEST_XDIST_WORKER\", \"gw0\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "GEF_DEFAULT_LOGFILE = \"/tmp/gef.log\"", "prediction_line": "GEF_DEFAULT_LOGFILE = \"/tmp/gef.log\"", "ground_truth": "GEF_PATH = pathlib.Path(os.getenv(\"GEF_PATH\", \"gef.py\"))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"\"\"\n    if gdbserver.poll() is None:", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"Execute a command inside GDB. `before` and `after` are lists of commands to be executed", "prediction_line": "    \"\"\"Execute a command inside GDB. `before` and `after` are lists of commands to be executed", "ground_truth": "    \"\"\"Disable the output and run entirely the `target` binary.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def gdb_start_silent_cmd(cmd: CommandType, before: CommandType = (), after: CommandType = (),", "prediction_line": "def gdb_start_silent_cmd(cmd: CommandType, before: CommandType = (), after: CommandType = (),", "ground_truth": "def gdb_start_silent_cmd(cmd: CommandType, before: CommandType = (), after: CommandType = (),", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        return None", "prediction_line": "        return None", "ground_truth": "        return None", "line_class": "random", "zero_context": true}
{"original_prediction": "        return buffer\n    if included:", "prediction_line": "        return buffer", "ground_truth": "        return buffer", "line_class": "random", "zero_context": true}
{"original_prediction": "        raise FileNotFoundError(f\"Target {target} does not exist\")", "prediction_line": "        raise FileNotFoundError(f\"Target {target} does not exist\")", "ground_truth": "        raise FileNotFoundError(f\"Could not find file '{target}'\")", "line_class": "random", "zero_context": true}
{"original_prediction": "    BLINK_OFF      = \"\\x1b[25m\"", "prediction_line": "    BLINK_OFF      = \"\\x1b[25m\"", "ground_truth": "    BLINK_OFF      = \"\\x1b[25m\"", "line_class": "random", "zero_context": true}
{"original_prediction": "    @staticmethod", "prediction_line": "    @staticmethod", "ground_truth": "        if \"is deprecated and will be removed in a feature release.\" in buf:", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__()\r", "prediction_line": "        super().__init__()\r", "ground_truth": "        super(LTI, self).__init__(time=False)\r", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(CartPole, self).__init__(time=True)\r", "prediction_line": "        super(CartPole, self).__init__(time=True)\r", "ground_truth": "        super().__init__(self)\r", "line_class": "commited", "zero_context": true}
{"original_prediction": "        '''\r\n        z = self.A @ x + self.B @ u + self.c1\r", "prediction_line": "        '''\r", "ground_truth": "             A, B, C, D and u, x are multiplied separately for each channel.\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "             A, B, C, D are all p x n matrices, and x, u are all q x n matrices.\r", "prediction_line": "             A, B, C, D are all p x n matrices, and x, u are all q x n matrices.\r", "ground_truth": "             A, B, C, D are n*n n*p q*n and q*p constant matrices.\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.jacargs['create_graph'] = True\r", "prediction_line": "            self.jacargs['create_graph'] = True\r", "ground_truth": "            self.register_forward_hook(self.forward_hook)\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "                lti = LTI(A, B, C, D, c1, c2)\r", "prediction_line": "                lti = LTI(A, B, C, D, c1, c2)\r", "ground_truth": "            >>> A\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        raise NotImplementedError\r", "prediction_line": "        raise NotImplementedError\r", "ground_truth": "        state = self.state_transition(state, input)\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return state\r", "prediction_line": "        return state\r", "ground_truth": "        return self.observation(state, input)\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "            >>> B\r", "prediction_line": "            >>> B\r", "ground_truth": "                B\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "                C\r\n            tensor([[ 0.3925, -0.1799, -0.0653],\r", "prediction_line": "                C\r", "ground_truth": "                C\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "                D\r\n            tensor([[ 0.1118, -0.1022],\r", "prediction_line": "                D\r", "ground_truth": "                D\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "                c1\r", "prediction_line": "                c1\r", "ground_truth": "                c1\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "                c2\r", "prediction_line": "                c2\r", "ground_truth": "                c2\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "            >>> sys = LTI(A, B, C, D, c1, c2)\r", "prediction_line": "            >>> sys = LTI(A, B, C, D, c1, c2)\r", "ground_truth": "            >>> lti = LTI(A, B, C, D, c1, c2)\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        z = self.A @ x + self.B @ u + self.c1\r", "prediction_line": "        z = self.A @ x + self.B @ u + self.c1\r", "ground_truth": "        if self.A.ndim >= 3:\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "            z = torch.matmul(self.A, x) + torch.matmul(self.B, u) + self.c1\r", "prediction_line": "            z = torch.matmul(self.A, x) + torch.matmul(self.B, u) + self.c1\r", "ground_truth": "            assert self.A.ndim == x.ndim == u.ndim,  \"Invalid System Matrices dimensions\"\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "            assert self.A.ndim == x.ndim == u.ndim == 2,  \"Invalid System Matrices dimensions\"\r", "prediction_line": "            assert self.A.ndim == x.ndim == u.ndim == 2,  \"Invalid System Matrices dimensions\"\r", "ground_truth": "            assert self.A.ndim == 2,  \"Invalid System Matrices dimensions\"\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self.A.ndim >= 3:\r", "prediction_line": "        if self.A.ndim >= 3:\r", "ground_truth": "        z = x.matmul(self.A.mT) + u.matmul(self.B.mT) + self.c1\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        y = x.matmul(self.C.mT) + u.matmul(self.D.mT) + self.c2\r", "prediction_line": "        y = x.matmul(self.C.mT) + u.matmul(self.D.mT) + self.c2\r", "ground_truth": "        y = x.matmul(self.C.mT) + u.matmul(self.D.mT) + self.c2\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "    Linear Time-Invariant (LTI) system\r", "prediction_line": "    Linear Time-Invariant (LTI) system\r", "ground_truth": "    A sub-class of: obj: '_System' to represent Linear Time-Invariant system.\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        time (bool, optional): If True, the system will record the time of each step.\r", "prediction_line": "        time (bool, optional): If True, the system will record the time of each step.\r", "ground_truth": "        c1, c2 (:obj:`Tensor`): Bias generated by system.\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        The state-space equation of LTI system is:\r", "prediction_line": "        The state-space equation of LTI system is:\r", "ground_truth": "        According to the actual physical meaning, the dimensions of A, B, C, D must be the same,\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._dstate = self.state_transition(state,input)\r", "prediction_line": "        self._dstate = self.state_transition(state,input)\r", "ground_truth": "        self._dstate = self.state_transition(state,input)\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.observation(state,input)\r", "prediction_line": "        return self.observation(state,input)\r", "ground_truth": "        return self.observation(state,input)\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.A = A\r", "prediction_line": "        self.A = A\r", "ground_truth": "        assert A.ndim == B.ndim == C.ndim == D.ndim, \"Invalid System Matrices dimensions\"\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert A.shape[-1] == A.shape[-2], \"Invalid System Matrices dimensions\"\r", "prediction_line": "        assert A.shape[-1] == A.shape[-2], \"Invalid System Matrices dimensions\"\r", "ground_truth": "        self._A, self._B, self._C, self._D = A, B, C, D\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.c1, self.c2 = c1, c2\r", "prediction_line": "        self.c1, self.c2 = c1, c2\r", "ground_truth": "        self._c1, self._c2 = c1, c2\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "            The state of the system.\r", "prediction_line": "            The state of the system.\r", "ground_truth": "            The state of LTI system\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "            The input of LTI system\r", "prediction_line": "            The input of LTI system\r", "ground_truth": "            The input of LTI system\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "            The output of LTI system\r", "prediction_line": "            The output of LTI system\r", "ground_truth": "            The output of LTI system, observation\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        '''\r\n        z = self.A @ x + self.B @ u + self.c1\r", "prediction_line": "        '''\r", "ground_truth": "            -A, B, C, D can only be two-dimensional matrices or the batch\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.output = outputs\r", "prediction_line": "        self.output = outputs\r", "ground_truth": "        self.t.add_(1)\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            >>> z, y = lti(x, u)\r", "prediction_line": "            >>> z, y = lti(x, u)\r", "ground_truth": "            tensor([[[-1.7951, -1.7544, -1.9603]],\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            where A is the state-transition matrix, B is the control matrix, C is the observation matrix,\r", "prediction_line": "            where A is the state-transition matrix, B is the control matrix, C is the observation matrix,\r", "ground_truth": "            usually in matrix form.\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                C = torch.randn((2,3))\r", "prediction_line": "                C = torch.randn((2,3))\r", "ground_truth": "                C = torch.randn((3,3))\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            tensor([[[-0.1088, -0.1088]],\r", "prediction_line": "            tensor([[[-0.1088, -0.1088]],\r", "ground_truth": "            tensor([[[1.7736, 0.7472]],\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \\end{align*}\r", "prediction_line": "            \\end{align*}\r", "ground_truth": "            \\end{align*}\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                D = torch.randn((3,2))\r", "prediction_line": "                D = torch.randn((3,2))\r", "ground_truth": "                D = torch.randn((3,2))\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                u = torch.randn((2,1,2))\r", "prediction_line": "                u = torch.randn((2,1,2))\r", "ground_truth": "                u = torch.randn((2,1,2))\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            func = lambda x: self.observation(x, self.input)\r", "prediction_line": "            func = lambda x: self.observation(x, self.input)\r", "ground_truth": "            func = lambda x: self.state_trasition(self.state, x)\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return jacobian(func, self.input, **self.jacargs)\r", "prediction_line": "            return jacobian(func, self.input, **self.jacargs)\r", "ground_truth": "            return jacobian(func, self.input, **self.jacargs)\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            tensor([[[-0.0000, -0.0000, -0.0000]],\r", "prediction_line": "            tensor([[[-0.0000, -0.0000, -0.0000]],\r", "ground_truth": "            tensor([[[ 1.0022, -0.1371,  1.0773]],\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        x,xDot,theta,thetaDot = state\r", "prediction_line": "        x,xDot,theta,thetaDot = state\r", "ground_truth": "        return state + torch.mul(self._dstate,self._tau)\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \r\n        .. math::\r", "prediction_line": "        \r", "ground_truth": "        :math:`\\mathbf{x}_i` represents each individual matrix in the batch. \r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self._A = jacobian(self.state_transition, self.state, create_graph=True, **self.jacargs)\r", "prediction_line": "            self._A = jacobian(self.state_transition, self.state, create_graph=True, **self.jacargs)\r", "ground_truth": "            func = lambda x: self.state_trasition(x, self.input)\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                x = torch.randn((3,3))\r", "prediction_line": "                x = torch.randn((3,3))\r", "ground_truth": "                c1 = torch.randn((2,1,3))\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self._dstate = torch.empty((3)).float()\r", "prediction_line": "        self._dstate = torch.empty((3)).float()\r", "ground_truth": "    \r", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def observation(self):\r", "prediction_line": "    def observation(self):\r", "ground_truth": "    def observation(self):\r", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    [[-0.8519, -0.6737, -0.3359]],\r", "prediction_line": "                    [[-0.8519, -0.6737, -0.3359]],\r", "ground_truth": "                    [[ 0.5543, -0.1456,  1.4389]]]) \r", "line_class": "random", "zero_context": true}
{"original_prediction": "        -------\r", "prediction_line": "        -------\r", "ground_truth": "        -------\r", "line_class": "random", "zero_context": true}
{"original_prediction": "                    [-0.1028, -0.1028]])\r", "prediction_line": "                    [-0.1028, -0.1028]])\r", "ground_truth": "                    [-1.2021, -0.5444]]) \r", "line_class": "random", "zero_context": true}
{"original_prediction": "                u\r\n            tensor([[[-0.1818, -0.1028]],\r", "prediction_line": "                u\r", "ground_truth": "                u\r", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.jacargs['time'] = True\r", "prediction_line": "            self.jacargs['time'] = True\r", "ground_truth": "            self.register_buffer('t',torch.zeros(1))\r", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__()", "prediction_line": "        super().__init__()", "ground_truth": "        super(AffineDynamics, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(NNDynamics, self).__init__()", "prediction_line": "        super(NNDynamics, self).__init__()", "ground_truth": "        super().__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "import torch.nn as nn", "prediction_line": "import torch.nn as nn", "ground_truth": "from torch.autograd import Function, Variable", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import torch.nn as nn", "prediction_line": "import torch.nn as nn", "ground_truth": "from torch import nn", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __init__(self, n_state, n_ctrl, hidden_sizes=[100],", "prediction_line": "    def __init__(self, n_state, n_ctrl, hidden_sizes=[100],", "ground_truth": "    def __init__(self, dynamics):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.act_f = act_f", "prediction_line": "        self.act_f = act_f", "ground_truth": "        self.acts = [act_f]*(len(self.fcs)-1)+[lambda x:x] # Activation functions.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            self.zs.append(z)", "prediction_line": "            self.zs.append(z)", "ground_truth": "            self.zs.append(z)", "line_class": "random", "zero_context": true}
{"original_prediction": "        z = torch.cat([x, u], dim=1)", "prediction_line": "        z = torch.cat([x, u], dim=1)", "ground_truth": "        z = torch.cat((x, u), 1)", "line_class": "random", "zero_context": true}
{"original_prediction": "        if x_dim == 1:", "prediction_line": "        if x_dim == 1:", "ground_truth": "        if not diff:", "line_class": "random", "zero_context": true}
{"original_prediction": "        x_dim, u_dim = x.ndimension(), u.ndimension()", "prediction_line": "        x_dim, u_dim = x.ndimension(), u.ndimension()", "ground_truth": "        x_dim, u_dim = x.ndimension(), u.ndimension()", "line_class": "random", "zero_context": true}
{"original_prediction": "            R -= I", "prediction_line": "            R -= I", "ground_truth": "            R = R + I", "line_class": "random", "zero_context": true}
{"original_prediction": "            super().__init__()", "prediction_line": "            super().__init__()", "ground_truth": "            super().__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "000\n    lr = 0.001", "prediction_line": "000", "ground_truth": "    net = SO3Layer(n).to(device)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    x = pp.randn_so3(2, device=device)", "prediction_line": "    x = pp.randn_so3(2, device=device)", "ground_truth": "    J = jacobian(func, p)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_lietensor()", "prediction_line": "    test_lietensor()", "ground_truth": "    test_lietensor()", "line_class": "infile", "zero_context": true}
{"original_prediction": "   so3I.grad = None", "prediction_line": "   so3I.grad = None", "ground_truth": "    SE3I = pp.identity_SE3(3, device=device, dtype=torch.float64)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    Z = pp.randn_SE3(2, requires_grad=True, dtype=torch.double)", "prediction_line": "    Z = pp.randn_SE3(2, requires_grad=True, dtype=torch.double)", "ground_truth": "    assert not isinstance(torch.randn(4), pp.LieTensor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = pp.randn_so3(2,2)", "prediction_line": "    x = pp.randn_so3(2,2)", "ground_truth": "    pp.Jr(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    S.Log().Exp()", "prediction_line": "    S.Log().Exp()", "ground_truth": "    s.Exp() * S", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    h = pp.randn_se3(1,5)", "prediction_line": "    h = pp.randn_se3(1,5)", "ground_truth": "    pp.Mul(a, b)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    SO3I.requires_grad = True", "prediction_line": "    SO3I.requires_grad = True", "ground_truth": "    so3I = pp.identity_so3(2, 1, device=device, requires_grad=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert isinstance(Z1, pp.LieTensor)", "prediction_line": "    assert isinstance(Z1, pp.LieTensor)", "ground_truth": "    assert isinstance(Z1, pp.LieTensor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        X = pp.randn_SO3(3,2).to(device)", "prediction_line": "        X = pp.randn_SO3(3,2).to(device)", "ground_truth": "        x = torch.randn(4, 5, device=device)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    X = pp.randn_SE3(8, requires_grad=True, dtype=torch.double)", "prediction_line": "    X = pp.randn_SE3(8, requires_grad=True, dtype=torch.double)", "ground_truth": "    X = pp.randn_SE3(2, requires_grad=True, dtype=torch.double)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    S = pp.randn_Sim3(4, requires_grad=True)", "prediction_line": "    S = pp.randn_Sim3(4, requires_grad=True)", "ground_truth": "    s = pp.randn_sim3(4)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    b = pp.randn_se3(1,5)", "prediction_line": "    b = pp.randn_se3(1,5)", "ground_truth": "    b = pp.randn_SE3(5,1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return x.Exp()", "prediction_line": "        return x.Exp()", "ground_truth": "        return x.Exp()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    Y = pp.randn_SO3(3,2).to(device)", "prediction_line": "    Y = pp.randn_SO3(3,2).to(device)", "ground_truth": "    X.identity_()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert torch.allclose(x.rotation, y.rotation)", "prediction_line": "    assert torch.allclose(x.rotation, y.rotation)", "ground_truth": "    (pp.Log(y.Exp())**2).sin().sum().backward()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    se3I = pp.identity_se3(4, device=device, requires_grad=True)", "prediction_line": "    se3I = pp.identity_se3(4, device=device, requires_grad=True)", "ground_truth": "    se3I = pp.identity_se3(2)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert count_parameters(x) == 3", "prediction_line": "    assert count_parameters(x) == 3", "ground_truth": "    class SO3Layer(nn.Module):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        def __init__(self, n):", "prediction_line": "        def __init__(self, n):", "ground_truth": "        def __init__(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   x = pp.randn_so3(2, device=device)", "prediction_line": "   x = pp.randn_so3(2, device=device)", "ground_truth": "    def func(x):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        assert(torch.all(torch.abs(torch.linalg.vector_norm(s, dim=1) - 1) < 1e-9))", "prediction_line": "        assert(torch.all(torch.abs(torch.linalg.vector_norm(s, dim=1) - 1) < 1e-9))", "ground_truth": "        if m.shape[-1] == 4:", "line_class": "random", "zero_context": true}
{"original_prediction": "    y = a.sin()", "prediction_line": "    y = a.sin()", "ground_truth": "    b = a.sin()", "line_class": "random", "zero_context": true}
{"original_prediction": "    class SE3Layer(nn.Module):", "prediction_line": "    class SE3Layer(nn.Module):", "ground_truth": "    n = 4", "line_class": "random", "zero_context": true}
{"original_prediction": "   points = pp.randn_se3(2,5,3)", "prediction_line": "   points = pp.randn_se3(2,5,3)", "ground_truth": "    pt = a * points", "line_class": "random", "zero_context": true}
{"original_prediction": "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)", "prediction_line": "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)", "ground_truth": "    weight = copy.deepcopy(net.weight)", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__()", "prediction_line": "        super().__init__()", "ground_truth": "        super().__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    forward pass of the dynamics and one backward pass of the cost function.", "prediction_line": "    forward pass of the dynamics and one backward pass of the cost function.", "ground_truth": "    additional forward pass of iLQR for the learning problem, such as learning the", "line_class": "commited", "zero_context": true}
{"original_prediction": "    - The forward recursion.", "prediction_line": "    - The forward recursion.", "ground_truth": "    - The forward recursion.", "line_class": "commited", "zero_context": true}
{"original_prediction": "        ...     def __init__(self):", "prediction_line": "        ...     def __init__(self):", "ground_truth": "        ...     def __init__(self, dt, length, cartmass, polemass, gravity):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        ...         super().__init__()", "prediction_line": "        ...         super().__init__()", "ground_truth": "        ...         super().__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "       for i in range(self.stepper.max_steps):", "prediction_line": "       for i in range(self.stepper.max_steps):", "ground_truth": "        self.stepper.reset()", "line_class": "common", "zero_context": true}
{"original_prediction": "        The MPC solver is based on the iterative LQR solver.", "prediction_line": "        The MPC solver is based on the iterative LQR solver.", "ground_truth": "        The definition of MPC is cited from this book:", "line_class": "infile", "zero_context": true}
{"original_prediction": "    Examples:", "prediction_line": "    Examples:", "ground_truth": "        The implementation of MPC is based on Eq. (10)~(13) of this paper:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        dynamics (Dynamics): dynamics model", "prediction_line": "        dynamics (Dynamics): dynamics model", "ground_truth": "        system (:obj:`instance`): The system to be soved by MPC.", "line_class": "infile", "zero_context": true}
{"original_prediction": "        Solve the MPC problem.", "prediction_line": "        Solve the MPC problem.", "ground_truth": "        Performs MPC for the discrete system.", "line_class": "infile", "zero_context": true}
{"original_prediction": "iterative\n    optimization problem.", "prediction_line": "iterative", "ground_truth": "    closed loop optimal control problem. Thus, the MPC scheme is able to utilize the", "line_class": "infile", "zero_context": true}
{"original_prediction": "of the\n    system.", "prediction_line": "of the", "ground_truth": "    and control inputs for the system. At each time stamp, MPC solves the", "line_class": "infile", "zero_context": true}
{"original_prediction": "        >>> x_sol, u_sol = MPC(x_init, current_u)", "prediction_line": "        >>> x_sol, u_sol = MPC(x_init, current_u)", "ground_truth": "        >>> x, u, cost = MPC(dt, x_init, u_init=current_u)", "line_class": "infile", "zero_context": true}
{"original_prediction": "          &\\text{s.t.} \\quad \\mathbf{x}_{t+1} = \\mathbf{f}(\\mathbf{x}_t, \\mathbf{u}_t) \\\\", "prediction_line": "          &\\text{s.t.} \\quad \\mathbf{x}_{t+1} = \\mathbf{f}(\\mathbf{x}_t, \\mathbf{u}_t) \\\\", "ground_truth": "          \\mathrm{s.t.}\\quad \\mathbf{x}_{t+1} &= \\mathbf{f}(\\mathbf{x}_t, \\mathbf{u}_t),\\\\", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \\end{align*}", "prediction_line": "            \\end{align*}", "ground_truth": "                    + \\mathbf{K}_t^\\top\\mathbf{Q}_{\\delta \\mathbf{u}_t,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        >>> system = CartPole(dt, len, m_cart, m_pole, g)", "prediction_line": "        >>> system = CartPole(dt, len, m_cart, m_pole, g)", "ground_truth": "        >>> Q = torch.tile(torch.eye(n_state + n_ctrl, device=device), (n_batch, T, 1, 1))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \\mathbf{g}(\\mathbf{x}, \\mathbf{u}, t^*) &\\approx \\mathbf{g}(\\mathbf{x}^*,", "prediction_line": "            \\mathbf{g}(\\mathbf{x}, \\mathbf{u}, t^*) &\\approx \\mathbf{g}(\\mathbf{x}^*,", "ground_truth": "            &= \\mathbf{f}(\\mathbf{x}^*, \\mathbf{u}^*, t^*) + \\mathbf{A} \\delta \\mathbf{x}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            the default stepper will be used.", "prediction_line": "            the default stepper will be used.", "ground_truth": "            the ``pypose.utils.ReduceToBason`` with a maximum of 10 steps are used.", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.system = system", "prediction_line": "        self.system = system", "ground_truth": "        self.lqr = LQR(system, Q, p, T)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \\end{align*}", "prediction_line": "            \\end{align*}", "ground_truth": "            \\end{align*}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                \\mathbf{\\tau}^\\top\\nabla^2_{\\mathbf{\\tau}}\\mathbf{c}\\left(\\mathbf{\\tau}^*,", "prediction_line": "                \\mathbf{\\tau}^\\top\\nabla^2_{\\mathbf{\\tau}}\\mathbf{c}\\left(\\mathbf{\\tau}^*,", "ground_truth": "                \\mathbf{\\tau}_t^\\top \\bar{\\mathbf{Q}}_t \\delta \\mathbf{\\tau}_t +", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        * J. Zhang, J. Liu, and J. Li, \"A Novel Model Predictive Control Method for", "prediction_line": "        * J. Zhang, J. Liu, and J. Li, \"A Novel Model Predictive Control Method for", "ground_truth": "        * Amos, Brandon, et al, `Differentiable mpc for end-to-end planning and control", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        >>> mpc = pp.solver.MPC(cartPoleSolver, Q, p, T, stepper=stepper)", "prediction_line": "        >>> mpc = pp.solver.MPC(cartPoleSolver, Q, p, T, stepper=stepper)", "ground_truth": "        >>> MPC = pp.module.MPC(cartPoleSolver, Q, p, T, stepper=stepper).to(device)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    .. math::", "prediction_line": "    .. math::", "ground_truth": "    - The backward recursion.", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    + \\mathbf{Q}_{\\delta \\mathbf{x}_t, \\delta \\mathbf{u}_t}\\mathbf{k}_t", "prediction_line": "                    + \\mathbf{Q}_{\\delta \\mathbf{x}_t, \\delta \\mathbf{u}_t}\\mathbf{k}_t", "ground_truth": "                    + \\mathbf{Q}_{\\delta \\mathbf{x}_t, \\delta \\mathbf{u}_t}\\mathbf{k}_t", "line_class": "inproject", "zero_context": true}
{"original_prediction": "\\\\\n                \\mathbf{v}_t &= \\mathbf{q}_{\\delta \\mathbf{x}_t}", "prediction_line": "\\\\", "ground_truth": "                    + \\mathbf{K}_t^\\top\\mathbf{Q}_{\\delta\\mathbf{u}_t,\\delta \\mathbf{u}_t}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "can\n                change. Default: ``None``.", "prediction_line": "can", "ground_truth": "                is allowed to change in each LQR iteration. Default: ``None``.", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    inputs.", "prediction_line": "    inputs.", "ground_truth": "    sequences. Then, analytical derivative for the backward can be computed using one", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def __init__(self, system, Q, p, T, stepper=None):", "prediction_line": "    def __init__(self, system, Q, p, T, stepper=None):", "ground_truth": "    def __init__(self, system, Q, p, T, stepper=None):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        >>> print(x.shape, u.shape, cost.shape)", "prediction_line": "        >>> print(x.shape, u.shape, cost.shape)", "ground_truth": "        >>> print(\"x = \", x)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        >>> print(\"u = \", u)", "prediction_line": "        >>> print(\"u = \", u)", "ground_truth": "        >>> print(\"u = \", u)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    .. math::", "prediction_line": "    .. math::", "ground_truth": "    Args:", "line_class": "random", "zero_context": true}
{"original_prediction": "                \\mathbf{\\tau}^T \\mathbf{Q}_t \\delta \\mathbf{\\tau} + \\delta \\mathbf{\\tau}^T", "prediction_line": "                \\mathbf{\\tau}^T \\mathbf{Q}_t \\delta \\mathbf{\\tau} + \\delta \\mathbf{\\tau}^T", "ground_truth": "                \\mathbf{\\tau}^\\top\\nabla^2_{\\mathbf{\\tau}}\\mathbf{c}\\left(\\mathbf{\\tau}^*,", "line_class": "random", "zero_context": true}
{"original_prediction": "        >>> system = CartPole(dt, len, m_cart, m_pole, g)", "prediction_line": "        >>> system = CartPole(dt, len, m_cart, m_pole, g)", "ground_truth": "        >>> current_u = torch.sin(time).unsqueeze(1).unsqueeze(0)", "line_class": "random", "zero_context": true}
{"original_prediction": "    .. math::", "prediction_line": "    .. math::", "ground_truth": "    .. math::", "line_class": "random", "zero_context": true}
{"original_prediction": "                    best['x'] = x", "prediction_line": "                    best['x'] = x", "ground_truth": "                    best = {'x': x, 'u': u, 'cost': cost}", "line_class": "random", "zero_context": true}
{"original_prediction": "    The LQR algorithm is as follows:", "prediction_line": "    The LQR algorithm is as follows:", "ground_truth": "    The LQR process can be summarised as a backward and a forward recursion.", "line_class": "commited", "zero_context": true}
{"original_prediction": "    - The forward recursion.", "prediction_line": "    - The forward recursion.", "ground_truth": "    - The forward recursion.", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(LQR, self).__init__()", "prediction_line": "        super(LQR, self).__init__()", "ground_truth": "        super().__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    The LQR problem can be described as:", "prediction_line": "    The LQR problem can be described as:", "ground_truth": "    LQR finds the optimal nominal trajectory :math:`\\mathbf{\\tau}_{1:T}^*` = ", "line_class": "infile", "zero_context": true}
{"original_prediction": "        Forward propagation of LQR.", "prediction_line": "        Forward propagation of LQR.", "ground_truth": "        Performs LQR for the linear system.", "line_class": "infile", "zero_context": true}
{"original_prediction": "        A (Tensor): dynamics matrix", "prediction_line": "        A (Tensor): dynamics matrix", "ground_truth": "        system (:obj:`instance`): The system to be soved by LQR.", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x, u, cost = self.backward_recursion(x_init)", "prediction_line": "        x, u, cost = self.backward_recursion(x_init)", "ground_truth": "        K, k = self.lqr_backward()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x, u, cost = self.lqr_forward(x_init, K, k)", "prediction_line": "        x, u, cost = self.lqr_forward(x_init, K, k)", "ground_truth": "        x, u, cost = self.lqr_forward(x_init, K, k)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        >>> \n        >>> x_init = torch.randn(n_batch, n_state)", "prediction_line": "        >>> ", "ground_truth": "        >>> x, u, cost = LQR(x_init)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        The LQR algorithm is based on the following paper:", "prediction_line": "        The LQR algorithm is based on the following paper:", "ground_truth": "        The discrete-time system to be solved by LQR could be both either linear time-invariant", "line_class": "infile", "zero_context": true}
{"original_prediction": "        Q (:obj:`torch.Tensor`): The state cost matrix.", "prediction_line": "        Q (:obj:`torch.Tensor`): The state cost matrix.", "ground_truth": "        Q (:obj:`Tensor`): The weight matrix of the quadratic term.", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    '''", "prediction_line": "    '''", "ground_truth": "        u =  tensor([[[ 1.0405,  0.1586, -0.1282],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \\end{bmatrix}`, :math:`\\mathbf{Q}_t` = :math:`\\begin{bmatrix} \\mathbf{Q} & \\mathbf{0} \\\\", "prediction_line": "    \\end{bmatrix}`, :math:`\\mathbf{Q}_t` = :math:`\\begin{bmatrix} \\mathbf{Q} & \\mathbf{0} \\\\", "ground_truth": "    \\end{bmatrix}`.", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                \\mathbf{V}_{t+1} &= \\mathbf{V}_{t+1} + \\mathbf{F}_t^\\top\\mathbf{Q}_t\\mathbf{F}_t \\\\", "prediction_line": "                \\mathbf{V}_{t+1} &= \\mathbf{V}_{t+1} + \\mathbf{F}_t^\\top\\mathbf{Q}_t\\mathbf{F}_t \\\\", "ground_truth": "                \\mathbf{K}_t &= -\\mathbf{Q}_{\\mathbf{u}_t, \\mathbf{u}_t}^{-1} ", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        x = x_init.unsqueeze(-2)", "prediction_line": "        x = x_init.unsqueeze(-2)", "ground_truth": "        x = torch.zeros(B + (self.T+1, ns), dtype=self.p.dtype, device=self.p.device)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        >>> lqr = pp.module.LQR(lti, Q, p)", "prediction_line": "        >>> lqr = pp.module.LQR(lti, Q, p)", "ground_truth": "        >>> LQR = pp.module.LQR(lti, Q, p, T)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        >>> p = torch.randn(n_batch, T, n_sc)", "prediction_line": "        >>> p = torch.randn(n_batch, T, n_sc)", "ground_truth": "        >>> p = torch.randn(n_batch, T, n_sc)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        >>> C = torch.randn(n_batch, n_state, n_state)", "prediction_line": "        >>> C = torch.randn(n_batch, n_state, n_state)", "ground_truth": "        >>> C = torch.tile(torch.eye(n_state), (n_batch, 1, 1))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for t in range(self.T):", "prediction_line": "        for t in range(self.T):", "ground_truth": "        self.system.set_refpoint(t=0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    + \\mathbf{K}_t^\\top\\mathbf{Q}_{\\mathbf{u}_t, \\mathbf{u}_t} ", "prediction_line": "                    + \\mathbf{K}_t^\\top\\mathbf{Q}_{\\mathbf{u}_t, \\mathbf{u}_t} ", "ground_truth": "                    + \\mathbf{K}_t^\\top\\mathbf{Q}_{\\mathbf{u}_t, \\mathbf{u}_t}\\mathbf{K}_t   \\\\", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        T = self.p.shape[-2]", "prediction_line": "        T = self.p.shape[-2]", "ground_truth": "        ns, nc = self.system.B.size(-2), self.system.B.size(-1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        >>> p = torch.randn(n_batch, T, n_sc)", "prediction_line": "        >>> p = torch.randn(n_batch, T, n_sc)", "ground_truth": "        >>> Q = torch.matmul(Q.mT, Q)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        >>> system = LTV(A, B, C, D, c1, c2)", "prediction_line": "        >>> system = LTV(A, B, C, D, c1, c2)", "ground_truth": "        >>> x_init = torch.randn(n_batch, n_state)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "+ bmv(F.mT, q)", "prediction_line": "+ bmv(F.mT, q)", "ground_truth": "                if self.system.c1 is not None:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    :math:`\\mathbf{C}`, :math:`\\mathbf{D}` are the observation matrix and input matrix of the linear system;", "prediction_line": "    :math:`\\mathbf{C}`, :math:`\\mathbf{D}` are the observation matrix and input matrix of the linear system;", "ground_truth": "    :math:`\\mathbf{C}`, :math:`\\mathbf{D}` are the output matrix and observation matrix of the", "line_class": "inproject", "zero_context": true}
{"original_prediction": "import torch.nn as nn", "prediction_line": "import torch.nn as nn", "ground_truth": "import torch.nn as nn", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.system = system", "prediction_line": "        self.system = system", "ground_truth": "        self.system = system", "line_class": "random", "zero_context": true}
{"original_prediction": "        Args:", "prediction_line": "        Args:", "ground_truth": "        Args:", "line_class": "random", "zero_context": true}
{"original_prediction": "    '''\n    def __init__(self, system, Q, p, T):", "prediction_line": "    '''", "ground_truth": "    Then quadratic costs of the system over the time horizon:", "line_class": "random", "zero_context": true}
{"original_prediction": "            if t == 0:", "prediction_line": "            if t == 0:", "ground_truth": "            Kt, kt = K[...,t,:,:], k[...,t,:]", "line_class": "random", "zero_context": true}
{"original_prediction": "                      [ 0.1849, -1.3884,  1.0898],", "prediction_line": "                      [ 0.1849, -1.3884,  1.0898],", "ground_truth": "                      [-0.6322, -0.3281, -0.3620],", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.start = start", "prediction_line": "        self.start = start", "ground_truth": "        self.start = start", "line_class": "common", "zero_context": true}
{"original_prediction": "        \"\"\" Returns the start actor for this queue.", "prediction_line": "        \"\"\" Returns the start actor for this queue.", "ground_truth": "        return self.start", "line_class": "common", "zero_context": true}
{"original_prediction": "    def log_to_limbo(self, item):", "prediction_line": "    def log_to_limbo(self, item):", "ground_truth": "        self._queue.cancel_join_thread()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            q.put(item)", "prediction_line": "            q.put(item)", "ground_truth": "            q.put(item)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._queue.join_thread()", "prediction_line": "        self._queue.join_thread()", "ground_truth": "        self._queue.join_thread()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            q.put_nowait(item)", "prediction_line": "            q.put_nowait(item)", "ground_truth": "            q.put_nowait(item)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\" Put an item into the queue.", "prediction_line": "        \"\"\" Put an item into the queue.", "ground_truth": "        self.log_to_limbo(item)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.limbo.log(self.name, self.num, item)", "prediction_line": "            self.limbo.log(self.name, self.num, item)", "ground_truth": "            self.limbo.put(item, f'q__{self.start}__{self.num}')", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def put_async(self, item):", "prediction_line": "    def put_async(self, item):", "ground_truth": "    async def put_async(self, item):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        await loop.run_in_executor(self._executor, self.queue.put, item)", "prediction_line": "        await loop.run_in_executor(self._executor, self.queue.put, item)", "ground_truth": "        res = await loop.run_in_executor(self._executor, self.put, item)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def get_async(self):", "prediction_line": "    def get_async(self):", "ground_truth": "    async def get_async(self):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        q_out.append(AsyncQueue(m.Queue(maxsize=0), name, start, endpoint, limbo))", "prediction_line": "        q_out.append(AsyncQueue(m.Queue(maxsize=0), name, start, endpoint, limbo))", "ground_truth": "        q = AsyncQueue(m.Queue(maxsize=0), name, start, endpoint, limbo=limbo)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            res = await loop.run_in_executor(self._executor, self.get)", "prediction_line": "            res = await loop.run_in_executor(self._executor, self.get)", "ground_truth": "            self.result = await loop.run_in_executor(self._executor, self.get)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    q = MultiAsyncQueue(m.Queue(maxsize=0), name, start, end, limbo=limbo)", "prediction_line": "    q = MultiAsyncQueue(m.Queue(maxsize=0), name, start, end, limbo=limbo)", "ground_truth": "    q = MultiAsyncQueue(m.Queue(maxsize=0), q_out, name, start, end)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    q = m.Queue()", "prediction_line": "    q = m.Queue()", "ground_truth": "    q = AsyncQueue(m.Queue(maxsize=0), name, start, end, limbo)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        super().__init__(q_in, name, start, end, limbo=None)", "prediction_line": "        super().__init__(q_in, name, start, end, limbo=None)", "ground_truth": "        self.queue = q_in", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.queue.put(item)", "prediction_line": "        self.queue.put(item)", "ground_truth": "        self.queue.put(item)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.queue.put_nowait(item)", "prediction_line": "        self.queue.put_nowait(item)", "ground_truth": "        self.queue.put_nowait(item)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return getattr(self.queue, name)", "prediction_line": "            return getattr(self.queue, name)", "ground_truth": "            return getattr(self.queue, name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.queue = q", "prediction_line": "        self.queue = q", "ground_truth": "        self.queue = q", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def put_async(self, item):", "prediction_line": "    def put_async(self, item):", "ground_truth": "    def put_nowait(self, item):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from typing import List, Dict, Any, Tuple, Optional, Union, Callable, Type", "prediction_line": "from typing import List, Dict, Any, Tuple, Optional, Union, Callable, Type", "ground_truth": "logger = logging.getLogger(__name__)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            start (int): Start of the queue", "prediction_line": "            start (int): Start of the queue", "ground_truth": "            start (str): The producer (input) actor for the queue", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            limbo:", "prediction_line": "            limbo:", "ground_truth": "            limbo:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def log_to_limbo(self, item):", "prediction_line": "    def log_to_limbo(self, item):", "ground_truth": "    def log_to_limbo(self, item):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                                    (self.__class__.__name__, name))", "prediction_line": "                                    (self.__class__.__name__, name))", "ground_truth": "                                    (self.__class__.__name__, name))", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.num = 0", "prediction_line": "        self.num = 0", "ground_truth": "        self.num = 0", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.log_to_limbo(item)", "prediction_line": "        self.log_to_limbo(item)", "ground_truth": "        loop = asyncio.get_event_loop()", "line_class": "random", "zero_context": true}
{"original_prediction": "        return getattr(self.queue, name)", "prediction_line": "        return getattr(self.queue, name)", "ground_truth": "        if name in ['qsize', 'empty', 'full',", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.q_out = q_out", "prediction_line": "        self.q_out = q_out", "ground_truth": "        self.output = q_out", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(*args, **kwargs)", "prediction_line": "        super().__init__(*args, **kwargs)", "ground_truth": "        super().__init__(*args, **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        while not self.done:", "prediction_line": "        while not self.done:", "ground_truth": "        with RunManager(self.name, self.runProcess, self.setup, self.q_sig, self.q_comm, runStore=self._getStoreInterface()) as rm:", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return labels[index], percentage[index].item(), top_five", "prediction_line": "        return labels[index], percentage[index].item(), top_five", "ground_truth": "        return labels[index], percentage[index], top_five", "line_class": "common", "zero_context": true}
{"original_prediction": "        pred_label = labels[np.argmax(predictions)]", "prediction_line": "        pred_label = labels[np.argmax(predictions)]", "ground_truth": "        index = np.argmax(predictions, axis=1)[0]  ", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.model = torch.jit.load(self.model_path, map_location=self.device)", "prediction_line": "        self.model = torch.jit.load(self.model_path, map_location=self.device)", "ground_truth": "        self.model = torch.jit.load(self.model_path).eval().to(self.device)", "line_class": "common", "zero_context": true}
{"original_prediction": "            ids = self.q_sig.get(timeout=1)", "prediction_line": "            ids = self.q_sig.get(timeout=1)", "ground_truth": "            res = self.q_in.get(timeout=0.005)", "line_class": "common", "zero_context": true}
{"original_prediction": "                self.client.putID(img, ids[1])", "prediction_line": "                self.client.putID(img, ids[1])", "ground_truth": "                output, _, _ = self._runInference(img)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            except CannotGetObjectError:", "prediction_line": "            except CannotGetObjectError:", "ground_truth": "                img = self._processImage(img)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        while not self.done:", "prediction_line": "        while not self.done:", "ground_truth": "        ids = self._checkInput()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self._classify(predictions)", "prediction_line": "                    self._classify(predictions)", "ground_truth": "                    pred_label, percent, top_five = self._classifyImage(predictions, self.labels)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if self.img_num % 100 == 0:", "prediction_line": "                if self.img_num % 100 == 0:", "ground_truth": "            except ObjectNotFoundError:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.model(sample_input)", "prediction_line": "            self.model(sample_input)", "ground_truth": "            for _ in range(10):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return None\n        img = img.to(self.device)", "prediction_line": "            return None", "ground_truth": "            raise ObjectNotFoundError", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.process(ids)", "prediction_line": "                self.process(ids)", "ground_truth": "                img = self.client.getID(ids[0])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.done = True", "prediction_line": "            self.done = True", "ground_truth": "            self.q_comm.put(None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    self.true_label.append(self.img_num)", "prediction_line": "                    self.true_label.append(self.img_num)", "ground_truth": "                    self.true_label.append(self.labels[self.client.getID(ids[1])])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "import torch.nn as nn", "prediction_line": "import torch.nn as nn", "ground_truth": "from scipy.special import softmax", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        if self.classify is True:", "prediction_line": "        if self.classify is True:", "ground_truth": "    def runProcess(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def _processImage(self, img):", "prediction_line": "    def _processImage(self, img):", "ground_truth": "            # return None", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import sys\nimport time", "prediction_line": "import sys", "ground_truth": "import time", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        ''' Checks if there is input data to process", "prediction_line": "        ''' Checks if there is input data to process", "ground_truth": "        ''' Check to see if we have images for processing", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                if self.img_num % 100 == 0:", "prediction_line": "                if self.img_num % 100 == 0:", "ground_truth": "                ", "line_class": "random", "zero_context": true}
{"original_prediction": "                self.client.putID(ids[1], output)", "prediction_line": "                self.client.putID(ids[1], output)", "ground_truth": "                features = output[0].to('cpu').numpy()", "line_class": "random", "zero_context": true}
{"original_prediction": "e, self.img_num))", "prediction_line": "e, self.img_num))", "ground_truth": "                                                                                            e, self.img_num))", "line_class": "random", "zero_context": true}
{"original_prediction": "            img = img.to(self.device)", "prediction_line": "            img = img.to(self.device)", "ground_truth": "            img = img.unsqueeze(dim=0).permute(0, 3, 1, 2)", "line_class": "random", "zero_context": true}
{"original_prediction": "    testfile.setup()", "prediction_line": "    testfile.setup()", "ground_truth": "    testfile.setup()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    testfile.run()", "prediction_line": "    testfile.run()", "ground_truth": "    testfile.run()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(FileAcquirerZMQ, self).__init__(*args, **kwargs)", "prediction_line": "        super(FileAcquirerZMQ, self).__init__(*args, **kwargs)", "ground_truth": "        super().__init__(*args, **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    testfile.start()", "prediction_line": "    testfile.start()", "ground_truth": "    testfile.setupZMQ()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.runAcquirer()", "prediction_line": "            self.runAcquirer()", "ground_truth": "            self.runAcquirer()", "line_class": "infile", "zero_context": true}
{"original_prediction": "   time.sleep(1)", "prediction_line": "   time.sleep(1)", "ground_truth": "    testfile = FileAcquirerZMQ(filename='tbif_ex_crop.h5', framerate=30, name='j')", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def run(self):", "prediction_line": "    def run(self):", "ground_truth": "        self.setupZMQ", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.flag = True", "prediction_line": "            self.flag = True", "ground_truth": "            frame = self.getFrame(self.frame_num)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.store.put(frame)", "prediction_line": "            self.store.put(frame)", "ground_truth": "            id = self.client.put(frame, 'acq_raw'+str(self.frame_num))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def shutdown(self):", "prediction_line": "    def shutdown(self):", "ground_truth": "        self.f.flush()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.done = True", "prediction_line": "            self.done = True", "ground_truth": "            self.q_comm.put(None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    testfile.run()", "prediction_line": "    testfile.run()", "ground_truth": "    lmb = Limbo(store_loc = \"/tmp/store\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    lmb.start()", "prediction_line": "    lmb.start()", "ground_truth": "    testfile.setStore(lmb)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from improv.actor import ActorSystem", "prediction_line": "from improv.actor import ActorSystem", "ground_truth": "import logging; logger = logging.getLogger(__name__)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       self.context = zmq.Context()", "prediction_line": "       self.context = zmq.Context()", "ground_truth": "    def setupZMQ(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ", and send to next actor", "prediction_line": ", and send to next actor", "ground_truth": "        '''", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def getFrame(self, frame_num):", "prediction_line": "    def getFrame(self, frame_num):", "ground_truth": "    def getFrame(self, num):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # subprocess.Popen(['python', '-m', 'improv', 'store', '--name', 'acq_store'])", "prediction_line": "    # subprocess.Popen(['python', '-m', 'improv', 'store', '--name', 'acq_store'])", "ground_truth": "    from improv.store import Limbo", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            #     self.frame_num += 1", "prediction_line": "            #     self.frame_num += 1", "ground_truth": "            t= time.time()", "line_class": "random", "zero_context": true}
{"original_prediction": "                self.data = h5py.File(self.filename, 'r')", "prediction_line": "                self.data = h5py.File(self.filename, 'r')", "ground_truth": "                with h5py.File(self.filename, 'r') as file:", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.framerate = framerate", "prediction_line": "        self.framerate = framerate", "ground_truth": "        self.framerate = 1/framerate", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.socket = context.socket(zmq.REP)", "prediction_line": "        self.socket = context.socket(zmq.REP)", "ground_truth": "        self.socket = context.socket(zmq.REP)", "line_class": "random", "zero_context": true}
{"original_prediction": "# class StimAcquirer(Actor):", "prediction_line": "# class StimAcquirer(Actor):", "ground_truth": "if __name__==\"__main__\":", "line_class": "random", "zero_context": true}
{"original_prediction": "[\"plasma_store\", \"-m\", store_loc, \"-s\", \"/tmp/plasma_store_socket\"])", "prediction_line": "[\"plasma_store\", \"-m\", store_loc, \"-s\", \"/tmp/plasma_store_socket\"])", "ground_truth": "            ['plasma_store', '-s', store_loc, '-m', str(100)], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    assert isinstance(id, bytes)", "prediction_line": "    assert isinstance(id, bytes)", "ground_truth": "    assert 1 == limbo.get('one')", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # TODO: shorter name???", "prediction_line": "    # TODO: shorter name???", "ground_truth": "    store_loc = None", "line_class": "infile", "zero_context": true}
{"original_prediction": "    limbo.reset()", "prediction_line": "    limbo.reset()", "ground_truth": "    limbo.reset()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        limbo = Limbo()", "prediction_line": "        limbo = Limbo()", "ground_truth": "        limbo.connnect_store(store_loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "def test_getTwo():", "prediction_line": "def test_getTwo():", "ground_truth": "    assert id == limbo.stored['one']", "line_class": "infile", "zero_context": true}
{"original_prediction": "    pytest.raises(ArrowIOError)", "prediction_line": "    pytest.raises(ArrowIOError)", "ground_truth": "    assert limbo.get('one') == 1", "line_class": "infile", "zero_context": true}
{"original_prediction": "    limbo.connect(store_loc)", "prediction_line": "    limbo.connect(store_loc)", "ground_truth": "    yield limbo", "line_class": "infile", "zero_context": true}
{"original_prediction": "        limbo.get('one')", "prediction_line": "        limbo.get('one')", "ground_truth": "        limbo.get('three')", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return '/tmp/plasma'", "prediction_line": "    return '/tmp/plasma'", "ground_truth": "    store_loc = '/dev/shm'", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return store_loc", "prediction_line": "    return store_loc", "ground_truth": "    return store_loc", "line_class": "infile", "zero_context": true}
{"original_prediction": "    assert limbo.store_loc == store_loc", "prediction_line": "    assert limbo.store_loc == store_loc", "ground_truth": "    assert isinstance(limbo.client, plasma.PlasmaClient)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    store_loc = '/dev/shm/incorrect'", "prediction_line": "    store_loc = '/dev/shm/incorrect'", "ground_truth": "    store_loc = 'asdf'", "line_class": "infile", "zero_context": true}
{"original_prediction": "    lmdb_store.put(2, 'two')", "prediction_line": "    lmdb_store.put(2, 'two')", "ground_truth": "    assert lmdb_store.getID('one', hdd_only=True) == 1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # self.limbo = Limbo()", "prediction_line": "    # self.limbo = Limbo()", "ground_truth": "    limbo.connect_store(store_loc)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # TODO: check if hdd_only is True", "prediction_line": "    # TODO: check if hdd_only is True", "ground_truth": "    lmdb_store.put(1, 'one')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert obj == False", "prediction_line": "    assert obj == False", "ground_truth": "    pytest.raises(ObjectNotFoundError)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # TODO: check that it is empty", "prediction_line": "    # TODO: check that it is empty", "ground_truth": "    assert limbo.get_all() == False", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # TODO: check if isinstance(mat, csc_matrix)", "prediction_line": "    # TODO: check if isinstance(mat, csc_matrix)", "ground_truth": "    x = limbo.put(mat, 'matrix' )", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert [1, 2, 3] == limbo.getAll()", "prediction_line": "    assert [1, 2, 3] == limbo.getAll()", "ground_truth": "    assert [1, 2, 3] == limbo.get_all()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert limbo.get_list() == [id, id2, id3]", "prediction_line": "    assert limbo.get_list() == [id, id2, id3]", "ground_truth": "    assert [1, 2] == limbo.getList(['one', 'two'])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    id = limbo.put(1, 'one')", "prediction_line": "    id = limbo.put(1, 'one')", "ground_truth": "    limbo.release()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    id = limbo.put(1, 'one')", "prediction_line": "    id = limbo.put(1, 'one')", "ground_truth": "    id = limbo.put(2, 'two')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert 1 == limbo.get('one')", "prediction_line": "    assert 1 == limbo.get('one')", "ground_truth": "    id2 = limbo.put(2, 'two')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # TODO: check if empty", "prediction_line": "    # TODO: check if empty", "ground_truth": "    id = limbo.put(1, 'one')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # TODO: check if not picklable", "prediction_line": "    # TODO: check if not picklable", "ground_truth": "    obj = limbo.getID(limbo.random_ObjectID(1))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    limbo = Limbo(store_loc)", "prediction_line": "    limbo = Limbo(store_loc)", "ground_truth": "    limbo = Limbo()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    id3 = limbo.put(3, 'three')", "prediction_line": "    id3 = limbo.put(3, 'three')", "ground_truth": "    id3 = limbo.put(3, 'three')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    '''\n    '''", "prediction_line": "    '''", "ground_truth": "    # self.limbo = Limbo()", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.limbo.saveTweak(fileName)", "prediction_line": "        self.limbo.saveTweak(fileName)", "ground_truth": "        id2= self.limbo.put(2, 'two')", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    store_loc = '/dev/shm/incorrect'", "prediction_line": "    store_loc = '/dev/shm/incorrect'", "ground_truth": "    # TODO: shorter name???", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_get_object_not_in_store(limbo):", "prediction_line": "def test_get_object_not_in_store(limbo):", "ground_truth": "    # Check raises...CannotGetObjectError (object never stored)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        assert 1 == self.limbo.getID(id[0])", "prediction_line": "        assert 1 == self.limbo.getID(id[0])", "ground_truth": "        assert 1 == self.limbo.client.get(id[0])", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        yield p", "prediction_line": "        yield p", "ground_truth": "        yield p", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert cm.exception.name == 'CannotGetObjectError'", "prediction_line": "    assert cm.exception.name == 'CannotGetObjectError'", "ground_truth": "    assert cm.exception.name == 'CannotGetObjectError'", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert isinstance(cm.exception, CannotConnectToStoreError)", "prediction_line": "    assert isinstance(cm.exception, CannotConnectToStoreError)", "ground_truth": "    assert cm.exception.name == 'CannotConnectToStoreError'", "line_class": "random", "zero_context": true}
{"original_prediction": "@pytest.fixture", "prediction_line": "@pytest.fixture", "ground_truth": "@pytest.fixture", "line_class": "random", "zero_context": true}
{"original_prediction": "    limbo.put(2, 'two')", "prediction_line": "    limbo.put(2, 'two')", "ground_truth": "    pytest.raises(ArrowIOError)", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(*args, **kwargs)", "prediction_line": "        super().__init__(*args, **kwargs)", "ground_truth": "        super().__init__(*args)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        while not self.done:", "prediction_line": "        while not self.done:", "ground_truth": "        with RunManager(self.name, self.runProcess, self.setup, self.q_sig, self.q_comm) as rm:", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.model = torch.jit.load(self.model_path).to(self.device)", "prediction_line": "        self.model = torch.jit.load(self.model_path).to(self.device)", "ground_truth": "        self.model = torch.jit.load(self.model_path).to(self.device)", "line_class": "common", "zero_context": true}
{"original_prediction": "            img = self.q_in.get(timeout=0)", "prediction_line": "            img = self.q_in.get(timeout=0)", "ground_truth": "            res = self.q_in.get(timeout=0)", "line_class": "common", "zero_context": true}
{"original_prediction": "       self.transforms = torch.jit.load(self.transforms_path)", "prediction_line": "       self.transforms = torch.jit.load(self.transforms_path)", "ground_truth": "        self.transforms = torch.jit.load(self.transforms_path).to(self.device)", "line_class": "common", "zero_context": true}
{"original_prediction": "                self.get_img_out.append(t1-t)", "prediction_line": "                self.get_img_out.append(t1-t)", "ground_truth": "                img = self._processImage(img, self.img_num)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        while not self.done:", "prediction_line": "        while not self.done:", "ground_truth": "        img = self._checkImages()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.done = True", "prediction_line": "                self.done = True", "ground_truth": "                output = self._runInference(img)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            except Exception as e:", "prediction_line": "            except Exception as e:", "ground_truth": "            except ObjectNotFoundError:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.img_num += 1", "prediction_line": "                self.img_num += 1", "ground_truth": "                self.q_out.put([1])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.img_num.append(img.ref_num)", "prediction_line": "                self.img_num.append(img.ref_num)", "ground_truth": "                img = self.client.getID([str(self.img_num)])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return None\n        else:", "prediction_line": "            return None", "ground_truth": "            raise ObjectNotFoundError", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self._putOutput(output, self.img_num)", "prediction_line": "                self._putOutput(output, self.img_num)", "ground_truth": "                out_obj_id = self.client.put(output.numpy(), 'output' + str(self.img_num))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    pred_obj_id = self.client.put(pred.numpy(), 'prediction' + str(self.img_num))", "prediction_line": "                    pred_obj_id = self.client.put(pred.numpy(), 'prediction' + str(self.img_num))", "ground_truth": "                    pred_obj_id = self.client.put(pred, 'prediction' + str(self.img_num))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        '''\n        try:", "prediction_line": "        '''", "ground_truth": "        '''", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        ''' Checks if there are any images in the store.", "prediction_line": "        ''' Checks if there are any images in the store.", "ground_truth": "        ''' Check to see if we have images for processing", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            img = self.client.getID([str(self.img_num)])", "prediction_line": "            img = self.client.getID([str(self.img_num)])", "ground_truth": "            # Timeout = 0 ms", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                t3 = time.time()", "prediction_line": "                t3 = time.time()", "ground_truth": "                t3 = time.time()", "line_class": "random", "zero_context": true}
{"original_prediction": "        if self.classify is True:", "prediction_line": "        if self.classify is True:", "ground_truth": "        with open(\"output/timing/load_transforms_time.txt\", \"w\") as text_file:", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.classify_img_time = []", "prediction_line": "        self.classify_img_time = []", "ground_truth": "        self.inference_time = []", "line_class": "random", "zero_context": true}
{"original_prediction": "                logger.error('Processor: Unknown error... {0}'.format(e))", "prediction_line": "                logger.error('Processor: Unknown error... {0}'.format(e))", "ground_truth": "                logger.error('Processor error: {}: {} during image number {}'.format(type(e).__name__,", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.classify_time = []", "prediction_line": "        self.classify_time = []", "ground_truth": "        self.put_out_time = []", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.context_similarity_factor = context_similarity_factor", "prediction_line": "        self.context_similarity_factor = context_similarity_factor", "ground_truth": "        super().__init__(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            nlp_artifacts.tokens, start, lemmatized_keywords", "prediction_line": "            nlp_artifacts.tokens, start, lemmatized_keywords", "ground_truth": "            word, start, nlp_artifacts.tokens, nlp_artifacts.tokens_indices", "line_class": "common", "zero_context": true}
{"original_prediction": "        index: int,", "prediction_line": "        index: int,", "ground_truth": "        index: int,", "line_class": "common", "zero_context": true}
{"original_prediction": "            # and compare it to the context words", "prediction_line": "            # and compare it to the context words", "ground_truth": "            word = text[result.start : result.end]", "line_class": "common", "zero_context": true}
{"original_prediction": "                text, result.start, result.end, nlp_artifacts", "prediction_line": "                text, result.start, result.end, nlp_artifacts", "ground_truth": "                nlp_artifacts=nlp_artifacts, word=word, start=result.start", "line_class": "common", "zero_context": true}
{"original_prediction": "            index, n_words, lemmas, lemmatized_filtered_keywords, False", "prediction_line": "            index, n_words, lemmas, lemmatized_filtered_keywords, False", "ground_truth": "            index, n_words, lemmas, lemmatized_filtered_keywords, False", "line_class": "common", "zero_context": true}
{"original_prediction": "            if (\n                token == word", "prediction_line": "            if (", "ground_truth": "            if (tokens_indices[i] == start) or (start < tokens_indices[i] + len(token)):", "line_class": "common", "zero_context": true}
{"original_prediction": "        context_list = []", "prediction_line": "        context_list = []", "ground_truth": "        i = index", "line_class": "common", "zero_context": true}
{"original_prediction": "            index, n_words, lemmas, lemmatized_filtered_keywords, True", "prediction_line": "            index, n_words, lemmas, lemmatized_filtered_keywords, True", "ground_truth": "            index, n_words, lemmas, lemmatized_filtered_keywords, True", "line_class": "common", "zero_context": true}
{"original_prediction": "index\n        # and use it to extract the context", "prediction_line": "index", "ground_truth": "        token_index = self._find_index_of_match_token(", "line_class": "infile", "zero_context": true}
{"original_prediction": "           context_words = self.get_context_words(", "prediction_line": "           context_words = self.get_context_words(", "ground_truth": "            surrounding_words = self.__extract_surrounding_words(", "line_class": "infile", "zero_context": true}
{"original_prediction": "       context_list = []", "prediction_line": "       context_list = []", "ground_truth": "        backward_context = self.__add_n_words_backward(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Prepare a string of context words.", "prediction_line": "        \"\"\"", "ground_truth": "        return self.__add_n_words(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            # check if the context words are in the surrounding words", "prediction_line": "            # check if the context words are in the surrounding words", "ground_truth": "            supportive_context_word = self.__find_supportive_word_in_context(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        forward_context = self.__add_n_words_forward(", "prediction_line": "        forward_context = self.__add_n_words_forward(", "ground_truth": "        forward_context = self.__add_n_words_forward(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    recognizer.name,", "prediction_line": "                    recognizer.name,", "ground_truth": "                    recognizer.name,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if result.explainability is not None:", "prediction_line": "                if result.explainability is not None:", "ground_truth": "                result.analysis_explanation.set_supportive_context_word(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self, nlp_artifacts: NlpArtifacts, word: str, start: int", "prediction_line": "        self, nlp_artifacts: NlpArtifacts, word: str, start: int", "ground_truth": "        self, nlp_artifacts: NlpArtifacts, word: str, start: int", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        recognizer_context_words = self.create_recognizer_context_words(", "prediction_line": "        recognizer_context_words = self.create_recognizer_context_words(", "ground_truth": "        recognizers_dict = {recognizer.name: recognizer for recognizer in recognizers}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        results: List[RecognizerResult],", "prediction_line": "        results: List[RecognizerResult],", "ground_truth": "        raw_results: List[RecognizerResult],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        context: Optional[List[str]] = None,", "prediction_line": "        context: Optional[List[str]] = None,", "ground_truth": "        nlp_artifacts: NlpArtifacts,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        recognizer: Optional[EntityRecognizer] = None,", "prediction_line": "        recognizer: Optional[EntityRecognizer] = None,", "ground_truth": "        recognizers: List[EntityRecognizer],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                surrounding_words=surrounding_words,", "prediction_line": "                surrounding_words=surrounding_words,", "ground_truth": "                surrounding_words, recognizer.context", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ) -> List[RecognizerResult]:", "prediction_line": "    ) -> List[RecognizerResult]:", "ground_truth": "    ) -> List[RecognizerResult]:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            recognizer = recognizers_dict.get(result.recognizer)", "prediction_line": "            recognizer = recognizers_dict.get(result.recognizer)", "ground_truth": "            recognizer = recognizers_dict[", "line_class": "inproject", "zero_context": true}
{"original_prediction": "result.recognizer]", "prediction_line": "result.recognizer]", "ground_truth": "                result.recognition_metadata[RecognizerResult.RECOGNIZER_NAME_KEY]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return results", "prediction_line": "        return results", "ground_truth": "                result.analysis_explanation.set_improved_score(result.score)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if not recognizer.support_context_enhancement:", "prediction_line": "            if not recognizer.support_context_enhancement:", "ground_truth": "            if not recognizer.context:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # get the context words of the recognizer", "prediction_line": "            # get the context words of the recognizer", "ground_truth": "            # extract lemmatized context from the surrounding of the match", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # token might be a substring of the original word", "prediction_line": "        # token might be a substring of the original word", "ground_truth": "        # token might be just a substring of that word (e.g. for phone number", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "list\n            return []", "prediction_line": "list", "ground_truth": "            # context", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "correct.\n\n        :param text: The text to analyze", "prediction_line": "correct.", "ground_truth": "        indeed of that PII entity type", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        word: str, start: int, tokens: List[str], tokens_indices: List[int]", "prediction_line": "        word: str, start: int, tokens: List[str], tokens_indices: List[int]", "ground_truth": "        word: str, start: int, tokens, tokens_indices: List[int]  # noqa ANN001", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            lemmatized_keywords,", "prediction_line": "            lemmatized_keywords,", "ground_truth": "            lemmatized_keywords,", "line_class": "random", "zero_context": true}
{"original_prediction": "                f\"Could not find the token index for the word '{word}'\"", "prediction_line": "                f\"Could not find the token index for the word '{word}'\"", "ground_truth": "                \"Did not find word '\" + word + \"' \"", "line_class": "random", "zero_context": true}
{"original_prediction": "            context = [word.lower() for word in context]", "prediction_line": "            context = [word.lower() for word in context]", "ground_truth": "            context = [word.lower() for word in context]", "line_class": "random", "zero_context": true}
{"original_prediction": "    ) -> List[str]:", "prediction_line": "    ) -> List[str]:", "ground_truth": "    ) -> List[str]:", "line_class": "random", "zero_context": true}
{"original_prediction": "            )\n\n            # check if the surrounding words are similar to the context words", "prediction_line": "            )", "ground_truth": "            )", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(supported_entities=supported_entities)", "prediction_line": "        super().__init__(supported_entities=supported_entities)", "ground_truth": "        super().__init__(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            # Convert transformers_rec results to Presidio RecognizerResult", "prediction_line": "            # Convert transformers_rec results to Presidio RecognizerResult", "ground_truth": "            entity = self.model_to_presidio_mapping.get(res[\"entity_group\"], None)", "line_class": "common", "zero_context": true}
{"original_prediction": "       self.aggregation_mechanism = kwargs.get(", "prediction_line": "       self.aggregation_mechanism = kwargs.get(", "ground_truth": "        self.entity_mapping = kwargs.get(\"DATASET_TO_PRESIDIO_MAPPING\", {})", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.model_to_presidio_mapping = kwargs.get(\"MODEL_TO_PRESIDIO_MAPPING\", {})", "prediction_line": "        self.model_to_presidio_mapping = kwargs.get(\"MODEL_TO_PRESIDIO_MAPPING\", {})", "ground_truth": "        self.model_to_presidio_mapping = kwargs.get(\"MODEL_TO_PRESIDIO_MAPPING\", {})", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.aggregation_mechanism = kwargs.get(\"SUB_WORD_AGGREGATION\", \"first\")", "prediction_line": "        self.aggregation_mechanism = kwargs.get(\"SUB_WORD_AGGREGATION\", \"first\")", "ground_truth": "        self.ignore_labels = kwargs.get(\"LABELS_TO_IGNORE\", [\"O\"])", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.aggregation_mechanism = kwargs.get(\"SUB_WORD_AGGREGATION\", \"first\")", "prediction_line": "        self.aggregation_mechanism = kwargs.get(\"SUB_WORD_AGGREGATION\", \"first\")", "ground_truth": "        self.aggregation_mechanism = kwargs.get(\"SUB_WORD_AGGREGATION\", \"simple\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.text_overlap_length = kwargs.get(\"CHUNK_OVERLAP_SIZE\", 10)", "prediction_line": "        self.text_overlap_length = kwargs.get(\"CHUNK_OVERLAP_SIZE\", 10)", "ground_truth": "        self.default_explanation = kwargs.get(\"DEFAULT_EXPLANATION\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.text_overlap_length = kwargs.get(\"CHUNK_OVERLAP_SIZE\", 10)", "prediction_line": "        self.text_overlap_length = kwargs.get(\"CHUNK_OVERLAP_SIZE\", 10)", "ground_truth": "        self.text_overlap_length = kwargs.get(\"CHUNK_OVERLAP_SIZE\", 40)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.chunk_length = kwargs.get(\"CHUNK_SIZE\", 512)", "prediction_line": "        self.chunk_length = kwargs.get(\"CHUNK_SIZE\", 512)", "ground_truth": "        self.chunk_length = kwargs.get(\"CHUNK_SIZE\", 600)", "line_class": "common", "zero_context": true}
{"original_prediction": "            start=prediction_result[\"start\"],", "prediction_line": "            start=prediction_result[\"start\"],", "ground_truth": "            start=prediction_result[\"start\"],", "line_class": "common", "zero_context": true}
{"original_prediction": "        label = self.model_to_presidio_mapping.get(label, None)", "prediction_line": "        label = self.model_to_presidio_mapping.get(label, None)", "ground_truth": "        entity = self.model_to_presidio_mapping.get(label, None)", "line_class": "common", "zero_context": true}
{"original_prediction": "        if self.is_loaded:", "prediction_line": "        if self.is_loaded:", "ground_truth": "        ner_results = self._get_ner_results_for_text(text)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for start, end in self.split_text_to_word_chunks(", "prediction_line": "        for start, end in self.split_text_to_word_chunks(", "ground_truth": "        chunk_indexes = TransformersRecognizer.split_text_to_word_chunks(", "line_class": "infile", "zero_context": true}
{"original_prediction": "           # If the entity is not in the supported entities list, skip it", "prediction_line": "           # If the entity is not in the supported entities list, skip it", "ground_truth": "            res[\"entity_group\"] = self.__check_label_transformer(res[\"entity_group\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            explanation = AnalysisExplanation(textual_explanation)", "prediction_line": "            explanation = AnalysisExplanation(textual_explanation)", "ground_truth": "            explanation = self.build_transformers_explanation(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            results.append(", "prediction_line": "            results.append(", "ground_truth": "            transformers_result = self._convert_to_recognizer_result(res, explanation)", "line_class": "infile", "zero_context": true}
{"original_prediction": "           self.pipeline = pipeline(", "prediction_line": "           self.pipeline = pipeline(", "ground_truth": "        self._load_pipeline()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        supported_entities: Optional[List[str]] = None,", "prediction_line": "        supported_entities: Optional[List[str]] = None,", "ground_truth": "        supported_entities: Optional[List[str]] = None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.model_path = model_path", "prediction_line": "        self.model_path = model_path", "ground_truth": "        if not supported_entities:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            supported_entities = BERT_DEID_CONFIGURATION.get(\"PRESIDIO_SUPPORTED_ENTITIES\")", "prediction_line": "            supported_entities = BERT_DEID_CONFIGURATION.get(\"PRESIDIO_SUPPORTED_ENTITIES\")", "ground_truth": "            supported_entities = BERT_DEID_CONFIGURATION[", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        res: dict, explanation: AnalysisExplanation", "prediction_line": "        res: dict, explanation: AnalysisExplanation", "ground_truth": "        prediction_result: dict, explanation: AnalysisExplanation", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            predictions.extend(aligned_predictions)", "prediction_line": "            predictions.extend(aligned_predictions)", "ground_truth": "            predictions.extend(aligned_predictions)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if entity not in self.supported_entities:", "prediction_line": "        if entity not in self.supported_entities:", "ground_truth": "        if entity not in self.supported_entities:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       return RecognizerResult(", "prediction_line": "       return RecognizerResult(", "ground_truth": "        transformers_results = RecognizerResult(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    RecognizerRegistry,", "prediction_line": "    RecognizerRegistry,", "ground_truth": "    AnalysisExplanation,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ) -> List[RecognizerResult]:", "prediction_line": "    ) -> List[RecognizerResult]:", "ground_truth": "    ) -> List[RecognizerResult]:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self, text: str, entities: Optional[List[str]] = None, nlp_artifacts: NlpArtifacts = None", "prediction_line": "        self, text: str, entities: Optional[List[str]] = None, nlp_artifacts: NlpArtifacts = None", "ground_truth": "        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts = None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self.supported_entities", "prediction_line": "        return self.supported_entities", "ground_truth": "        return self.supported_entities", "line_class": "inproject", "zero_context": true}
{"original_prediction": "supported_entities=supported_entities)", "prediction_line": "supported_entities=supported_entities)", "ground_truth": "            supported_entities=supported_entities,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ) -> RecognizerResult:", "prediction_line": "    ) -> RecognizerResult:", "ground_truth": "    ) -> RecognizerResult:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            original_score=original_score,", "prediction_line": "            original_score=original_score,", "ground_truth": "            recognizer=self.__class__.__name__,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        explanation = AnalysisExplanation(", "prediction_line": "        explanation = AnalysisExplanation(", "ground_truth": "        explanation = AnalysisExplanation(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def build_transformers_explanation(", "prediction_line": "    def build_transformers_explanation(", "ground_truth": "    def _convert_to_recognizer_result(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Run transformers_rec model on the provided text", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"The function runs model inference on the provided text.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "in\n        https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.convert_tokens_to_ids", "prediction_line": "in", "ground_truth": "        in HuggingFace https://huggingface.co/transformers/v4.8.0/main_classes/pipelines.html#transformers.TokenClassificationPipeline # noqa", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       for chunk_index in chunk_indexes:", "prediction_line": "       for chunk_index in chunk_indexes:", "ground_truth": "        # iterate over text chunks and run inference", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        explanation = AnalysisExplanation(", "prediction_line": "        \"\"\"", "ground_truth": "        :rtype: AnalysisExplanation", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            logger.info(", "prediction_line": "            logger.info(", "ground_truth": "            chunk_preds = self.pipeline(chunk_text)", "line_class": "random", "zero_context": true}
{"original_prediction": "            supported_language=\"en\",", "prediction_line": "            supported_language=\"en\",", "ground_truth": "            name=f\"Transformers model {model_path}\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                continue\n            # If the entity is not in the supported entities list, skip it", "prediction_line": "                continue", "ground_truth": "                continue", "line_class": "random", "zero_context": true}
{"original_prediction": "            return [[0, input_length]]", "prediction_line": "            return [[0, input_length]]", "ground_truth": "            return [[0, input_length]]", "line_class": "random", "zero_context": true}
{"original_prediction": "        predictions = list(set(predictions))", "prediction_line": "        predictions = list(set(predictions))", "ground_truth": "        predictions = [dict(t) for t in {tuple(d.items()) for d in predictions}]", "line_class": "random", "zero_context": true}
{"original_prediction": "    test_metadata_text, test_is_name, test_is_patient = mock_engine._get_text_metadata(", "prediction_line": "    test_metadata_text, test_is_name, test_is_patient = mock_engine._get_text_metadata(", "ground_truth": "    test_metadata_text, test_is_name, test_is_patient = mock_engine._get_text_metadata(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine.redact_from_directory(dcm_path, \"output\", 25, \"contrast\")", "prediction_line": "    mock_engine.redact_from_directory(dcm_path, \"output\", 25, \"contrast\")", "ground_truth": "    mock_engine.redact_from_directory(dcm_path, \"output\", 25, \"contrast\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "        DicomImageRedactorEngine, \"_add_padding\", return_value=None", "prediction_line": "        DicomImageRedactorEngine, \"_add_padding\", return_value=None", "ground_truth": "        DicomImageRedactorEngine,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    engine = DicomImageRedactorEngine()", "prediction_line": "    engine = DicomImageRedactorEngine()", "ground_truth": "    dicom_image_redactor_engine = DicomImageRedactorEngine()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine: DicomImageRedactorEngine,", "prediction_line": "    mock_engine: DicomImageRedactorEngine,", "ground_truth": "    mock_engine: DicomImageRedactorEngine,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine = DicomImageRedactorEngine()", "prediction_line": "    mock_engine = DicomImageRedactorEngine()", "ground_truth": "    mock_engine = DicomImageRedactorEngine()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_instance = mock_engine._add_redact_box(", "prediction_line": "    test_instance = mock_engine._add_redact_box(", "ground_truth": "    test_redacted_instance = mock_engine._add_redact_box(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        mock_engine.redact_from_directory(input_path, output_path, 25, \"contrast\")", "prediction_line": "        mock_engine.redact_from_directory(input_path, output_path, 25, \"contrast\")", "ground_truth": "        mock_engine.redact_from_directory(input_path, output_path, 25, \"contrast\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_phi_list = mock_engine._process_names(text_metadata, is_name)", "prediction_line": "    test_phi_list = mock_engine._process_names(text_metadata, is_name)", "ground_truth": "    test_phi_list = mock_engine._process_names(text_metadata, is_name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine: DicomImageRedactorEngine, dcm_dir: Path, expected_list: list", "prediction_line": "    mock_engine: DicomImageRedactorEngine, dcm_dir: Path, expected_list: list", "ground_truth": "    mock_engine: DicomImageRedactorEngine, dcm_dir: Path, expected_list: list", "line_class": "commited", "zero_context": true}
{"original_prediction": "    actual_list = mock_engine._get_all_dcm_files(dcm_dir)", "prediction_line": "    actual_list = mock_engine._get_all_dcm_files(dcm_dir)", "ground_truth": "    test_files = mock_engine._get_all_dcm_files(dcm_dir)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine: DicomImageRedactorEngine,", "prediction_line": "    mock_engine: DicomImageRedactorEngine,", "ground_truth": "    mock_engine: DicomImageRedactorEngine, phi_list: list, expected_return_list: list", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine: DicomImageRedactorEngine,", "prediction_line": "    mock_engine: DicomImageRedactorEngine,", "ground_truth": "    mock_engine: DicomImageRedactorEngine, dcm_file: Path, expected_result: bool", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_return_list = mock_engine._add_known_generic_phi(phi_list)", "prediction_line": "    test_return_list = mock_engine._add_known_generic_phi(phi_list)", "ground_truth": "    test_phi_list = mock_engine._add_known_generic_phi(phi_list)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        DicomImageRedactorEngine,", "prediction_line": "        DicomImageRedactorEngine,", "ground_truth": "        DicomImageRedactorEngine, \"_check_if_greyscale\", return_value=None", "line_class": "commited", "zero_context": true}
{"original_prediction": "        DicomImageRedactorEngine, \"_rescale_dcm\", return_value=None", "prediction_line": "        DicomImageRedactorEngine, \"_rescale_dcm\", return_value=None", "ground_truth": "        DicomImageRedactorEngine, \"_rescale_dcm_pixel_array\", return_value=None", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_result = mock_engine._check_if_greyscale(test_instance)", "prediction_line": "    test_result = mock_engine._check_if_greyscale(test_instance)", "ground_truth": "    test_is_greyscale = mock_engine._check_if_greyscale(test_instance)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        DicomImageRedactorEngine, \"_save_pixel_array\", return_value=None", "prediction_line": "        DicomImageRedactorEngine, \"_save_pixel_array\", return_value=None", "ground_truth": "        DicomImageRedactorEngine, \"_save_pixel_array_as_png\", return_value=None", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine: DicomImageRedactorEngine, dcm_file: Path, is_greyscale: bool", "prediction_line": "    mock_engine: DicomImageRedactorEngine, dcm_file: Path, is_greyscale: bool", "ground_truth": "    mock_engine: DicomImageRedactorEngine, dcm_file: Path, is_greyscale: bool", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_rescaled_image = mock_engine._rescale_dcm_pixel_array(", "prediction_line": "    test_rescaled_image = mock_engine._rescale_dcm_pixel_array(", "ground_truth": "    test_scaled_image = mock_engine._rescale_dcm_pixel_array(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_redacted_instance = mock_engine.redact(test_image, None, None)", "prediction_line": "    test_redacted_instance = mock_engine.redact(test_image, None, None)", "ground_truth": "    mock_engine.redact(test_image)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_rescaled_image = np.load(rescaled_image_numpy_path)", "prediction_line": "    test_rescaled_image = np.load(rescaled_image_numpy_path)", "ground_truth": "    test_image = mock_engine._rescale_dcm_pixel_array(test_instance, is_greyscale)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        test_png_path = mock_engine._save_pixel_array_as_png(", "prediction_line": "        test_png_path = mock_engine._save_pixel_array_as_png(", "ground_truth": "        _ = mock_engine._save_pixel_array_as_png(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_phi_list = mock_engine._make_phi_list(original_metadata)", "prediction_line": "    test_phi_list = mock_engine._make_phi_list(original_metadata)", "ground_truth": "    test_phi_str_list = mock_engine._make_phi_list(original_metadata, [], [])", "line_class": "commited", "zero_context": true}
{"original_prediction": "        mock_engine._convert_dcm_to_png(", "prediction_line": "        mock_engine._convert_dcm_to_png(", "ground_truth": "        _, _ = mock_engine._convert_dcm_to_png(Path(\"filename.dcm\"), tmpdirname)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine._redact_single_dicom_image(dcm_path, output_dir, overwrite)", "prediction_line": "    mock_engine._redact_single_dicom_image(dcm_path, output_dir, overwrite)", "ground_truth": "    mock_engine._redact_single_dicom_image(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_bg_color = mock_engine._get_bg_color(test_image, is_greyscale, invert_flag)", "prediction_line": "    test_bg_color = mock_engine._get_bg_color(test_image, is_greyscale, invert_flag)", "ground_truth": "    test_bg_color = mock_engine._get_bg_color(test_image, is_greyscale, invert_flag)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        mock_engine._redact_single_dicom_image(dcm_path, \"contrast\", 25, False, \"output\")", "prediction_line": "        mock_engine._redact_single_dicom_image(dcm_path, \"contrast\", 25, False, \"output\")", "ground_truth": "        mock_engine._redact_single_dicom_image(dcm_path, \"contrast\", 25, False, \".\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_bboxes_dict = mock_engine._get_bboxes_from_analyzer_results(analyzer_results)", "prediction_line": "    test_bboxes_dict = mock_engine._get_bboxes_from_analyzer_results(analyzer_results)", "ground_truth": "    test_bboxes_dict = mock_engine._get_bboxes_from_analyzer_results(analyzer_results)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_color = mock_engine._get_most_common_pixel_value(test_instance, fill)", "prediction_line": "    test_color = mock_engine._get_most_common_pixel_value(test_instance, fill)", "ground_truth": "    test_color = mock_engine._get_most_common_pixel_value(test_instance, fill)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine: DicomImageRedactorEngine,", "prediction_line": "    mock_engine: DicomImageRedactorEngine,", "ground_truth": "    mock_engine: DicomImageRedactorEngine, dcm_file: Path, expected_error_type: str", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine._redact_multiple_dicom_images(", "prediction_line": "    mock_engine._redact_multiple_dicom_images(", "ground_truth": "    mock_engine._redact_multiple_dicom_images(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _ = mock_engine._get_most_common_pixel_value(test_instance, \"contrast\")", "prediction_line": "        _ = mock_engine._get_most_common_pixel_value(test_instance, \"contrast\")", "ground_truth": "        _ = mock_engine._get_most_common_pixel_value(test_instance, \"contrast\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_bboxes_dict = mock_engine._format_bboxes(mock_intermediate_bbox, padding_width)", "prediction_line": "    test_bboxes_dict = mock_engine._format_bboxes(mock_intermediate_bbox, padding_width)", "ground_truth": "    test_bboxes_dict = mock_engine._format_bboxes([], padding_width)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        mock_engine._redact_multiple_dicom_images(dcm_path, \"contrast\", 25, False, \".\")", "prediction_line": "        mock_engine._redact_multiple_dicom_images(dcm_path, \"contrast\", 25, False, \".\")", "ground_truth": "        mock_engine._redact_multiple_dicom_images(dcm_path, \"contrast\", 25, False, \".\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine: DicomImageRedactorEngine,", "prediction_line": "    mock_engine: DicomImageRedactorEngine,", "ground_truth": "    mock_engine: DicomImageRedactorEngine, padding_width: int, expected_error_type: str", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_image = mock_engine._add_padding(test_image, is_greyscale, padding_width)", "prediction_line": "    test_image = mock_engine._add_padding(test_image, is_greyscale, padding_width)", "ground_truth": "    test_image_with_padding = mock_engine._add_padding(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _ = mock_engine._format_bboxes([], padding_width)", "prediction_line": "        _ = mock_engine._format_bboxes([], padding_width)", "ground_truth": "        _ = mock_engine._format_bboxes([], padding_width)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        DicomImageRedactorEngine,", "prediction_line": "        DicomImageRedactorEngine,", "ground_truth": "        DicomImageRedactorEngine, \"_convert_dcm_to_png\", return_value=[None, True]", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _ = mock_engine._add_padding(test_image, is_greyscale, padding_width)", "prediction_line": "        _ = mock_engine._add_padding(test_image, is_greyscale, padding_width)", "ground_truth": "        _, _ = mock_engine._add_padding(test_image, is_greyscale, padding_width)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine.redact_from_file(dcm_path, \"contrast\", 25, False, \".\")", "prediction_line": "    mock_engine.redact_from_file(dcm_path, \"contrast\", 25, False, \".\")", "ground_truth": "    mock_engine.redact_from_file(dcm_path, \"output\", 25, \"contrast\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    test_instance = mock_engine._set_bbox_color(test_instance, fill)", "prediction_line": "    test_instance = mock_engine._set_bbox_color(test_instance, fill)", "ground_truth": "    test_box_color = mock_engine._set_bbox_color(test_instance, fill)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_engine: DicomImageRedactorEngine,", "prediction_line": "    mock_engine: DicomImageRedactorEngine,", "ground_truth": "    mock_engine: DicomImageRedactorEngine, src_path: Path, expected_num_of_files: int", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _, _ = mock_engine._copy_files_for_processing(src_path, tmpdirname)", "prediction_line": "        _, _ = mock_engine._copy_files_for_processing(src_path, tmpdirname)", "ground_truth": "        test_dst_path = mock_engine._copy_files_for_processing(src_path, tmpdirname)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        mock_engine.redact_from_file(input_path, output_path, 25, \"contrast\")", "prediction_line": "        mock_engine.redact_from_file(input_path, output_path, 25, \"contrast\")", "ground_truth": "        mock_engine.redact_from_file(input_path, output_path, 25, \"contrast\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _ = mock_engine._set_bbox_color(test_instance, fill)", "prediction_line": "        _ = mock_engine._set_bbox_color(test_instance, fill)", "ground_truth": "        _ = mock_engine._set_bbox_color(test_instance, fill)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    start=20,", "prediction_line": "                    start=20,", "ground_truth": "                    start=25,", "line_class": "common", "zero_context": true}
{"original_prediction": "        test_image_numpy = np.load(f)", "prediction_line": "        test_image_numpy = np.load(f)", "ground_truth": "        loaded_numpy_array = np.load(f)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    start_x=10,", "prediction_line": "                    start_x=10,", "ground_truth": "                    start=0,", "line_class": "common", "zero_context": true}
{"original_prediction": "                    start=0,", "prediction_line": "                    start=0,", "ground_truth": "                    start=10,", "line_class": "common", "zero_context": true}
{"original_prediction": "        return_value=MockInstance(),", "prediction_line": "        return_value=MockInstance(),", "ground_truth": "        return_value=MockInstance(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "                {\n                    \"start\": 0,", "prediction_line": "                {", "ground_truth": "                ImageRecognizerResult(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "):\n    \"\"\"Test happy path for DicomImageRedactorEngine._process_names", "prediction_line": "):", "ground_truth": "):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# ------------------------------------------------------", "prediction_line": "# ------------------------------------------------------", "ground_truth": "# ------------------------------------------------------", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    mock_convert_dcm_to_png = mocker.patch(", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        expected_return_list (list): List of expected output.", "prediction_line": "        expected_return_list (list): List of expected output.", "ground_truth": "        expected_return_list (list): List of expected output.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        (TEST_DICOM_DIR_1, [TEST_DICOM_DIR_1]),", "prediction_line": "        (TEST_DICOM_DIR_1, [TEST_DICOM_DIR_1]),", "ground_truth": "        (", "line_class": "random", "zero_context": true}
{"original_prediction": "        (Path(TEST_DICOM_PARENT_DIR, \"0_ORIGINAL.dcm\"), ValueError),", "prediction_line": "        (Path(TEST_DICOM_PARENT_DIR, \"0_ORIGINAL.dcm\"), ValueError),", "ground_truth": "        (Path(TEST_DICOM_PARENT_DIR, \"RGB_ORIGINAL.dcm\"), \"TypeError\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"[U]\",", "prediction_line": "                \"[U]\",", "ground_truth": "                \"[U]\",", "line_class": "random", "zero_context": true}
{"original_prediction": "# ------------------------------------------------------", "prediction_line": "# ------------------------------------------------------", "ground_truth": "    if is_greyscale is True:", "line_class": "random", "zero_context": true}
{"original_prediction": "        return_value=mock_dcm_files,", "prediction_line": "        return_value=mock_dcm_files,", "ground_truth": "        return_value=mock_dcm_files,", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.supported_entities = supported_entities", "prediction_line": "        self.supported_entities = supported_entities", "ground_truth": "        super().__init__(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            start=res[\"start\"],", "prediction_line": "            start=res[\"start\"],", "ground_truth": "            start=res[\"start\"],", "line_class": "common", "zero_context": true}
{"original_prediction": "       \"\"\"\n        Convert transformers result to Presidio RecognizerResult.", "prediction_line": "       \"\"\"", "ground_truth": "        entity_type = self.PRESIDIO_EQUIVALENCES.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "    results = analyzer.analyze(", "prediction_line": "    results = analyzer.analyze(", "ground_truth": "    results = analyzer.analyze(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if res[\"entity_group\"] == self.PRESIDIO_EQUIVALENCES[entity]:", "prediction_line": "                if res[\"entity_group\"] == self.PRESIDIO_EQUIVALENCES[entity]:", "ground_truth": "                if not self.__check_label(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        TransformersRecognizer(", "prediction_line": "        TransformersRecognizer(", "ground_truth": "        TransformersRecognizer()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                results.append(", "prediction_line": "                results.append(", "ground_truth": "                explanation = self.build_transformers_explanation(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                results.append(", "prediction_line": "                results.append(", "ground_truth": "                transformers_result = self._convert_to_recognizer_result(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            original_score=original_score,", "prediction_line": "            original_score=original_score,", "ground_truth": "            recognizer=self.__class__.__name__,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    analyzer = AnalyzerEngine(registry=registry)", "prediction_line": "    analyzer = AnalyzerEngine(registry=registry)", "ground_truth": "    analyzer = AnalyzerEngine(registry=registry)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self.supported_entities", "prediction_line": "        return self.supported_entities", "ground_truth": "        return self.supported_entities", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ) -> AnalysisExplanation:", "prediction_line": "    ) -> AnalysisExplanation:", "ground_truth": "    ) -> AnalysisExplanation:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts", "prediction_line": "        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts", "ground_truth": "        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts = None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            entities = self.supported_entities", "prediction_line": "            entities = self.supported_entities", "ground_truth": "            entities = self.supported_entities", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for entity in entities:", "prediction_line": "        for entity in entities:", "ground_truth": "        for entity in entities:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       transformers_result = RecognizerResult(", "prediction_line": "       transformers_result = RecognizerResult(", "ground_truth": "        transformers_results = RecognizerResult(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    registry = RecognizerRegistry()", "prediction_line": "    registry = RecognizerRegistry()", "ground_truth": "    registry = RecognizerRegistry()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return AnalysisExplanation(", "prediction_line": "        return AnalysisExplanation(", "ground_truth": "        explanation = AnalysisExplanation(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       self.supported_entities = (", "prediction_line": "       self.supported_entities = (", "ground_truth": "        supported_entities = supported_entities if supported_entities else self.ENTITIES", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ) -> List[RecognizerResult]:", "prediction_line": "    ) -> List[RecognizerResult]:", "ground_truth": "    ) -> List[RecognizerResult]:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            supported_entities=supported_entities,", "prediction_line": "            supported_entities=supported_entities,", "ground_truth": "            supported_entities=supported_entities, name=\"transformers Analytics\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for ner_result in ner_results:", "prediction_line": "            for ner_result in ner_results:", "ground_truth": "            if entity not in self.supported_entities:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        supported_languages=[\"en\"],", "prediction_line": "        supported_languages=[\"en\"],", "ground_truth": "        supported_entities: Optional[List[str]] = None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    )\n\n    _MODEL_NAME_TO_MODEL_CLASS = {", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        print(result.analysis_explanation)", "prediction_line": "        print(result.analysis_explanation)", "ground_truth": "        print(result.analysis_explanation)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from presidio_analyzer.nlp_engine import NlpEngine", "prediction_line": "from presidio_analyzer.nlp_engine import NlpEngine", "ground_truth": "from presidio_analyzer.nlp_engine import NlpArtifacts", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Build an explanation for the transformers results.", "prediction_line": "        Build an explanation for the transformers results.", "ground_truth": "        Create explanation for why this result was detected.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            else AutoModelForTokenClassification.from_pretrained(model_path)", "prediction_line": "            else AutoModelForTokenClassification.from_pretrained(model_path)", "ground_truth": "            else pipeline(", "line_class": "random", "zero_context": true}
{"original_prediction": "                model=model_path,", "prediction_line": "                model=model_path,", "ground_truth": "                model=AutoModelForTokenClassification.from_pretrained(model_path),", "line_class": "random", "zero_context": true}
{"original_prediction": "        )\n\n        return transformers_results", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"ORG\": \"ORGANIZATION\",", "prediction_line": "        \"ORG\": \"ORGANIZATION\",", "ground_truth": "        \"ORG\": \"ORGANIZATION\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        tokenizer: Optional[AutoTokenizer] = None,", "prediction_line": "        tokenizer: Optional[AutoTokenizer] = None,", "ground_truth": "        model_path: Optional[str] = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "                    start=0,", "prediction_line": "                    start=0,", "ground_truth": "                    start=10,", "line_class": "common", "zero_context": true}
{"original_prediction": "                    start=20,", "prediction_line": "                    start=20,", "ground_truth": "                    start=25,", "line_class": "common", "zero_context": true}
{"original_prediction": "                    start_x=123,", "prediction_line": "                    start_x=123,", "ground_truth": "                    start=0,", "line_class": "common", "zero_context": true}
{"original_prediction": "    mock_bbox_processor: BboxProcessor,", "prediction_line": "    mock_bbox_processor: BboxProcessor,", "ground_truth": "    mock_bbox_processor: BboxProcessor,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        mock_bbox_processor.remove_bbox_padding(", "prediction_line": "        mock_bbox_processor.remove_bbox_padding(", "ground_truth": "        _ = mock_bbox_processor.remove_bbox_padding([], padding_width)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_results, test_match_found = mock_bbox_processor.match_with_source(", "prediction_line": "    test_results, test_match_found = mock_bbox_processor.match_with_source(", "ground_truth": "    test_all_pos, test_match_found = mock_bbox_processor.match_with_source(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_bboxes = mock_bbox_processor.get_bboxes_from_analyzer_results(", "prediction_line": "    test_bboxes = mock_bbox_processor.get_bboxes_from_analyzer_results(", "ground_truth": "    test_bboxes = mock_bbox_processor.get_bboxes_from_analyzer_results(analyzer_results)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_bboxes = mock_bbox_processor.remove_bbox_padding(", "prediction_line": "    test_bboxes = mock_bbox_processor.remove_bbox_padding(", "ground_truth": "    test_bboxes_dict = mock_bbox_processor.remove_bbox_padding(mock_intermediate_bbox, padding_width)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    actual_results = mock_bbox_processor.get_bboxes_from_ocr_results(", "prediction_line": "    actual_results = mock_bbox_processor.get_bboxes_from_ocr_results(", "ground_truth": "    test_bboxes = mock_bbox_processor.get_bboxes_from_ocr_results(ocr_results_raw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    mock_bbox_processor: BboxProcessor,", "prediction_line": "    mock_bbox_processor: BboxProcessor,", "ground_truth": "    mock_bbox_processor: BboxProcessor, padding_width: int, expected_error_type: str", "line_class": "infile", "zero_context": true}
{"original_prediction": "                ImageRecognizerResult(", "prediction_line": "                ImageRecognizerResult(", "ground_truth": "                ImageRecognizerResult(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "# ------------------------------------------------------", "prediction_line": "# ------------------------------------------------------", "ground_truth": "# ------------------------------------------------------", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        mock_bbox_processor: BboxProcessor instance", "prediction_line": "        mock_bbox_processor: BboxProcessor instance", "ground_truth": "        mock_bbox_processor (BboxProcessor): Instantiated engine.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        expected_bboxes (list): Formatted results.", "prediction_line": "        expected_bboxes (list): Formatted results.", "ground_truth": "        expected_bboxes (list): Expected output bounding box list.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def bbox_processor() -> BboxProcessor:", "prediction_line": "def bbox_processor() -> BboxProcessor:", "ground_truth": "def mock_bbox_processor():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   for source_label in source_labels:", "prediction_line": "   for source_label in source_labels:", "ground_truth": "    # Act", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    \"left\": 25,", "prediction_line": "                    \"left\": 25,", "ground_truth": "                    \"left\": 25,", "line_class": "random", "zero_context": true}
{"original_prediction": "                {\n                    \"entity_type\": \"TYPE_3\",", "prediction_line": "                {", "ground_truth": "                {", "line_class": "random", "zero_context": true}
{"original_prediction": "                    \"left\": 25,", "prediction_line": "                    \"left\": 25,", "ground_truth": "                    \"entity_type\": \"TYPE_1\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                    \"height\": 37,", "prediction_line": "                    \"height\": 37,", "ground_truth": "                    \"height\": 37,", "line_class": "random", "zero_context": true}
{"original_prediction": "            0.5,", "prediction_line": "            0.5,", "ground_truth": "            50,", "line_class": "random", "zero_context": true}
{"original_prediction": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "prediction_line": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "ground_truth": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    string += write_rpc_notification(", "prediction_line": "    string += write_rpc_notification(", "ground_truth": "    string += write_rpc_notification(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string)", "prediction_line": "    errcode, results = run_request(string)", "ground_truth": "    errcode, results = run_request(string)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "prediction_line": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "ground_truth": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(root)})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string)", "prediction_line": "    errcode, results = run_request(string)", "ground_truth": "    root = path_to_uri(str((test_dir / \"diag\" / \"test_external.f90\").resolve()))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    string += write_rpc_notification(", "prediction_line": "    string += write_rpc_notification(", "ground_truth": "    errcode, results = run_request(string, [f\"--config {file_path}\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    setup_test_db,", "prediction_line": "    setup_test_db,", "ground_truth": "    path_to_uri,", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    errcode, results = run_request(string)", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    \"location\": {", "prediction_line": "                    \"location\": {", "ground_truth": "                    \"location\": {", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"message\": \"Variable 'a' declared in PUBLIC scope\",", "prediction_line": "            \"message\": \"Variable 'a' declared in PUBLIC scope\",", "ground_truth": "            \"message\": \"Visibility statement without enclosing scope\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"end\": {\"line\": 4, \"character\": 10},", "prediction_line": "                \"end\": {\"line\": 4, \"character\": 10},", "ground_truth": "                \"end\": {\"line\": 4, \"character\": 13},", "line_class": "random", "zero_context": true}
{"original_prediction": "    file_path = str(test_dir / \"diag\" / \"test_module_procedure.f90\")", "prediction_line": "    file_path = str(test_dir / \"diag\" / \"test_module_procedure.f90\")", "ground_truth": "    file_path = str(test_dir / \"subdir\" / \"test_submod.F90\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"textDocument/didOpen\",", "prediction_line": "        \"textDocument/didOpen\",", "ground_truth": "        \"textDocument/didOpen\", {\"textDocument\": {\"uri\": file_path}}", "line_class": "random", "zero_context": true}
{"original_prediction": "        check_return(results[i + 1], exp_results[i])", "prediction_line": "        check_return(results[i + 1], exp_results[i])", "ground_truth": "        check_return(results[i + 1], exp_results[i])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 12)", "prediction_line": "    string += comp_request(file_path, 10, 12)", "ground_truth": "    string += comp_request(file_path, 21, 7)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "prediction_line": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "ground_truth": "    string += comp_request(file_path, 23, 7)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 25, 7)", "prediction_line": "    string += comp_request(file_path, 25, 7)", "ground_truth": "    string += comp_request(file_path, 25, 7)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 27, 7)", "prediction_line": "    string += comp_request(file_path, 27, 7)", "ground_truth": "    string += comp_request(file_path, 30, 7)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 11)", "prediction_line": "    string += comp_request(file_path, 10, 11)", "ground_truth": "    string += comp_request(file_path, 14, 10)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 12, 6)", "prediction_line": "    string += comp_request(file_path, 12, 6)", "ground_truth": "    string += comp_request(file_path, 12, 6)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    result = run_request(string)", "prediction_line": "    result = run_request(string)", "ground_truth": "    string += comp_request(file_path, 13, 6)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 14, 6)", "prediction_line": "    string += comp_request(file_path, 14, 6)", "ground_truth": "    string += comp_request(file_path, 17, 24)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 18, 24)", "prediction_line": "    string += comp_request(file_path, 18, 24)", "ground_truth": "    string += comp_request(file_path, 18, 23)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 20, 10)", "prediction_line": "    string += comp_request(file_path, 20, 10)", "ground_truth": "    string += comp_request(file_path, 20, 7)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 21, 7)", "prediction_line": "    string += comp_request(file_path, 21, 7)", "ground_truth": "    string += comp_request(file_path, 21, 20)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 22, 20)", "prediction_line": "    string += comp_request(file_path, 22, 20)", "ground_truth": "    string += comp_request(file_path, 21, 42)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 22, 10)", "prediction_line": "    string += comp_request(file_path, 22, 10)", "ground_truth": "    string += comp_request(file_path, 23, 26)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 12)", "prediction_line": "    string += comp_request(file_path, 10, 12)", "ground_truth": "    string += comp_request(file_path, 2, 2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 3, 2)", "prediction_line": "    string += comp_request(file_path, 3, 2)", "ground_truth": "    string += comp_request(file_path, 5, 4)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 10)", "prediction_line": "    string += comp_request(file_path, 10, 10)", "ground_truth": "    string += comp_request(file_path, 8, 6)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 12)", "prediction_line": "    string += comp_request(file_path, 10, 12)", "ground_truth": "    string += comp_request(file_path, 10, 11)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 10)", "prediction_line": "    string += comp_request(file_path, 10, 10)", "ground_truth": "    string += comp_request(file_path, 15, 8)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "prediction_line": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "ground_truth": "    string += comp_request(file_path, 15, 21)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 10)", "prediction_line": "    string += comp_request(file_path, 10, 10)", "ground_truth": "    string += comp_request(file_path, 30, 12)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 31, 12)", "prediction_line": "    string += comp_request(file_path, 31, 12)", "ground_truth": "    string += comp_request(file_path, 31, 8)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 32, 12)", "prediction_line": "    string += comp_request(file_path, 32, 12)", "ground_truth": "    string += comp_request(file_path, 31, 23)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 32, 12)", "prediction_line": "    string += comp_request(file_path, 32, 12)", "ground_truth": "    string += comp_request(file_path, 35, 12)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 36, 12)", "prediction_line": "    string += comp_request(file_path, 36, 12)", "ground_truth": "    string += comp_request(file_path, 36, 48)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 11)", "prediction_line": "    string += comp_request(file_path, 10, 11)", "ground_truth": "    string += comp_request(file_path, 13, 5)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "prediction_line": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "ground_truth": "    string += comp_request(file_path, 14, 5)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 12)", "prediction_line": "    string += comp_request(file_path, 10, 12)", "ground_truth": "    string += comp_request(file_path, 10, 2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 2)", "prediction_line": "    string += comp_request(file_path, 10, 2)", "ground_truth": "    string += comp_request(file_path, 3, 2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 11)", "prediction_line": "    string += comp_request(file_path, 10, 11)", "ground_truth": "    string += comp_request(file_path, 8, 10)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 12)", "prediction_line": "    string += comp_request(file_path, 10, 12)", "ground_truth": "    string += comp_request(file_path, 7, 12)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 10)", "prediction_line": "    string += comp_request(file_path, 10, 10)", "ground_truth": "    string += comp_request(file_path, 15, 20)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "prediction_line": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "ground_truth": "    string += comp_request(file_path, 28, 15)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 12)", "prediction_line": "    string += comp_request(file_path, 10, 12)", "ground_truth": "    string += comp_request(file_path, 10, 22)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "prediction_line": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "ground_truth": "    string += comp_request(file_path, 14, 27)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 10, 10)", "prediction_line": "    string += comp_request(file_path, 10, 10)", "ground_truth": "    string += comp_request(file_path, 12, 16)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "prediction_line": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "ground_truth": "    string += comp_request(file_path, 12, 24)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "prediction_line": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "ground_truth": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 24, 26)", "prediction_line": "    string += comp_request(file_path, 24, 26)", "ground_truth": "    errcode, results = run_request(string, [\"--use_signature_help\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return run_request(", "prediction_line": "    return run_request(", "ground_truth": "    return write_rpc_request(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    string += comp_request(file_path, 13, 6)", "prediction_line": "    string += comp_request(file_path, 13, 6)", "ground_truth": "    errcode, results = run_request(string)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_comp9():", "prediction_line": "def test_comp9():", "ground_truth": "def test_comp9():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_get_block_by_number(client):", "prediction_line": "def test_get_block_by_number(client):", "ground_truth": "def check_return(result_array, checks):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "prediction_line": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "ground_truth": "    \"\"\"Test that PUBLIC, PRIVATE scopes are enforced in autocomplete results.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        [1, \"public_var\", \"REAL(8)\"],", "prediction_line": "        [1, \"public_var\", \"REAL(8)\"],", "ground_truth": "        [1, \"some_var\", \"INTEGER\"],", "line_class": "random", "zero_context": true}
{"original_prediction": "    exp_results = (", "prediction_line": "    exp_results = (", "ground_truth": "    exp_results = (", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"DOUBLE PRECISION FUNCTION myfun(n, xval)\",", "prediction_line": "            \"DOUBLE PRECISION FUNCTION myfun(n, xval)\",", "ground_truth": "            \"DOUBLE PRECISION FUNCTION myfun(n, xval)\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    file_path = test_dir / \"subdir\" / \"test_generic.f90\"", "prediction_line": "    file_path = test_dir / \"subdir\" / \"test_generic.f90\"", "ground_truth": "    file_path = test_dir / \"subdir\" / \"test_vis.f90\"", "line_class": "random", "zero_context": true}
{"original_prediction": "    for i in range(len(exp_results)):", "prediction_line": "    for i in range(len(exp_results)):", "ground_truth": "    for i in range(len(exp_results)):", "line_class": "random", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 1, 11)", "prediction_line": "    string += hover_req(file_path, 1, 11)", "ground_truth": "    string += hover_req(file_path, 1, 45)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 8, 38)", "prediction_line": "    string += hover_req(file_path, 8, 38)", "ground_truth": "    string += hover_req(file_path, 8, 38)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 2, 45)", "prediction_line": "    string += hover_req(file_path, 2, 45)", "ground_truth": "    string += hover_req(file_path, 2, 99)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    validate_hover(results, ref_results)", "prediction_line": "    validate_hover(results, ref_results)", "ground_truth": "    validate_hover(results, ref_results)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 9, 38)", "prediction_line": "    string += hover_req(file_path, 9, 38)", "ground_truth": "    string += hover_req(file_path, 8, 50)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 1, 11)", "prediction_line": "    string += hover_req(file_path, 1, 11)", "ground_truth": "    string += hover_req(file_path, 9, 40)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 9, 38)", "prediction_line": "    string += hover_req(file_path, 9, 38)", "ground_truth": "    string += hover_req(file_path, 9, 37)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 10, 10)", "prediction_line": "    string += hover_req(file_path, 10, 10)", "ground_truth": "    string += hover_req(file_path, 7, 30)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 1, 11)", "prediction_line": "    string += hover_req(file_path, 1, 11)", "ground_truth": "    string += hover_req(file_path, 29, 24)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string, fortls_args=[\"--sort_keywords\"])", "prediction_line": "    errcode, results = run_request(string, fortls_args=[\"--sort_keywords\"])", "ground_truth": "    string += hover_req(file_path, 34, 24)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 9, 50)", "prediction_line": "    string += hover_req(file_path, 9, 50)", "ground_truth": "    string += hover_req(file_path, 9, 48)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 10, 10)", "prediction_line": "    string += hover_req(file_path, 10, 10)", "ground_truth": "    string += hover_req(file_path, 2, 28)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 10, 37)", "prediction_line": "    string += hover_req(file_path, 10, 37)", "ground_truth": "    string += hover_req(file_path, 10, 37)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 1, 24)", "prediction_line": "    string += hover_req(file_path, 1, 24)", "ground_truth": "    string += hover_req(file_path, 19, 14)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 10, 10)", "prediction_line": "    string += hover_req(file_path, 10, 10)", "ground_truth": "    string += hover_req(file_path, 3, 28)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 10, 48)", "prediction_line": "    string += hover_req(file_path, 10, 48)", "ground_truth": "    string += hover_req(file_path, 10, 48)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 4, 28)", "prediction_line": "    string += hover_req(file_path, 4, 28)", "ground_truth": "    string += hover_req(file_path, 4, 28)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 3, 28)", "prediction_line": "    string += hover_req(file_path, 3, 28)", "ground_truth": "    string += hover_req(file_path, 1, 26)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 5, 28)", "prediction_line": "    string += hover_req(file_path, 5, 28)", "ground_truth": "    string += hover_req(file_path, 4, 41)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 1, 26)", "prediction_line": "    string += hover_req(file_path, 1, 26)", "ground_truth": "    string += hover_req(file_path, 1, 11)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string, fortls_args=[\"--sort_keywords\"])", "prediction_line": "    errcode, results = run_request(string, fortls_args=[\"--sort_keywords\"])", "ground_truth": "    string += hover_req(file_path, 7, 19)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 10, 19)", "prediction_line": "    string += hover_req(file_path, 10, 19)", "ground_truth": "    string += hover_req(file_path, 12, 12)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 13, 12)", "prediction_line": "    string += hover_req(file_path, 13, 12)", "ground_truth": "    string += hover_req(file_path, 18, 19)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 23, 19)", "prediction_line": "    string += hover_req(file_path, 23, 19)", "ground_truth": "    string += hover_req(file_path, 23, 34)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 28, 19)", "prediction_line": "    string += hover_req(file_path, 28, 19)", "ground_truth": "    string += hover_req(file_path, 28, 11)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 5, 28)", "prediction_line": "    string += hover_req(file_path, 5, 28)", "ground_truth": "    string += hover_req(file_path, 6, 28)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 33, 11)", "prediction_line": "    string += hover_req(file_path, 33, 11)", "ground_truth": "    string += hover_req(file_path, 34, 21)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 39, 11)", "prediction_line": "    string += hover_req(file_path, 39, 11)", "ground_truth": "    string += hover_req(file_path, 46, 11)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 50, 11)", "prediction_line": "    string += hover_req(file_path, 50, 11)", "ground_truth": "    string += hover_req(file_path, 51, 11)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 56, 11)", "prediction_line": "    string += hover_req(file_path, 56, 11)", "ground_truth": "    string += hover_req(file_path, 55, 11)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 7, 28)", "prediction_line": "    string += hover_req(file_path, 7, 28)", "ground_truth": "    string += hover_req(file_path, 7, 47)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 8, 28)", "prediction_line": "    string += hover_req(file_path, 8, 28)", "ground_truth": "    string += hover_req(file_path, 7, 38)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += hover_req(file_path, 8, 38)", "prediction_line": "    string += hover_req(file_path, 8, 38)", "ground_truth": "    string += hover_req(file_path, 7, 55)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "prediction_line": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "ground_truth": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string, fortls_args=[\"--sort_keywords\"])", "prediction_line": "    errcode, results = run_request(string, fortls_args=[\"--sort_keywords\"])", "ground_truth": "    errcode, results = run_request(string, fortls_args=[\"--sort_keywords\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"FUNCTION fun2(arg) RESULT(fun2)", "prediction_line": "        \"\"\"FUNCTION fun2(arg) RESULT(fun2)", "ground_truth": "        \"\"\"FUNCTION fun2(arg) RESULT(fun2)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_hover_parameter_multiline_missing_value():", "prediction_line": "def test_hover_parameter_multiline_missing_value():", "ground_truth": "def test_hover_literal_real():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    write_rpc_response,", "prediction_line": "    write_rpc_response,", "ground_truth": ")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_hover_parameter_bool_sf():", "prediction_line": "def test_hover_parameter_bool_sf():", "ground_truth": "def test_hover_literal_bool():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    file_path = test_dir / \"hover\" / \"parameters.f90\"", "prediction_line": "    file_path = test_dir / \"hover\" / \"parameters.f90\"", "ground_truth": "    file_path = test_dir / \"hover\" / \"parameters.f90\"", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert errcode == 0", "prediction_line": "    assert errcode == 0", "ground_truth": "    assert errcode == 0", "line_class": "random", "zero_context": true}
{"original_prediction": "        {\n            \"textDocument\": {\"uri\": f\"file://{file_path}\"},", "prediction_line": "        {", "ground_truth": "        {", "line_class": "random", "zero_context": true}
{"original_prediction": "    ref_results = [\"INTEGER, PARAMETER :: var2 = 23\"]", "prediction_line": "    ref_results = [\"INTEGER, PARAMETER :: var2 = 23\"]", "ground_truth": "    ref_results = [\"INTEGER, PARAMETER :: var3 = var*var2\"]", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"Debug options\", description=hide_opt(\"Debug options\")", "prediction_line": "        \"Debug options\", description=hide_opt(\"Debug options\")", "ground_truth": "        hide_opt(\"DEBUG\"), hide_opt(\"Options for debugging language server\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Print parser debug information\"),", "prediction_line": "        help=hide_opt(\"Print parser debug information\"),", "ground_truth": "        help=hide_opt(\"Test source code parser on specified file\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Test diagnostics on specified file\"),", "prediction_line": "        help=hide_opt(\"Test diagnostics on specified file\"),", "ground_truth": "        help=hide_opt(\"Test diagnostic notifications for specified file\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Test document symbol notifications for specified file\"),", "prediction_line": "        help=hide_opt(\"Test document symbol notifications for specified file\"),", "ground_truth": "        help=hide_opt(\"Test symbol request for specified file\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Test workspace symbol request for specified query\"),", "prediction_line": "        help=hide_opt(\"Test workspace symbol request for specified query\"),", "ground_truth": "        help=hide_opt(\"Test workspace/symbol request\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Test completion request for specified file\"),", "prediction_line": "        help=hide_opt(\"Test completion request for specified file\"),", "ground_truth": "        help=hide_opt(\"Test completion request for specified file and position\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Test signature help request for specified file and position\"),", "prediction_line": "        help=hide_opt(\"Test signature help request for specified file and position\"),", "ground_truth": "        help=hide_opt(\"Test signatureHelp request for specified file and position\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Test gotoDefinition request for specified file and position\"),", "prediction_line": "        help=hide_opt(\"Test gotoDefinition request for specified file and position\"),", "ground_truth": "        help=hide_opt(\"Test definition request for specified file and position\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Test hover request for specified file and position\"),", "prediction_line": "        help=hide_opt(\"Test hover request for specified file and position\"),", "ground_truth": "        help=hide_opt(\"Test hover request for specified file and position\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Test implementation request for specified file and position\"),", "prediction_line": "        help=hide_opt(\"Test implementation request for specified file and position\"),", "ground_truth": "        help=hide_opt(\"Test implementation request for specified file and position\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Test references request for specified file and position\"),", "prediction_line": "        help=hide_opt(\"Test references request for specified file and position\"),", "ground_truth": "        help=hide_opt(\"Test references request for specified file and position\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Test rename request for specified file and position\"),", "prediction_line": "        help=hide_opt(\"Test rename request for specified file and position\"),", "ground_truth": "        help=hide_opt(\"Test rename request for specified file and position\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Test code actions request for specified file and position\"),", "prediction_line": "        help=hide_opt(\"Test code actions request for specified file and position\"),", "ground_truth": "        help=hide_opt(\"Test codeAction request for specified file and position\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Path to file for debug request\"),", "prediction_line": "        help=hide_opt(\"Path to file for debug request\"),", "ground_truth": "        help=hide_opt(\"File path for language server tests\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Root path for language server tests\"),", "prediction_line": "        help=hide_opt(\"Root path for language server tests\"),", "ground_truth": "        help=hide_opt(\"Root path for language server tests\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        action=SetAction,", "prediction_line": "        action=SetAction,", "ground_truth": "        action=SetAction,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Line number for language server tests\"),", "prediction_line": "        help=hide_opt(\"Line number for language server tests\"),", "ground_truth": "        help=hide_opt(\"Line position for language server tests (1-indexed)\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Character position for language server tests (1-indexed)\"),", "prediction_line": "        help=hide_opt(\"Character position for language server tests (1-indexed)\"),", "ground_truth": "        help=hide_opt(\"Character position for language server tests (1-indexed)\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        help=hide_opt(\"Print full result for language server tests\"),", "prediction_line": "        help=hide_opt(\"Print full result for language server tests\"),", "ground_truth": "        help=hide_opt(\"Print full result object instead of condensed version\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "from the user\n    # To see them, use the --debug_help argument", "prediction_line": "from the user", "ground_truth": "    _debug_commandline_args(parser)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    Parameters\n    ----------", "prediction_line": "    Parameters", "ground_truth": "    Parameters", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    group.add_argument(", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    ----------", "prediction_line": "    ----------", "ground_truth": "    ----------", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    group.add_argument(", "prediction_line": "    )", "ground_truth": "        # TODO: make a set?", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from typing import Any, Dict, List, Optional, Tuple, Union", "prediction_line": "from typing import Any, Dict, List, Optional, Tuple, Union", "ground_truth": "from ._version import __version__", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        action=\"store_true\",", "prediction_line": "        action=\"store_true\",", "ground_truth": "        action=\"store_true\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        ),\n    )", "prediction_line": "        ),", "ground_truth": "        ),", "line_class": "random", "zero_context": true}
{"original_prediction": "    group.add_argument(", "prediction_line": "    group.add_argument(", "ground_truth": "    group.add_argument(", "line_class": "random", "zero_context": true}
{"original_prediction": "            \" %(default)s)\"", "prediction_line": "            \" %(default)s)\"", "ground_truth": "            \" %(default)s)\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        validate_def(results[i + 1], ref_res[i])", "prediction_line": "        validate_def(results[i + 1], ref_res[i])", "ground_truth": "        validate_def(results[i + 1], ref_res[i])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 4, 16)", "prediction_line": "    string += def_request(file_path, 4, 16)", "ground_truth": "    string += def_request(file_path, 11, 3)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 11, 3)", "prediction_line": "    string += def_request(file_path, 11, 3)", "ground_truth": "    string += def_request(file_path, 4, 3)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 10, 10)", "prediction_line": "    string += def_request(file_path, 10, 10)", "ground_truth": "    string += def_request(file_path, 13, 7)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 14, 7)", "prediction_line": "    string += def_request(file_path, 14, 7)", "ground_truth": "    string += def_request(file_path, 14, 7)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 11, 3)", "prediction_line": "    string += def_request(file_path, 11, 3)", "ground_truth": "    string += def_request(file_path, 13, 14)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 15, 10)", "prediction_line": "    string += def_request(file_path, 15, 10)", "ground_truth": "    string += def_request(file_path, 21, 8)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 11, 10)", "prediction_line": "    string += def_request(file_path, 11, 10)", "ground_truth": "    string += def_request(file_path, 14, 6)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 25, 10)", "prediction_line": "    string += def_request(file_path, 25, 10)", "ground_truth": "    string += def_request(file_path, 22, 21)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 15, 6)", "prediction_line": "    string += def_request(file_path, 15, 6)", "ground_truth": "    string += def_request(file_path, 15, 6)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 23, 21)", "prediction_line": "    string += def_request(file_path, 23, 21)", "ground_truth": "    string += def_request(file_path, 22, 43)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 10, 10)", "prediction_line": "    string += def_request(file_path, 10, 10)", "ground_truth": "    string += def_request(file_path, 4, 18)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 22, 50)", "prediction_line": "    string += def_request(file_path, 22, 50)", "ground_truth": "    string += def_request(file_path, 24, 27)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 10, 17)", "prediction_line": "    string += def_request(file_path, 10, 17)", "ground_truth": "    string += def_request(file_path, 31, 13)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 32, 13)", "prediction_line": "    string += def_request(file_path, 32, 13)", "ground_truth": "    string += def_request(file_path, 36, 13)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string += def_request(file_path, 1, 1)", "prediction_line": "    string += def_request(file_path, 1, 1)", "ground_truth": "    string += def_request(file_path, 3, 16)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "prediction_line": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "ground_truth": "    string = write_rpc_request(1, \"initialize\", {\"rootPath\": str(test_dir)})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    errcode, results = run_request(string)", "prediction_line": "    errcode, results = run_request(string)", "ground_truth": "    errcode, results = run_request(string)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # If definition is given, result is a list of dicts", "prediction_line": "    # If definition is given, result is a list of dicts", "ground_truth": "    assert result_array[\"uri\"] == path_to_uri(checks[2])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return write_rpc_request(", "prediction_line": "    return write_rpc_request(", "ground_truth": "    return write_rpc_request(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_def_rename_only_variable_nested_2():", "prediction_line": "def test_def_rename_only_variable_nested_2():", "ground_truth": "def test_def_function_implicit_result_variable():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_def_type_in_submod_subroutine():", "prediction_line": "def test_def_type_in_submod_subroutine():", "ground_truth": "def test_def_type_in_submod_procedure():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"Test that going to definition of a type bound procedure works.\"\"\"", "prediction_line": "    \"\"\"Test that going to definition of a type bound procedure works.\"\"\"", "ground_truth": "    \"\"\"Test that going to definition of type bound procedure works.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    assert errcode == 0", "prediction_line": "    assert errcode == 0", "ground_truth": "    assert errcode == 0", "line_class": "random", "zero_context": true}
{"original_prediction": "    for i in range(len(ref_res)):", "prediction_line": "    for i in range(len(ref_res)):", "ground_truth": "    for i in range(len(ref_res)):", "line_class": "random", "zero_context": true}
{"original_prediction": "        files_to_backup = chunks[index]", "prediction_line": "        files_to_backup = chunks[index]", "ground_truth": "        one_chunk_files = chunks[index]", "line_class": "common", "zero_context": true}
{"original_prediction": "            metadata.update(extra_metadata)", "prediction_line": "            metadata.update(extra_metadata)", "ground_truth": "            metadata.update(extra_metadata)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.hash.update(data)", "prediction_line": "        self.hash.update(data)", "ground_truth": "        self.hash.update(data)", "line_class": "common", "zero_context": true}
{"original_prediction": "            chunk_name,", "prediction_line": "            chunk_name,", "ground_truth": "            chunk_name, self.chunks_on_disk + 1, index, len(chunks)", "line_class": "common", "zero_context": true}
{"original_prediction": "                        index=i,", "prediction_line": "                        index=i,", "ground_truth": "                        index=i,", "line_class": "common", "zero_context": true}
{"original_prediction": "        files_to_backup: List[Tuple[str, Path, bool]],", "prediction_line": "        files_to_backup: List[Tuple[str, Path, bool]],", "ground_truth": "        index: int,", "line_class": "common", "zero_context": true}
{"original_prediction": "            for _ in range(chunk_count):", "prediction_line": "            for _ in range(chunk_count):", "ground_truth": "            upload_results.append(chunk_callback_queue.get(timeout=queue_timeout))", "line_class": "common", "zero_context": true}
{"original_prediction": "        chunk_name, input_size, result_size = self.tar_one_file(", "prediction_line": "        chunk_name, input_size, result_size = self.tar_one_file(", "ground_truth": "        chunk_name, input_size, result_size = self.tar_one_file(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if self.wait_for_chunk_transfer_to_complete(", "prediction_line": "            if self.wait_for_chunk_transfer_to_complete(", "ground_truth": "            self.wait_for_chunk_transfer_to_complete(len(chunks), upload_results, chunk_callback_queue, start_time)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        callback_queue.put(", "prediction_line": "        callback_queue.put(", "ground_truth": "        middle_path, chunk_name = ChunkUploader.chunk_path_to_middle_path_name(Path(chunk_path), file_type)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data = self._file.read(n)", "prediction_line": "        data = self._file.read(n)", "ground_truth": "        data = self._file.read(n)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        self.handle_single_chunk,", "prediction_line": "                        self.handle_single_chunk,", "ground_truth": "                        self.handle_single_chunk,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        chunk_callback_queue: CallbackQueue,", "prediction_line": "        chunk_callback_queue: CallbackQueue,", "ground_truth": "        delta_stats: Optional[DeltaStats] = None,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        delta_stats: Optional[DeltaStats] = None,", "prediction_line": "        delta_stats: Optional[DeltaStats] = None,", "ground_truth": "        delta_stats: Optional[DeltaStats] = None", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        if os.path.getsize(local_path) >= min_delta_file_size:", "prediction_line": "                        if os.path.getsize(local_path) >= min_delta_file_size:", "ground_truth": "                        with HashFile(path=local_path) as fileobj:", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    if not self.wait_for_chunk_transfer_to_complete(", "prediction_line": "                    if not self.wait_for_chunk_transfer_to_complete(", "ground_truth": "                    if self.wait_for_chunk_transfer_to_complete(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self.write_files_to_tar(", "prediction_line": "                    self.write_files_to_tar(", "ground_truth": "                    self.write_files_to_tar(files=files_to_backup, tar=output_tar, delta_stats=delta_stats)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                raw_output_obj.name,", "prediction_line": "                raw_output_obj.name,", "ground_truth": "                compression_algorithm=self.compression_data.algorithm,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                encryption_algorithm=self.encryption_data.algorithm,", "prediction_line": "                encryption_algorithm=self.encryption_data.algorithm,", "ground_truth": "                rsa_public_key=self.encryption_data.rsa_public_key,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        middle_path = chunk_rel_path.parent", "prediction_line": "        middle_path = chunk_rel_path.parent", "ground_truth": "        if file_type == FileType.Basebackup_chunk:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"encryption_key_id\": self.encryption_data.encryption_key_id,", "prediction_line": "            \"encryption_key_id\": self.encryption_data.encryption_key_id,", "ground_truth": "            \"compression-algorithm\": self.compression_data.algorithm,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"compression-level\": self.compression_data.level,", "prediction_line": "            \"compression-level\": self.compression_data.level,", "ground_truth": "            \"encryption-key-id\": self.encryption_data.encryption_key_id,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif file_type == FileType.Wal:", "prediction_line": "        elif file_type == FileType.Wal:", "ground_truth": "        elif file_type == FileType.Basebackup_delta_chunk:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "\"site\": self.site, \"file_type\": file_type.name},", "prediction_line": "\"site\": self.site, \"file_type\": file_type.name},", "ground_truth": "                \"algorithm\": self.compression_data.algorithm,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif file_type == FileType.Wal_chunk:", "prediction_line": "        elif file_type == FileType.Wal_chunk:", "ground_truth": "        elif file_type == FileType.Basebackup:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       callback_queue.put(", "prediction_line": "       callback_queue.put(", "ground_truth": "        self.transfer_queue.put(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       while i < len(chunks):", "prediction_line": "       while i < len(chunks):", "ground_truth": "        max_chunks_on_disk = self.site_config[\"basebackup_chunks_in_progress\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        file_type: FileType = FileType.Basebackup_chunk", "prediction_line": "        file_type: FileType = FileType.Basebackup_chunk", "ground_truth": "        file_type: FileType = FileType.Basebackup_chunk", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.close()", "prediction_line": "        self.close()", "ground_truth": "        self._file.close()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            except OSError as e:", "prediction_line": "            except OSError as e:", "ground_truth": "            except (FileNotFoundError if missing_ok else NoException):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        callback_queue: CallbackQueue, transfer_queue: TransferQueue,", "prediction_line": "        callback_queue: CallbackQueue, transfer_queue: TransferQueue,", "ground_truth": "        site_config: Dict[str, Any], site: str, is_running: Callable[[], bool], transfer_queue: TransferQueue", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.log,", "prediction_line": "            self.log,", "ground_truth": "            encrypted=bool(self.encryption_data.encryption_key_id),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from rohmu.local_storage import LocalFileStorage", "prediction_line": "from rohmu.local_storage import LocalFileStorage", "ground_truth": "from rohmu.delta.common import EMBEDDED_FILE_SIZE", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                                elif file_size >= min_delta_file_size:", "prediction_line": "                                elif file_size >= min_delta_file_size:", "ground_truth": "                                # Unfortunately we can't tell what will be the total size of the chunk without actually", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def handle_chunks(", "prediction_line": "    def handle_chunks(", "ground_truth": "    def wait_for_chunk_transfer_to_complete(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ",\n    PGHoardThread, PGHoardThreadStatus, PGHoardWorkerThread, PGHoardWorkerThreadStatus, PGHoardWorkerThreadStatusUpdate,", "prediction_line": ",", "ground_truth": ")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __exit__(", "prediction_line": "    def __exit__(", "ground_truth": "    def __exit__(self, t: Optional[Type[BaseException]], v: Optional[BaseException], tb: Optional[TracebackType]) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    self.log.info(", "prediction_line": "                    self.log.info(", "ground_truth": "                if self.chunks_on_disk < max_chunks_on_disk:", "line_class": "random", "zero_context": true}
{"original_prediction": "        *,\n        chunk_callback_queue: CallbackQueue,", "prediction_line": "        *,", "ground_truth": "        chunk_count: int,", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"chunk_size\": result_size,", "prediction_line": "            \"chunk_size\": result_size,", "ground_truth": "            \"input_size\": input_size,", "line_class": "random", "zero_context": true}
{"original_prediction": "time.monotonic() - start_time", "prediction_line": "time.monotonic() - start_time", "ground_truth": "                time.monotonic() - start_time", "line_class": "random", "zero_context": true}
{"original_prediction": "                with tarfile.TarFile(fileobj=output_obj, mode=\"w\") as tar:", "prediction_line": "                with tarfile.TarFile(fileobj=output_obj, mode=\"w\") as tar:", "ground_truth": "                with tarfile.TarFile(fileobj=output_obj, mode=\"w\") as output_tar:", "line_class": "random", "zero_context": true}
{"original_prediction": "    return DeltaBaseBackup(", "prediction_line": "    return DeltaBaseBackup(", "ground_truth": "    chunk_uploader = ChunkUploader(", "line_class": "commited", "zero_context": true}
{"original_prediction": "       with patch.object(deltabasebackup, \"_delta_upload_hexdigest\") as mock_delta_upload_hexdigest:", "prediction_line": "       with patch.object(deltabasebackup, \"_delta_upload_hexdigest\") as mock_delta_upload_hexdigest:", "ground_truth": "        callback_queue.get = Mock()", "line_class": "common", "zero_context": true}
{"original_prediction": "        callback_queue.get.side_effect = [", "prediction_line": "        callback_queue.get.side_effect = [", "ground_truth": "        callback_queue.get.side_effect = [Empty, None]", "line_class": "common", "zero_context": true}
{"original_prediction": "                patch.object(deltabasebackup, \"download_backup_meta\") as mock_download_backup_meta:", "prediction_line": "                patch.object(deltabasebackup, \"download_backup_meta\") as mock_download_backup_meta:", "ground_truth": "                patch(\"pghoard.basebackup.delta.download_backup_meta_file\", new=fake_download_backup_meta):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if base_backup_format == BaseBackupFormat.TAR:", "prediction_line": "    if base_backup_format == BaseBackupFormat.TAR:", "ground_truth": "    if base_backup_format == BaseBackupFormat.delta_v1:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        \"format\": BaseBackupFormat.v2", "prediction_line": "                        \"format\": BaseBackupFormat.v2", "ground_truth": "                        \"format\": BaseBackupFormat.v2", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    callback_queue = CallbackQueue()", "prediction_line": "    callback_queue = CallbackQueue()", "ground_truth": "    site_config = {", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        compression_data=compression_data,", "prediction_line": "        compression_data=compression_data,", "ground_truth": "        compression_data=compression_data,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        metrics=metrics,", "prediction_line": "        metrics=metrics,", "ground_truth": "        site_config=site_config,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        \"basebackup_format\": BaseBackupFormat.tar_xz,", "prediction_line": "                        \"basebackup_format\": BaseBackupFormat.tar_xz,", "ground_truth": "                        \"format\": BaseBackupFormat.v1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            mock_delta_upload_hexdigest.return_value = (200, 10, file_hash, False)", "prediction_line": "            mock_delta_upload_hexdigest.return_value = (200, 10, file_hash, False)", "ground_truth": "            mock_delta_upload_hexdigest.side_effect = callback_queue.put(\"abc\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        chunk_uploader=chunk_uploader,", "prediction_line": "        chunk_uploader=chunk_uploader,", "ground_truth": "        get_remote_basebackups_info=MagicMock(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    compression_data = CompressionData(None, None)", "prediction_line": "    compression_data = CompressionData(None, None)", "ground_truth": "    compression_data = CompressionData(\"snappy\", 0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return DeltaBaseBackup(", "prediction_line": "    return DeltaBaseBackup(", "ground_truth": "    encryption_data = EncryptionData(\"test_key\", CONSTANT_TEST_RSA_PUBLIC_KEY)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        meta = generate_backup_meta_sample(BaseBackupFormat.delta_v2)", "prediction_line": "        meta = generate_backup_meta_sample(BaseBackupFormat.delta_v2)", "ground_truth": "        meta = generate_backup_meta_sample(BaseBackupFormat.delta_v2)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        \"format\": BaseBackupFormat.v3", "prediction_line": "                        \"format\": BaseBackupFormat.v3", "ground_truth": "                        \"format\": BaseBackupFormat.delta_v1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        chunk_upload_timeout=10,", "prediction_line": "        chunk_upload_timeout=10,", "ground_truth": "        encryption_data=encryption_data,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                assert not deltabasebackup._upload_single_delta_files(  # pylint: disable=protected-access", "prediction_line": "                assert not deltabasebackup._upload_single_delta_files(  # pylint: disable=protected-access", "ground_truth": "                with pytest.raises(BackupFailure):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return DeltaBaseBackup(", "prediction_line": "    return DeltaBaseBackup(", "ground_truth": "    delta_base_backup = DeltaBaseBackup(", "line_class": "inproject", "zero_context": true}
{"original_prediction": ",\n        callback_queue=CallbackQueue(),", "prediction_line": ",", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import pytest\nfrom aiven.client import AivenClient", "prediction_line": "import pytest", "ground_truth": "import pytest", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        chunks = DeltaBaseBackup._split_files_for_upload(snapshot_result, chunk_size)  # pylint: disable=protected-access", "prediction_line": "        chunks = DeltaBaseBackup._split_files_for_upload(snapshot_result, chunk_size)  # pylint: disable=protected-access", "ground_truth": "        delta_chunks, hexdigests = DeltaBaseBackup._split_files_for_upload(  # pylint: disable=protected-access", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                assert deltabasebackup._submit_files_in_thread(  # pylint: disable=protected-access", "prediction_line": "                assert deltabasebackup._submit_files_in_thread(  # pylint: disable=protected-access", "ground_truth": "                assert deltabasebackup._submit_files_in_thread(  # pylint: disable=protected-access", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                deltabasebackup._upload_single_delta_files(todo_hexdigests={file_hash}, snapshotter=snapshotter)  # pylint: disable=protected-access", "prediction_line": "                deltabasebackup._upload_single_delta_files(todo_hexdigests={file_hash}, snapshotter=snapshotter)  # pylint: disable=protected-access", "ground_truth": "                metric = deltabasebackup._upload_single_delta_files(todo_hexdigests={file_hash}, snapshotter=snapshotter)  # pylint: disable=protected-access", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    meta[\"manifest\"] = {}", "prediction_line": "    meta[\"manifest\"] = {}", "ground_truth": "    if basebackup_path == \"abc/basebackup/delta_v1\":", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"stored_file_size\": 150,", "prediction_line": "            \"stored_file_size\": 150,", "ground_truth": "            \"stored_file_size\": 0,", "line_class": "random", "zero_context": true}
{"original_prediction": "            with patch.object(deltabasebackup, \"_delta_upload_bundled_file\"):", "prediction_line": "            with patch.object(deltabasebackup, \"_delta_upload_bundled_file\"):", "ground_truth": "            with snapshotter.lock:", "line_class": "random", "zero_context": true}
{"original_prediction": ",\n            hexdigest=\"\",", "prediction_line": ",", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "        }]\n    elif base_backup_format == BaseBackupFormat.delta_v2:", "prediction_line": "        }]", "ground_truth": "        }]", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(config, site, connection_info, basebackup_path, compression_queue, metrics, storage,", "prediction_line": "        super().__init__(config, site, connection_info, basebackup_path, compression_queue, metrics, storage,", "ground_truth": "        super().__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            for file_hash, file_size in meta[\"delta_stats\"].items():", "prediction_line": "            for file_hash, file_size in meta[\"delta_stats\"].items():", "ground_truth": "            hashes.update(meta[\"delta_stats\"][\"hashes\"])", "line_class": "common", "zero_context": true}
{"original_prediction": "                # since it's the default and it's more efficient.", "prediction_line": "                # since it's the default and it's more efficient.", "ground_truth": "                cursor.execute(\"SELECT pg_start_backup(%s, true, false)\", [BASEBACKUP_NAME])", "line_class": "common", "zero_context": true}
{"original_prediction": "                cursor.execute(\"SELECT pg_is_in_recovery()\")", "prediction_line": "                cursor.execute(\"SELECT pg_is_in_recovery()\")", "ground_truth": "                cursor.execute(", "line_class": "common", "zero_context": true}
{"original_prediction": "            metadata[\"start-wal-segment\"] = start_wal_segment", "prediction_line": "            metadata[\"start-wal-segment\"] = start_wal_segment", "ground_truth": "            metadata.update({\"start-wal-segment\": start_wal_segment})", "line_class": "common", "zero_context": true}
{"original_prediction": "            metadata.update({\"start-time\": datetime.datetime.utcnow().isoformat()})", "prediction_line": "            metadata.update({\"start-time\": datetime.datetime.utcnow().isoformat()})", "ground_truth": "            metadata.update({\"start-time\": datetime.datetime.now(datetime.timezone.utc).isoformat()})", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.log.info(\"Basebackup completed, original_input_size: %r, compressed_file_size: %r\", original_input_size, compressed_file_size)", "prediction_line": "        self.log.info(\"Basebackup completed, original_input_size: %r, compressed_file_size: %r\", original_input_size, compressed_file_size)", "ground_truth": "        metadata.update({", "line_class": "common", "zero_context": true}
{"original_prediction": "                    # We're running on a replica, use pgespresso's backup control functions", "prediction_line": "                    # We're running on a replica, use pgespresso's backup control functions", "ground_truth": "                    cursor.execute(\"SELECT pgespresso_start_backup(%s, true)\", [BASEBACKUP_NAME])", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.log.info(\"Finished basebackup: %r, size: %r, metadata: %r\", basebackup_path, compressed_file_size, metadata)", "prediction_line": "        self.log.info(\"Finished basebackup: %r, size: %r, metadata: %r\", basebackup_path, compressed_file_size, metadata)", "ground_truth": "        metadata.update(self.metadata)", "line_class": "common", "zero_context": true}
{"original_prediction": "                        db_conn.commit()", "prediction_line": "                        db_conn.commit()", "ground_truth": "                        cursor.execute(\"SELECT pg_start_backup(%s, true)\", [BASEBACKUP_NAME])", "line_class": "common", "zero_context": true}
{"original_prediction": "            if is_superuser:", "prediction_line": "            if is_superuser:", "ground_truth": "            cursor.execute(\"SELECT pg_walfile_name(pg_current_wal_lsn()), txid_current()\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                    cursor.execute(\"SELECT pg_stop_backup(%s, false)\", [backup_label])", "prediction_line": "                    cursor.execute(\"SELECT pg_stop_backup(%s, false)\", [backup_label])", "ground_truth": "                    cursor.execute(\"SELECT pg_stop_backup()\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                    cursor.execute(\"SELECT pg_stop_backup(%s)\", [backup_label])", "prediction_line": "                    cursor.execute(\"SELECT pg_stop_backup(%s)\", [backup_label])", "ground_truth": "                    cursor.execute(\"SELECT labelfile FROM pg_stop_backup(false)\")", "line_class": "common", "zero_context": true}
{"original_prediction": "            cursor.execute(\"SELECT pg_xlogfile_name(pg_current_xlog_location()), txid_current()\")", "prediction_line": "            cursor.execute(\"SELECT pg_xlogfile_name(pg_current_xlog_location()), txid_current()\")", "ground_truth": "            cursor.execute(\"SELECT pg_xlogfile_name(pg_current_xlog_location()), txid_current()\")", "line_class": "common", "zero_context": true}
{"original_prediction": " # type: ignore", "prediction_line": " # type: ignore", "ground_truth": "            cursor.execute(\"SELECT pgespresso_stop_backup(%s)\", [backup_label])", "line_class": "common", "zero_context": true}
{"original_prediction": "                cursor.execute(\"SELECT spcname, pg_tablespace_location(oid) FROM pg_tablespace\")", "prediction_line": "                cursor.execute(\"SELECT spcname, pg_tablespace_location(oid) FROM pg_tablespace\")", "ground_truth": "                cursor.execute(\"SELECT oid, spcname FROM pg_tablespace WHERE spcname NOT IN ('pg_default', 'pg_global')\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                cursor.execute(\"SELECT pg_switch_wal()\")", "prediction_line": "                cursor.execute(\"SELECT pg_switch_wal()\")", "ground_truth": "                cursor.execute(\"SELECT pg_switch_wal()\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                cursor.execute(\"SELECT pg_switch_xlog()\")", "prediction_line": "                cursor.execute(\"SELECT pg_switch_xlog()\")", "ground_truth": "                cursor.execute(\"SELECT pg_switch_xlog()\")", "line_class": "common", "zero_context": true}
{"original_prediction": "            cursor.execute(\"SELECT pg_stop_backup(true)\")", "prediction_line": "            cursor.execute(\"SELECT pg_stop_backup(true)\")", "ground_truth": "            cursor.execute(\"SELECT pg_start_backup(%s, true, false)\", [backup_end_name])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        cursor.execute(\"SELECT pg_stop_backup(false)\")", "prediction_line": "                        cursor.execute(\"SELECT pg_stop_backup(false)\")", "ground_truth": "                        cursor.execute(\"SELECT pg_stop_backup(false)\")", "line_class": "common", "zero_context": true}
{"original_prediction": "            cursor.execute(\"SELECT pgespresso_start_backup(%s)\", [backup_end_name])", "prediction_line": "            cursor.execute(\"SELECT pgespresso_start_backup(%s)\", [backup_end_name])", "ground_truth": "            cursor.execute(\"SELECT pgespresso_start_backup(%s, true)\", [backup_end_name])", "line_class": "common", "zero_context": true}
{"original_prediction": "            cursor.execute(\"SELECT pg_start_backup(%s, true)\", [backup_end_name])", "prediction_line": "            cursor.execute(\"SELECT pg_start_backup(%s, true)\", [backup_end_name])", "ground_truth": "            cursor.execute(\"SELECT pg_start_backup(%s, true)\", [backup_end_name])", "line_class": "common", "zero_context": true}
{"original_prediction": "                   metadata[\"start-wal-segment\"] = start_wal_segment", "prediction_line": "                   metadata[\"start-wal-segment\"] = start_wal_segment", "ground_truth": "                    metadata.update({\"start-wal-segment\": start_wal_segment, \"start-time\": start_time})", "line_class": "common", "zero_context": true}
{"original_prediction": "                    delta_backup.start()", "prediction_line": "                    delta_backup.start()", "ground_truth": "                    total_size_plain, total_size_enc, manifest, total_file_count, chunk_files = delta_backup.run(", "line_class": "common", "zero_context": true}
{"original_prediction": "        metadata.update(self.metadata)", "prediction_line": "        metadata.update(self.metadata)", "ground_truth": "        metadata.update(control_files_metadata_extra)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    \"pg-version\": self.pg_version_server,", "prediction_line": "                    \"pg-version\": self.pg_version_server,", "ground_truth": "                    \"active-backup-mode\": self.site_config[\"active_backup_mode\"],", "line_class": "infile", "zero_context": true}
{"original_prediction": "        basebackup_path, local_basebackup_path = self.get_backup_path()", "prediction_line": "        basebackup_path, local_basebackup_path = self.get_backup_path()", "ground_truth": "        basebackup_path, local_basebackup_path = self.get_backup_path()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.log.info(\"Starting piped basebackup to %r\", basebackup_path)", "prediction_line": "        self.log.info(\"Starting piped basebackup to %r\", basebackup_path)", "ground_truth": "        command = self.get_command_line(\"-\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "                       self.metadata[\"format\"] = BaseBackupFormat.v2", "prediction_line": "                       self.metadata[\"format\"] = BaseBackupFormat.v2", "ground_truth": "                        existing_hashes = self.fetch_all_data_files_hashes()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if delta:", "prediction_line": "        if delta:", "ground_truth": "        pgdata = self.site_config[\"pg_data_directory\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # FIXME: this should look at the object storage, not the local incoming", "prediction_line": "        # FIXME: this should look at the object storage, not the local incoming", "ground_truth": "        _, compressed_base = self.get_backup_path()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                            (total_size_plain + sum(new_hashes.values())) / target_chunk_size", "prediction_line": "                            (total_size_plain + sum(new_hashes.values())) / target_chunk_size", "ground_truth": "                            delta_stats.chunked_files_size / self.site_config[\"basebackup_delta_mode_chunk_size\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        chunk_size = self.site_config.get(\"chunk_size\", 2 * 1024 * 1024 * 1024)", "prediction_line": "        chunk_size = self.site_config.get(\"chunk_size\", 2 * 1024 * 1024 * 1024)", "ground_truth": "        target_chunk_size = self.site_config[\"basebackup_chunk_size\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.basebackup_compression_pipe(proc, stream_target)", "prediction_line": "                self.basebackup_compression_pipe(proc, stream_target)", "ground_truth": "                self.basebackup_compression_pipe(proc, stream_target)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            \"pg_basebackup\",", "prediction_line": "            \"pg_basebackup\",", "ground_truth": "            self.site_config[\"pg_basebackup_path\"],", "line_class": "infile", "zero_context": true}
{"original_prediction": "           original_input_size = None", "prediction_line": "           original_input_size = None", "ground_truth": "        self.check_command_success(proc, stream_target)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       if self.site_config[\"basebackup_mode\"] == BaseBackupMode.pipe:", "prediction_line": "       if self.site_config[\"basebackup_mode\"] == BaseBackupMode.pipe:", "ground_truth": "        if self.site_config[\"active_backup_mode\"] == \"standalone_hot_backup\":", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if os.path.isdir(local_path):", "prediction_line": "                if os.path.isdir(local_path):", "ground_truth": "                yield from add_entry(archive_path, local_path, missing_ok=missing_ok)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                yield from add_directory(archive_path, local_path, missing_ok=True)", "prediction_line": "                yield from add_directory(archive_path, local_path, missing_ok=True)", "ground_truth": "                yield from add_directory(archive_path, local_path, missing_ok=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self.site_config[\"compression_algorithm\"] == \"pghoard_rsa\":", "prediction_line": "        if self.site_config[\"compression_algorithm\"] == \"pghoard_rsa\":", "ground_truth": "        encryption_key_id = self.site_config[\"encryption_key_id\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            rsa_public_key = self.site_config[\"encryption_keys\"][encryption_key_id]", "prediction_line": "            rsa_public_key = self.site_config[\"encryption_keys\"][encryption_key_id]", "ground_truth": "            rsa_public_key = self.site_config[\"encryption_keys\"][encryption_key_id][\"public\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.parse_backup_label(content)", "prediction_line": "            return self.parse_backup_label(content)", "ground_truth": "        return self.parse_backup_label(content)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        get_remote_basebackups_info=self.get_remote_basebackups_info,", "prediction_line": "                        get_remote_basebackups_info=self.get_remote_basebackups_info,", "ground_truth": "                        encryption_data=self.encryption_data,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            compression_data=self.compression_data,", "prediction_line": "            compression_data=self.compression_data,", "ground_truth": "            compression_data=self.compression_data,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            transfer_queue=self.transfer_queue,", "prediction_line": "            transfer_queue=self.transfer_queue,", "ground_truth": "            site_config=self.site_config,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    return input_data[512:]", "prediction_line": "                    return input_data[512:]", "ground_truth": "                    start_wal_segment, start_time = self.parse_backup_label(input_data[512:1024])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        basebackup_tar_file.parent.mkdir(parents=True, exist_ok=True)", "prediction_line": "        basebackup_tar_file.parent.mkdir(parents=True, exist_ok=True)", "ground_truth": "        command = self.get_command_line(local_basebackup_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            yield from add_entry(archive_path, local_path, missing_ok=False)", "prediction_line": "            yield from add_entry(archive_path, local_path, missing_ok=False)", "ground_truth": "            yield from add_entry(archive_path, local_path, missing_ok=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        fetch_all_data_files_hashes=self.fetch_all_data_files_hashes", "prediction_line": "                        fetch_all_data_files_hashes=self.fetch_all_data_files_hashes", "ground_truth": "                        parallel=self.site_config[\"basebackup_threads\"],", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.run()", "prediction_line": "            self.run()", "ground_truth": "            basebackup_mode = self.site_config[\"basebackup_mode\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            yield from add_directory(archive_path, local_path, missing_ok=False)", "prediction_line": "            yield from add_directory(archive_path, local_path, missing_ok=False)", "ground_truth": "            yield from add_directory(archive_path, local_path, missing_ok=False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.log.info(\"Starting basic basebackup\")", "prediction_line": "                self.log.info(\"Starting basic basebackup\")", "ground_truth": "                self.run_basic_basebackup()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            control_files_metadata_extra.update({", "prediction_line": "            control_files_metadata_extra.update({", "ground_truth": "            backup_end_wal_segment, backup_end_time = self.get_backup_end_segment_and_time(db_conn, backup_mode)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.run_local_tar_basebackup()", "prediction_line": "                self.run_local_tar_basebackup()", "ground_truth": "                self.run_local_tar_basebackup()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.run_local_tar_basebackup(delta=True, delta_stats=True)", "prediction_line": "                self.run_local_tar_basebackup(delta=True, delta_stats=True)", "ground_truth": "                self.run_local_tar_basebackup(with_delta_stats=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                encryption_key_id=encryption_key_id,", "prediction_line": "                encryption_key_id=encryption_key_id,", "ground_truth": "                progress_callback=progress_callback,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.run_pipe_basebackup()", "prediction_line": "                self.run_pipe_basebackup()", "ground_truth": "                self.run_piped_basebackup()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                extract_header_func=extract_header_func,", "prediction_line": "                extract_header_func=extract_header_func,", "ground_truth": "                header_func=extract_header_func", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.check_command_success(proc, basebackup_tar_file)", "prediction_line": "        self.check_command_success(proc, basebackup_tar_file)", "ground_truth": "        self.check_command_success(proc, basebackup_tar_file)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # FIXME: this should be done in a separate thread", "prediction_line": "        # FIXME: this should be done in a separate thread", "ground_truth": "        start_wal_segment, start_time = self.parse_backup_label_in_tar(basebackup_tar_file)", "line_class": "infile", "zero_context": true}
{"original_prediction": "self.get_control_entries_for_tar(", "prediction_line": "self.get_control_entries_for_tar(", "ground_truth": "            self.get_control_entries_for_tar(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    total_size_plain, total_size_enc, chunks_count, total_file_count = self.chunk_uploader.run(", "prediction_line": "                    total_size_plain, total_size_enc, chunks_count, total_file_count = self.chunk_uploader.run(", "ground_truth": "                    total_file_count, chunks = self.find_and_split_files_to_backup(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            control_files_metadata_extra[\"backup_label\"] = backup_label_data", "prediction_line": "            control_files_metadata_extra[\"backup_label\"] = backup_label_data", "ground_truth": "            backup_start_wal_segment, backup_start_time = self.parse_backup_label(backup_label_data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "UploadEvent(\n            site=self.site,", "prediction_line": "UploadEvent(", "ground_truth": "            UploadEvent(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.callback_queue.put(CallbackEvent(", "prediction_line": "            self.callback_queue.put(CallbackEvent(", "ground_truth": "                self.metrics.unexpected_exception(ex, where=\"PGBaseBackup\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            archive_path = os.path.join(\"pgdata\", \"tablespaces\", spcname)", "prediction_line": "            archive_path = os.path.join(\"pgdata\", \"tablespaces\", spcname)", "ground_truth": "            archive_path = os.path.join(\"tablespaces\", spcname)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.log.info(\"Stopping backup process\")", "prediction_line": "                self.log.info(\"Stopping backup process\")", "ground_truth": "                with open(os.path.join(pgdata, \"global\", \"pg_control\"), \"rb\") as fp:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "to the callback queue\n                self.callback_queue.put(CallbackEvent(", "prediction_line": "to the callback queue", "ground_truth": "                self.callback_queue.put(CallbackEvent(success=False, exception=ex))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.running = False", "prediction_line": "            self.running = False", "ground_truth": "            self.running = False", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if proc.returncode != 0:", "prediction_line": "        if proc.returncode != 0:", "ground_truth": "        rc = terminate_subprocess(proc, log=self.log)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"pghoard\": {", "prediction_line": "            \"pghoard\": {", "ground_truth": "            \"compression-algorithm\": compression_algorithm,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.log.exception(\"Basebackup failed\")", "prediction_line": "            self.log.exception(\"Basebackup failed\")", "ground_truth": "            if isinstance(ex, (BackupFailure, errors.InvalidConfigurationError)):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                # Create a tar file with the contents of $PGDATA and the tablespaces", "prediction_line": "                # Create a tar file with the contents of $PGDATA and the tablespaces", "ground_truth": "                self.log.info(\"Starting to backup %r and %r tablespaces to %r\", pgdata, len(tablespaces), compressed_base)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            storage=self.storage,", "prediction_line": "            storage=self.storage,", "ground_truth": "            is_running=lambda: self.running,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        encryption_key_id = self.site_config[\"encryption_key_id\"]", "prediction_line": "        encryption_key_id = self.site_config[\"encryption_key_id\"]", "ground_truth": "        return EncryptionData.from_site_config(self.site_config)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            local_path = os.path.join(pgdata, fn)", "prediction_line": "            local_path = os.path.join(pgdata, fn)", "ground_truth": "            local_path = os.path.join(pgdata, fn)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                compression_algorithm=compression_algorithm,", "prediction_line": "                compression_algorithm=compression_algorithm,", "ground_truth": "                compression_algorithm=compression_algorithm,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "to upload\n        for archive_path, local_path, missing_ok, action in self.find_files_to_backup(pgdata=pgdata, tablespaces=tablespaces):", "prediction_line": "to upload", "ground_truth": "        for archive_path, local_path, missing_ok, operation in \\", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # the oldest WAL segment that is required to restore from this backup.", "prediction_line": "        # the oldest WAL segment that is required to restore from this backup.", "ground_truth": "        # in the future but not exactly correct. These both are valid only as long as no other", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "           with rohmufile.File(output_obj.name, \"wb\", rsa_public_key=rsa_public_key) as output_file:", "prediction_line": "           with rohmufile.File(output_obj.name, \"wb\", rsa_public_key=rsa_public_key) as output_file:", "ground_truth": "            def extract_header_func(input_data):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        if backup_mode == \"non-exclusive\":", "prediction_line": "        if backup_mode == \"non-exclusive\":", "ground_truth": "        \"\"\"Grab a timestamp and WAL segment name after the end of the backup: this is a point in time to which", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"Returns the path to the basebackup and the path to the metadata file\"\"\"", "prediction_line": "        \"\"\"Returns the path to the basebackup and the path to the metadata file\"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"pg_snapshots\",", "prediction_line": "    \"pg_snapshots\",", "ground_truth": "    \"pg_snapshot\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                metadata=metadata, pg_control=pg_control, backup_label=backup_label_data", "prediction_line": "                metadata=metadata, pg_control=pg_control, backup_label=backup_label_data", "ground_truth": "                metadata=metadata,", "line_class": "random", "zero_context": true}
{"original_prediction": "                if not backup_stopped:", "prediction_line": "                if not backup_stopped:", "ground_truth": "                db_conn.rollback()", "line_class": "random", "zero_context": true}
{"original_prediction": "        ti.size = len(blob.getbuffer())", "prediction_line": "        ti.size = len(blob.getbuffer())", "ground_truth": "        ti.size = len(blob.getbuffer())", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"backup_end_wal_segment\": backup_end_wal_segment,", "prediction_line": "            \"backup_end_wal_segment\": backup_end_wal_segment,", "ground_truth": "            \"backup_end_wal_segment\": backup_end_wal_segment,", "line_class": "random", "zero_context": true}
{"original_prediction": "   modified_dict, ticker_list = array_construction(", "prediction_line": "   modified_dict, ticker_list = array_construction(", "ground_truth": "    modified_dict, ticker_list = array_construction(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for col in range(no_cols):", "prediction_line": "        for col in range(no_cols):", "ground_truth": "        condition = column_check(v, col=1, no_cols=no_cols, debug=debug)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    returns a DataFrame.", "prediction_line": "    returns a DataFrame.", "ground_truth": "    subsequently stores that structure in a dictionary where the dictionary's", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # Object for a valid Ticker.", "prediction_line": "        # Object for a valid Ticker.", "ground_truth": "        # Object for a series that is available in the database.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    into a single DataFrame.", "prediction_line": "    into a single DataFrame.", "ground_truth": "    into a single DataFrame retaining the order both row-wise, in terms of cross-", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            # If the series is not returned, potentially the fault of the threading", "prediction_line": "            # If the series is not returned, potentially the fault of the threading", "ground_truth": "            # If a requested metric has not been returned, its absence could be", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # Initializes the DataFrame with the correct number of rows and columns.", "prediction_line": "    # Initializes the DataFrame with the correct number of rows and columns.", "ground_truth": "    arr = np.empty(shape=(length * tickers_no, 3 + no_metrics), dtype=object)", "line_class": "random", "zero_context": true}
{"original_prediction": "        missing_metrics = set(metrics) - available_metrics", "prediction_line": "        missing_metrics = set(metrics) - available_metrics", "ground_truth": "        expected_metrics = set(d_frame_order)", "line_class": "random", "zero_context": true}
{"original_prediction": "    ticker_list: List[str],", "prediction_line": "    ticker_list: List[str],", "ground_truth": "    _dict, ", "line_class": "random", "zero_context": true}
{"original_prediction": "        if ts_arr is None:", "prediction_line": "        if ts_arr is None:", "ground_truth": "        if ts_arr.size == 1:", "line_class": "random", "zero_context": true}
{"original_prediction": "            pass\n\n    if ticker_list:", "prediction_line": "            pass", "ground_truth": "            continue", "line_class": "random", "zero_context": true}
{"original_prediction": "        if params is None:", "prediction_line": "        if params is None:", "ground_truth": "        r = requests.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "        r = requests.get(", "prediction_line": "        r = requests.get(", "ground_truth": "        with requests.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "        self._stored_token = self._request_token()", "prediction_line": "        self._stored_token = self._request_token()", "ground_truth": "        with requests.post(", "line_class": "common", "zero_context": true}
{"original_prediction": "        if params is None:", "prediction_line": "        if params is None:", "ground_truth": "        r = self.get_dq_api_result(url=url, params=params)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                headers={'Authorization': f'Bearer {self._get_token()}'}", "prediction_line": "                headers={'Authorization': f'Bearer {self._get_token()}'}", "ground_truth": "                headers={'Authorization': 'Bearer ' + self._get_token()},", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Method used to get the token from the OAuth API.", "prediction_line": "        \"\"\"", "ground_truth": "        if self._valid_token():", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.crt = crt", "prediction_line": "        self.crt = crt", "ground_truth": "        self.key = self.valid_path(key, \"key\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.crt = self.valid_path(crt, \"crt\")", "prediction_line": "        self.crt = self.valid_path(crt, \"crt\")", "ground_truth": "        self.crt = self.valid_path(crt, \"crt\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        :param <dict> params: default None, dictionary with parameters to be passed to the", "prediction_line": "        :param <dict> params: default None, dictionary with parameters to be passed to the", "ground_truth": "        :param <str> params: dictionary of parameters to be passed to request", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Get DataQuery API result.", "prediction_line": "        Get DataQuery API result.", "ground_truth": "        Method used exclusively to request data from the API.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Method used to fetch data from the API.", "prediction_line": "        Method used to fetch data from the API.", "ground_truth": "        Used to test if DataQuery is responding.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        return results", "prediction_line": "        return results", "ground_truth": "            print(results['description'])", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ",\n    you must have a certificate and private key.", "prediction_line": ",", "ground_truth": "    login both username & password are required as well as a certified certificate", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            return False", "prediction_line": "            return False", "ground_truth": "            return False", "line_class": "random", "zero_context": true}
{"original_prediction": "class OAuth:", "prediction_line": "class OAuth:", "ground_truth": "OAUTH_DQ_RESOURCE_ID = \"JPMC:URI:RS-06785-DataQueryExternalApi-PROD\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        assert isinstance(crt, str), (", "prediction_line": "        assert isinstance(crt, str), (", "ground_truth": "        self.auth = base64.b64encode(", "line_class": "random", "zero_context": true}
{"original_prediction": "            f\"client_secret argument must be a string and not <{type(client_secret)}>.\"", "prediction_line": "            f\"client_secret argument must be a string and not <{type(client_secret)}>.\"", "ground_truth": "            f\"client_secret must be a str and not <{type(client_secret)}>.\"", "line_class": "random", "zero_context": true}
{"original_prediction": "                    'grant_type': 'client_credentials',", "prediction_line": "                    'grant_type': 'client_credentials',", "ground_truth": "                    'grant_type': 'client_credentials',", "line_class": "random", "zero_context": true}
{"original_prediction": "           output_dict = {**output_dict, **o_dict}", "prediction_line": "           output_dict = {**output_dict, **o_dict}", "ground_truth": "        results_dict = framer.valid_ticker(results_dict, suppress_warning, self.debug)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            pass\n\n        # TODO: This is a good entry point for the DataFrame conversion.", "prediction_line": "            pass", "ground_truth": "            return framer.dataframe_wrapper(results_dict, no_metrics, original_metrics)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    Auth,\n    AuthError,", "prediction_line": "    Auth,", "ground_truth": "    CertAuth, OAuth, CERT_BASE_URL, OAUTH_BASE_URL, OAUTH_TOKEN_URL, OAUTH_DQ_RESOURCE_ID", "line_class": "commited", "zero_context": true}
{"original_prediction": "       no_tix = len(set([tick.split(\",\")[1] for tick in expression]))", "prediction_line": "       no_tix = len(set([tick.split(\",\")[1] for tick in expression]))", "ground_truth": "        results_dict, output_dict, s_list = framer.isolate_timeseries(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self.auth = OAuth(**kwargs)", "prediction_line": "            self.auth = OAuth(**kwargs)", "ground_truth": "            self.access: OAuth = OAuth(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        url = self.access.base_url + endpoint", "prediction_line": "        url = self.access.base_url + endpoint", "ground_truth": "        js, success, msg = self.access.get_dq_api_result(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self.access: CertAuth = CertAuth(", "prediction_line": "            self.access: CertAuth = CertAuth(", "ground_truth": "            self.access: CertAuth = CertAuth(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            results_seq, error_tickers, error_messages = results_seq", "prediction_line": "            results_seq, error_tickers, error_messages = results_seq", "ground_truth": "            r_dict, o_dict, s_list = framer.isolate_timeseries(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            params_.update(params)", "prediction_line": "            params_.update(params)", "ground_truth": "            params.update(params_)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    recursive_call = False", "prediction_line": "                    recursive_call = False", "ground_truth": "                    rec_final_output, rec_error_tickers, rec_error_messages = self._request(", "line_class": "infile", "zero_context": true}
{"original_prediction": "       no_tickers = len(unique_tix)", "prediction_line": "       no_tickers = len(unique_tix)", "ground_truth": "        dq_tix = self.jpmaqs_indicators(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        start_date = kwargs.pop(\"start_date\", None)", "prediction_line": "        start_date = kwargs.pop(\"start_date\", None)", "ground_truth": "        c_delay = self.delay_compute(len(dq_tix))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            try:\n                results, error_tickers, error_messages = self._request(", "prediction_line": "            try:", "ground_truth": "            results = self._request(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            sequential_results = self._request(", "prediction_line": "            sequential_results = self._request(", "ground_truth": "            results_seq = self._request(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                response, status, msg = self._fetch_threading(endpoint, params, server_count=5)", "prediction_line": "                response, status, msg = self._fetch_threading(endpoint, params, server_count=5)", "ground_truth": "                results = self._fetch_threading(endpoint=endpoint, params=params)", "line_class": "infile", "zero_context": true}
{"original_prediction": "self._fetch_threading, endpoint, params_copy)])", "prediction_line": "self._fetch_threading, endpoint, params_copy)])", "ground_truth": "                        self._fetch_threading, endpoint, params_copy), r_list])", "line_class": "infile", "zero_context": true}
{"original_prediction": "       df = self.get_ts_expression(", "prediction_line": "       df = self.get_ts_expression(", "ground_truth": "            df = self.get_ts_expression(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def __init__(self, debug=False, concurrent=True, batch_size=100, **kwargs):", "prediction_line": "    def __init__(self, debug=False, concurrent=True, batch_size=100, **kwargs):", "ground_truth": "    def __init__(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import os\nimport json", "prediction_line": "import os", "ground_truth": "from typing import List, Tuple", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        :param <str> expression:", "prediction_line": "        :param <str> expression:", "ground_truth": "        :param <List[str]> expression: categories & respective cross-sections requested.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        :param <dict> response: response from DataQuery", "prediction_line": "        :param <dict> response: response from DataQuery", "ground_truth": "        :param <dict> response: server response.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        elif not floor(no_tickers / 10000):", "prediction_line": "        elif not floor(no_tickers / 10000):", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "                        else:", "prediction_line": "                        else:", "ground_truth": "                        ", "line_class": "random", "zero_context": true}
{"original_prediction": "                time.sleep(1)", "prediction_line": "                time.sleep(1)", "ground_truth": "                time.sleep(0.05)", "line_class": "random", "zero_context": true}
{"original_prediction": "                        else:", "prediction_line": "                        else:", "ground_truth": "                            logger.warning(f\"Error in requestion tickers: {', '.join(futures[i][1])}.\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        # The url is instantiated on the ancillary Classes as it depends on the DQ access", "prediction_line": "        # The url is instantiated on the ancillary Classes as it depends on the DQ access", "ground_truth": "        if delay > 0.9999:", "line_class": "random", "zero_context": true}
{"original_prediction": "    df_xcats = pd.DataFrame(index=xcats, columns=['earliest', 'latest', 'mean_add',", "prediction_line": "    df_xcats = pd.DataFrame(index=xcats, columns=['earliest', 'latest', 'mean_add',", "ground_truth": "    df_xcats = pd.DataFrame(index=xcats, columns=['earliest', 'latest', 'mean_add',", "line_class": "common", "zero_context": true}
{"original_prediction": "        dfx = dfx.pivot(index=\"real_date\", columns=\"ticker\", values=\"value\")", "prediction_line": "        dfx = dfx.pivot(index=\"real_date\", columns=\"ticker\", values=\"value\")", "ground_truth": "        dfw = dfx.pivot(index=\"real_date\", columns=\"ticker\", values=\"value\")", "line_class": "common", "zero_context": true}
{"original_prediction": "   df = make_qdf(cids, xcats, start='2000-01-01', end='2020-01-01')", "prediction_line": "   df = make_qdf(cids, xcats, start='2000-01-01', end='2020-01-01')", "ground_truth": "    df_cids = pd.DataFrame(index=cids, columns=['earliest', 'latest', 'mean_add',", "line_class": "common", "zero_context": true}
{"original_prediction": "                 vol: str = \"XR_NSA\", weight_type: str = \"expo\",", "prediction_line": "                 vol: str = \"XR_NSA\", weight_type: str = \"expo\",", "ground_truth": "                 cry: Union[str, List[str]] = None, start: str = None, end: str = None,", "line_class": "common", "zero_context": true}
{"original_prediction": "    df_equal = basket_3.return_basket(\"GLB_EQUAL\")", "prediction_line": "    df_equal = basket_3.return_basket(\"GLB_EQUAL\")", "ground_truth": "    df_equal = basket_3.return_basket(\"GLB_EQUAL\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    gdp_figures = [17.0, 17.0, 41.0, 9.0, 250.0]", "prediction_line": "    gdp_figures = [17.0, 17.0, 41.0, 9.0, 250.0]", "ground_truth": "    basket_4 = Basket(df=dfd, contracts=contracts, ret=\"XR_NSA\",", "line_class": "infile", "zero_context": true}
{"original_prediction": "    df_values = basket_4.return_basket(\"GLB_VALUES\")", "prediction_line": "    df_values = basket_4.return_basket(\"GLB_VALUES\")", "ground_truth": "    weight_equal = basket_4.return_weights(basket_names=\"GLB_EQUAL\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.check_weights(weights)", "prediction_line": "        self.check_weights(weights)", "ground_truth": "        self.check_weights(weights)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.cry = cry", "prediction_line": "        self.cry = cry", "ground_truth": "        self.dfw_ret = self.pivot_dataframe(df, self.ticks_ret)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if cry is not None:", "prediction_line": "        if cry is not None:", "ground_truth": "        self.store_attributes(df, cry, \"cry\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.store_attributes(df, ewgts, \"ewgts\")", "prediction_line": "        self.store_attributes(df, ewgts, \"ewgts\")", "ground_truth": "        self.store_attributes(df, ewgts, \"wgt\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.__dict__['basket_name'] = basket_name", "prediction_line": "        self.__dict__['basket_name'] = basket_name", "ground_truth": "        dfw_wgs = self.make_weights(weight_meth=weight_meth, weights=weights,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.dfw = self.pivot_dataframe(df, self.tickers)", "prediction_line": "        self.dfw = self.pivot_dataframe(df, self.tickers)", "ground_truth": "        self.start = self.date_check(start)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.end = self.date_check(end)", "prediction_line": "        self.end = self.date_check(end)", "ground_truth": "        self.end = self.date_check(end)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        weight = weight.fillna(0)", "prediction_line": "        weight = weight.fillna(0)", "ground_truth": "        self.check_weights(weight=weight)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       dfw_wgs = dfw_wgs.loc[:, select]", "prediction_line": "       dfw_wgs = dfw_wgs.loc[:, select]", "ground_truth": "        dfw_wgs_copy = self.column_manager(df_cat=self.dfw_ret, dfw_wgs=dfw_wgs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            weights = self.equal_weight(df_ret=self.dfw_ret)", "prediction_line": "            weights = self.equal_weight(df_ret=self.dfw_ret)", "ground_truth": "            dfw_wgs = self.equal_weight(df_ret=self.dfw_ret)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                dfw_wgs_copy = self.column_manager(df_cat=self.dfws_cry[cr],", "prediction_line": "                dfw_wgs_copy = self.column_manager(df_cat=self.dfws_cry[cr],", "ground_truth": "                dfw_wgs_copy = self.column_manager(df_cat=self.dfws_cry[cr],", "line_class": "infile", "zero_context": true}
{"original_prediction": "           dfw_wgs = self.fixed_weight(df_ret=self.dfw_ret, weights=weights)", "prediction_line": "           dfw_wgs = self.fixed_weight(df_ret=self.dfw_ret, weights=weights)", "ground_truth": "            dfw_wgs = self.fixed_weight(df_ret=self.dfw_ret, weights=weights)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    b = Basket(dfd, contracts, ret=\"XR_NSA\", cry=[\"CRY_NSA\", \"CRR_NSA\"],", "prediction_line": "    b = Basket(dfd, contracts, ret=\"XR_NSA\", cry=[\"CRY_NSA\", \"CRR_NSA\"],", "ground_truth": "    basket_1 = Basket(df=dfd, contracts=contracts_1,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            assert lback_periods > 0, \"Lookback period must be greater than zero.\"", "prediction_line": "            assert lback_periods > 0, \"Lookback period must be greater than zero.\"", "ground_truth": "            dfw_wgs = self.inverse_weight(dfw_ret=self.dfw_ret, lback_meth=lback_meth,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.check_weights(weight=weight)", "prediction_line": "        self.check_weights(weight=weight)", "ground_truth": "        self.check_weights(weight)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    basket_1.make_basket(weight_meth=\"invsd\", max_weight=0.55,", "prediction_line": "    basket_1.make_basket(weight_meth=\"invsd\", max_weight=0.55,", "ground_truth": "    dfp_1 = basket_1.return_basket()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    dfp_1 = dfp_1.loc[dfp_1.ticker.isin(contracts_1)]", "prediction_line": "    dfp_1 = dfp_1.loc[dfp_1.ticker.isin(contracts_1)]", "ground_truth": "    dfw_1 = basket_1.return_weights()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Second test. Single carry. Equal weight method.", "prediction_line": "    # Second test. Single carry. Equal weight method.", "ground_truth": "    df_basket = basket_1.return_basket(\"GLB_EQUAL\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "                dfws_pfx[cat] = self.pivot_dataframe(df, ticks)", "prediction_line": "                dfws_pfx[cat] = self.pivot_dataframe(df, ticks)", "ground_truth": "                dfws_pfx[cat] = self.pivot_dataframe(df, ticks)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Second test. Single carry. Equal weight method.", "prediction_line": "    # Second test. Single carry. Equal weight method.", "ground_truth": "    df_weight = basket_1.return_weights(\"GLB_EQUAL\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "                dfw_wgs = self.values_weight(dfw_ret=dfw_ret, dfw_wgt=dfw_wgt,", "prediction_line": "                dfw_wgs = self.values_weight(dfw_ret=dfw_ret, dfw_wgt=dfw_wgt,", "ground_truth": "                dfw_wgs = self.values_weight(dfw_ret, dfw_wgt, weight_meth)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    basket_2 = Basket(df=dfd, contracts=contracts,", "prediction_line": "    basket_2 = Basket(df=dfd, contracts=contracts,", "ground_truth": "    basket_2 = Basket(df=dfd, contracts=contracts_1,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    basket_2.make_basket(weight_meth=\"equal\", max_weight=0.55,", "prediction_line": "    basket_2.make_basket(weight_meth=\"equal\", max_weight=0.55,", "ground_truth": "    basket_2.make_basket(weight_meth=\"invsd\", lback_meth=\"ma\", lback_periods=21,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.check_weights(df_wgts)", "prediction_line": "        self.check_weights(df_wgts)", "ground_truth": "        self.check_weights(df_wgts)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    basket_2.make_basket(weight_meth=\"equal\", max_weight=0.55,", "prediction_line": "    basket_2.make_basket(weight_meth=\"equal\", max_weight=0.55,", "ground_truth": "    df_basket_inv = basket_2.return_basket(\"GLB_INVERSE\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    df_basket_eq = basket_2.return_basket(\"GLB_EQUAL\")", "prediction_line": "    df_basket_eq = basket_2.return_basket(\"GLB_EQUAL\")", "ground_truth": "    df_basket_equal = basket_2.return_basket(\"GLB_EQUAL\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "   basket_3 = Basket(df=dfd, contracts=contracts_1,", "prediction_line": "   basket_3 = Basket(df=dfd, contracts=contracts_1,", "ground_truth": "    basket_3 = Basket(df=dfd, contracts=contracts_1, ret=\"XR_NSA\", cry=[\"CRY_NSA\"],", "line_class": "infile", "zero_context": true}
{"original_prediction": "   df_basket_inv_values = basket_3.return_basket(\"GLB_INV_VALUES\")", "prediction_line": "   df_basket_inv_values = basket_3.return_basket(\"GLB_INV_VALUES\")", "ground_truth": "    df_inv_values = basket_3.return_basket(\"GLB_INV_VALUES\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Fourth test. One carry. Values weight method.", "prediction_line": "    # Fourth test. One carry. Values weight method.", "ground_truth": "    df_weight = basket_3.return_weights(\"GLB_INV_VALUES\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if max_weight < 1:", "prediction_line": "            if max_weight < 1:", "ground_truth": "            row = ConvergeRow.application(row, max_weight)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   df_weight_inv = basket_2.return_weights(\"GLB_INVERSE\")", "prediction_line": "   df_weight_inv = basket_2.return_weights(\"GLB_INVERSE\")", "ground_truth": "    basket_2.make_basket(weight_meth=\"equal\", max_weight=0.55, basket_name=\"GLB_EQUAL\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    basket_1.make_basket(weight_meth=\"equal\")", "prediction_line": "    basket_1.make_basket(weight_meth=\"equal\")", "ground_truth": "    basket_1.make_basket(weight_meth=\"equal\", max_weight=0.55,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                    ewgt=ewgt, max_weight=max_weight,", "prediction_line": "                                    ewgt=ewgt, max_weight=max_weight,", "ground_truth": "                                    ewgt=ewgt, max_weight=max_weight,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if weight_meth == \"equal\":", "prediction_line": "        if weight_meth == \"equal\":", "ground_truth": "        assert 0.0 < max_weight <= 1.0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            dfw_wgs = self.max_weight_func(dfw_wgs, max_weight)", "prediction_line": "            dfw_wgs = self.max_weight_func(dfw_wgs, max_weight)", "ground_truth": "            dfw_wgs = self.max_weight_func(weights=dfw_wgs, max_weight=max_weight)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    basket_1.make_basket(weight_meth=\"equal\", max_weight=0.55,", "prediction_line": "    basket_1.make_basket(weight_meth=\"equal\", max_weight=0.55,", "ground_truth": "    basket_1.make_basket(weight_meth=\"fixed\", max_weight=0.55,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        dfw_wgs = self.max_weight_func(dfw_wgs, max_weight)", "prediction_line": "        dfw_wgs = self.max_weight_func(dfw_wgs, max_weight)", "ground_truth": "        if max_weight < 1.0:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            lback_periods = lback_periods - 1", "prediction_line": "            lback_periods = lback_periods - 1", "ground_truth": "            dfwa = dfw_ret.rolling(window=lback_periods).agg(flat_std, remove_zeros)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                     max_weight: float = 1.0, remove_zeros: bool = True):", "prediction_line": "                     max_weight: float = 1.0, remove_zeros: bool = True):", "ground_truth": "                     ewgt: str = None, max_weight: float = 1.0,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # Fourth test. Multiple carries. Inverse values weight method.", "prediction_line": "    # Fourth test. Multiple carries. Inverse values weight method.", "ground_truth": "    basket_3.make_basket(weight_meth=\"equal\", max_weight=0.55, remove_zeros=True,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    basket_4.make_basket(weight_meth=\"inv_values\", ewgt=\"WBASE_NSA\", max_weight=0.55,", "prediction_line": "    basket_4.make_basket(weight_meth=\"inv_values\", ewgt=\"WBASE_NSA\", max_weight=0.55,", "ground_truth": "    basket_4.make_basket(weight_meth=\"values\", ewgt=\"WBASE_NSA\", max_weight=0.55,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   basket_3.make_basket(weight_meth=\"inv_values\", ewgt=\"WBASE_NSA\",", "prediction_line": "   basket_3.make_basket(weight_meth=\"inv_values\", ewgt=\"WBASE_NSA\",", "ground_truth": "    basket_3.make_basket(weight_meth=\"inv_values\", ewgt=\"WBASE_NSA\", max_weight=0.55,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    df = make_qdf(df_cids, df_xcats, 10000, 10000, 10000, 10000, 10000, 10000, 10000,", "prediction_line": "    df = make_qdf(df_cids, df_xcats, 10000, 10000, 10000, 10000, 10000, 10000, 10000,", "ground_truth": "    dfd = make_qdf(df_cids, df_xcats, back_ar=0.75)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                         basket_name=\"GLB_INVSMA\")", "prediction_line": "                         basket_name=\"GLB_INVSMA\")", "ground_truth": "                         max_weight=0.55, remove_zeros=True, basket_name=\"GLB_INVERSE\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        :param <pd.DataFrame> weight: wide dataframe of weights.", "prediction_line": "        :param <pd.DataFrame> weight: wide dataframe of weights.", "ground_truth": "        :param <pd.DataFrame> weight: weight dataframe.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    print(df_equal)", "prediction_line": "    print(df_equal)", "ground_truth": "    print(df_equal)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def make_basket(dfw_ret: pd.DataFrame, dfw_wgs: pd.DataFrame,", "prediction_line": "    def make_basket(dfw_ret: pd.DataFrame, dfw_wgs: pd.DataFrame,", "ground_truth": "    def column_manager(df_cat: pd.DataFrame, dfw_wgs: pd.DataFrame):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # Apply maximum weight cap.", "prediction_line": "        # Apply maximum weight cap.", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "    xcats = ['FX', 'FX']", "prediction_line": "    xcats = ['FX', 'FX']", "ground_truth": "    xcats = ['FXXR_NSA', 'FXCRY_NSA', 'FXCRR_NSA', 'EQXR_NSA', 'EQCRY_NSA', 'EQCRR_NSA',", "line_class": "random", "zero_context": true}
{"original_prediction": "        # Calculate the rolling standard deviation.", "prediction_line": "        # Calculate the rolling standard deviation.", "ground_truth": "        if lback_meth == \"ma\":", "line_class": "random", "zero_context": true}
{"original_prediction": "        dfxr[\"cid\"] = basket_name", "prediction_line": "        dfxr[\"cid\"] = basket_name", "ground_truth": "        basket_ret = basket_name + \"_\" + self.ret", "line_class": "random", "zero_context": true}
{"original_prediction": "                dfw_wgs = dfw_wgs.reindex(cols, axis=1)", "prediction_line": "                dfw_wgs = dfw_wgs.reindex(cols, axis=1)", "ground_truth": "                dfw_wgs_copy = dfw_wgs.copy()", "line_class": "random", "zero_context": true}
{"original_prediction": "                if var in oauth_var_names:", "prediction_line": "                if var in oauth_var_names:", "ground_truth": "                loaded_vars[var] = os.environ.get(f\"JPMAQS_API_{var.upper()}\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    config_dict = json.load(f)", "prediction_line": "                    config_dict = json.load(f)", "ground_truth": "                    config_dict = json.load(f)", "line_class": "common", "zero_context": true}
{"original_prediction": "            result = rec_search_dict(v, key, match_substring)", "prediction_line": "            result = rec_search_dict(v, key, match_substring)", "ground_truth": "            item = rec_search_dict(v, key, match_substring)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            creds_str = yaml.dump(self.credentials(mask=True))", "prediction_line": "            creds_str = yaml.dump(self.credentials(mask=True))", "ground_truth": "            creds_str = yaml.dump(self.credentials(mask=True))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if config_path is None:", "prediction_line": "        if config_path is None:", "ground_truth": "        proxy_vars: Optional[dict] = [proxy, proxies]", "line_class": "infile", "zero_context": true}
{"original_prediction": "   df = df.sort_values(by=idx_cols)", "prediction_line": "   df = df.sort_values(by=idx_cols)", "ground_truth": "    return standardise_dataframe(df)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Converts an ISO date string to a date query string.", "prediction_line": "    \"\"\"", "ground_truth": "    if is_valid_iso_date(date):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for k in self._credentials.keys():", "prediction_line": "        for k in self._credentials.keys():", "ground_truth": "        credentials: Dict[str, dict] = self.credentials(mask=mask)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            output_dict[\"cert\"] = credentials[\"cert\"]", "prediction_line": "            output_dict[\"cert\"] = credentials[\"cert\"]", "ground_truth": "            output_dict[\"cert\"] = credentials[\"cert\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            and (\"proxy\" in credentials.keys())", "prediction_line": "            and (\"proxy\" in credentials.keys())", "ground_truth": "            and (\"proxy\" in credentials.keys())", "line_class": "infile", "zero_context": true}
{"original_prediction": "            and (\"proxies\" in credentials.keys())", "prediction_line": "            and (\"proxies\" in credentials.keys())", "ground_truth": "            or (\"proxies\" in credentials.keys())", "line_class": "infile", "zero_context": true}
{"original_prediction": "            output_dict[\"proxies\"] = credentials[\"proxy\"]", "prediction_line": "            output_dict[\"proxies\"] = credentials[\"proxy\"]", "ground_truth": "            output_dict[\"proxy\"] = credentials[\"proxy\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if oauth_only:", "prediction_line": "        if oauth_only:", "ground_truth": "            output_dict[\"proxies\"] = credentials[\"proxies\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            creds_str = json.dumps(self._credentials, indent=2)", "prediction_line": "            creds_str = json.dumps(self._credentials, indent=2)", "ground_truth": "            creds_str = json.dumps(self.credentials(mask=True), indent=2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    loaded_vars[var] = rec_search_dict(config_dict, var)", "prediction_line": "                    loaded_vars[var] = rec_search_dict(config_dict, var)", "ground_truth": "                    loaded_vars[var] = rec_search_dict(config_dict, var, True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            output_dict[\"oauth\"] = credentials[\"oauth\"]", "prediction_line": "            output_dict[\"oauth\"] = credentials[\"oauth\"]", "ground_truth": "            output_dict[\"oauth\"] = credentials[\"oauth\"]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        token: Optional[str] = None,", "prediction_line": "        token: Optional[str] = None,", "ground_truth": "        proxy: Optional[dict] = None,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    loaded_vars[\"crt\"] = rec_search_dict(config_dict, \"crt_file\", True)", "prediction_line": "                    loaded_vars[\"crt\"] = rec_search_dict(config_dict, \"crt_file\", True)", "ground_truth": "                    loaded_vars[\"crt\"] = rec_search_dict(config_dict, \"cert\", True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert is_valid_iso_date(r), \"Date formatting failed\"", "prediction_line": "        assert is_valid_iso_date(r), \"Date formatting failed\"", "ground_truth": "        assert is_valid_iso_date(r), \"Date format incorrect\"", "line_class": "infile", "zero_context": true}
{"original_prediction": "        max(\n            [", "prediction_line": "        max(", "ground_truth": "        1 + max(map(get_dict_max_depth, d.values()), default=0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Class to store the configuration parameters for the JPMaQS API.", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        the wide_var should be \"cid\".", "prediction_line": "        the wide_var should be \"cid\".", "ground_truth": "        wide_var should be \"cid\", else \"xcat\" or \"real_date\" must be", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def _get_data_path() -> str:", "prediction_line": "def _get_data_path() -> str:", "ground_truth": "def get_dict_max_depth(d: dict) -> int:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def config_type(self) -> str:", "prediction_line": "    def config_type(self) -> str:", "ground_truth": "    def export_credentials(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            assert set(df.columns).issuperset(set(idx_cols)), fail_str", "prediction_line": "            assert set(df.columns).issuperset(set(idx_cols)), fail_str", "ground_truth": "            dft: pd.DataFrame = df.reset_index()", "line_class": "random", "zero_context": true}
{"original_prediction": "                            f\"{loaded_vars[pkx]}\"", "prediction_line": "                            f\"{loaded_vars[pkx]}\"", "ground_truth": "                            f\"{loaded_vars[pkx]}\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        return f\"JPMaQSAPIConfigObject(config_path={self._config_path}, config_type={self._config_type})\"", "prediction_line": "        return f\"JPMaQSAPIConfigObject(config_path={self._config_path}, config_type={self._config_type})\"", "ground_truth": "        return f\"JPMaQS API Config Object, methods : {list(self._credentials.keys())}\"", "line_class": "random", "zero_context": true}
{"original_prediction": "    df: pd.DataFrame,", "prediction_line": "    df: pd.DataFrame,", "ground_truth": "    df: pd.DataFrame,", "line_class": "random", "zero_context": true}
{"original_prediction": "rdict[\"client_secret\"])", "prediction_line": "rdict[\"client_secret\"])", "ground_truth": "                    self._credentials[\"oauth\"][\"client_secret\"]", "line_class": "random", "zero_context": true}
{"original_prediction": "            name=\"language\",", "prediction_line": "            name=\"language\",", "ground_truth": "            name=\"timezone\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ('core', '0001_initial'),", "prediction_line": "        ('core', '0001_initial'),", "ground_truth": "        (\"babybuddy\", \"0022_alter_settings_language\"),", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    ]\n\n    operations = [", "prediction_line": "    ]", "ground_truth": "    ]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    (\"Africa/Niamey\", \"Africa/Niamey\"),", "prediction_line": "                    (\"Africa/Niamey\", \"Africa/Niamey\"),", "ground_truth": "                    (\"Africa/Niamey\", \"Africa/Niamey\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                    (\"Africa/Bujumbura\", \"Africa/Bujumbura\"),", "prediction_line": "                    (\"Africa/Bujumbura\", \"Africa/Bujumbura\"),", "ground_truth": "                    (\"Africa/Bujumbura\", \"Africa/Bujumbura\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                    (\"Africa/Windhoek\", \"Africa/Windhoek\"),", "prediction_line": "                    (\"Africa/Windhoek\", \"Africa/Windhoek\"),", "ground_truth": "                    (\"Africa/Windhoek\", \"Africa/Windhoek\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                default=\"UTC\",", "prediction_line": "                default=\"UTC\",", "ground_truth": "                default=\"UTC\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                    (\"America/Managua\", \"America/Managua\"),", "prediction_line": "                    (\"America/Managua\", \"America/Managua\"),", "ground_truth": "                    (\"America/Managua\", \"America/Managua\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "            name=\"default_timezone\",", "prediction_line": "            name=\"default_timezone\",", "ground_truth": "            name=\"timezone\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ]\n\n    operations = [", "prediction_line": "    ]", "ground_truth": "    ]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from django.db import migrations, models", "prediction_line": "from django.db import migrations, models", "ground_truth": "from django.db import migrations, models", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        ('core', '0001_initial'),", "prediction_line": "        ('core', '0001_initial'),", "ground_truth": "        (\"babybuddy\", \"0025_auto_20221023_0821\"),", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    (\"Europe/Astrakhan\", \"Europe/Astrakhan\"),", "prediction_line": "                    (\"Europe/Astrakhan\", \"Europe/Astrakhan\"),", "ground_truth": "                    (\"Europe/Astrakhan\", \"Europe/Astrakhan\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                    (\"Africa/Sao_Tome\", \"Africa/Sao_Tome\"),", "prediction_line": "                    (\"Africa/Sao_Tome\", \"Africa/Sao_Tome\"),", "ground_truth": "                    (\"Africa/Sao_Tome\", \"Africa/Sao_Tome\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                    (\"Africa/Dakar\", \"Africa/Dakar\"),", "prediction_line": "                    (\"Africa/Dakar\", \"Africa/Dakar\"),", "ground_truth": "                    (\"Africa/Dakar\", \"Africa/Dakar\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                    (\"Asia/Urumqi\", \"Asia/Urumqi\"),", "prediction_line": "                    (\"Asia/Urumqi\", \"Asia/Urumqi\"),", "ground_truth": "                    (\"Asia/Urumqi\", \"Asia/Urumqi\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                    (\"Asia/Oral\", \"Asia/Oral\"),", "prediction_line": "                    (\"Asia/Oral\", \"Asia/Oral\"),", "ground_truth": "                    (\"Asia/Oral\", \"Asia/Oral\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "            name=\"timezone\",", "prediction_line": "            name=\"timezone\",", "ground_truth": "            name=\"timezone\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            name=\"default_timezone\",", "prediction_line": "            name=\"default_timezone\",", "ground_truth": "            name=\"language\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ]\n\n    operations = [", "prediction_line": "    ]", "ground_truth": "    ]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from django.db import migrations, models", "prediction_line": "from django.db import migrations, models", "ground_truth": "from django.db import migrations, models", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class Migration(migrations.Migration):", "prediction_line": "class Migration(migrations.Migration):", "ground_truth": "class Migration(migrations.Migration):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "# Generated by Django 4.2.2 on 2023-06-16 19:28", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    (\"pl\", \"Polish\"),", "prediction_line": "                    (\"pl\", \"Polish\"),", "ground_truth": "                    (\"pl\", \"Polish\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                    (\"Africa/Asmara\", \"Africa/Asmara\"),", "prediction_line": "                    (\"Africa/Asmara\", \"Africa/Asmara\"),", "ground_truth": "                    (\"Africa/Asmara\", \"Africa/Asmara\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                    (\"Asia/Hebron\", \"Asia/Hebron\"),", "prediction_line": "                    (\"Asia/Hebron\", \"Asia/Hebron\"),", "ground_truth": "                    (\"Asia/Hebron\", \"Asia/Hebron\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                    (\"Asia/Pontianak\", \"Asia/Pontianak\"),", "prediction_line": "                    (\"Asia/Pontianak\", \"Asia/Pontianak\"),", "ground_truth": "                    (\"Asia/Pontianak\", \"Asia/Pontianak\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "                    (\"Pacific/Palau\", \"Pacific/Palau\"),", "prediction_line": "                    (\"Pacific/Palau\", \"Pacific/Palau\"),", "ground_truth": "                    (\"Pacific/Palau\", \"Pacific/Palau\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "        super(Insight, self).__init__(*args, **kwargs)", "prediction_line": "        super(Insight, self).__init__(*args, **kwargs)", "ground_truth": "        super(Insight, self).__init__(*args, **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return self.delete(url)", "prediction_line": "        return self.delete(url)", "ground_truth": "        return self.delete(url)", "line_class": "common", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Get the workspace id for the current user.", "prediction_line": "        \"\"\"", "ground_truth": "        return self.get(\"rest/servicedeskapi/insight/workspace\", headers=self.default_headers,)[\"values\"][", "line_class": "common", "zero_context": true}
{"original_prediction": "        return self.post(url)", "prediction_line": "        return self.post(url)", "ground_truth": "        return self.post(url)", "line_class": "common", "zero_context": true}
{"original_prediction": "        return self.get(url)", "prediction_line": "        return self.get(url)", "ground_truth": "        return self.get(url)", "line_class": "common", "zero_context": true}
{"original_prediction": "        return self.post(url, params=params)", "prediction_line": "        return self.post(url, params=params)", "ground_truth": "        return self.post(url, params=params)", "line_class": "common", "zero_context": true}
{"original_prediction": "        if kwargs.get(\"cloud\"):", "prediction_line": "        if kwargs.get(\"cloud\"):", "ground_truth": "        if kwargs.get(\"cloud\"):", "line_class": "common", "zero_context": true}
{"original_prediction": "            return self.post(url, files=files)", "prediction_line": "            return self.post(url, files=files)", "ground_truth": "            return self.post(url, headers=self.no_check_headers, files=files)", "line_class": "common", "zero_context": true}
{"original_prediction": "        return self.get(url, params=params)", "prediction_line": "        return self.get(url, params=params)", "ground_truth": "        return self.get(url, params=params)", "line_class": "common", "zero_context": true}
{"original_prediction": "        if self.cloud:", "prediction_line": "        if self.cloud:", "ground_truth": "        params = {\"iql\": iql, \"objectSchemaId\": object_schema_id, \"page\": page}", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.__cloud__init(*args, **kwargs)", "prediction_line": "            self.__cloud__init(*args, **kwargs)", "ground_truth": "            args, kwargs = self.__cloud_init(*args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        query,\n        start=0,", "prediction_line": "        query,", "ground_truth": "        iql,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        super(Insight, self).__init__(*args, **kwargs)", "prediction_line": "        super(Insight, self).__init__(*args, **kwargs)", "ground_truth": "        temp = Insight(*args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        cloud_workspace_id = temp.get_cloud_workspace_id()", "prediction_line": "        cloud_workspace_id = temp.get_cloud_workspace_id()", "ground_truth": "        kwargs[\"api_root\"] = \"/jsm/insight/workspace/{}/v1/\".format(temp.__get_workspace_id())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        url = self.url_joiner(self.api_root, \"attachments/object/{objectId}\".format(objectId=object_id))", "prediction_line": "        url = self.url_joiner(self.api_root, \"attachments/object/{objectId}\".format(objectId=object_id))", "ground_truth": "        log.warning(\"Adding attachment...\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        url = self.url_joiner(self.api_root, \"index/reindex\")", "prediction_line": "        url = self.url_joiner(self.api_root, \"index/reindex\")", "ground_truth": "        url = self.url_joiner(self.api_root, \"index/reindex/start\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if self.cloud:", "prediction_line": "        if self.cloud:", "ground_truth": "        url = self.url_joiner(self.api_root, \"icon/{id}\".format(id=id))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        url = self.url_joiner(self.api_root, \"comments/object/{objectId}\".format(objectId=object_id))", "prediction_line": "        url = self.url_joiner(self.api_root, \"comments/object/{objectId}\".format(objectId=object_id))", "ground_truth": "        params = {\"comment\": comment, \"objectId\": object_id, \"role\": role}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "(\"Cloud does not support attachments\")", "prediction_line": "(\"Cloud does not support attachments\")", "ground_truth": "        url = self.url_joiner(self.api_root, \"attachments/object/{objectId}\".format(objectId=object_id))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        url = self.url_joiner(self.api_root, \"icon/global\")", "prediction_line": "        url = self.url_joiner(self.api_root, \"icon/global\")", "ground_truth": "        url = self.url_joiner(self.api_root, \"icon/global\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        url = self.url_joiner(self.api_root, \"index/reindex/currentNode\")", "prediction_line": "        url = self.url_joiner(self.api_root, \"index/reindex/currentNode\")", "ground_truth": "        url = self.url_joiner(self.api_root, \"index/reindex/currentnode\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        url = self.url_joiner(self.api_root, \"iql\")", "prediction_line": "        url = self.url_joiner(self.api_root, \"iql\")", "ground_truth": "        url = self.url_joiner(self.api_root, \"iql/objects\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Get Comment info", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        :return:", "prediction_line": "        :return:", "ground_truth": "        :return list of object", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            mimeType: (string)", "prediction_line": "            mimeType: (string)", "ground_truth": "            mimeType: (string)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        :param include_attributes_deep:", "prediction_line": "        :param include_attributes_deep:", "ground_truth": "        :param include_attributes_deep:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        include_relationships=False,", "prediction_line": "        include_relationships=False,", "ground_truth": "        extended=None,", "line_class": "random", "zero_context": true}
{"original_prediction": "            raise NotImplementedError", "prediction_line": "            raise NotImplementedError", "ground_truth": "            raise NotImplementedError", "line_class": "random", "zero_context": true}
{"original_prediction": "        kwargs[\"cloud\"] = True", "prediction_line": "        kwargs[\"cloud\"] = True", "ground_truth": "        kwargs[\"cloud\"] = True", "line_class": "random", "zero_context": true}
{"original_prediction": "        url = \"rest/insight/1.0/attachments/{attachmentId}\".format(attachmentId=attachment_id)", "prediction_line": "        url = \"rest/insight/1.0/attachments/{attachmentId}\".format(attachmentId=attachment_id)", "ground_truth": "        url = \"rest/insight/1.0/attachments/{attachmentId}\".format(attachmentId=attachment_id)", "line_class": "random", "zero_context": true}
{"original_prediction": "        res = session.get(", "prediction_line": "        res = session.get(", "ground_truth": "        res = session.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "        session.headers.update(API_HEADERS)", "prediction_line": "        session.headers.update(API_HEADERS)", "ground_truth": "        session.headers.update(API_HEADERS)", "line_class": "common", "zero_context": true}
{"original_prediction": "    Abfuhrplaene: List[CollectionPlan]", "prediction_line": "    Abfuhrplaene: List[CollectionPlan]", "ground_truth": "    Abfuhrplan: CollectionPlan", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for entry in res.json()[\"value\"]:", "prediction_line": "        for entry in res.json()[\"value\"]:", "ground_truth": "        payload: CollectionsRes = res.json()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        payload: DistrictsRes = res.json()", "prediction_line": "        payload: DistrictsRes = res.json()", "ground_truth": "        payload: DistrictsRes = res.json()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    d: List[CollectionRes]", "prediction_line": "    d: List[CollectionRes]", "ground_truth": "    d: List[CollectionRes]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    d: List[DistrictRes]", "prediction_line": "    d: List[DistrictRes]", "ground_truth": "    d: List[DistrictRes]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Get all waste types", "prediction_line": "        # Get all waste types", "ground_truth": "        district_id = self.fetch_district_id(session)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if district_id is None:", "prediction_line": "        if district_id is None:", "ground_truth": "        street_id = self.fetch_street_id(session, district_id)", "line_class": "infile", "zero_context": true}
{"original_prediction": "\"orteId\": district_id},", "prediction_line": "\"orteId\": district_id},", "ground_truth": "                \"$filter\": f\"Ort/OrteId eq {district_id} and OrtsteilName eq {quote_none(self.subdistrict)}\",", "line_class": "infile", "zero_context": true}
{"original_prediction": "    Aktiv: None", "prediction_line": "    Aktiv: None", "ground_truth": "    Volumen: Capacity", "line_class": "infile", "zero_context": true}
{"original_prediction": "    Abfallart: WasteType", "prediction_line": "    Abfallart: WasteType", "ground_truth": "    Abfallart: WasteType", "line_class": "infile", "zero_context": true}
{"original_prediction": "    d: List[StreetRes]", "prediction_line": "    d: List[StreetRes]", "ground_truth": "    d: List[StreetRes]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        payload: StreetsRes = res.json()", "prediction_line": "        payload: StreetsRes = res.json()", "ground_truth": "        payload: StreetsRes = res.json()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    AbfuhrplaeneArt: int", "prediction_line": "    AbfuhrplaeneArt: int", "ground_truth": "    GefaesstarifArt: ContainerType", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._url = url", "prediction_line": "        self._url = url", "ground_truth": "        self.api_url = f\"{url.removesuffix('/')}/api\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                date = datetime.fromtimestamp(timestamp)", "prediction_line": "                date = datetime.fromtimestamp(timestamp)", "ground_truth": "                date = datetime.utcfromtimestamp(timestamp / 1000).date()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                entries.append(", "prediction_line": "                entries.append(", "ground_truth": "                waste_type = collection[\"Abfuhrplan\"][\"GefaesstarifArt\"][\"Abfallart\"][", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        month = datetime.now().month", "prediction_line": "        month = datetime.now().month", "ground_truth": "        entries: list[Collection] = []", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                waste_volume = collection[\"Abfuhrplan\"][\"GefaesstarifArt\"][\"Volumen\"][", "prediction_line": "                waste_volume = collection[\"Abfuhrplan\"][\"GefaesstarifArt\"][\"Volumen\"][", "ground_truth": "                icon = None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if icon_type in waste_type.lower():", "prediction_line": "                    if icon_type in waste_type.lower():", "ground_truth": "                    if icon_type.lower() in waste_type.lower():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return f'\"{value}\"' if value else \"null\"", "prediction_line": "    return f'\"{value}\"' if value else \"null\"", "ground_truth": "    if value is None:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        icon = tested_icon", "prediction_line": "                        icon = tested_icon", "ground_truth": "                        icon = tested_icon", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                       break\n\n                entries.append(", "prediction_line": "                       break", "ground_truth": "                entries.append(Collection(date, waste_type, icon or \"mdi:trash-can\"))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   return f'\"{value}\"'", "prediction_line": "   return f'\"{value}\"'", "ground_truth": "    return f\"'{value}'\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return entries", "prediction_line": "        return entries", "ground_truth": "        if len(entries) == 0:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        url: str,", "prediction_line": "        url: str,", "ground_truth": "        url: str,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return entries", "prediction_line": "        return entries", "ground_truth": "        return entries", "line_class": "inproject", "zero_context": true}
{"original_prediction": "class ServiceArea(TypedDict):", "prediction_line": "class ServiceArea(TypedDict):", "ground_truth": "def quote_none(value: Optional[str]) -> str:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    #     \"service_area\": \"Cochem-Zell\",", "prediction_line": "    #     \"service_area\": \"Cochem-Zell\",", "ground_truth": "    #     \"district\": \"Bullay\",", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class Source:", "prediction_line": "class Source:", "ground_truth": "API_HEADERS = {", "line_class": "random", "zero_context": true}
{"original_prediction": "    d: List[District]", "prediction_line": "    d: List[District]", "ground_truth": "    OrteId: int", "line_class": "random", "zero_context": true}
{"original_prediction": "class Arguments(TypedDict):", "prediction_line": "class Arguments(TypedDict):", "ground_truth": "ICONS = {", "line_class": "random", "zero_context": true}
{"original_prediction": "            if entry[\"Name\"] == self.district", "prediction_line": "            if entry[\"Name\"] == self.district", "ground_truth": "            if entry[\"Ortsname\"] == self.district", "line_class": "random", "zero_context": true}
{"original_prediction": "    StrassenId: int", "prediction_line": "    StrassenId: int", "ground_truth": "    StrassenId: int", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"118\": \"mdi:recycle\",  # Gelbe Säcke", "prediction_line": "            \"118\": \"mdi:recycle\",  # Gelbe Säcke", "ground_truth": "            \"122\": \"mdi:tree\",  # Gartenabraum", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    {\n        \"hpid\": 442,", "prediction_line": "    {", "ground_truth": "    {", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            \"66\": \"mdi:package-variant\",  # Papiertonne", "prediction_line": "            \"66\": \"mdi:package-variant\",  # Papiertonne", "ground_truth": "            \"66\": \"mdi:package-variant\",  # Papiertonne", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            \"93\": \"mdi:trash-can\",  # Restmülltonne", "prediction_line": "            \"93\": \"mdi:trash-can\",  # Restmülltonne", "ground_truth": "            \"103\": \"mdi:biohazard\",  # Schadstoffmobil", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"hpid\": 226,", "prediction_line": "        \"hpid\": 226,", "ground_truth": "        \"hpid\": 233,", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"icons\": {", "prediction_line": "        \"icons\": {", "ground_truth": "        \"icons\": {", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"name\": \"www.schwaebischhall.de - Müllkalender\",", "prediction_line": "        \"name\": \"www.schwaebischhall.de - Müllkalender\",", "ground_truth": "        \"name\": \"kraichtal.de - Müllkalender 1\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"162\": \"mdi:truck-flatbed\",  # Sondermüll Sondermüll-Parkplatz", "prediction_line": "            \"162\": \"mdi:truck-flatbed\",  # Sondermüll Sondermüll-Parkplatz", "ground_truth": "        },", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"name\": \"www.kraichtal.de - Müllkalender 2\",", "prediction_line": "        \"name\": \"www.kraichtal.de - Müllkalender 2\",", "ground_truth": "        \"name\": \"Messstetten App - Müllkalender\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            #sema.release()", "prediction_line": "            #sema.release()", "ground_truth": "            \"\"\" wasteschedule=requests.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "                #if used characters add a addresslist to checked list and check aggainst checked_list", "prediction_line": "                #if used characters add a addresslist to checked list and check aggainst checked_list", "ground_truth": "                adresslist=requests.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "                    response = requests.post(API_URLS[\"address_search\"], data=payload_str, headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:88.0) Gecko/20100101 Firefox/88.0\"})", "prediction_line": "                    response = requests.post(API_URLS[\"address_search\"], data=payload_str, headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:88.0) Gecko/20100101 Firefox/88.0\"})", "ground_truth": "                    wasteschedule=requests.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "        #sema = threading.Semaphore(10)", "prediction_line": "        #sema = threading.Semaphore(10)", "ground_truth": "            waste_searcher(line)", "line_class": "infile", "zero_context": true}
{"original_prediction": "parser.add_argument('--postal_code', type=str, required=False)", "prediction_line": "parser.add_argument('--postal_code', type=str, required=False)", "ground_truth": "args = parser.parse_args()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "#sema = threading.Semaphore(10)", "prediction_line": "#sema = threading.Semaphore(10)", "ground_truth": "if args.street or args.city:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if args.street:", "prediction_line": "    if args.street:", "ground_truth": "elif args.used_char:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    used_char = args.used_char.split(\",\")", "prediction_line": "    used_char = args.used_char.split(\",\")", "ground_truth": "    used_char = list(args.used_char)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "for line in checked_addresses:", "prediction_line": "for line in checked_addresses:", "ground_truth": "if args.city and args.street:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if args.street in line and args.city in line:", "prediction_line": "        if args.street in line and args.city in line:", "ground_truth": "          if args.city.lower() in line and args.street.lower() in line:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "elif args.street:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "          if args.street.lower() in line:", "prediction_line": "          if args.street.lower() in line:", "ground_truth": "          if args.street.lower() in line:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "elif args.city:", "prediction_line": "elif args.city:", "ground_truth": "elif args.city:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "          if args.city.lower() in line:", "prediction_line": "          if args.city.lower() in line:", "ground_truth": "          if args.city.lower() in line:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "parser.add_argument(\"-a\", \"--address\", help=\"Address to search for\", required=True)", "prediction_line": "parser.add_argument(\"-a\", \"--address\", help=\"Address to search for\", required=True)", "ground_truth": "parser.add_argument('--street', type=str, required=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "parser.add_argument('--zip', type=str, required=False)", "prediction_line": "parser.add_argument('--zip', type=str, required=False)", "ground_truth": "parser.add_argument('--city', type=str, required=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "parser.add_argument('--zip', type=str, required=False)", "prediction_line": "parser.add_argument('--zip', type=str, required=False)", "ground_truth": "parser.add_argument('--used_char', type=str, required=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "for line in checked_addresses:", "prediction_line": "for line in checked_addresses:", "ground_truth": "sema = threading.Semaphore(value=maxthreads)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"HKARL2-H\": \"Fyrfackskärl 2 - Helgvecka\", # Förpackningar av Papper, Plast & Metall samt Ofärgat glas", "prediction_line": "    \"HKARL2-H\": \"Fyrfackskärl 2 - Helgvecka\", # Förpackningar av Papper, Plast & Metall samt Ofärgat glas", "ground_truth": "    \"HKARL2-H\": \"Fyrfackskärl 2 - Helgvecka\", # Förpackningar av Papper, Plast & Metall samt Ofärgat glas", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"HGLAS\": \"Färgat glas\",", "prediction_line": "    \"HGLAS\": \"Färgat glas\",", "ground_truth": "    'FKARL1': \"Fyrfackskärl 1\",  # Matavfall, Restavfall, Tidningar & Färgat glas", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            try:\n                response = requests.post(API_URLS[\"address_search\"], data=payload)", "prediction_line": "            try:", "ground_truth": "            payload_str=urllib.parse.urlencode(payload, encoding=\"cp1252\")", "line_class": "random", "zero_context": true}
{"original_prediction": "                    if exc.response.status_code in retry_codes:", "prediction_line": "                    if exc.response.status_code in retry_codes:", "ground_truth": "                    code = exc.wasteschedule.status_code", "line_class": "random", "zero_context": true}
{"original_prediction": "                        checked_addresses.append(line.strip(\"\\n\"))", "prediction_line": "                        checked_addresses.append(line.strip(\"\\n\"))", "ground_truth": "                        checked_addresses.append(line)", "line_class": "random", "zero_context": true}
{"original_prediction": "for line in checked_addresses:", "prediction_line": "for line in checked_addresses:", "ground_truth": "maxthreads = 10", "line_class": "random", "zero_context": true}
{"original_prediction": "    #print(checked_addresses)", "prediction_line": "    #print(checked_addresses)", "ground_truth": "                ", "line_class": "random", "zero_context": true}
{"original_prediction": "        response = requests.post(self._search_url, data=args)", "prediction_line": "        response = requests.post(self._search_url, data=args)", "ground_truth": "        r = requests.get(self._api_url)", "line_class": "common", "zero_context": true}
{"original_prediction": "            if i.get(\"name\") == \"hidden_id_ort\":", "prediction_line": "            if i.get(\"name\") == \"hidden_id_ort\":", "ground_truth": "            if i.get(\"name\").startswith(\"showBins\"):", "line_class": "common", "zero_context": true}
{"original_prediction": "                r = requests.post(self._search_url+\"search_hnr.php\", data=replace_special_chars_args(args), params={", "prediction_line": "                r = requests.post(self._search_url+\"search_hnr.php\", data=replace_special_chars_args(args), params={", "ground_truth": "                r = requests.post(self._search_url+\"search_hnr.php\",", "line_class": "common", "zero_context": true}
{"original_prediction": "        for elem in li.find_all(\"a\"):", "prediction_line": "        for elem in li.find_all(\"a\"):", "ground_truth": "        onclick = li.get(\"onclick\")", "line_class": "common", "zero_context": true}
{"original_prediction": "            ids = self._get_elemts(r.text)", "prediction_line": "            ids = self._get_elemts(r.text)", "ground_truth": "            ids = self._get_elemts(r.text)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            to_return[replace_special_chars(k)] = [replace_special_chars(x) for x in v]", "prediction_line": "            to_return[replace_special_chars(k)] = [replace_special_chars(x) for x in v]", "ground_truth": "            to_return[k] = [replace_special_chars(i) for i in v]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            to_return[k] = replace_special_chars(v)", "prediction_line": "            to_return[k] = replace_special_chars(v)", "ground_truth": "            to_return[k] = replace_special_chars(v)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                                  params={\"input\": self._ort, \"ort_id\": \"0\"})", "prediction_line": "                                  params={\"input\": self._ort, \"ort_id\": \"0\"})", "ground_truth": "                                  params={\"input\": replace_special_chars(self._ort), \"ort_id\": \"0\"})", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def _get_ics_url(self) -> str:", "prediction_line": "    def _get_ics_url(self) -> str:", "ground_truth": "        self._ics = ICS()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        params = {", "prediction_line": "        params = {", "ground_truth": "        args = {", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            r = requests.post(self._search_url + \"search_hnr.php\", data=args, params={", "prediction_line": "            r = requests.post(self._search_url + \"search_hnr.php\", data=args, params={", "ground_truth": "            args[\"input\"] = self._hausnummer", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return dates", "prediction_line": "        return dates", "ground_truth": "        entries = []", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                r = requests.post(self._search_url + \"search_strassen.php\", data=replace_special_chars_args(args), params={", "prediction_line": "                r = requests.post(self._search_url + \"search_strassen.php\", data=replace_special_chars_args(args), params={", "ground_truth": "                r = requests.post(self._search_url + \"search_strassen.php\", data=replace_special_chars_args(args), params={", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            r = requests.get(self._search_url, params=args)", "prediction_line": "            r = requests.get(self._search_url, params=args)", "ground_truth": "            r = requests.post(self._search_url+\"search_orte.php\", data=args,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            args[\"hidden_id_str\"] = args[\"str_id\"] = ids[0]", "prediction_line": "            args[\"hidden_id_str\"] = args[\"str_id\"] = ids[0]", "ground_truth": "            args[\"hidden_id_str\"] = args[\"str_id\"] = ids[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       r = requests.post(self._ics_url, data=args)", "prediction_line": "       r = requests.post(self._ics_url, data=args)", "ground_truth": "        r = requests.post(self._search_url+\"check_zusatz.php\", data=args)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            args[\"hidden_id_ortsteil\"] = args[\"ortteil_id\"] = ids[0]", "prediction_line": "            args[\"hidden_id_ortsteil\"] = args[\"ortteil_id\"] = ids[0]", "ground_truth": "            args[\"hidden_id_ortsteil\"] = args[\"hidden_id_ort\"] if ids[0] == \"0\" else ids[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            r = requests.post(self._search_url, data=replace_special_chars_args(args))", "prediction_line": "            r = requests.post(self._search_url, data=replace_special_chars_args(args))", "ground_truth": "            args[\"input\"] = self._ort", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                              \"input\": self._hausnummer, \"hnr_id\": \"0\", \"ort_id\": args[\"ort_id\"]})", "prediction_line": "                              \"input\": self._hausnummer, \"hnr_id\": \"0\", \"ort_id\": args[\"ort_id\"]})", "ground_truth": "                              \"input\": self._hausnummer, \"hnr_id\": \"0\", \"str_id\": args[\"str_id\"]})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            args[\"hidden_id_hnr\"] = args[\"hnr_id\"] = ids[0]", "prediction_line": "            args[\"hidden_id_hnr\"] = args[\"hnr_id\"] = ids[0]", "ground_truth": "            args[\"hidden_id_hnr\"] = args[\"hnr_id\"] = ids[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "class Source:", "prediction_line": "class Source:", "ground_truth": "EXTRA_INFO = [{\"title\": p[\"title\"], \"url\": p[\"url\"], \"country\": \"de\"}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return entries", "prediction_line": "        return entries", "ground_truth": "        return entries", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        r = requests.post(self._ics_url, data=args)", "prediction_line": "        r = requests.post(self._ics_url, data=args)", "ground_truth": "        r = requests.post(self._ics_url, data=args)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "class Source:\n    def __init__(self, city_name: str, city_name_replace: str, subdomain: str, ortsteil: str = None):", "prediction_line": "class Source:", "ground_truth": "def replace_special_chars_args(d: dict) -> dict:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    {\n        \"subdomain\": \"ew\",", "prediction_line": "    {", "ground_truth": "    {", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"wesel, Flüren, In der Flürener Heide\": {", "prediction_line": "    \"wesel, Flüren, In der Flürener Heide\": {", "ground_truth": "}", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from waste_collection_schedule.service.ICS import ICS", "prediction_line": "from waste_collection_schedule.service.ICS import ICS", "ground_truth": "from waste_collection_schedule.service.ICS import ICS", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"subdomain\": \"azv\",", "prediction_line": "        \"subdomain\": \"azv\",", "ground_truth": "        \"subdomain\": \"azv\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"azv, Dornheim\": {", "prediction_line": "    \"azv, Dornheim\": {", "ground_truth": "    \"azv, Hörselberg-Hainich\": {", "line_class": "random", "zero_context": true}
{"original_prediction": "    },\n    {", "prediction_line": "    },", "ground_truth": "    },", "line_class": "random", "zero_context": true}
{"original_prediction": "        self._ics.content = r.text", "prediction_line": "        self._ics.content = r.text", "ground_truth": "        r.raise_for_status()", "line_class": "random", "zero_context": true}
{"original_prediction": "        r = requests.post(self._search_url, data=args)", "prediction_line": "        r = requests.post(self._search_url, data=args)", "ground_truth": "        if self._ort:", "line_class": "random", "zero_context": true}
{"original_prediction": "                # Get the properties", "prediction_line": "                # Get the properties", "ground_truth": "                return_type = get_type_hints(h.execute)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                docs.hooks.append(", "prediction_line": "                docs.hooks.append(", "ground_truth": "                hook_doc = HookDoc(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    hook_type=h.__name__,", "prediction_line": "                    hook_type=h.__name__,", "ground_truth": "                    properties=get_hook_properties(schema),", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    arguments=get_hook_arguments(h),", "prediction_line": "                    arguments=get_hook_arguments(h),", "ground_truth": "                    arguments=get_hook_arguments(h),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    hook_name: str = \"\"", "prediction_line": "    hook_name: str = \"\"", "ground_truth": "    properties: List[HookDocField]", "line_class": "infile", "zero_context": true}
{"original_prediction": "= []\n    args: List[HookArgField] = []", "prediction_line": "= []", "ground_truth": "    arguments: List[HookArgField]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            HookArgField(", "prediction_line": "            HookArgField(", "ground_truth": "            HookArgField(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Bypass anyOf", "prediction_line": "        # Bypass anyOf", "ground_truth": "        hook_doc = HookDocField(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    description: str = None", "prediction_line": "    description: str = None", "ground_truth": "    hooks: List[HookDoc] = []", "line_class": "infile", "zero_context": true}
{"original_prediction": "        docs = ProviderDocs(", "prediction_line": "        docs = ProviderDocs(", "ground_truth": "        docs = ProviderDocs(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        hook_arg = HookArgField(", "prediction_line": "        hook_arg = HookArgField(", "ground_truth": "        output.append(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                docs.hooks.append(hook_doc)", "prediction_line": "                docs.hooks.append(hook_doc)", "ground_truth": "                docs.hooks.append(hook_doc)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if issubclass(i[1], BaseHook) and i[1].hook_type != 'provider_docs'", "prediction_line": "                if issubclass(i[1], BaseHook) and i[1].hook_type != 'provider_docs'", "ground_truth": "                if issubclass(i[1], BaseHook) and i[1] != BaseHook", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            with open('requirements.txt') as f:", "prediction_line": "            with open('requirements.txt') as f:", "ground_truth": "            with open('requirements.txt') as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                requirements = f.readlines()", "prediction_line": "                requirements = f.readlines()", "ground_truth": "                requirements = f.readlines()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        output.append(hook_doc)", "prediction_line": "        output.append(hook_doc)", "ground_truth": "        output.append(hook_doc)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    properties = []", "prediction_line": "    properties = []", "ground_truth": "    basehook_properties = json.loads(BaseHook(hook_type='tmp').schema_json())[", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def get_hook_doc(hook: BaseHook) -> HookDoc:", "prediction_line": "def get_hook_doc(hook: BaseHook) -> HookDoc:", "ground_truth": "class ProviderDocsHook(BaseHook):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # Bypass anyOf", "prediction_line": "        # Bypass anyOf", "ground_truth": "        # Type is dealt with elsewhere", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    # fmt: on", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"Get the input params for a hook.\"\"\"", "prediction_line": "    \"\"\"Get the input params for a hook.\"\"\"", "ground_truth": "    \"\"\"Get the arguments for a hook.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class Provider(BaseModel):", "prediction_line": "class Provider(BaseModel):", "ground_truth": "from tackle.models import BaseHook", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    name: str", "prediction_line": "    name: str", "ground_truth": "    name: str", "line_class": "random", "zero_context": true}
{"original_prediction": "                else:\n                    return_type = None", "prediction_line": "                else:", "ground_truth": "                    if isinstance(return_type, _GenericAlias):", "line_class": "random", "zero_context": true}
{"original_prediction": "        else:\n            type = hook.__fields__[i].type_", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "                type=type,", "prediction_line": "                type=type,", "ground_truth": "                type=type,", "line_class": "random", "zero_context": true}
{"original_prediction": "                os.path.dirname(os.path.abspath(__file__)), 'templates'", "prediction_line": "                os.path.dirname(os.path.abspath(__file__)), 'templates'", "ground_truth": "                os.path.dirname(__file__), '..', 'templates'", "line_class": "random", "zero_context": true}
{"original_prediction": "                context.private_hooks[hook_type] = LazyBaseFunction(", "prediction_line": "                context.private_hooks[hook_type] = LazyBaseFunction(", "ground_truth": "                context.private_hooks[hook_type] = LazyBaseFunction(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        hook_func = getattr(", "prediction_line": "        hook_func = getattr(", "ground_truth": "        return kwargs['provider_hooks'][self.hook_type].wrapped_exec()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    for provider_path in get_native_provider_paths():", "prediction_line": "    for provider_path in get_native_provider_paths():", "ground_truth": "    native_provider_paths = get_native_provider_paths()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                context.public_hooks[hook_type] = LazyImportHook(", "prediction_line": "                context.public_hooks[hook_type] = LazyImportHook(", "ground_truth": "                context.public_hooks[hook_type] = LazyBaseFunction(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            context.provider_hooks.add_hook_type(h, provider_name)", "prediction_line": "            context.provider_hooks.add_hook_type(h, provider_name)", "ground_truth": "            hook = LazyImportHook(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        os.path.join(providers_path, p)", "prediction_line": "        os.path.join(providers_path, p)", "ground_truth": "        os.path.join(providers_path, f)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for f in os.listdir(providers_path)", "prediction_line": "        for f in os.listdir(providers_path)", "ground_truth": "        for f in os.listdir(providers_path)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if os.path.isdir(os.path.join(providers_path, f))", "prediction_line": "        if os.path.isdir(os.path.join(providers_path, f))", "ground_truth": "        if os.path.isdir(os.path.join(providers_path, f)) and f != '__pycache__'", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        hook_dict = read_config_file(file_path)", "prediction_line": "        hook_dict = read_config_file(file_path)", "ground_truth": "        file_contents = read_config_file(file_path)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if not os.path.isdir(path):", "prediction_line": "    if not os.path.isdir(path):", "ground_truth": "    potential_hooks = listdir_absolute(path)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    for i in potential_hooks:", "prediction_line": "    for i in potential_hooks:", "ground_truth": "    for f in potential_hooks:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # Import python hooks", "prediction_line": "    # Import python hooks", "ground_truth": "    # TODO: RM after dealing with namespace issue for validators", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # RUN_ID = ''.join(random.choice(string.ascii_lowercase) for i in range(10))", "prediction_line": "    # RUN_ID = ''.join(random.choice(string.ascii_lowercase) for i in range(10))", "ground_truth": "    # _run_id = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(4))", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "if TYPE_CHECKING:", "prediction_line": "if TYPE_CHECKING:", "ground_truth": "# import random", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            )\n            import_hooks_from_dir(context, mod_name, path, skip_on_error)", "prediction_line": "            )", "ground_truth": "            )", "line_class": "random", "zero_context": true}
{"original_prediction": "        ):\n            hook_type = v.__fields__['hook_type'].default", "prediction_line": "        ):", "ground_truth": "        ):", "line_class": "random", "zero_context": true}
{"original_prediction": "        return\n\n    if file_extension == 'py':", "prediction_line": "        return", "ground_truth": "        return", "line_class": "random", "zero_context": true}
{"original_prediction": "                hook_type=h,", "prediction_line": "                hook_type=h,", "ground_truth": "                hook_type=h,", "line_class": "random", "zero_context": true}
{"original_prediction": "                [sys.executable, '-m', 'pip', 'install', '-r', requirements_path]", "prediction_line": "                [sys.executable, '-m', 'pip', 'install', '-r', requirements_path]", "ground_truth": "                [", "line_class": "random", "zero_context": true}
{"original_prediction": "    o = main('a_funky', 'func_method')", "prediction_line": "    o = main('a_funky', 'func_method')", "ground_truth": "    main(['a_funky'])", "line_class": "common", "zero_context": true}
{"original_prediction": "    output = tackle('method-no-default.yaml')", "prediction_line": "    output = tackle('method-no-default.yaml')", "ground_truth": "    o = tackle('method-call-no-default.yaml')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        expected_output = yaml.load(f)", "prediction_line": "        expected_output = yaml.load(f)", "ground_truth": "        expected_output_dict = yaml.load(f)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    os.chdir('func-provider')", "prediction_line": "    os.chdir('func-provider')", "ground_truth": "    os.chdir(os.path.join('func-provider-hook', 'a-dir'))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   os.chdir(os.path.join('func-provider-method', 'a-dir'))", "prediction_line": "   os.chdir(os.path.join('func-provider-method', 'a-dir'))", "ground_truth": "    os.chdir(os.path.join('func-provider-method', 'a-dir'))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    output = tackle('method-args.yaml')", "prediction_line": "    output = tackle('method-args.yaml')", "ground_truth": "    output = tackle('method-args.yaml')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    output = tackle('return-no-exec.yaml')", "prediction_line": "    output = tackle('return-no-exec.yaml')", "ground_truth": "    output = tackle('no-exec.yaml')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    output = tackle('method-embed.yaml')", "prediction_line": "    output = tackle('method-embed.yaml')", "ground_truth": "    output = tackle('method-embed.yaml')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    chdir('method-fixtures')", "prediction_line": "    chdir('method-fixtures')", "ground_truth": "    chdir('method-fixtures')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    output = tackle('import-func-from-hooks-dir.yaml')", "prediction_line": "    output = tackle('import-func-from-hooks-dir.yaml')", "ground_truth": "    os.chdir('func-provider')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    output = tackle('method-hook-simple.yaml')", "prediction_line": "    output = tackle('method-hook-simple.yaml')", "ground_truth": "    output = tackle('method-single.yaml')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    output = tackle(no_input=True, context_file=fixture)", "prediction_line": "    output = tackle(no_input=True, context_file=fixture)", "ground_truth": "    with open(expected_output) as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    o = tackle('a_funky', a_field='an-arg')", "prediction_line": "    o = tackle('a_funky', a_field='an-arg')", "ground_truth": "    o = tackle('a_funky', 'func_method')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    output = tackle('method-call-from-default.yaml')", "prediction_line": "    output = tackle('method-call-from-default.yaml')", "ground_truth": "    output = tackle('method-call-from-default.yaml', target='foo')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    output = tackle('method-maintain-context.yaml')", "prediction_line": "    output = tackle('method-maintain-context.yaml')", "ground_truth": "    output = tackle('method-maintain-context.yaml')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    o = tackle(a_field='an-arg', a_field_2='an-arg-2')", "prediction_line": "    o = tackle(a_field='an-arg', a_field_2='an-arg-2')", "ground_truth": "    o = tackle('a_funky')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_function_import_func_from_hooks_dir_call_in_tackle_with_args(change_curdir_fixtures):", "prediction_line": "def test_function_import_func_from_hooks_dir_call_in_tackle_with_args(change_curdir_fixtures):", "ground_truth": "def test_function_import_func_from_hooks_dir_context_preserved(change_curdir_fixtures):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_function_method_override_jinja(chdir):", "prediction_line": "def test_function_method_override_jinja(chdir):", "ground_truth": "def test_function_import_func_from_hooks_dir_call_in_tackle(change_curdir_fixtures):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"Check that we can create a method.\"\"\"", "prediction_line": "    \"\"\"Check that we can create a method.\"\"\"", "ground_truth": "    \"\"\"Check that we can create a method that takes args.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "@pytest.fixture", "prediction_line": "@pytest.fixture", "ground_truth": "FIXTURES = [", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_function_method_no_exec(chdir):", "prediction_line": "def test_function_method_no_exec(chdir):", "ground_truth": "    assert output['jinja_base']['bar'] == 'foo'", "line_class": "random", "zero_context": true}
{"original_prediction": "def test_function_method_override_jinja(chdir):", "prediction_line": "def test_function_method_override_jinja(chdir):", "ground_truth": "    assert output['nested_jinja']['home'] == 'baz'", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert o['jinja'] == 'a-default'", "prediction_line": "    assert o['jinja'] == 'a-default'", "ground_truth": "    assert o['jinja_extension_default'] == 'a-default'", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert o['jinja_extension_override'] == 'a-override'", "prediction_line": "    assert o['jinja_extension_override'] == 'a-override'", "ground_truth": "    assert o['jinja_extension'] == 'things'", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert output['int_field'] == 1", "prediction_line": "    assert output['int_field'] == 1", "ground_truth": "    assert output", "line_class": "random", "zero_context": true}
{"original_prediction": "        with zipfile.ZipFile(log_recorder.log_archive, 'r') as z:", "prediction_line": "        with zipfile.ZipFile(log_recorder.log_archive, 'r') as z:", "ground_truth": "        with zipfile.ZipFile(log_recorder.log_archive, 'r') as z:", "line_class": "infile", "zero_context": true}
{"original_prediction": "['timings']['start'] = '20180101T000000'", "prediction_line": "['timings']['start'] = '20180101T000000'", "ground_truth": "        assert len([f.filename for f in log_archive.filelist", "line_class": "infile", "zero_context": true}
{"original_prediction": "log_recorder.log_archive, 'r') as z:", "prediction_line": "log_recorder.log_archive, 'r') as z:", "ground_truth": "                log_recorder.log_archive, 'w',", "line_class": "infile", "zero_context": true}
{"original_prediction": "        recorder = RepeatableLogRecorder(temp_directory)", "prediction_line": "        recorder = RepeatableLogRecorder(temp_directory)", "ground_truth": "        assert not os.path.exists(temp_directory)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert os.path.exists(temp_directory)", "prediction_line": "        assert os.path.exists(temp_directory)", "ground_truth": "        assert os.path.exists(temp_directory)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # The following is a list of files that are expected to be in the", "prediction_line": "        # The following is a list of files that are expected to be in the", "ground_truth": "        assert 'metadata.json' in [f.filename for f in log_archive.filelist]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert os.path.exists(os.path.join(temp_directory, 'log.zip'))", "prediction_line": "        assert os.path.exists(os.path.join(temp_directory, 'log.zip'))", "ground_truth": "        assert len(os.listdir(temp_directory)) == 1", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def test_create_log_archive_name(self, temp_directory):", "prediction_line": "    def test_create_log_archive_name(self, temp_directory):", "ground_truth": "        log_file = os.listdir(temp_directory)[0]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @pytest.mark.skipif(not ServiceCheck.service_ok(),", "prediction_line": "    @pytest.mark.skipif(not ServiceCheck.service_ok(),", "ground_truth": "    @pytest.mark.skipif(not ServiceCheck.service_ok(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        with log_archive.open('metadata.json') as f:", "prediction_line": "        with log_archive.open('metadata.json') as f:", "ground_truth": "        metadata = json.loads(log_archive.read('metadata.json'))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    temp_dir = tempfile.mkdtemp()", "prediction_line": "    temp_dir = tempfile.mkdtemp()", "ground_truth": "    temp_dir = os.path.join(tempfile.gettempdir(), 'pydov-test-repeatable-log')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    yield RepeatableLogRecorder(temp_directory)", "prediction_line": "    yield RepeatableLogRecorder(temp_directory)", "ground_truth": "    orig_hooks = Hooks(pydov.hooks)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    pydov.hooks = Hooks(RepeatableLogRecorder(temp_directory))", "prediction_line": "    pydov.hooks = Hooks(RepeatableLogRecorder(temp_directory))", "ground_truth": "    recorder = RepeatableLogRecorder(temp_directory)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    pydov.hooks.register(recorder)", "prediction_line": "    pydov.hooks.register(recorder)", "ground_truth": "    pydov.hooks = Hooks((recorder,))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # install the log recorder", "prediction_line": "    # install the log recorder", "ground_truth": "    bs = BoringSearch()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        bs.search(max_features=1)", "prediction_line": "        bs.search(max_features=1)", "ground_truth": "        bs.search(max_features=1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        log_recorder._pydov_exit()", "prediction_line": "        log_recorder._pydov_exit()", "ground_truth": "        log_recorder._pydov_exit()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                zip_contents[f] = z.read(f)", "prediction_line": "                zip_contents[f] = z.read(f)", "ground_truth": "                zip_contents[f] = z.read(f)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        with pytest.raises(LogReplayError):", "prediction_line": "        with pytest.raises(LogReplayError):", "ground_truth": "        pydov.hooks = Hooks((RepeatableLogReplayer(log_recorder.log_archive),))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        result = bs.search(max_features=1)", "prediction_line": "        result = bs.search(max_features=1)", "ground_truth": "        df = bs.search(max_features=1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        recorder = RepeatableLogRecorder(temp_directory)", "prediction_line": "        recorder = RepeatableLogRecorder(temp_directory)", "ground_truth": "        RepeatableLogRecorder(temp_directory)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        bs = BoringSearch()", "prediction_line": "        bs = BoringSearch()", "ground_truth": "        with pytest.raises(LogReplayError):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            df = bs.search(max_features=2)", "prediction_line": "            df = bs.search(max_features=2)", "ground_truth": "            bs.search(max_features=2)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       assert isinstance(metadata['timings']['run_time_secs'], float)", "prediction_line": "       assert isinstance(metadata['timings']['run_time_secs'], float)", "ground_truth": "        # metadata", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"Test whether the replay of a recorded session works.", "prediction_line": "        \"\"\"Test whether the replay of a recorded session works.", "ground_truth": "        \"\"\"Test whether a recorded session can be replayed using the archive.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        replayed.", "prediction_line": "        replayed.", "ground_truth": "        cannot be replayed using the saved archive.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        recorder = RepeatableLogRecorder(temp_directory)", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        shutil.rmtree(temp_dir)", "prediction_line": "        shutil.rmtree(temp_dir)", "ground_truth": "        shutil.rmtree(temp_dir)", "line_class": "random", "zero_context": true}
{"original_prediction": "                else:\n                    z.writestr(f, zip_contents[f])", "prediction_line": "                else:", "ground_truth": "                else:", "line_class": "random", "zero_context": true}
{"original_prediction": "    if os.path.exists(temp_dir):", "prediction_line": "    if os.path.exists(temp_dir):", "ground_truth": "    if os.path.exists(temp_dir):", "line_class": "random", "zero_context": true}
{"original_prediction": "                        reason=\"DOV service is unreachable\")", "prediction_line": "                        reason=\"DOV service is unreachable\")", "ground_truth": "                        reason=\"DOV service is unreachable\")", "line_class": "random", "zero_context": true}
{"original_prediction": "   os.makedirs(temp_dir)", "prediction_line": "   os.makedirs(temp_dir)", "ground_truth": "    yield temp_dir", "line_class": "random", "zero_context": true}
{"original_prediction": "if __name__ == \"__main__\":", "prediction_line": "if __name__ == \"__main__\":", "ground_truth": "RequestPFASdata().main(['all'], True)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.dictionary[\"nb_datapoints\"][0].update(nb_datapoints)", "prediction_line": "        self.dictionary[\"nb_datapoints\"][0].update(nb_datapoints)", "ground_truth": "        self.dictionary[\"nb_datapoints\"][0].update(nb_datapoints)", "line_class": "common", "zero_context": true}
{"original_prediction": "        if save == True:", "prediction_line": "        if save == True:", "ground_truth": "        if save:", "line_class": "common", "zero_context": true}
{"original_prediction": "                metadata = json.load(metadata_file)", "prediction_line": "                metadata = json.load(metadata_file)", "ground_truth": "                metadata = json.load(metadata_file)", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Biota_VMM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Biota_VMM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Biota_VMM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Effluent_OVAM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Effluent_OVAM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Effluent_OVAM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Groundwater_VMM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Groundwater_VMM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Groundwater_VMM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Groundwater_OVAM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Groundwater_OVAM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Groundwater_OVAM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Groundwater_Lantis'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Groundwater_Lantis'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Groundwater_Lantis'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Migration_OVAM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Migration_OVAM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Migration_OVAM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Pure_product_OVAM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Pure_product_OVAM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Pure_product_OVAM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Rainwater_OVAM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Rainwater_OVAM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Rainwater_OVAM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_OVAM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_OVAM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_OVAM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_Lantis'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_Lantis'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_Lantis'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_water_VMM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_water_VMM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_water_VMM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_water_OVAM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_water_OVAM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Soil_water_OVAM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Surface_water_VMM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Surface_water_VMM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Surface_water_VMM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Surface_water_OVAM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Surface_water_OVAM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Surface_water_OVAM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                        pbar.update(metadata['nb_datapoints'][0]['Waste_water_VMM'])", "prediction_line": "                        pbar.update(metadata['nb_datapoints'][0]['Waste_water_VMM'])", "ground_truth": "                        pbar.update(metadata['nb_datapoints'][0]['Waste_water_VMM'])", "line_class": "common", "zero_context": true}
{"original_prediction": "                data_wfs_OVAM_rw = self.rainwater()", "prediction_line": "                data_wfs_OVAM_rw = self.rainwater()", "ground_truth": "                data_wfs_OVAM_rainwater = self.rainwater()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                data_wfs_OVAM_soil, data_wfs_Lantis_soil = self.soil()", "prediction_line": "                data_wfs_OVAM_soil, data_wfs_Lantis_soil = self.soil()", "ground_truth": "                data_wfs_OVAM_soil, data_wfs_Lantis_soil = self.soil()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                data_wfs_VMM_ws, data_wfs_OVAM_sw = self.soil_water()", "prediction_line": "                data_wfs_VMM_ws, data_wfs_OVAM_sw = self.soil_water()", "ground_truth": "                data_wfs_VMM_ws, data_wfs_OVAM_ws = self.soil_water()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                data_wfs_VMM_sw, data_wfs_OVAM_sw = self.surface_water()", "prediction_line": "                data_wfs_VMM_sw, data_wfs_OVAM_sw = self.surface_water()", "ground_truth": "                data_wfs_VMM_sw, data_wfs_OVAM_sw = self.surface_water()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                data_wfs_VMM_ww = self.waste_water()", "prediction_line": "                data_wfs_VMM_ww = self.waste_water()", "ground_truth": "                data_wfs_VMM_ww = self.waste_water()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                data_biota = self.biota()", "prediction_line": "                data_biota = self.biota()", "ground_truth": "                data_wfs_VMM_biota = self.biota()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data_wfs_OVAM = self.wfs_request(", "prediction_line": "        data_wfs_OVAM = self.wfs_request(", "ground_truth": "        data_wfs_OVAM = self.wfs_request(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                data_wfs_OVAM = self.effluent()", "prediction_line": "                data_wfs_OVAM = self.effluent()", "ground_truth": "                data_wfs_OVAM_effluent = self.effluent()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                data_pydov_VMM_gw, data_wfs_OVAM_gw, data_wfs_Lantis_gw = self.groundwater()", "prediction_line": "                data_pydov_VMM_gw, data_wfs_OVAM_gw, data_wfs_Lantis_gw = self.groundwater()", "ground_truth": "                data_pydov_VMM_gw, data_wfs_OVAM_gw, data_wfs_Lantis_gw = self.groundwater()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                data_wfs_OVAM_migration = self.migration()", "prediction_line": "                data_wfs_OVAM_migration = self.migration()", "ground_truth": "                data_wfs_OVAM_migration = self.migration()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                data_wfs_OVAM_pure_product = self.pure_product()", "prediction_line": "                data_wfs_OVAM_pure_product = self.pure_product()", "ground_truth": "                data_wfs_OVAM_pp = self.pure_product()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data_wfs_OVAM = self.wfs_request(", "prediction_line": "        data_wfs_OVAM = self.wfs_request(", "ground_truth": "        data_wfs_VMM_ws = self.wfs_request(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data_wfs_OVAM = self.wfs_request(", "prediction_line": "        data_wfs_OVAM = self.wfs_request(", "ground_truth": "        data_pydov_VMM_gw = self.pydov_request(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data_wfs_OVAM = data_wfs_OVAM.drop_duplicates(", "prediction_line": "        data_wfs_OVAM = data_wfs_OVAM.drop_duplicates(", "ground_truth": "        data_wfs_Lantis_gw = self.wfs_request(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.metadata = {", "prediction_line": "        self.metadata = {", "ground_truth": "        date = json_serial(date)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data_wfs_OVAM = self.wfs_request(", "prediction_line": "        data_wfs_OVAM = self.wfs_request(", "ground_truth": "        data_wfs_VMM_sw = self.wfs_request(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data_wfs_OVAM = self.wfs_request(", "prediction_line": "        data_wfs_OVAM = self.wfs_request(", "ground_truth": "        data_wfs_VMM_ww = self.wfs_request(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        logger.info(f\"Downloading biota data\")", "prediction_line": "        logger.info(f\"Downloading biota data\")", "ground_truth": "        data_wfs_VMM_biota = self.wfs_request(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        data_wfs_OVAM = data_wfs_OVAM.drop_duplicates(", "prediction_line": "        data_wfs_OVAM = data_wfs_OVAM.drop_duplicates(", "ground_truth": "        data_wfs_Lantis_soil = self.wfs_request(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            Box(self.lowerleftx, self.lowerlefty, self.upperrightx, self.upperrighty))", "prediction_line": "            Box(self.lowerleftx, self.lowerlefty, self.upperrightx, self.upperrighty))", "ground_truth": "            Box(self.lowerleftx, self.lowerlefty, self.upperrightx, self.upperrighty))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        #todo: check if the layer is a valid layer", "prediction_line": "        #todo: check if the layer is a valid layer", "ground_truth": "        wfsSearch = WfsSearch(layer)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        wfsSearch.filter(bbox=bbox)", "prediction_line": "        wfsSearch.filter(bbox=bbox)", "ground_truth": "        return wfsSearch.search(location=Within(bbox))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        logger.info(f\"Downloading groundwater monster and filter data\")", "prediction_line": "        logger.info(f\"Downloading groundwater monster and filter data\")", "ground_truth": "        gwmonster = GrondwaterMonsterSearch()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        gwmonster_data = gwmonster.search(query=query, location=Within(bbox))", "prediction_line": "        gwmonster_data = gwmonster.search(query=query, location=Within(bbox))", "ground_truth": "        df = gwmonster.search(location=Within(bbox), query=query)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            gwfilter = GrondwaterFilterSearch()", "prediction_line": "            gwfilter = GrondwaterFilterSearch()", "ground_truth": "            gwfilter = GrondwaterFilterSearch()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            logger.info(f\"Downloading groundwater filters data\")", "prediction_line": "            logger.info(f\"Downloading groundwater filters data\")", "ground_truth": "            filter_elements = gwfilter.search(query=Join(data, \"pkey_filter\"), return_fields=[", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Download the surface water data.", "prediction_line": "        Download the surface water data.", "ground_truth": "        Download the surface water data.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Download the waste water data.", "prediction_line": "        Download the waste water data.", "ground_truth": "        Download the waste water data.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def water(self):", "prediction_line": "    def water(self):", "ground_truth": "    def pure_product(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        data_wfs_VMM_ww_len = len(data_wfs_VMM_ww)", "prediction_line": "        data_wfs_VMM_ww_len = len(data_wfs_VMM_ww)", "ground_truth": "        data_wfs_VMM_ww_len = len(data_wfs_VMM_ww)", "line_class": "random", "zero_context": true}
{"original_prediction": "                        data_wfs_Lantis_gw.to_excel(writer, sheet_name='Groundwater_Lantis')", "prediction_line": "                        data_wfs_Lantis_gw.to_excel(writer, sheet_name='Groundwater_Lantis')", "ground_truth": "                        data_wfs_Lantis_gw.to_excel(writer, sheet_name='Groundwater_Lantis')", "line_class": "random", "zero_context": true}
{"original_prediction": "        nb_datapoints = {\"Rainwater_OVAM\" : data_wfs_OVAM_len}", "prediction_line": "        nb_datapoints = {\"Rainwater_OVAM\" : data_wfs_OVAM_len}", "ground_truth": "        nb_datapoints = {\"Rainwater_OVAM\" : data_wfs_OVAM_len}", "line_class": "random", "zero_context": true}
{"original_prediction": "            subset=data_wfs_OVAM.columns)", "prediction_line": "            subset=data_wfs_OVAM.columns)", "ground_truth": "            subset=data_wfs_OVAM.columns)", "line_class": "random", "zero_context": true}
{"original_prediction": "        return data_wfs_VMM_sw, data_wfs_OVAM", "prediction_line": "        return data_wfs_VMM_sw, data_wfs_OVAM", "ground_truth": "        return data_wfs_VMM_sw, data_wfs_OVAM", "line_class": "random", "zero_context": true}
{"original_prediction": "        if k not in event_dict:", "prediction_line": "        if k not in event_dict:", "ground_truth": "        if k.startswith(structlog.contextvars.STRUCTLOG_KEY_PREFIX) and v.get() is not Ellipsis:", "line_class": "commited", "zero_context": true}
{"original_prediction": "            event_dict[k] = v.get()", "prediction_line": "            event_dict[k] = v.get()", "ground_truth": "            event_dict[k[structlog.contextvars.STRUCTLOG_KEY_PREFIX_LEN :]] = v.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return self._data.get(key, default)", "prediction_line": "        return self._data.get(key, default)", "ground_truth": "        return self._data.get(key, default)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if key in event_dict:", "prediction_line": "        if key in event_dict:", "ground_truth": "        if key in event_dict and isinstance(event_dict.get(key), BaseException):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            exception = event_dict.get(key)", "prediction_line": "            exception = event_dict.get(key)", "ground_truth": "            exception = event_dict.get(key)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    if exception:", "prediction_line": "    if exception:", "ground_truth": "    exc_info = event_dict.get(\"exc_info\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if key in event_dict:", "prediction_line": "        if key in event_dict:", "ground_truth": "        if key in event_dict and exception == event_dict.get(key):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        event_dict[\"tb_module_name\"] = tb.tb_frame.f_globals.get(\"__name__\", \"\")", "prediction_line": "        event_dict[\"tb_module_name\"] = tb.tb_frame.f_globals.get(\"__name__\", \"\")", "ground_truth": "        event_dict[\"tb_module_name\"] = tb.tb_frame.f_globals.get(\"__name__\", \"<unknown>\") if tb else \"<unknown>\"", "line_class": "commited", "zero_context": true}
{"original_prediction": "    def __getitem__(self, key: str) -> Any:", "prediction_line": "    def __getitem__(self, key: str) -> Any:", "ground_truth": "        name = self._data.get(\"logger\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if LOGGER_DISABLED_KEY in event_dict:", "prediction_line": "        if LOGGER_DISABLED_KEY in event_dict:", "ground_truth": "        name = event_dict.get(\"logger\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "        ctx = get_context(name)", "prediction_line": "        ctx = get_context(name)", "ground_truth": "        ctx = _loggers.get().get(name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                self._data.update(ctx)", "prediction_line": "                self._data.update(ctx)", "ground_truth": "                _loggers.set({**_loggers.get(), **{self._data[\"logger\"]: self}})", "line_class": "commited", "zero_context": true}
{"original_prediction": "    @property", "prediction_line": "    @property", "ground_truth": "                if name and name == _context.get().get(\"logger\"):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                is_disabled = ctx[LOGGER_DISABLED_KEY]", "prediction_line": "                is_disabled = ctx[LOGGER_DISABLED_KEY]", "ground_truth": "                is_disabled = bool(ctx.get(LOGGER_DISABLED_KEY))", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return _loggers.get().get(logger)", "prediction_line": "        return _loggers.get().get(logger)", "ground_truth": "        ctx = _loggers.get().get(logger)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return self._data.get(item)", "prediction_line": "        return self._data.get(item)", "ground_truth": "        value = self._data.get(item)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return self._data.get(item)", "prediction_line": "        return self._data.get(item)", "ground_truth": "        return self.__getitem__(item)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return bool(get_context(logger).get(LOGGER_DISABLED_KEY, False))", "prediction_line": "    return bool(get_context(logger).get(LOGGER_DISABLED_KEY, False))", "ground_truth": "    return True if get_context(logger).get(LOGGER_DISABLED_KEY) else False", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return iter(self._data)", "prediction_line": "        return iter(self._data)", "ground_truth": "        return self._data.__iter__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return logger", "prediction_line": "    return logger", "ground_truth": "    return logger.new(**_context.get())", "line_class": "commited", "zero_context": true}
{"original_prediction": "        merge_contextvars,", "prediction_line": "        merge_contextvars,", "ground_truth": "        merge_contextvars,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self._data == other._data", "prediction_line": "            return self._data == other._data", "ground_truth": "            return bool(self._data == other._data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ctx = get_context(logger)", "prediction_line": "    ctx = get_context(logger)", "ground_truth": "    get_context(logger)[LOGGER_DISABLED_KEY] = True", "line_class": "infile", "zero_context": true}
{"original_prediction": "        else:\n            return self._data.pop(item, default[0])", "prediction_line": "        else:", "ground_truth": "        return self._data.pop(item, default[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    context_class=LoggerContext,", "prediction_line": "    context_class=LoggerContext,", "ground_truth": "    context_class=LoggerContext,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self._data.pop(item)", "prediction_line": "            return self._data.pop(item)", "ground_truth": "            return self._data.pop(item)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        add_exception_info,", "prediction_line": "        add_exception_info,", "ground_truth": "        add_exception_info,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        structlog.processors.format_exc_info,", "prediction_line": "        structlog.processors.format_exc_info,", "ground_truth": "        RenameKeys(pairs=RENAME_KEYS),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            del event_dict[self.key]", "prediction_line": "            del event_dict[self.key]", "ground_truth": "            event_dict.pop(self.key)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if \"context\" in event_dict:", "prediction_line": "    if \"context\" in event_dict:", "ground_truth": "    ctx = structlog.contextvars._CONTEXT_VARS.copy()", "line_class": "infile", "zero_context": true}
{"original_prediction": "class TomodachiLogger:", "prediction_line": "class TomodachiLogger:", "ground_truth": "_context: ContextVar[Union[LoggerContext, Dict]] = ContextVar(\"tomodachi.logging._context\", default={})", "line_class": "infile", "zero_context": true}
{"original_prediction": "        structlog.processors.format_exc_info,", "prediction_line": "        structlog.processors.format_exc_info,", "ground_truth": "        AddMissingDictKey(key=\"message\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.__data = {**self._data, **a[0], **kw}", "prediction_line": "            self.__data = {**self._data, **a[0], **kw}", "ground_truth": "            return LoggerContext(self, {**a[0], **kw})", "line_class": "infile", "zero_context": true}
{"original_prediction": "            break\n    else:", "prediction_line": "            break", "ground_truth": "            event_dict.pop(key)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                is_disabled = bool(ctx.get(\"_logger_disabled\"))", "prediction_line": "                is_disabled = bool(ctx.get(\"_logger_disabled\"))", "ground_truth": "                is_disabled = event_dict.pop(LOGGER_DISABLED_KEY, False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self._data.keys()", "prediction_line": "        return self._data.keys()", "ground_truth": "        return self._data.keys()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                event_dict[new_key] = event_dict.pop(old_key)", "prediction_line": "                event_dict[new_key] = event_dict.pop(old_key)", "ground_truth": "                event_dict[new_key] = event_dict.pop(old_key)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if name in _loggers.get():", "prediction_line": "            if name in _loggers.get():", "ground_truth": "            ctx = get_context(str(name))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self._data.__eq__(other)", "prediction_line": "        return self._data.__eq__(other)", "ground_truth": "        if isinstance(other, LoggerContext):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    get_context(logger)[LOGGER_DISABLED_KEY] = False", "prediction_line": "    get_context(logger)[LOGGER_DISABLED_KEY] = False", "ground_truth": "    get_context(logger)[LOGGER_DISABLED_KEY] = False", "line_class": "infile", "zero_context": true}
{"original_prediction": "#\n# This is a workaround for the fact that `get_logger` is not a valid Python identifier.", "prediction_line": "#", "ground_truth": "getLogger = get_logger", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.__data.pop(item, None)", "prediction_line": "        self.__data.pop(item, None)", "ground_truth": "        del self._data[item]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if isinstance(logger, structlog.BoundLoggerBase):", "prediction_line": "    if isinstance(logger, structlog.BoundLoggerBase):", "ground_truth": "    _context.set(get_context(logger))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        AddMissingDictKey(key=\"message\"),", "prediction_line": "        AddMissingDictKey(key=\"message\"),", "ground_truth": "        RemoveDictKey(key=\"exc_info\"),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return False if get_context(logger).get(LOGGER_DISABLED_KEY) else True", "prediction_line": "    return False if get_context(logger).get(LOGGER_DISABLED_KEY) else True", "ground_truth": "    return not is_logger_disabled(logger)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        logger = logger.name", "prediction_line": "        logger = logger.name", "ground_truth": "        if not isinstance(logger._context, LoggerContext):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return len(self._data)", "prediction_line": "        return len(self._data)", "ground_truth": "        return len(self._data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if is_disabled:", "prediction_line": "        if is_disabled:", "ground_truth": "                event_dict.pop(LOGGER_DISABLED_KEY, None)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return bool(self._data)", "prediction_line": "        return bool(self._data)", "ground_truth": "        if self._data:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            ctx = _loggers.get().get(\"default\")", "prediction_line": "            ctx = _loggers.get().get(\"default\")", "ground_truth": "            ctx = LoggerContext(logger=logger, **{LOGGER_DISABLED_KEY: False})", "line_class": "infile", "zero_context": true}
{"original_prediction": "        AddMissingDictKey(key=\"message\"),", "prediction_line": "        AddMissingDictKey(key=\"message\"),", "ground_truth": "        SquelchDisabledLogger(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "def get_context(name: Optional[str] = None) -> LoggerContext:", "prediction_line": "def get_context(name: Optional[str] = None) -> LoggerContext:", "ground_truth": "console_logger: structlog.stdlib.BoundLogger = structlog.get_logger(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._data.clear()", "prediction_line": "        self._data.clear()", "ground_truth": "        self._data.clear()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return bool(self._data == other)", "prediction_line": "            return bool(self._data == other)", "ground_truth": "            return bool(self._data == other)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return LoggerContext(self, {**kw})", "prediction_line": "            return LoggerContext(self, {**kw})", "ground_truth": "            return LoggerContext(self, {**kw})", "line_class": "infile", "zero_context": true}
{"original_prediction": "def get_context(name: Optional[str] = None) -> LoggerContext:", "prediction_line": "def get_context(name: Optional[str] = None) -> LoggerContext:", "ground_truth": "_context.set(LoggerContext(logger=\"default\", **{LOGGER_DISABLED_KEY: False}))", "line_class": "infile", "zero_context": true}
{"original_prediction": "               return None\n\n            setattr(logger, method_name, func)", "prediction_line": "               return None", "ground_truth": "            setattr(logger, method_name, func.__get__(logger))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        structlog.processors.JSONRenderer(serializer=serializer_func),", "prediction_line": "        structlog.processors.JSONRenderer(serializer=serializer_func),", "ground_truth": "        structlog.processors.JSONRenderer(serializer=serializer_func),", "line_class": "infile", "zero_context": true}
{"original_prediction": "                pass\n\n            if _func:", "prediction_line": "                pass", "ground_truth": "                setattr(logger, method_name, _func)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return {}\n        return event_dict", "prediction_line": "            return {}", "ground_truth": "            _func = getattr(logger, method_name, None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   ctx.update(get_context())", "prediction_line": "   ctx.update(get_context())", "ground_truth": "    for k, v in ctx.items():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "class LoggerContext(dict):", "prediction_line": "class LoggerContext(dict):", "ground_truth": "class LogProcessorTimestamp:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __init__(", "prediction_line": "    def __init__(", "ground_truth": "    def __init__(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __iter__(self) -> KeysView:", "prediction_line": "    def __iter__(self) -> KeysView:", "ground_truth": "    def __iter__(self) -> Any:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def get_logger(name: Optional[str] = None) -> structlog.stdlib.BoundLogger:", "prediction_line": "def get_logger(name: Optional[str] = None) -> structlog.stdlib.BoundLogger:", "ground_truth": "def get_context(logger: Union[LoggerContext, Dict, structlog.BoundLoggerBase, str]) -> Union[LoggerContext, Dict]:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    __slots__ = (\"key\", \"value\")", "prediction_line": "    __slots__ = (\"key\", \"value\")", "ground_truth": "    __slots__ = (\"key\",)", "line_class": "random", "zero_context": true}
{"original_prediction": "    event_dict[\"exception\"] = exception", "prediction_line": "    event_dict[\"exception\"] = exception", "ground_truth": "    for key in EXCEPTION_KEYS:", "line_class": "random", "zero_context": true}
{"original_prediction": "    if isinstance(logger, LoggerContext):", "prediction_line": "    if isinstance(logger, LoggerContext):", "ground_truth": "    if isinstance(logger, structlog.BoundLoggerBase):", "line_class": "random", "zero_context": true}
{"original_prediction": "    if \"tb_filename\" not in event_dict:", "prediction_line": "    if \"tb_filename\" not in event_dict:", "ground_truth": "    if \"tb_filename\" not in event_dict:", "line_class": "random", "zero_context": true}
{"original_prediction": "from django.conf import settings", "prediction_line": "from django.conf import settings", "ground_truth": "LOGGER_DISABLED_KEY = \"_logger_disabled\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        aws_endpoint_urls: Union[Mapping[str, Any], AWSEndpointURLs] = DEFAULT(AWSEndpointURLs),", "prediction_line": "        aws_endpoint_urls: Union[Mapping[str, Any], AWSEndpointURLs] = DEFAULT(AWSEndpointURLs),", "ground_truth": "        aws_endpoint_urls: Union[Mapping[str, Any], AWSEndpointURLs] = DEFAULT(AWSEndpointURLs),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        watcher: Union[Mapping[str, Any], Watcher] = DEFAULT(Watcher),", "prediction_line": "        watcher: Union[Mapping[str, Any], Watcher] = DEFAULT(Watcher),", "ground_truth": "        watcher: Union[Mapping[str, Any], Watcher] = DEFAULT(Watcher),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    amqp: AMQP", "prediction_line": "    amqp: AMQP", "ground_truth": "    aws_endpoint_urls: AWSEndpointURLs", "line_class": "infile", "zero_context": true}
{"original_prediction": "    watcher: Watcher", "prediction_line": "    watcher: Watcher", "ground_truth": "    watcher: Watcher", "line_class": "infile", "zero_context": true}
{"original_prediction": "       self.qos = qos if isinstance(qos, QOS) else QOS(**qos)", "prediction_line": "       self.qos = qos if isinstance(qos, QOS) else QOS(**qos)", "ground_truth": "        input_: Tuple[Tuple[str, Union[Mapping[str, Any], OptionsInterface], type], ...] = ((\"qos\", qos, self.QOS),)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        qos: QOS = DEFAULT(QOS),", "prediction_line": "        qos: QOS = DEFAULT(QOS),", "ground_truth": "        qos: Union[Mapping[str, Any], QOS] = DEFAULT(QOS),", "line_class": "infile", "zero_context": true}
{"original_prediction": "class OptionsFactory:", "prediction_line": "class OptionsFactory:", "ground_truth": "    HTTP = HTTP", "line_class": "infile", "zero_context": true}
{"original_prediction": "    AWSSNSSQS = AWSSNSSQS", "prediction_line": "    AWSSNSSQS = AWSSNSSQS", "ground_truth": "    AWSSNSSQS = AWSSNSSQS", "line_class": "infile", "zero_context": true}
{"original_prediction": "    AWSEndpointURLs = AWSEndpointURLs", "prediction_line": "    AWSEndpointURLs = AWSEndpointURLs", "ground_truth": "    AWSEndpointURLs = AWSEndpointURLs", "line_class": "infile", "zero_context": true}
{"original_prediction": "    AMQP = AMQP", "prediction_line": "    AMQP = AMQP", "ground_truth": "    AMQP = AMQP", "line_class": "infile", "zero_context": true}
{"original_prediction": "    Watcher = Watcher", "prediction_line": "    Watcher = Watcher", "ground_truth": "    Watcher = Watcher", "line_class": "infile", "zero_context": true}
{"original_prediction": "    queue_expiration_interval: int", "prediction_line": "    queue_expiration_interval: int", "ground_truth": "    qos: QOS", "line_class": "infile", "zero_context": true}
{"original_prediction": "        http: Union[Mapping[str, Any], HTTP] = DEFAULT(HTTP),", "prediction_line": "        http: Union[Mapping[str, Any], HTTP] = DEFAULT(HTTP),", "ground_truth": "        http: Union[Mapping[str, Any], HTTP] = DEFAULT(HTTP),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        aws_sns_sqs: Union[Mapping[str, Any], AWSSNSSQS] = DEFAULT(AWSSNSSQS),", "prediction_line": "        aws_sns_sqs: Union[Mapping[str, Any], AWSSNSSQS] = DEFAULT(AWSSNSSQS),", "ground_truth": "        aws_sns_sqs: Union[Mapping[str, Any], AWSSNSSQS] = DEFAULT(AWSSNSSQS),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    http: HTTP", "prediction_line": "    http: HTTP", "ground_truth": "    http: HTTP", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    amqp: AMQP", "prediction_line": "    amqp: AMQP", "ground_truth": "    aws_sns_sqs: AWSSNSSQS", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.heartbeat = heartbeat", "prediction_line": "        self.heartbeat = heartbeat", "ground_truth": "        self.heartbeat = heartbeat", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    amqp: AMQP", "prediction_line": "    amqp: AMQP", "ground_truth": "    amqp: AMQP", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        amqp: Union[Mapping[str, Any], AMQP] = DEFAULT(AMQP),", "prediction_line": "        amqp: Union[Mapping[str, Any], AMQP] = DEFAULT(AMQP),", "ground_truth": "        amqp: Union[Mapping[str, Any], AMQP] = DEFAULT(AMQP),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        heartbeat: int = 60,", "prediction_line": "        heartbeat: int = 60,", "ground_truth": "        heartbeat: int = 60,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    qos: QOS", "prediction_line": "    qos: QOS", "ground_truth": "    heartbeat: int", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        input_: Tuple[Tuple[str, Union[Mapping[str, Any], OptionsInterface], type], ...] = (", "prediction_line": "        input_: Tuple[Tuple[str, Union[Mapping[str, Any], OptionsInterface], type], ...] = (", "ground_truth": "        input_: Tuple[Tuple[str, Union[Mapping[str, Any], OptionsInterface], type], ...] = ((\"http\", http, HTTP), (\"aws_sns_sqs\", aws_sns_sqs, AWSSNSSQS), (\"aws_endpoint_urls\", aws_endpoint_urls, AWSEndpointURLs), (\"amqp\", amqp, AMQP), (\"watcher\", watcher, Watcher))", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    host: Optional[str]", "prediction_line": "    host: Optional[str]", "ground_truth": "    class QOS(OptionsInterface):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    ssl: bool", "prediction_line": "    ssl: bool", "ground_truth": "    ssl: bool", "line_class": "random", "zero_context": true}
{"original_prediction": "        self,\n        *,", "prediction_line": "        self,", "ground_truth": "        self,", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.client_max_size = client_max_size", "prediction_line": "        self.client_max_size = client_max_size", "ground_truth": "        self.client_max_size = client_max_size", "line_class": "random", "zero_context": true}
{"original_prediction": "        exchange_name: str = \"tomodachi\",", "prediction_line": "        exchange_name: str = \"tomodachi\",", "ground_truth": "        exchange_name: str = \"amq.topic\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    sns_use_ssl: bool", "prediction_line": "    sns_use_ssl: bool", "ground_truth": "    sqs_kms_data_key_reuse_period: Optional[int]", "line_class": "random", "zero_context": true}
{"original_prediction": "                logger_provider = LoggerProvider()", "prediction_line": "                logger_provider = LoggerProvider()", "ground_truth": "                resource = Resource.create().merge(OTELResourceDetector().detect())", "line_class": "common", "zero_context": true}
{"original_prediction": "        if names:", "prediction_line": "        if names:", "ground_truth": "        log_level_ = environ.get(OTEL_LOG_LEVEL, log_level) or logging.NOTSET", "line_class": "common", "zero_context": true}
{"original_prediction": "        if not cls._original_service_cls:", "prediction_line": "        if not cls._original_service_cls:", "ground_truth": "        tracer_provider = cls._tracer_provider(tracer_provider)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        logger_provider: LoggerProvider = self._logger_provider(kwargs.get(\"logger_provider\"))", "prediction_line": "        logger_provider: LoggerProvider = self._logger_provider(kwargs.get(\"logger_provider\"))", "ground_truth": "        logger_provider: Optional[LoggerProvider] = self._logger_provider(kwargs.get(\"logger_provider\"))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if logger_provider:", "prediction_line": "        if logger_provider:", "ground_truth": "        self.instrument_logging([\"tomodachi\", \"exception\"], logger_provider=logger_provider)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.uninstrument_structlog_logger(logger)", "prediction_line": "            self.uninstrument_structlog_logger(logger)", "ground_truth": "            TomodachiInstrumentor.uninstrument_structlog_logger(logger)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self._is_instrumented_by_opentelemetry:", "prediction_line": "        if self._is_instrumented_by_opentelemetry:", "ground_truth": "        if not self._is_instrumented_by_opentelemetry or not TomodachiInstrumentor._instrumented_services:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if isinstance(names, str):", "prediction_line": "        if isinstance(names, str):", "ground_truth": "        logger_provider = cls._logger_provider(logger_provider)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._instrument(**kwargs)", "prediction_line": "            self._instrument(**kwargs)", "ground_truth": "            super().instrument(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.instrument_structlog_logger(logger)", "prediction_line": "            self.instrument_structlog_logger(logger)", "ground_truth": "            self.instrument_structlog_logger(logger)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._is_instrumented_by_opentelemetry = True", "prediction_line": "            self._is_instrumented_by_opentelemetry = True", "ground_truth": "            self._uninstrument(**kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        TomodachiInstrumentor.uninstrument_service(self)", "prediction_line": "        TomodachiInstrumentor.uninstrument_service(self)", "ground_truth": "        TomodachiInstrumentor.uninstrument_service(self)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self._original_service_cls is not None:", "prediction_line": "        if self._original_service_cls is not None:", "ground_truth": "        _InstrumentedTomodachiService._tracer_provider = None", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _tracer_provider: Optional[TracerProvider] = None", "prediction_line": "    _tracer_provider: Optional[TracerProvider] = None", "ground_truth": "    _tracer_provider: Optional[TracerProvider] = None", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # ...", "prediction_line": "        # ...", "ground_truth": "        if TomodachiInstrumentor._instrumented_services is not None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self._is_instrumented_by_opentelemetry:", "prediction_line": "        if self._is_instrumented_by_opentelemetry:", "ground_truth": "        TomodachiInstrumentor.instrument_service(self, tracer_provider=self._tracer_provider)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self._original_service_cls is None:", "prediction_line": "        if self._original_service_cls is None:", "ground_truth": "        tracer_provider: TracerProvider = self._tracer_provider(kwargs.get(\"tracer_provider\"))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        logger_provider: LoggerProvider = self._logger_provider(kwargs.get(\"logger_provider\"))", "prediction_line": "        logger_provider: LoggerProvider = self._logger_provider(kwargs.get(\"logger_provider\"))", "ground_truth": "        _InstrumentedTomodachiService._tracer_provider = tracer_provider", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.uninstrument_logging([\"tomodachi\", \"exception\"])", "prediction_line": "        self.uninstrument_logging([\"tomodachi\", \"exception\"])", "ground_truth": "        TomodachiInstrumentor.uninstrument_logging([\"tomodachi\", \"exception\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            tomodachi.Service = _InstrumentedTomodachiService", "prediction_line": "            tomodachi.Service = _InstrumentedTomodachiService", "ground_truth": "            setattr(tomodachi, \"Service\", _InstrumentedTomodachiService)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            setattr(service, \"_aiohttp_middleware\", aiohttp_middleware)", "prediction_line": "            setattr(service, \"_aiohttp_middleware\", aiohttp_middleware)", "ground_truth": "            setattr(service, \"_aiohttp_middleware\", aiohttp_middleware)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    aiohttp_middleware.remove(middleware)", "prediction_line": "                    aiohttp_middleware.remove(middleware)", "ground_truth": "                    aiohttp_middleware.remove(middleware)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        else:\n            log_level = log_level_", "prediction_line": "        else:", "ground_truth": "        handler = OpenTelemetryLoggingHandler(level=log_level, logger_provider=logger_provider)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for _, exporter in log_exporters.items():", "prediction_line": "            for _, exporter in log_exporters.items():", "ground_truth": "            for _, exporter in log_exporters.items():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for exporter in trace_exporters:", "prediction_line": "            for exporter in trace_exporters:", "ground_truth": "            for _, exporter in trace_exporters.items():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    handler.close()", "prediction_line": "                    handler.close()", "ground_truth": "                    handler.acquire()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       for name in names:", "prediction_line": "       for name in names:", "ground_truth": "        for name in names:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for service in TomodachiInstrumentor._instrumented_services:", "prediction_line": "            for service in TomodachiInstrumentor._instrumented_services:", "ground_truth": "            for service in TomodachiInstrumentor._instrumented_services:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    handler.close()", "prediction_line": "                    handler.close()", "ground_truth": "                    handler.close()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                cls._instrumented_services.remove(service)", "prediction_line": "                cls._instrumented_services.remove(service)", "ground_truth": "                cls._instrumented_services.remove(service)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            logger = logging.getLogger(name)", "prediction_line": "            logger = logging.getLogger(name)", "ground_truth": "            logging.getLogger(name).addHandler(handler)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if cls._original_service_cls is None:", "prediction_line": "        if cls._original_service_cls is None:", "ground_truth": "        setattr(service, \"_is_instrumented_by_opentelemetry\", True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if service in cls._instrumented_services:", "prediction_line": "        if service in cls._instrumented_services:", "ground_truth": "        cls._instrumented_services.add(service)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    names.remove(name)", "prediction_line": "                    names.remove(name)", "ground_truth": "                    names.remove(name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        aiohttp_middleware = getattr(service, \"_aiohttp_middleware\", None)", "prediction_line": "        aiohttp_middleware = getattr(service, \"_aiohttp_middleware\", None)", "ground_truth": "        aiohttp_middleware = getattr(service, \"_aiohttp_middleware\", None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def instrument(", "prediction_line": "    def instrument(", "ground_truth": "    def instrument_service(cls, service: tomodachi.Service, tracer_provider: Optional[TracerProvider] = None) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class OpenTelemetryInstrumentor(BaseInstrumentor):", "prediction_line": "class OpenTelemetryInstrumentor(BaseInstrumentor):", "ground_truth": "class TomodachiInstrumentor(BaseInstrumentor):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # uninstrument tomodachi.Service", "prediction_line": "        # uninstrument tomodachi.Service", "ground_truth": "        # uninstrument tomodachi.Service", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "import logging", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            raise Exception(\"uninstrument_service must be called with an instance of tomodachi.Service\")", "prediction_line": "            raise Exception(\"uninstrument_service must be called with an instance of tomodachi.Service\")", "ground_truth": "            raise Exception(\"uninstrument_service must be called with an instance of tomodachi.Service\")", "line_class": "random", "zero_context": true}
{"original_prediction": "                pass\n\n        aiohttp_middleware = getattr(service, \"_aiohttp_middleware\", None)", "prediction_line": "                pass", "ground_truth": "                pass", "line_class": "random", "zero_context": true}
{"original_prediction": "        if log_level_ != logging.NOTSET:", "prediction_line": "        if log_level_ != logging.NOTSET:", "ground_truth": "        if isinstance(log_level_, str) and not log_level_.isdigit():", "line_class": "random", "zero_context": true}
{"original_prediction": "    @classmethod", "prediction_line": "    @classmethod", "ground_truth": "    @classmethod", "line_class": "random", "zero_context": true}
{"original_prediction": "        if isinstance(names, str):", "prediction_line": "        if isinstance(names, str):", "ground_truth": "        if not isinstance(names, (list, tuple)):", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert Options(**{\"http\": {\"port\": 404, \"termination_grace_period_seconds\": 10}}).http.port == 404", "prediction_line": "    assert Options(**{\"http\": {\"port\": 404, \"termination_grace_period_seconds\": 10}}).http.port == 404", "ground_truth": "    assert Options(**{\"http.port\": 1234, \"http.termination_grace_period_seconds\": 60}).http.port == 1234", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   assert options.get(\"http.port\") == 1234", "prediction_line": "   assert options.get(\"http.port\") == 1234", "ground_truth": "    options[\"http.port\"] = 9999", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert options.http.content_type == \"application/json; charset=utf-8\"", "prediction_line": "    assert options.http.content_type == \"application/json; charset=utf-8\"", "ground_truth": "    assert options.aws_endpoint_urls.sns is \"http://localhost:4566\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    options = Options()", "prediction_line": "    options = Options()", "ground_truth": "    options = Options()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ).aws_endpoint_urls.asdict() == {\"sns\": None, \"sqs\": \"http://localhost:4566\"}", "prediction_line": "    ).aws_endpoint_urls.asdict() == {\"sns\": None, \"sqs\": \"http://localhost:4566\"}", "ground_truth": "    ).aws_endpoint_urls.asdict() == {\"sns\": None, \"sqs\": \"http://localhost:4566\"}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    options.http = {\"port\": 1234}", "prediction_line": "    options.http = {\"port\": 1234}", "ground_truth": "    options[\"http\"] = Options.HTTP(port=1111)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert options.http.port == 4711", "prediction_line": "    assert options.http.port == 4711", "ground_truth": "    assert options.http.port == 4711", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ).amqp.login", "prediction_line": "        ).amqp.login", "ground_truth": "        ).amqp.login", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert options.http.port == 1234", "prediction_line": "    assert options.http.port == 1234", "ground_truth": "    assert options.http.port == 1234", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Options(http={\"keepalive_timeout\": 5, \"max_keepalive_time\": 30}, **{\"http.port\": 555}).http.keepalive_timeout", "prediction_line": "        Options(http={\"keepalive_timeout\": 5, \"max_keepalive_time\": 30}, **{\"http.port\": 555}).http.keepalive_timeout", "ground_truth": "        Options(http={\"keepalive_timeout\": 5, \"max_keepalive_time\": 30}, **{\"http.port\": 555}).http.keepalive_timeout", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert options.http.port == 8080", "prediction_line": "    assert options.http.port == 8080", "ground_truth": "    assert options.http.port == 8080", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert options.aws_sns_sqs.region_name == \"eu-west-1\"", "prediction_line": "    assert options.aws_sns_sqs.region_name == \"eu-west-1\"", "ground_truth": "    assert options.aws_sns_sqs.region_name == \"eu-west-1\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert options.get(\"http\").port == 1234", "prediction_line": "    assert options.get(\"http\").port == 1234", "ground_truth": "    assert options[\"http.port\"] == 1234", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_options_from_dict() -> None:", "prediction_line": "def test_options_from_dict() -> None:", "ground_truth": "    assert Options.HTTP().port == 9700", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert options.http.port == 1111", "prediction_line": "    assert options.http.port == 1111", "ground_truth": "    assert options.http.port == 1111", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            host=\"0.0.0.0\",", "prediction_line": "            host=\"0.0.0.0\",", "ground_truth": "            content_type=\"application/json; charset=utf-8\",", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n\n    assert Options(**{\"http\": {\"keepalive_timeout\": 5, \"max_keepalive_time\": 30}, \"http.port\": 555}).http.port == 555", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"watcher.watched_file_paths\": [],", "prediction_line": "        \"watcher.watched_file_paths\": [],", "ground_truth": "    }", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"http.max_keepalive_time\": 0,", "prediction_line": "        \"http.max_keepalive_time\": 0,", "ground_truth": "        \"http.max_keepalive_time\": None,", "line_class": "random", "zero_context": true}
{"original_prediction": "            http={\"keepalive_timeout\": 5, \"max_keepalive_time\": 30}, **{\"http.port\": 555, \"http.termination_grace_period_seconds\": 60}", "prediction_line": "            http={\"keepalive_timeout\": 5, \"max_keepalive_time\": 30}, **{\"http.port\": 555, \"http.termination_grace_period_seconds\": 60}", "ground_truth": "            **{\"amqp.login\": \"tron\", \"amqp.qos\": {\"queue_prefetch_count\": 10, \"global_prefetch_count\": 50}}", "line_class": "random", "zero_context": true}
{"original_prediction": "            sqs=\"https://sqs.eu-west-1.amazonaws.com\",", "prediction_line": "            sqs=\"https://sqs.eu-west-1.amazonaws.com\",", "ground_truth": "            sns=\"http://localhost:4566\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"aws_secret_access_key\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",", "prediction_line": "        \"aws_secret_access_key\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",", "ground_truth": "        \"aws_secret_access_key\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            **{\"amqp.login\": \"tron\", \"amqp.qos\": {\"queue_prefetch_count\": 10, \"global_prefetch_count\": 50}}", "prediction_line": "            **{\"amqp.login\": \"tron\", \"amqp.qos\": {\"queue_prefetch_count\": 10, \"global_prefetch_count\": 50}}", "ground_truth": "            **{\"amqp.login\": \"tron\", \"amqp.qos\": {\"queue_prefetch_count\": 42, \"global_prefetch_count\": 0}}", "line_class": "random", "zero_context": true}
{"original_prediction": "            aws_access_key_id=os.environ.get(\"AWS_ACCESS_KEY_ID\"),", "prediction_line": "            aws_access_key_id=os.environ.get(\"AWS_ACCESS_KEY_ID\"),", "ground_truth": "            region_name=os.environ.get(\"TOMODACHI_TEST_AWS_REGION\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "            aws_access_key_id=os.environ.get(\"TOMODACHI_TEST_AWS_ACCESS_KEY_ID\"),", "prediction_line": "            aws_access_key_id=os.environ.get(\"TOMODACHI_TEST_AWS_ACCESS_KEY_ID\"),", "ground_truth": "            aws_access_key_id=os.environ.get(\"TOMODACHI_TEST_AWS_ACCESS_KEY_ID\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "            aws_secret_access_key=os.environ.get(\"TOMODACHI_TEST_AWS_SECRET_ACCESS_KEY\"),", "prediction_line": "            aws_secret_access_key=os.environ.get(\"TOMODACHI_TEST_AWS_SECRET_ACCESS_KEY\"),", "ground_truth": "            aws_secret_access_key=os.environ.get(\"TOMODACHI_TEST_AWS_ACCESS_SECRET\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "            aws_session_token=os.environ.get(\"TOMODACHI_TEST_AWS_SESSION_TOKEN\"),", "prediction_line": "            aws_session_token=os.environ.get(\"TOMODACHI_TEST_AWS_SESSION_TOKEN\"),", "ground_truth": "            queue_name_prefix=os.environ.get(\"TOMODACHI_TEST_SQS_QUEUE_PREFIX\") or \"\",", "line_class": "common", "zero_context": true}
{"original_prediction": "            topic_name_prefix=os.environ.get(\"TOMODACHI_TEST_SNS_TOPIC_PREFIX\") or \"\",", "prediction_line": "            topic_name_prefix=os.environ.get(\"TOMODACHI_TEST_SNS_TOPIC_PREFIX\") or \"\",", "ground_truth": "            topic_prefix=os.environ.get(\"TOMODACHI_TEST_SNS_TOPIC_PREFIX\") or \"\",", "line_class": "common", "zero_context": true}
{"original_prediction": "    kwarg_xyz = kwargs.get(\"kwarg_abc\", 0) + 1", "prediction_line": "    kwarg_xyz = kwargs.get(\"kwarg_abc\", 0) + 1", "ground_truth": "    kwarg_xyz = int(kwargs.get(\"kwarg_abc\", 0)) + 1", "line_class": "common", "zero_context": true}
{"original_prediction": "            sqs=os.environ.get(\"TOMODACHI_TEST_SQS_ENDPOINT_URL\"),", "prediction_line": "            sqs=os.environ.get(\"TOMODACHI_TEST_SQS_ENDPOINT_URL\"),", "ground_truth": "            sns=os.environ.get(\"TOMODACHI_TEST_AWS_SNS_ENDPOINT_URL\") or None,", "line_class": "common", "zero_context": true}
{"original_prediction": "            sqs=os.environ.get(\"TOMODACHI_TEST_AWS_SQS_ENDPOINT_URL\") or None,", "prediction_line": "            sqs=os.environ.get(\"TOMODACHI_TEST_AWS_SQS_ENDPOINT_URL\") or None,", "ground_truth": "            sqs=os.environ.get(\"TOMODACHI_TEST_AWS_SQS_ENDPOINT_URL\") or None,", "line_class": "common", "zero_context": true}
{"original_prediction": "    middlewares_called = (kwargs.get(\"middlewares_called\") or []) + [\"middleware_func_xyz\"]", "prediction_line": "    middlewares_called = (kwargs.get(\"middlewares_called\") or []) + [\"middleware_func_xyz\"]", "ground_truth": "    middlewares_called = kwargs.get(\"middlewares_called\", []) + [\"middleware_func_xyz\"]", "line_class": "common", "zero_context": true}
{"original_prediction": "    @aws_sns_sqs(\"test_aws_sns_sqs.test_aws_sns_sqs_service.test_aws_sns_sqs_service_function\")", "prediction_line": "    @aws_sns_sqs(\"test_aws_sns_sqs.test_aws_sns_sqs_service.test_aws_sns_sqs_service_function\")", "ground_truth": "    uuid = os.environ.get(\"TOMODACHI_TEST_SERVICE_UUID\") or \"\"", "line_class": "common", "zero_context": true}
{"original_prediction": "    message_attributes[\"initial_a_value\"] = message_attributes.get(\"initial_a_value\", 1)", "prediction_line": "    message_attributes[\"initial_a_value\"] = message_attributes.get(\"initial_a_value\", 1)", "ground_truth": "    initial_a_value = int(message_attributes.get(\"initial_a_value\", 1))", "line_class": "common", "zero_context": true}
{"original_prediction": "    async def test_middleware_topic(self, data: Dict, message_attributes: Dict, approximate_receive_count: int) -> None:", "prediction_line": "    async def test_middleware_topic(self, data: Dict, message_attributes: Dict, approximate_receive_count: int) -> None:", "ground_truth": "    async def test_middleware_kwargs(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return wrapped_middleware_func", "prediction_line": "    return wrapped_middleware_func", "ground_truth": "    return wrapped_middleware_func", "line_class": "infile", "zero_context": true}
{"original_prediction": "@middleware_decorator", "prediction_line": "@middleware_decorator", "ground_truth": "@middleware_decorator", "line_class": "infile", "zero_context": true}
{"original_prediction": "           self.check_closer()", "prediction_line": "           self.check_closer()", "ground_truth": "            self.check_closer()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    async def start(self) -> None:", "prediction_line": "    async def start(self) -> None:", "ground_truth": "    async def _start_service(self) -> None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "       await self.start()", "prediction_line": "       await self.start()", "ground_truth": "    async def _started_service(self) -> None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        await aws_sns_sqs_publish(", "prediction_line": "        await aws_sns_sqs_publish(", "ground_truth": "        async def publish(data: Any, topic: str, **kwargs: Any) -> None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        await publish(self.data_uuid, \"test-middleware-topic\")", "prediction_line": "        await publish(self.data_uuid, \"test-middleware-topic\")", "ground_truth": "        async def _async() -> None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            await publish(self.data_uuid, \"test-middleware-topic\", initial_a_value=1)", "prediction_line": "            await publish(self.data_uuid, \"test-middleware-topic\", initial_a_value=1)", "ground_truth": "            async def sleep_and_kill() -> None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            await asyncio.gather(", "prediction_line": "            await asyncio.gather(", "ground_truth": "            task = asyncio.ensure_future(sleep_and_kill())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        await asyncio.ensure_future(_async())", "prediction_line": "        await asyncio.ensure_future(_async())", "ground_truth": "        asyncio.ensure_future(_async())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        await publish(self.data_uuid, \"test-middleware-topic\", initial_a_value=1)", "prediction_line": "        await publish(self.data_uuid, \"test-middleware-topic\", initial_a_value=1)", "ground_truth": "        async def _async_publisher() -> None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            await publish(self.data_uuid, \"test-middleware-topic\", initial_a_value=1)", "prediction_line": "            await publish(self.data_uuid, \"test-middleware-topic\", initial_a_value=1)", "ground_truth": "            await publish(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        asyncio.ensure_future(_async_publisher())", "prediction_line": "        asyncio.ensure_future(_async_publisher())", "ground_truth": "        asyncio.ensure_future(_async_publisher())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        middleware_init_000,", "prediction_line": "        middleware_init_000,", "ground_truth": "        middleware_init_000,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        middleware_func_abc,", "prediction_line": "        middleware_func_abc,", "ground_truth": "        middleware_func_abc,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        middleware_func_xyz,", "prediction_line": "        middleware_func_xyz,", "ground_truth": "        middleware_func_xyz,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    options = Options(aws_sns_sqs=aws_sns_sqs)", "prediction_line": "    options = Options(aws_sns_sqs=aws_sns_sqs)", "ground_truth": "    message_envelope = JsonBase", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    options = Options(aws_sns_sqs=aws_sns_sqs)", "prediction_line": "    options = Options(aws_sns_sqs=aws_sns_sqs)", "ground_truth": "    options = Options(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "aws_sns_sqs=aws_sns_sqs)", "prediction_line": "aws_sns_sqs=aws_sns_sqs)", "ground_truth": "        aws_sns_sqs=Options.AWSSNSSQS(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    async def _on_start(self) -> None:", "prediction_line": "    async def _on_start(self) -> None:", "ground_truth": "    @aws_sns_sqs(\"test-middleware-topic\", queue_name=\"test-middleware-{}\".format(data_uuid))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    )\n    uuid = data_uuid", "prediction_line": "    )", "ground_truth": "        aws_endpoint_urls=Options.AWSEndpointURLs(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    async def _middleware_decorator(*args: Any, **kwargs: Any) -> None:", "prediction_line": "    async def _middleware_decorator(*args: Any, **kwargs: Any) -> None:", "ground_truth": "    async def wrapped_middleware_func(func: Callable, service: Any, *args: Any, **kwargs: Any) -> Any:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        async with _middleware_func(func, service, *args, **kwargs) as result:", "prediction_line": "        async with _middleware_func(func, service, *args, **kwargs) as result:", "ground_truth": "        with _middleware_func(func, service, *args, **kwargs) as task:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        await publish(self.data_uuid, \"test-middleware-topic\", initial_a_value=1)", "prediction_line": "        await publish(self.data_uuid, \"test-middleware-topic\", initial_a_value=1)", "ground_truth": "            tomodachi.exit()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from tomodachi.transport.base import Transport", "prediction_line": "from tomodachi.transport.base import Transport", "ground_truth": "from tomodachi.transport.aws_sns_sqs import aws_sns_sqs, aws_sns_sqs_publish", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    async def _stopping_service(self) -> None:", "prediction_line": "    async def _stopping_service(self) -> None:", "ground_truth": "    def stop_service(self) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import logging\nimport os", "prediction_line": "import logging", "ground_truth": "import functools", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            }\n            self.check_closer()", "prediction_line": "            }", "ground_truth": "            }", "line_class": "random", "zero_context": true}
{"original_prediction": "        a_value=a_value,", "prediction_line": "        a_value=a_value,", "ground_truth": "        a_value=a_value,", "line_class": "random", "zero_context": true}
{"original_prediction": "        approximate_receive_count: int = 0,", "prediction_line": "        approximate_receive_count: int = 0,", "ground_truth": "        approximate_receive_count: int = 0,", "line_class": "random", "zero_context": true}
{"original_prediction": "        middlewares_called: List,", "prediction_line": "        middlewares_called: List,", "ground_truth": "        initial_a_value: int,", "line_class": "random", "zero_context": true}
{"original_prediction": "    @aws_sns_sqs(\"test_aws_sns_sqs.test_aws_sns_sqs_service.test_aws_sns_sqs_service_function\")", "prediction_line": "    @aws_sns_sqs(\"test_aws_sns_sqs.test_aws_sns_sqs_service.test_aws_sns_sqs_service_function\")", "ground_truth": "    closer: asyncio.Future", "line_class": "random", "zero_context": true}
{"original_prediction": "    # Get any stages which were included via config files which will be available", "prediction_line": "    # Get any stages which were included via config files which will be available", "ground_truth": "    if test_spec.get(\"includes\"):", "line_class": "common", "zero_context": true}
{"original_prediction": "    try:\n        response = r.run(verifiers)", "prediction_line": "    try:", "ground_truth": "    response = r.run()", "line_class": "common", "zero_context": true}
{"original_prediction": "            if getonly(stage) and not has_only:", "prediction_line": "            if getonly(stage) and not has_only:", "ground_truth": "            if stage.get(\"skip\"):", "line_class": "common", "zero_context": true}
{"original_prediction": "            if \"file\" in included:", "prediction_line": "            if \"file\" in included:", "ground_truth": "            for stage in included.get(\"stages\", {}):", "line_class": "common", "zero_context": true}
{"original_prediction": "    if stage.get(\"strict\", None) is not None:", "prediction_line": "    if stage.get(\"strict\", None) is not None:", "ground_truth": "    mqtt_response = stage.get(\"mqtt_response\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "            if mqtt_response.get(\"strict\", None) is not None:", "prediction_line": "            if mqtt_response.get(\"strict\", None) is not None:", "ground_truth": "            if mqtt_response.get(\"strict\", None) is not None:", "line_class": "common", "zero_context": true}
{"original_prediction": "            if saved:", "prediction_line": "            if saved:", "ground_truth": "            test_block_config.variables.update(saved)", "line_class": "common", "zero_context": true}
{"original_prediction": "                if response.get(\"strict\", None) is not None:", "prediction_line": "                if response.get(\"strict\", None) is not None:", "ground_truth": "                if response.get(\"strict\", None) is not None:", "line_class": "common", "zero_context": true}
{"original_prediction": "    if \"strict\" in stage:", "prediction_line": "    if \"strict\" in stage:", "ground_truth": "    if test_spec.get(\"strict\", None) is not None:", "line_class": "common", "zero_context": true}
{"original_prediction": "            else:\n                formatted_include = {}", "prediction_line": "            else:", "ground_truth": "                test_block_config.variables.update(formatted_include)", "line_class": "common", "zero_context": true}
{"original_prediction": "            if \"stages\" in included:", "prediction_line": "            if \"stages\" in included:", "ground_truth": "            for stage in included.get(\"stages\", []):", "line_class": "common", "zero_context": true}
{"original_prediction": "            \"\"\"Get the 'only' value for a stage", "prediction_line": "            \"\"\"Get the 'only' value for a stage", "ground_truth": "            o = stage.get(\"only\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        if \"ref\" in stage:", "prediction_line": "        if \"ref\" in stage:", "ground_truth": "        if stage.get(\"type\") == \"ref\":", "line_class": "common", "zero_context": true}
{"original_prediction": "    if stage.get(\"strict\", None) is not None:", "prediction_line": "    if stage.get(\"strict\", None) is not None:", "ground_truth": "    if stage.get(\"response\", {}).get(\"strict\", None) is not None:", "line_class": "common", "zero_context": true}
{"original_prediction": "                stage_strictness_set = stage_options = update_stage_options(", "prediction_line": "                stage_strictness_set = stage_options = update_stage_options(", "ground_truth": "                stage_strictness_set = stage_options = update_stage_options(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for stage in test_spec[\"stages\"]:", "prediction_line": "        for stage in test_spec[\"stages\"]:", "ground_truth": "        has_only = any(getonly(stage) for stage in test_spec[\"stages\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "def _calculate_stage_strictness(stage, test_block_config, test_spec):", "prediction_line": "def _calculate_stage_strictness(stage, test_block_config, test_spec):", "ground_truth": "            if getonly(stage):", "line_class": "infile", "zero_context": true}
{"original_prediction": "+ _get_included_stages(", "prediction_line": "+ _get_included_stages(", "ground_truth": "    included_stages = _get_included_stages(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if has_only and not getonly(stage):", "prediction_line": "            if has_only and not getonly(stage):", "ground_truth": "            if has_only and not getonly(stage):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if stage.get(\"id\") in stage_ids(available_stages):", "prediction_line": "                if stage.get(\"id\") in stage_ids(available_stages):", "ground_truth": "                if stage[\"id\"] in stage_ids(available_stages):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_stages = _resolve_test_stages(test_spec, all_stages)", "prediction_line": "    test_stages = _resolve_test_stages(test_spec, all_stages)", "ground_truth": "    test_spec[\"stages\"] = _resolve_test_stages(test_spec, all_stages)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                stage.get(\"strict\", default_global_stricness)", "prediction_line": "                stage.get(\"strict\", default_global_stricness)", "ground_truth": "                _calculate_stage_strictness(stage, test_block_config, test_spec)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            run_stage = retry(", "prediction_line": "            run_stage = retry(", "ground_truth": "            run_stage_with_retries = retry(stage, test_block_config)(run_stage)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                # Need to do this separately here so there is no confusion between global and included stages", "prediction_line": "                # Need to do this separately here so there is no confusion between global and included stages", "ground_truth": "                if stage[\"id\"] in stage_ids(included_stages):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        stage=stage,", "prediction_line": "        stage=stage,", "ground_truth": "        request_args=r.request_vars,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            v.verify(response)", "prediction_line": "            v.verify(response)", "ground_truth": "            saved = v.verify(response)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # Get expected response", "prediction_line": "    # Get expected response", "ground_truth": "    tavern_box.update(request_vars=r.request_vars)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        sessions (dict): Any extra sessions which need to be used for this stage", "prediction_line": "        sessions (dict): Any extra sessions which need to be used for this stage", "ground_truth": "        sessions (dict): Dictionary of relevant 'session' objects used for this test", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def _get_global_stages(tavern_box, test_block_config, test_spec):", "prediction_line": "def _get_global_stages(tavern_box, test_block_config, test_spec):", "ground_truth": "def run_test(in_file, test_spec, global_cfg):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    mqtt_response[\"strict\"]", "prediction_line": "                    mqtt_response[\"strict\"]", "ground_truth": "                    stage[\"mqtt_response\"][\"strict\"]", "line_class": "random", "zero_context": true}
{"original_prediction": "            return bool(strtobool(o))", "prediction_line": "            return bool(strtobool(o))", "ground_truth": "            elif isinstance(o, bool):", "line_class": "random", "zero_context": true}
{"original_prediction": "        # Setup any extra sessions", "prediction_line": "        # Setup any extra sessions", "ground_truth": "        sessions = get_extra_sessions(test_spec, test_block_config)", "line_class": "random", "zero_context": true}
{"original_prediction": "            new_strict = StrictLevel.all_off()", "prediction_line": "            new_strict = StrictLevel.all_off()", "ground_truth": "            new_strict = StrictLevel.all_off()", "line_class": "random", "zero_context": true}
{"original_prediction": "            # Get the request type", "prediction_line": "            # Get the request type", "ground_truth": "            test_block_config = test_block_config.with_strictness(", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(display_name='recall')", "prediction_line": "        super().__init__(display_name='recall')", "ground_truth": "        super().__init__(display_name='recall')", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(display_name='precision')", "prediction_line": "        super().__init__(display_name='precision')", "ground_truth": "        super().__init__(display_name='precision')", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(display_name='f1')", "prediction_line": "        super().__init__(display_name='f1')", "ground_truth": "        super().__init__(display_name='F1')", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"AUROC\", upper_threshold=1.0)", "prediction_line": "        super().__init__(\"AUROC\", upper_threshold=1.0)", "ground_truth": "        super().__init__(display_name='roc_auc')", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(display_name='accuracy')", "prediction_line": "        super().__init__(display_name='accuracy')", "ground_truth": "        super().__init__(display_name='accuracy')", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(display_name='sensitivity')", "prediction_line": "        super().__init__(display_name='sensitivity')", "ground_truth": "        super().__init__(display_name='sensitivity')", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(display_name='specificity')", "prediction_line": "        super().__init__(display_name='specificity')", "ground_truth": "        super().__init__(display_name='specificity')", "line_class": "commited", "zero_context": true}
{"original_prediction": "    def __init__(self, metric_specification: Union[str, Metric]):", "prediction_line": "    def __init__(self, metric_specification: Union[str, Metric]):", "ground_truth": "    _str_to_metric: Dict[str, Metric] = {", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'auc': AUROC(),", "prediction_line": "        'auc': AUROC(),", "ground_truth": "        'roc_auc': AUROC(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'f1': F1(),", "prediction_line": "        'f1': F1(),", "ground_truth": "        'f1': F1(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'precision': Precision(),", "prediction_line": "        'precision': Precision(),", "ground_truth": "        'precision': Precision(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'recall': Recall(),", "prediction_line": "        'recall': Recall(),", "ground_truth": "        'recall': Recall(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'specificity': Specificity(),", "prediction_line": "        'specificity': Specificity(),", "ground_truth": "        'sensitivity': Sensitivity(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'specificity': Specificity(),", "prediction_line": "        'specificity': Specificity(),", "ground_truth": "        'specificity': Specificity(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        'accuracy': Accuracy(),", "prediction_line": "        'accuracy': Accuracy(),", "ground_truth": "        'accuracy': Accuracy(),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        y_true, y_pred = _common_data_cleaning(y_true, y_pred)", "prediction_line": "        y_true, y_pred = _common_data_cleaning(y_true, y_pred)", "ground_truth": "        y_true, y_pred = _common_data_cleaning(y_true, y_pred)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return cls._str_to_metric[key]", "prediction_line": "            return cls._str_to_metric[key]", "ground_truth": "            return cls._create_from_str(key)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        elif isinstance(key, Metric):", "prediction_line": "        elif isinstance(key, Metric):", "ground_truth": "        elif isinstance(key, Metric):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if auc < 0.5:", "prediction_line": "    if auc < 0.5:", "ground_truth": "    chunk_size = get_prediction([[class_balance, auc]])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    chunk_size = np.minimum(chunk_size, 10000)", "prediction_line": "    chunk_size = np.minimum(chunk_size, 10000)", "ground_truth": "    minimum_chunk_size = int(chunk_size)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return minimum_chunk_size", "prediction_line": "    return minimum_chunk_size", "ground_truth": "    return minimum_chunk_size", "line_class": "infile", "zero_context": true}
{"original_prediction": "        pass\n\n    def calculate(self, reference_data: pd.DataFrame, chunk: Chunk) -> float:", "prediction_line": "        pass", "ground_truth": "        self._fit(reference_data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._min_chunk_size = _minimum_roc_auc_based_chunk_size(reference_data)", "prediction_line": "        self._min_chunk_size = _minimum_roc_auc_based_chunk_size(reference_data)", "ground_truth": "        self._min_chunk_size = _minimum_roc_auc_based_chunk_size(reference_data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.upper_threshold = self.calculate_upper_threshold(reference_chunks)", "prediction_line": "            self.upper_threshold = self.calculate_upper_threshold(reference_chunks)", "ground_truth": "            self.lower_threshold, self.upper_threshold = self._calculate_alert_thresholds(reference_chunks)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return 100", "prediction_line": "        return 100", "ground_truth": "        return self._minimum_chunk_size()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.upper_threshold = self._calculate_upper_threshold(reference_data, chunker)", "prediction_line": "            self.upper_threshold = self._calculate_upper_threshold(reference_data, chunker)", "ground_truth": "            reference_chunks = chunker.split(reference_data, minimum_chunk_size=self.minimum_chunk_size())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return np.nan", "prediction_line": "            return np.nan", "ground_truth": "            raise InvalidArgumentsException(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        y_pred = data[NML_METADATA_PREDICTED_PROBABILITY_COLUMN_NAME]  # TODO: this should be predicted_probabilities", "prediction_line": "        y_pred = data[NML_METADATA_PREDICTED_PROBABILITY_COLUMN_NAME]  # TODO: this should be predicted_probabilities", "ground_truth": "        y_pred = data[NML_METADATA_PREDICTION_COLUMN_NAME]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    y_pred = data.loc[data[partition_column_name] == NML_METADATA_REFERENCE_PARTITION_NAME, predicted_probability_column_name]", "prediction_line": "    y_pred = data.loc[data[partition_column_name] == NML_METADATA_REFERENCE_PARTITION_NAME, predicted_probability_column_name]", "ground_truth": "    y_pred_proba = data.loc[", "line_class": "inproject", "zero_context": true}
{"original_prediction": "reference_data: pd.DataFrame) -> int:", "prediction_line": "reference_data: pd.DataFrame) -> int:", "ground_truth": "    data: pd.DataFrame,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        y_true = data[NML_METADATA_TARGET_COLUMN_NAME]", "prediction_line": "        y_true = data[NML_METADATA_TARGET_COLUMN_NAME]", "ground_truth": "        y_true = data[NML_METADATA_TARGET_COLUMN_NAME]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    data = data.dropna()", "prediction_line": "    data = data.dropna()", "ground_truth": "    y_true = data.loc[data[partition_column_name] == NML_METADATA_REFERENCE_PARTITION_NAME, target_column_name]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            and NML_METADATA_PREDICTED_PROBABILITY_COLUMN_NAME not in data.columns", "prediction_line": "            and NML_METADATA_PREDICTED_PROBABILITY_COLUMN_NAME not in data.columns", "ground_truth": "            and NML_METADATA_PREDICTED_PROBABILITY_COLUMN_NAME not in data.columns", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"Calculates the lower and upper thresholds for this metric.", "prediction_line": "        \"\"\"Calculates the lower and upper thresholds for this metric.", "ground_truth": "        chunked_reference_metric = [self.calculate(chunk.data) for chunk in reference_chunks]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # get the number of observations per partition", "prediction_line": "    # get the number of observations per partition", "ground_truth": "    class_balance = np.mean(data[target_column_name])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    chunker: Chunker,", "prediction_line": "    chunker: Chunker,", "ground_truth": "    partition_column_name: str = NML_METADATA_PARTITION_COLUMN_NAME,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise InvalidArgumentsException(", "prediction_line": "            raise InvalidArgumentsException(", "ground_truth": "            raise InvalidArgumentsException(f\"unknown metric key '{key}' given. \" \"Should be one of ['roc_auc'].\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self._calculate(data)", "prediction_line": "        return self._calculate(data)", "ground_truth": "        return self._calculate(data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            NML_METADATA_PREDICTION_COLUMN_NAME not in data.columns", "prediction_line": "            NML_METADATA_PREDICTION_COLUMN_NAME not in data.columns", "ground_truth": "            NML_METADATA_PREDICTION_COLUMN_NAME not in data.columns", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    target_column_name: str = NML_METADATA_TARGET_COLUMN_NAME,", "prediction_line": "    target_column_name: str = NML_METADATA_TARGET_COLUMN_NAME,", "ground_truth": "    target_column_name: str = NML_METADATA_TARGET_COLUMN_NAME,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            The upper threshold for the metric. If given, the metric will be calculated for the given threshold.", "prediction_line": "            The upper threshold for the metric. If given, the metric will be calculated for the given threshold.", "ground_truth": "            An optional upper threshold for the performance metric.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import logging\nfrom typing import Any, Dict, List, Optional, Tuple, Union", "prediction_line": "import logging", "ground_truth": "from typing import Dict, List, Tuple, Union", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "#  Author:   Niels Nuyttens  <niels@nannyml.com>", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    @abc.abstractmethod", "prediction_line": "    @abc.abstractmethod", "ground_truth": "    def __init__(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        raise NotImplementedError", "prediction_line": "        raise NotImplementedError", "ground_truth": "        raise NotImplementedError", "line_class": "random", "zero_context": true}
{"original_prediction": "                'Specificity cannot be calculated on data with no predictions. '", "prediction_line": "                'Specificity cannot be calculated on data with no predictions. '", "ground_truth": "                f\"could not calculate metric {self.display_name}: \" \"prediction column contains no data\"", "line_class": "random", "zero_context": true}
{"original_prediction": "            return np.nan", "prediction_line": "            return np.nan", "ground_truth": "            return np.nan", "line_class": "random", "zero_context": true}
{"original_prediction": "        return 100", "prediction_line": "        return 100", "ground_truth": "        return 300", "line_class": "random", "zero_context": true}
{"original_prediction": "        self._performance_results: Optional[Union[CBPEResults, DLEResults, PerformanceCalculationResults]] = None", "prediction_line": "        self._performance_results: Optional[Union[CBPEResults, DLEResults, PerformanceCalculationResults]] = None", "ground_truth": "        super().__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        ranking['rank'] = ranking['number_of_alerts'].rank(ascending=False)", "prediction_line": "        ranking['rank'] = ranking['number_of_alerts'].rank(ascending=False)", "ground_truth": "        ranking['column_name'] = ranking.index", "line_class": "common", "zero_context": true}
{"original_prediction": "        ranked['rank'] = ranked.index + 1", "prediction_line": "        ranked['rank'] = ranked.index + 1", "ground_truth": "        ranked['rank'] = ranked.index + 1", "line_class": "common", "zero_context": true}
{"original_prediction": "        ranking['rank'] = ranking.index + 1", "prediction_line": "        ranking['rank'] = ranking.index + 1", "ground_truth": "        ranking['rank'] = ranking.index + 1", "line_class": "common", "zero_context": true}
{"original_prediction": "        performance_calculation_result: Optional[", "prediction_line": "        performance_calculation_result: Optional[", "ground_truth": "    ) -> CorrelationRanker:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _validate_performance_result(reference_performance_calculation_result)", "prediction_line": "        _validate_performance_result(reference_performance_calculation_result)", "ground_truth": "        _validate_performance_result(reference_performance_calculation_result)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _validate_drift_result(drift_calculation_result)", "prediction_line": "        _validate_drift_result(drift_calculation_result)", "ground_truth": "        _validate_drift_result(drift_calculation_result)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _validate_performance_result(performance_calculation_result)", "prediction_line": "        _validate_performance_result(performance_calculation_result)", "ground_truth": "        _validate_performance_result(performance_calculation_result)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        raise InvalidArgumentsException(", "prediction_line": "        raise InvalidArgumentsException(", "ground_truth": "        raise InvalidArgumentsException(\"Univariate Results object required for drift_calculation_result argument.\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def _validate_performance_calculation_result(performance_calculation_result: PerformanceCalculationResults):", "prediction_line": "def _validate_performance_calculation_result(performance_calculation_result: PerformanceCalculationResults):", "ground_truth": "    if drift_calculation_result.data.empty:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        raise InvalidArgumentsException(\"Univariate Results object must contain data.\")", "prediction_line": "        raise InvalidArgumentsException(\"Univariate Results object must contain data.\")", "ground_truth": "        raise InvalidArgumentsException('drift results contain no data to use for ranking')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise InvalidArgumentsException(", "prediction_line": "            raise InvalidArgumentsException(", "ground_truth": "            raise InvalidArgumentsException(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise NotFittedException(", "prediction_line": "            raise NotFittedException(", "ground_truth": "            raise InvalidArgumentsException(\"reference performance calculation results can not be None.\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            reference_performance_calculation_result.mean_reference_performance[self.metric]", "prediction_line": "            reference_performance_calculation_result.mean_reference_performance[self.metric]", "ground_truth": "            reference_performance_calculation_result.to_df().loc[:, (self.metric.column_name, 'value')].mean()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise NotFittedException(\"CorrelationRanker must be fitted before ranking.\")", "prediction_line": "            raise NotFittedException(\"CorrelationRanker must be fitted before ranking.\")", "ground_truth": "            raise NotFittedException(\"trying to call 'rank()' on an unfitted Ranker. Please call 'fit()' first\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if self.metric not in performance_calculation_result.metrics:", "prediction_line": "        if self.metric not in performance_calculation_result.metrics:", "ground_truth": "        _drift_index = drift_calculation_result.to_df().loc[:, ('chunk', 'chunk', 'start_index')]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        _performance_index = performance_calculation_result.to_df().loc[:, ('chunk', 'chunk', 'start_index')]", "prediction_line": "        _performance_index = performance_calculation_result.to_df().loc[:, ('chunk', 'chunk', 'start_index')]", "ground_truth": "        _perf_index = performance_calculation_result.to_df().loc[:, ('chunk', 'start_index')]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            performance_calculation_result.to_df().loc[:, (self.metric.column_name, 'value')]", "prediction_line": "            performance_calculation_result.to_df().loc[:, (self.metric.column_name, 'value')]", "ground_truth": "            performance_calculation_result.to_df().loc[:, (self.metric.column_name, 'value')].to_numpy()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                drift_calculation_result.to_df().loc[:, (ftr, 'value')].to_numpy(),", "prediction_line": "                drift_calculation_result.to_df().loc[:, (ftr, 'value')].to_numpy(),", "ground_truth": "                drift_calculation_result.to_df().loc[:, (ftr, slice(None), 'value')].to_numpy().ravel(), abs_perf_change", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if only_drifting:", "prediction_line": "        if only_drifting:", "ground_truth": "        non_chunk = list(set(drift_calculation_result.data.columns.get_level_values(0)) - {'chunk'})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            drift_calculation_result.data.groupby(non_chunk)", "prediction_line": "            drift_calculation_result.data.groupby(non_chunk)", "ground_truth": "            drift_calculation_result.filter(period='analysis')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            .data.groupby(non_chunk)", "prediction_line": "            .data.groupby(non_chunk)", "ground_truth": "            .to_df()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from nannyml.performance_estimation.result import Result as PEResults", "prediction_line": "from nannyml.performance_estimation.result import Result as PEResults", "ground_truth": "from nannyml.performance_estimation.direct_loss_estimation.result import Result as DLEResults", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        5  public_transportation_cost_prev_workday                 5     5", "prediction_line": "        5  public_transportation_cost_prev_workday                 5     5", "ground_truth": "        5                      tenure                 2     5", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class Ranker:", "prediction_line": "class Ranker:", "ground_truth": "def _validate_drift_result(drift_calculation_result: UnivariateResults):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            The results of the drift calculation.", "prediction_line": "            The results of the drift calculation.", "ground_truth": "            The result of a univariate drift calculation.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        _validate_drift_result(drift_calculation_result)", "prediction_line": "        _validate_drift_result(drift_calculation_result)", "ground_truth": "        if performance_calculation_result is None:", "line_class": "random", "zero_context": true}
{"original_prediction": "        features2 = []", "prediction_line": "        features2 = []", "ground_truth": "        spearmanr2 = []", "line_class": "random", "zero_context": true}
{"original_prediction": "        )\n        ranked = ranked.sort_values(['pearsonr_correlation', 'column_name'], ascending=False)", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "            f\"Found {len(drift_calculation_result.categorical_method_names)}.\"", "prediction_line": "            f\"Found {len(drift_calculation_result.categorical_method_names)}.\"", "ground_truth": "            f\"\\nFound: {drift_calculation_result.categorical_method_names}\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(display_name='RMSLE', column_name='rmsle', calculator=calculator)", "prediction_line": "        super().__init__(display_name='RMSLE', column_name='rmsle', calculator=calculator)", "ground_truth": "        super().__init__(display_name='RMSLE', column_name='rmsle', calculator=calculator)", "line_class": "commited", "zero_context": true}
{"original_prediction": "class MeanAbsoluteError(Metric):", "prediction_line": "class MeanAbsoluteError(Metric):", "ground_truth": "@MetricFactory.register(metric='mae', use_case=UseCase.REGRESSION)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        # handle NaNs", "prediction_line": "        # handle NaNs", "ground_truth": "        y_true, y_pred = _common_data_cleaning(y_true, y_pred)", "line_class": "commited", "zero_context": true}
{"original_prediction": "@MetricFactory.register(metric='mape', use_case=UseCase.REGRESSION)", "prediction_line": "@MetricFactory.register(metric='mape', use_case=UseCase.REGRESSION)", "ground_truth": "@MetricFactory.register(metric='mape', use_case=UseCase.REGRESSION)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(calculator)", "prediction_line": "        super().__init__(calculator)", "ground_truth": "        super().__init__(display_name='MAE', column_name='mae', calculator=calculator)", "line_class": "commited", "zero_context": true}
{"original_prediction": "@MetricFactory.register(metric='mse', use_case=UseCase.REGRESSION)", "prediction_line": "@MetricFactory.register(metric='mse', use_case=UseCase.REGRESSION)", "ground_truth": "@MetricFactory.register(metric='mse', use_case=UseCase.REGRESSION)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(display_name='MAPE', column_name='mape', calculator=calculator)", "prediction_line": "        super().__init__(display_name='MAPE', column_name='mape', calculator=calculator)", "ground_truth": "        super().__init__(display_name='MAPE', column_name='mape', calculator=calculator)", "line_class": "commited", "zero_context": true}
{"original_prediction": "@MetricFactory.register(metric='msle', use_case=UseCase.REGRESSION)", "prediction_line": "@MetricFactory.register(metric='msle', use_case=UseCase.REGRESSION)", "ground_truth": "@MetricFactory.register(metric='msle', use_case=UseCase.REGRESSION)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(display_name='MSE', column_name='mse', calculator=calculator)", "prediction_line": "        super().__init__(display_name='MSE', column_name='mse', calculator=calculator)", "ground_truth": "        super().__init__(display_name='MSE', column_name='mse', calculator=calculator)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(display_name='MSLE', column_name='msle', calculator=calculator)", "prediction_line": "        super().__init__(display_name='MSLE', column_name='msle', calculator=calculator)", "ground_truth": "        super().__init__(display_name='MSLE', column_name='msle', calculator=calculator)", "line_class": "commited", "zero_context": true}
{"original_prediction": "@MetricFactory.register(metric='rmse', use_case=UseCase.REGRESSION)", "prediction_line": "@MetricFactory.register(metric='rmse', use_case=UseCase.REGRESSION)", "ground_truth": "@MetricFactory.register(metric='rmse', use_case=UseCase.REGRESSION)", "line_class": "commited", "zero_context": true}
{"original_prediction": "@MetricFactory.register(metric='rmsle', use_case=UseCase.REGRESSION)", "prediction_line": "@MetricFactory.register(metric='rmsle', use_case=UseCase.REGRESSION)", "ground_truth": "@MetricFactory.register(metric='rmsle', use_case=UseCase.REGRESSION)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(display_name='RMSE', column_name='rmse', calculator=calculator)", "prediction_line": "        super().__init__(display_name='RMSE', column_name='rmse', calculator=calculator)", "ground_truth": "        super().__init__(display_name='RMSE', column_name='rmse', calculator=calculator)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _raise_exception_for_negative_values(self.calculator.y_true, y_true)", "prediction_line": "        _raise_exception_for_negative_values(self.calculator.y_true, y_true)", "ground_truth": "        _raise_exception_for_negative_values(self.calculator.y_true, y_true)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _raise_exception_for_negative_values(self.calculator.y_pred, y_pred)", "prediction_line": "        _raise_exception_for_negative_values(self.calculator.y_pred, y_pred)", "ground_truth": "        _raise_exception_for_negative_values(self.calculator.y_pred, y_pred)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _list_missing([self.calculator.y_true, self.calculator.y_pred], list(data.columns))", "prediction_line": "        _list_missing([self.calculator.y_true, self.calculator.y_pred], list(data.columns))", "ground_truth": "        _list_missing([self.calculator.y_true, self.calculator.y_pred], list(data.columns))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return rmsle_sampling_error(self._sampling_error_components, data)", "prediction_line": "        return rmsle_sampling_error(self._sampling_error_components, data)", "ground_truth": "        return rmsle_sampling_error(self._sampling_error_components, data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        y_true = data[self.calculator.y_true]", "prediction_line": "        y_true = data[self.calculator.y_true]", "ground_truth": "        y_true = data[self.calculator.y_true]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        y_pred = data[self.calculator.y_pred]", "prediction_line": "        y_pred = data[self.calculator.y_pred]", "ground_truth": "        y_pred = data[self.calculator.y_pred]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return mse_sampling_error(self._sampling_error_components, data)", "prediction_line": "        return mse_sampling_error(self._sampling_error_components, data)", "ground_truth": "        return mse_sampling_error(self._sampling_error_components, data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        negative_item_indices = negative_item_indices[0].tolist()", "prediction_line": "        negative_item_indices = negative_item_indices[0].tolist()", "ground_truth": "        raise InvalidArgumentsException(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"Fits the metric to the reference data.", "prediction_line": "        \"\"\"Fits the metric to the reference data.", "ground_truth": "        _list_missing([self.calculator.y_true, self.calculator.y_pred], list(reference_data.columns))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return msle_sampling_error(self._sampling_error_components, data)", "prediction_line": "        return msle_sampling_error(self._sampling_error_components, data)", "ground_truth": "        return msle_sampling_error(self._sampling_error_components, data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"Calculate the sampling error for this metric.\"\"\"", "prediction_line": "        \"\"\"Calculate the sampling error for this metric.\"\"\"", "ground_truth": "        return mae_sampling_error(self._sampling_error_components, data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return rmse_sampling_error(self._sampling_error_components, data)", "prediction_line": "        return rmse_sampling_error(self._sampling_error_components, data)", "ground_truth": "        return rmse_sampling_error(self._sampling_error_components, data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return mape_sampling_error(self._sampling_error_components, data)", "prediction_line": "        return mape_sampling_error(self._sampling_error_components, data)", "ground_truth": "        return mape_sampling_error(self._sampling_error_components, data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def __str__(self):", "prediction_line": "    def __str__(self):", "ground_truth": "    def __str__(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __init__(self, calculator):", "prediction_line": "    def __init__(self, calculator):", "ground_truth": "    def __init__(self, calculator):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class MSLE(Metric):", "prediction_line": "class MSLE(Metric):", "ground_truth": "class MSLE(Metric):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # sampling error", "prediction_line": "        # sampling error", "ground_truth": "        # sampling error", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    mse_sampling_error,", "prediction_line": "    mse_sampling_error,", "ground_truth": "    mape_sampling_error,", "line_class": "random", "zero_context": true}
{"original_prediction": "            y_pred_reference=reference_data[self.calculator.y_pred],", "prediction_line": "            y_pred_reference=reference_data[self.calculator.y_pred],", "ground_truth": "            y_pred_reference=reference_data[self.calculator.y_pred],", "line_class": "random", "zero_context": true}
{"original_prediction": "        self._sampling_error_components: Tuple = ()", "prediction_line": "        self._sampling_error_components: Tuple = ()", "ground_truth": "        self._sampling_error_components: Tuple = ()", "line_class": "random", "zero_context": true}
{"original_prediction": "    rmsle_sampling_error_components,", "prediction_line": "    rmsle_sampling_error_components,", "ground_truth": "    rmsle_sampling_error_components,", "line_class": "random", "zero_context": true}
{"original_prediction": "    mean_squared_error,", "prediction_line": "    mean_squared_error,", "ground_truth": "    mean_squared_error,", "line_class": "random", "zero_context": true}
{"original_prediction": "        if subplot_args is None:", "prediction_line": "        if subplot_args is None:", "ground_truth": "        super().__init__(layout=layout)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                show_in_legend = kwargs['showlegend']", "prediction_line": "                show_in_legend = kwargs['showlegend']", "ground_truth": "                is_first_subplot = subplot_args.get('row', 0) == 1 and subplot_args.get('col', 0) == 1", "line_class": "common", "zero_context": true}
{"original_prediction": "            if 'showlegend' in kwargs:", "prediction_line": "            if 'showlegend' in kwargs:", "ground_truth": "            show_in_legend = subplot_args.get('row', 0) == 1 and subplot_args.get('col', 0) == 1", "line_class": "common", "zero_context": true}
{"original_prediction": "            self.set_subplots(**subplot_args)", "prediction_line": "            self.set_subplots(**subplot_args)", "ground_truth": "            kwargs.update(subplot_args)", "line_class": "common", "zero_context": true}
{"original_prediction": "                y=data,", "prediction_line": "                y=data,", "ground_truth": "                y=data,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        color=Colors.BLUE_SKY_CRAYOLA,", "prediction_line": "        color=Colors.BLUE_SKY_CRAYOLA,", "ground_truth": "        color=Colors.RED_IMPERIAL,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        upper_confidence_boundaries, start_dates, end_dates, indices = check_and_convert(", "prediction_line": "        upper_confidence_boundaries, start_dates, end_dates, indices = check_and_convert(", "ground_truth": "        data, start_dates, end_dates, indices = check_and_convert(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            x = add_artificial_endpoint(x)", "prediction_line": "            x = add_artificial_endpoint(x)", "ground_truth": "            x, data = add_artificial_endpoint(indices, start_dates, end_dates, data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "title=x_axis_title),", "prediction_line": "title=x_axis_title),", "ground_truth": "                title=x_axis_title, linecolor=Colors.INDIGO_PERSIAN, showgrid=False, mirror=True, zeroline=False", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                linecolor=Colors.INDIGO_PERSIAN,", "prediction_line": "                linecolor=Colors.INDIGO_PERSIAN,", "ground_truth": "                linecolor=Colors.INDIGO_PERSIAN,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                y=data,", "prediction_line": "                y=data,", "ground_truth": "                y=data[0],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise InvalidArgumentsException(", "prediction_line": "            raise InvalidArgumentsException(", "ground_truth": "            raise InvalidArgumentsException(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                y=data[1],", "prediction_line": "                y=data[1],", "ground_truth": "                y=data[1],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        metric_name: str,", "prediction_line": "        metric_name: str,", "ground_truth": "        data: Union[np.ndarray, pd.Series],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        color: str,", "prediction_line": "        color: str,", "ground_truth": "        color: str = Colors.RED_IMPERIAL,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                data=data,", "prediction_line": "                data=data,", "ground_truth": "                data=data,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "self, date: pd.Timestamp, color: str, **kwargs):", "prediction_line": "self, date: pd.Timestamp, color: str, **kwargs):", "ground_truth": "        self, x, color=Colors.BLUE_SKY_CRAYOLA, subplot_args: Optional[Dict[str, Any]] = None, **kwargs", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        x,\n        color=Colors.BLUE_SKY_CRAYOLA,", "prediction_line": "        x,", "ground_truth": "        data,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if subplot_args is not None:", "prediction_line": "        if subplot_args is not None:", "ground_truth": "        data, start_dates, end_dates, indices = check_and_convert(data, start_dates, end_dates, indices)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from nannyml.plots.components.step_plot import step_plot", "prediction_line": "from nannyml.plots.components.step_plot import step_plot", "ground_truth": "from nannyml.plots.util import add_artificial_endpoint, check_and_convert, is_time_based_x_axis", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Create a new figure.", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"Creates a new Figure.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def alert(\n    df: pd.DataFrame,", "prediction_line": "def alert(", "ground_truth": "class Figure(go.Figure):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            showlegend=False,", "prediction_line": "            showlegend=False,", "ground_truth": "            paper_bgcolor='rgba(255,255,255,1)',", "line_class": "random", "zero_context": true}
{"original_prediction": "            yaxis=dict(", "prediction_line": "            yaxis=dict(", "ground_truth": "            yaxis=dict(", "line_class": "random", "zero_context": true}
{"original_prediction": "                **kwargs,", "prediction_line": "                **kwargs,", "ground_truth": "                **kwargs,", "line_class": "random", "zero_context": true}
{"original_prediction": "                f\"{str.join(',', self.SUPPORTED_METRIC_STYLES)}\"", "prediction_line": "                f\"{str.join(',', self.SUPPORTED_METRIC_STYLES)}\"", "ground_truth": "                f\"{str.join(',', self.SUPPORTED_METRIC_STYLES)}\"", "line_class": "random", "zero_context": true}
{"original_prediction": "            **subplot_args,", "prediction_line": "            **subplot_args,", "ground_truth": "            **subplot_args,", "line_class": "random", "zero_context": true}
{"original_prediction": ") -> Figure:", "prediction_line": ") -> Figure:", "ground_truth": ") -> Figure:", "line_class": "commited", "zero_context": true}
{"original_prediction": "    figure: Figure,", "prediction_line": "    figure: Figure,", "ground_truth": "    figure: Figure,", "line_class": "commited", "zero_context": true}
{"original_prediction": "        kwargs.update(subplot_args)", "prediction_line": "        kwargs.update(subplot_args)", "ground_truth": "        kwargs.update(subplot_args)", "line_class": "common", "zero_context": true}
{"original_prediction": "    x = x[:-1]", "prediction_line": "    x = x[:-1]", "ground_truth": "    alert_indices = [idx for idx, alert in enumerate(alerts[:-1]) if alert]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # slice off the last (artificially added) endpoint", "prediction_line": "    # slice off the last (artificially added) endpoint", "ground_truth": "    alert_indices = [idx for idx, alert in enumerate(alerts) if alert]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    data: Union[np.ndarray, pd.Series],", "prediction_line": "    data: Union[np.ndarray, pd.Series],", "ground_truth": "    data: Union[np.ndarray, pd.Series],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        y=data,", "prediction_line": "        y=data,", "ground_truth": "        y=data,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    data, start_dates, end_dates, indices = check_and_convert(data, chunk_start_dates, chunk_end_dates, chunk_indices)", "prediction_line": "    data, start_dates, end_dates, indices = check_and_convert(data, chunk_start_dates, chunk_end_dates, chunk_indices)", "ground_truth": "    data, start_dates, end_dates, indices = check_and_convert(data, chunk_start_dates, chunk_end_dates, chunk_indices)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    data: Union[np.ndarray, pd.Series],", "prediction_line": "    data: Union[np.ndarray, pd.Series],", "ground_truth": "    data: np.ndarray,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x, data = add_artificial_endpoint(indices, start_dates, end_dates, data)", "prediction_line": "    x, data = add_artificial_endpoint(indices, start_dates, end_dates, data)", "ground_truth": "    x, data = add_artificial_endpoint(indices, start_dates, end_dates, data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            linecolor=Colors.INDIGO_PERSIAN,", "prediction_line": "            linecolor=Colors.INDIGO_PERSIAN,", "ground_truth": "            linecolor=Colors.INDIGO_PERSIAN,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   x_alert = x[alert_indices]", "prediction_line": "   x_alert = x[alert_indices]", "ground_truth": "    data = data[alert_indices]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if hover is None:", "prediction_line": "    if hover is None:", "ground_truth": "    figure = _add_metric_line(figure, data, x, name, color, subplot_args=subplot_args, **kwargs)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        figure = _add_metric_markers(figure, data, x, name, color, subplot_args=subplot_args, **kwargs)", "prediction_line": "        figure = _add_metric_markers(figure, data, x, name, color, subplot_args=subplot_args, **kwargs)", "ground_truth": "        figure = _add_metric_markers(figure, data, x, name, color, subplot_args=subplot_args, **kwargs)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if subplot_args is None:", "prediction_line": "    if subplot_args is None:", "ground_truth": "    figure = _add_alert_markers(figure, data, alerts, x, name, color, subplot_args=subplot_args, **kwargs)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        figure = _add_alert_areas(figure, data, alerts, x, name, color, subplot_args=subplot_args, **kwargs)", "prediction_line": "        figure = _add_alert_areas(figure, data, alerts, x, name, color, subplot_args=subplot_args, **kwargs)", "ground_truth": "        figure = _add_alert_areas(figure, data, alerts, x, name, color, subplot_args=subplot_args, **kwargs)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    )\n\n    return figure", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#  Date:     2021-01-19", "prediction_line": "#  Date:     2021-01-19", "ground_truth": "#", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    figure.add_scatter(", "prediction_line": "    figure.add_scatter(", "ground_truth": "    del kwargs['showlegend']", "line_class": "random", "zero_context": true}
{"original_prediction": "            showgrid=False,", "prediction_line": "            showgrid=False,", "ground_truth": "            showgrid=False,", "line_class": "random", "zero_context": true}
{"original_prediction": "        line=dict(color=color, width=line_args.get('width', 2), dash=line_args.get('dash', 'solid')),", "prediction_line": "        line=dict(color=color, width=line_args.get('width', 2), dash=line_args.get('dash', 'solid')),", "ground_truth": "        line=dict(shape='hv', color=color, width=2, dash=None, **line_args),", "line_class": "random", "zero_context": true}
{"original_prediction": "    x: np.ndarray,", "prediction_line": "    x: np.ndarray,", "ground_truth": "    x: np.ndarray,", "line_class": "random", "zero_context": true}
{"original_prediction": "            **subplot_args,", "prediction_line": "            **subplot_args,", "ground_truth": "            title=subplot_args.pop('subplot_x_axis_title', figure.layout.xaxis.title),", "line_class": "random", "zero_context": true}
{"original_prediction": "    dmap = tf.reshape(dmaps[-1], [-1, 32, 32, num_keypoints * 3])", "prediction_line": "    dmap = tf.reshape(dmaps[-1], [-1, 32, 32, num_keypoints * 3])", "ground_truth": "    xyz = tf.gather_nd(", "line_class": "commited", "zero_context": true}
{"original_prediction": "   dmap = dmaps[-1]", "prediction_line": "   dmap = dmaps[-1]", "ground_truth": "    uv = tf_hmap_to_uv(hmap)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    hmap = net_2d(features, num_keypoints, name + '/hmap', False)", "prediction_line": "    hmap = net_2d(features, num_keypoints, name + '/hmap', False)", "ground_truth": "    pose_tile = get_pose_tile(tf.shape(x)[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x = zero_padding(tensor, pad_1, pad_2)", "prediction_line": "        x = zero_padding(tensor, pad_1, pad_2)", "ground_truth": "        x = zero_padding(tensor, pad_1, pad_2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x = bottleneck(", "prediction_line": "        x = bottleneck(", "ground_truth": "        x = bottleneck(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        dmap = net_3d(features, num_keypoints, name + '/dmap_%d' % i, True,", "prediction_line": "        dmap = net_3d(features, num_keypoints, name + '/dmap_%d' % i, True,", "ground_truth": "        dmap = net_3d(features, num_keypoints, name + '/dmap_%d' % i, False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            x, 1024, 1, name + '/block3/unit%d' % (arg + 1), training, 4)", "prediction_line": "            x, 1024, 1, name + '/block3/unit%d' % (arg + 1), training, 4)", "ground_truth": "            x, 1024, 1, name + '/block3/unit%d' % (arg + 1), training, 4)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            x, 512, 1, name + '/block2/unit%d' % (arg + 1), training)", "prediction_line": "            x, 512, 1, name + '/block2/unit%d' % (arg + 1), training)", "ground_truth": "            x, 512, 1, name + '/block2/unit%d' % (arg + 1), training, 2)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   x = tf.subtract(x, 0.5)", "prediction_line": "   x = tf.subtract(x, 0.5)", "ground_truth": "    name = 'prior_based_hand'", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    residual = block(residual, (filters // 4), 3, strides,", "prediction_line": "    residual = block(residual, (filters // 4), 3, strides,", "ground_truth": "    residual = block(residual, (filters // 4), 3, strides, name + '/conv2',", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    for arg in range(2):", "prediction_line": "    for arg in range(2):", "ground_truth": "    x = bottleneck(x, 256, 2, name + '/block1/unit3', training)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = BatchNormalization(name=name + '/bn')(x, training=training)", "prediction_line": "    x = BatchNormalization(name=name + '/bn')(x, training=training)", "ground_truth": "    x = BatchNormalization(name=name + '/batch_normalization')(x, training)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                  activation=tf.sigmoid, name=name + '/prediction/conv2d',", "prediction_line": "                  activation=tf.sigmoid, name=name + '/prediction/conv2d',", "ground_truth": "                  name=name + '/prediction/conv2d',", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    model.load_weights(get_file('detnet_weights.hdf5', URL,", "prediction_line": "    model.load_weights(get_file('detnet_weights.hdf5', URL,", "ground_truth": "    filename = os.path.basename(URL)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                  use_bias=True, name=name + '/hmap',", "prediction_line": "                  use_bias=True, name=name + '/hmap',", "ground_truth": "                  activation=tf.sigmoid, name=name + '/prediction/conv2d',", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = resnet50(x, name, training=False)", "prediction_line": "    x = resnet50(x, name, training=False)", "ground_truth": "    features = resnet50(x, name + '/resnet', False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = block(x, filters, 3, 1, name + '/bottleneck', training, rate)", "prediction_line": "    x = block(x, filters, 3, 1, name + '/bottleneck', training, rate)", "ground_truth": "    residual = block(tensor, (filters // 4), 1, 1, name + '/conv1', training)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                   kernel_initializer=VarianceScaling(),", "prediction_line": "                   kernel_initializer=VarianceScaling(),", "ground_truth": "                   kernel_regularizer=l2(0.5 * 1.0), name=name + '/conv2d',", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        hmap = net_2d(features, num_keypoints, name + '/hmap_%d' % i, False)", "prediction_line": "        hmap = net_2d(features, num_keypoints, name + '/hmap_%d' % i, False)", "ground_truth": "        hmap = net_2d(features, num_keypoints, name + '/hmap_%d' % i, False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    residual = block(residual, filters, 1, 1, name + '/conv3', training,", "prediction_line": "    residual = block(residual, filters, 1, 1, name + '/conv3', training,", "ground_truth": "    residual = block(residual, filters, 1, 1, name + '/conv3', training,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "      Normalized 2D keypoint locations.", "prediction_line": "      Normalized 2D keypoint locations.", "ground_truth": "      The uv coordinates of the keypoints on the heat map, whose resolution is", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def get_pose_tile_3d(N):", "prediction_line": "def get_pose_tile_3d(N):", "ground_truth": "def tf_hmap_to_uv(hmap):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from tensorflow.keras.layers import Activation", "prediction_line": "from tensorflow.keras.layers import Activation", "ground_truth": "from tensorflow.keras.layers import ReLU", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from tensorflow.keras.layers import UpSampling2D", "prediction_line": "from tensorflow.keras.layers import UpSampling2D", "ground_truth": "from tensorflow.keras.regularizers import l2", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                   kernel_initializer=VarianceScaling(scale=2.0))(tensor)", "prediction_line": "                   kernel_initializer=VarianceScaling(scale=2.0))(tensor)", "ground_truth": "                   kernel_initializer=VarianceScaling(", "line_class": "random", "zero_context": true}
{"original_prediction": "        features = concatenate([features, lmap], -1)", "prediction_line": "        features = concatenate([features, lmap], -1)", "ground_truth": "        features = concatenate([features, lmap], -1)", "line_class": "random", "zero_context": true}
{"original_prediction": "   if not os.path.exists('weights'):", "prediction_line": "   if not os.path.exists('weights'):", "ground_truth": "    URL = ('https://github.com/oarriaga/altamira-data/releases/download'", "line_class": "random", "zero_context": true}
{"original_prediction": "    if shape == filters:", "prediction_line": "    if shape == filters:", "ground_truth": "    if shape == filters:", "line_class": "random", "zero_context": true}
{"original_prediction": "    return output", "prediction_line": "    return output", "ground_truth": "    return output", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.cost_matrix = pad_matrix(cost_matrix, self.H, self.W)", "prediction_line": "        self.cost_matrix = pad_matrix(cost_matrix, self.H, self.W)", "ground_truth": "        self.cost_matrix = pad_matrix(cost_matrix, padding='square')", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__()", "prediction_line": "        super().__init__()", "ground_truth": "        super(Munkres, self).__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.marked = []", "prediction_line": "        self.marked = []", "ground_truth": "        self.steps = {1: self._step1,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                      2: self._step2,", "prediction_line": "                      2: self._step2,", "ground_truth": "                      2: self._step2,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                      3: self._step3,", "prediction_line": "                      3: self._step3,", "ground_truth": "                      3: self._step3,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                      4: self._step4,", "prediction_line": "                      4: self._step4,", "ground_truth": "                      4: self._step4,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                      5: self._step5,", "prediction_line": "                      5: self._step5,", "ground_truth": "                      5: self._step5,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                      6: self._step6}", "prediction_line": "                      6: self._step6}", "ground_truth": "                      6: self._step6}", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return 3", "prediction_line": "        return 3", "ground_truth": "        self._erase_primes()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            row = path[count][0]", "prediction_line": "            row = path[count][0]", "ground_truth": "            row = find_star_in_col(self.n, path[count][1], self.marked)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self._convert_path(path, count)", "prediction_line": "        self._convert_path(path, count)", "ground_truth": "        self._convert_path(path, count)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        path = np.zeros((self.n * 2, self.n * 2), dtype=np.int)", "prediction_line": "        path = np.zeros((self.n * 2, self.n * 2), dtype=np.int)", "ground_truth": "        path = self.path", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.marked[path[i][0]][path[i][1]] = 0", "prediction_line": "                self.marked[path[i][0]][path[i][1]] = 0", "ground_truth": "                self.marked[path[i][0]][path[i][1]] = 0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                self.marked[path[i][0]][path[i][1]] = 1", "prediction_line": "                self.marked[path[i][0]][path[i][1]] = 1", "ground_truth": "                self.marked[path[i][0]][path[i][1]] = 1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self.path", "prediction_line": "        return self.path", "ground_truth": "            if step == 7:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                col = find_prime_in_row(self.n, path[count][0], self.marked)", "prediction_line": "                col = find_prime_in_row(self.n, path[count][0], self.marked)", "ground_truth": "                col = find_prime_in_row(self.n, path[count][0], self.marked)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if path[i] < self.n:", "prediction_line": "            if path[i] < self.n:", "ground_truth": "            if self.marked[path[i][0]][path[i][1]] == 1:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.done = True", "prediction_line": "            self.done = True", "ground_truth": "            step = 7", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.steps[step]()", "prediction_line": "            self.steps[step]()", "ground_truth": "            step_func = self.steps[step]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.covered_rows = np.zeros(self.n, dtype=np.int)", "prediction_line": "        self.covered_rows = np.zeros(self.n, dtype=np.int)", "ground_truth": "        self.path = np.zeros((self.n * 2, self.n * 2), dtype=np.int)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            step_func()", "prediction_line": "            step_func()", "ground_truth": "            step = step_func()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                path[count][0] = row", "prediction_line": "                path[count][0] = row", "ground_truth": "                path[count][0] = row", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            else:\n                self.marked[row][col] = 2", "prediction_line": "            else:", "ground_truth": "                step = 6", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            step = 4", "prediction_line": "            step = 4", "ground_truth": "            step = 4", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Add the value found in Step 4 to every element of each covered row,", "prediction_line": "        Add the value found in Step 4 to every element of each covered row,", "ground_truth": "        Add the value found in Step 4 to every element of each covered row,", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def _step4(self):", "prediction_line": "    def _step4(self):", "ground_truth": "    def _step4(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def _step5(self):", "prediction_line": "    def _step5(self):", "ground_truth": "    def _step5(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        and subtract it from every element of each uncovered column. Return", "prediction_line": "        and subtract it from every element of each uncovered column. Return", "ground_truth": "        and subtract it from every element of each uncovered column. Return", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "_in_col\nfrom ..backend.munkres import get_min_uncovered_in_row", "prediction_line": "_in_col", "ground_truth": "from ..backend.munkres import find_smallest_uncovered", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    self.marked[row][col] = 1", "prediction_line": "                    self.marked[row][col] = 1", "ground_truth": "                    self.marked[row][col] = 1", "line_class": "random", "zero_context": true}
{"original_prediction": "        else:\n            step = 4", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "                                             self.col_covered)", "prediction_line": "                                             self.col_covered)", "ground_truth": "                                             self.col_covered, row, col)", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.Z0_r, self.Z0_c = find_uncovered_zero(self.cost_matrix,", "prediction_line": "        self.Z0_r, self.Z0_c = find_uncovered_zero(self.cost_matrix,", "ground_truth": "        done = False", "line_class": "random", "zero_context": true}
{"original_prediction": "    x = bottleneck(x_list[1], filters=128, expansion=4,", "prediction_line": "    x = bottleneck(x_list[1], filters=128, expansion=4,", "ground_truth": "    for block in range(4):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            x_list = blocks_in_branch(x_list, stage=3, in_channels=32,", "prediction_line": "            x_list = blocks_in_branch(x_list, stage=3, in_channels=32,", "ground_truth": "            name = 'stage3.' + str(module) + '.branches.' + str(block)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    # print(f\"check 2 bottleneck TF ==> {x.get_shape()}\")", "prediction_line": "    # print(f\"check 2 bottleneck TF ==> {x.get_shape()}\")", "ground_truth": "    for block in range(3):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                       downsample=False, name='layer1' + '.' + str(block + 1))", "prediction_line": "                       downsample=False, name='layer1' + '.' + str(block + 1))", "ground_truth": "                       downsample=None, name='layer1' + '.' + str(block + 1))", "line_class": "commited", "zero_context": true}
{"original_prediction": "            name = 'stage4.' + str(module) + '.branches.' + str(block)", "prediction_line": "            name = 'stage4.' + str(module) + '.branches.' + str(block)", "ground_truth": "            name = 'stage4.' + str(module) + '.branches.' + str(block)", "line_class": "commited", "zero_context": true}
{"original_prediction": "name='deconv_layers.0.1.' + str(block))", "prediction_line": "name='deconv_layers.0.1.' + str(block))", "ground_truth": "                name='deconv_layers.0.' + str(block + 1) + '.' + '0')", "line_class": "commited", "zero_context": true}
{"original_prediction": "                                  name='layer2' + '.' + str(block + 1))", "prediction_line": "                                  name='layer2' + '.' + str(block + 1))", "ground_truth": "                                  name='stage2.0.branches.' + str(block))", "line_class": "commited", "zero_context": true}
{"original_prediction": "            x_list = blocks_in_branch(x_list, stage=3, in_channels=32,", "prediction_line": "            x_list = blocks_in_branch(x_list, stage=3, in_channels=32,", "ground_truth": "            x_list = blocks_in_branch(x_list, stage=3,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x_list = fuse_layers(x_list, stage=3, output_branches=2,", "prediction_line": "        x_list = fuse_layers(x_list, stage=3, output_branches=2,", "ground_truth": "        x_list = fuse_layers(x_list, stage=3, output_branches=3,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            x_list = blocks_in_branch(x_list, stage=4,", "prediction_line": "            x_list = blocks_in_branch(x_list, stage=4,", "ground_truth": "            x_list = blocks_in_branch(x_list, stage=4,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                y = UpSampling2D(size=2 ** steps, name=name0 + '.0')(y)", "prediction_line": "                y = UpSampling2D(size=2 ** steps, name=name0 + '.0')(y)", "ground_truth": "                y = upsample(tensors[stage_arg], filters * (2 ** branch_arg),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    x2 = deconv_layers(x2, 32, num_deconv=1)", "prediction_line": "    x2 = deconv_layers(x2, 32, num_deconv=1)", "ground_truth": "    output = final_layers(num_keypoints, with_AE_loss=with_AE_loss)[0](x2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        name2 = get_names(name, branch_arg, stage_arg, 1.1)", "prediction_line": "                        name2 = get_names(name, branch_arg, stage_arg, 1.1)", "ground_truth": "                        y = downsample(y, filters * (2 ** stage_arg), name1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    x2 = deconv_layers(x2, 32, num_deconv=1)", "prediction_line": "    x2 = deconv_layers(x2, 32, num_deconv=1)", "ground_truth": "    x2 = deconv_layers(x2, 32)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    output = final_layers(num_keypoints, with_AE_loss=with_AE_loss)[1](x2)", "prediction_line": "    output = final_layers(num_keypoints, with_AE_loss=with_AE_loss)[1](x2)", "ground_truth": "    x2 = final_layers(num_keypoints, with_AE_loss=with_AE_loss)[1](x2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    y = downsample(tensors[stage_arg],", "prediction_line": "                    y = downsample(tensors[stage_arg],", "ground_truth": "                    y = downsample(tensors[stage_arg],", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if downsample is not None:", "prediction_line": "    if downsample is not None:", "ground_truth": "    if downsample is not None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    y = downsample(y, filters * (2 ** branch_arg), name4)", "prediction_line": "                    y = downsample(y, filters * (2 ** branch_arg), name4)", "ground_truth": "                    y = downsample(y, filters * (2 ** branch_arg), name4)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x = bottleneck(tensors[arg], filters, 4, name=name + '.' + str(arg))", "prediction_line": "        x = bottleneck(tensors[arg], filters, 4, name=name + '.' + str(arg))", "ground_truth": "        tensors[arg] = basic_block(tensors[arg], filters,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    x = Conv2D(256, 3, padding='same', use_bias=False, name='final.0.conv')(tensors[-1])", "prediction_line": "    x = Conv2D(256, 3, padding='same', use_bias=False, name='final.0.conv')(tensors[-1])", "ground_truth": "    final_layers = []", "line_class": "infile", "zero_context": true}
{"original_prediction": "    final_layers.append(x)", "prediction_line": "    final_layers.append(x)", "ground_truth": "    final_layers.append(x)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    stem_filters = 64", "prediction_line": "    stem_filters = 64", "ground_truth": "    x = stem(image, 64)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        final_layers.append(x1)", "prediction_line": "        final_layers.append(x1)", "ground_truth": "        final_layers.append(x1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return final_layers", "prediction_line": "    return final_layers", "ground_truth": "    return final_layers", "line_class": "infile", "zero_context": true}
{"original_prediction": "-\n    x = bottleneck(x, 64, 1, name='layer1.0')", "prediction_line": "-", "ground_truth": "    x = bottleneck(x, filters=64, expansion=4,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            x = Conv2D(output_channels, 3, padding='same',", "prediction_line": "            x = Conv2D(output_channels, 3, padding='same',", "ground_truth": "            x = basic_block(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x = bottleneck(x, filters=64, expansion=4,", "prediction_line": "        x = bottleneck(x, filters=64, expansion=4,", "ground_truth": "        x_list = blocks_in_branch(x_list, stage=2, in_channels=32,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Stage 3 -----------------------------------------------------------------", "prediction_line": "    # Stage 3 -----------------------------------------------------------------", "ground_truth": "    x_list = fuse_layers(x_list, stage=2, output_branches=2,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        name1, name2 = get_names(name, branch_arg, stage_arg,", "prediction_line": "                        name1, name2 = get_names(name, branch_arg, stage_arg,", "ground_truth": "                        name1 = get_names(name, branch_arg, stage_arg, 1.0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = Conv2D(filters, 3, strides=2, use_bias=False, name='conv2')(x)", "prediction_line": "    x = Conv2D(filters, 3, strides=2, use_bias=False, name='conv2')(x)", "ground_truth": "    x = Conv2D(filters, 3, strides=2, use_bias=False, name='conv2')(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = BatchNormalization(momentum=0.1, epsilon=1e-05,", "prediction_line": "    x = BatchNormalization(momentum=0.1, epsilon=1e-05,", "ground_truth": "    x = BatchNormalization(momentum=0.1, epsilon=1e-05, name='bn2')(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                for arg in range(steps):", "prediction_line": "                for arg in range(steps):", "ground_truth": "                name0 = '.'.join((name, str(branch_arg), str(stage_arg)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    model = Model(image, final_outputs)", "prediction_line": "    model = Model(image, final_outputs)", "ground_truth": "    model = Model(image, outputs=final_outputs, name='HigherHRNet')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            name='deconv_layers.0')(tensor)", "prediction_line": "                            name='deconv_layers.0')(tensor)", "ground_truth": "                            name='deconv_layers.0.0.0')(tensor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "name=name + str(arg))", "prediction_line": "name=name + str(arg))", "ground_truth": "                                   name=name[:18] + str(arg) + '.' + name[18:])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            x_list = fuse_layers(x_list, stage=4, output_branches=4,", "prediction_line": "            x_list = fuse_layers(x_list, stage=4, output_branches=4,", "ground_truth": "            x_list = fuse_layers(x_list, stage=4, output_branches=1, name=name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    name4 = get_names(name, branch_arg, stage_arg, 1.0)", "prediction_line": "                    name4 = get_names(name, branch_arg, stage_arg, 1.0)", "ground_truth": "                    name4 = get_names(name, branch_arg, stage_arg,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = ReLU()(x)", "prediction_line": "    x = ReLU()(x)", "ground_truth": "    x = UpSampling2D(size=size, interpolation='nearest', name=name + '.2')(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "in_channels=32,", "prediction_line": "in_channels=32,", "ground_truth": "                                      in_channels=32, name=name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "name='bn1')(x)", "prediction_line": "name='bn1')(x)", "ground_truth": "                           name='bn1')(x, training=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = Conv2DTranspose(filters, size, strides=2,", "prediction_line": "    x = Conv2DTranspose(filters, size, strides=2,", "ground_truth": "    x = Conv2D(filters, 1, use_bias=False, name=name + '.0')(tensor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = BatchNormalization(momentum=0.1, epsilon=1.0e-5, name=name + '.bn1')(x)", "prediction_line": "    x = BatchNormalization(momentum=0.1, epsilon=1.0e-5, name=name + '.bn1')(x)", "ground_truth": "    x = BatchNormalization(momentum=0.1, epsilon=1e-05, name=name + '.bn1')(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        name2 = get_names(name, branch_arg, stage_arg, 0.0)", "prediction_line": "                        name2 = get_names(name, branch_arg, stage_arg, 0.0)", "ground_truth": "                        name2 = get_names(name, branch_arg, stage_arg, 0.0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from tensorflow.keras.models import Model", "prediction_line": "from tensorflow.keras.models import Model", "ground_truth": "from tensorflow.keras.models import Model", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            If None, the model will be created without any weights.", "prediction_line": "            If None, the model will be created without any weights.", "ground_truth": "            Current valid datasets include `COCO`.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   x1 = Conv2D(32, 3, strides=1, padding='same',", "prediction_line": "   x1 = Conv2D(32, 3, strides=1, padding='same',", "ground_truth": "    x_list.append(x1)", "line_class": "random", "zero_context": true}
{"original_prediction": "    return x", "prediction_line": "    return x", "ground_truth": "    return x", "line_class": "random", "zero_context": true}
{"original_prediction": "def conv_block(input_tensor, n_filters, kernel_size=3, batch_norm=True,", "prediction_line": "def conv_block(input_tensor, n_filters, kernel_size=3, batch_norm=True,", "ground_truth": "WEIGHT_PATH = ('https://github.com/oarriaga/altamira-data/releases/download'", "line_class": "random", "zero_context": true}
{"original_prediction": "                x = all_tensors[x_tensor_arg][y_tensor_arg]", "prediction_line": "                x = all_tensors[x_tensor_arg][y_tensor_arg]", "ground_truth": "                x_fused.append(all_tensors[x_tensor_arg][0])", "line_class": "random", "zero_context": true}
{"original_prediction": "    if with_padding:", "prediction_line": "    if with_padding:", "ground_truth": "    if with_padding:", "line_class": "random", "zero_context": true}
{"original_prediction": "        return flip_left_right(image)", "prediction_line": "        return flip_left_right(image)", "ground_truth": "        image = flip_left_right(image)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    image = cast_image(image, np.float32)", "prediction_line": "    image = cast_image(image, np.float32)", "ground_truth": "    image = cast_image(image, np.float32)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    image = image + np.random.uniform(-delta, delta)", "prediction_line": "    image = image + np.random.uniform(-delta, delta)", "ground_truth": "    random_brightness = np.random.uniform(-delta, delta)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    image = image + random_brightness", "prediction_line": "    image = image + random_brightness", "ground_truth": "    image = image + random_brightness", "line_class": "infile", "zero_context": true}
{"original_prediction": "    image = cast_image(image, np.uint8)", "prediction_line": "    image = cast_image(image, np.uint8)", "ground_truth": "    image = cast_image(image, np.uint8)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    x_delta = np.random.uniform(-x_delta_scale, x_delta_scale)", "prediction_line": "    x_delta = np.random.uniform(-x_delta_scale, x_delta_scale)", "ground_truth": "    x = image_shape[1] * np.random.uniform(-x_delta_scale, x_delta_scale)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    y = image_shape[0] * np.random.uniform(-y_delta_scale, y_delta_scale)", "prediction_line": "    y = image_shape[0] * np.random.uniform(-y_delta_scale, y_delta_scale)", "ground_truth": "    y = image_shape[0] * np.random.uniform(-y_delta_scale, y_delta_scale)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    image = convert_color_space(image, HSV2RGB)", "prediction_line": "    image = convert_color_space(image, HSV2RGB)", "ground_truth": "    image = convert_color_space(image, HSV2RGB)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if np.random.uniform([1], 0, 2) == 1:", "prediction_line": "    if np.random.uniform([1], 0, 2) == 1:", "ground_truth": "    blur = np.random.choice([gaussian_image_blur, median_image_blur])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    image = convert_color_space(image, RGB2HSV)", "prediction_line": "    image = convert_color_space(image, RGB2HSV)", "ground_truth": "    image = convert_color_space(image, RGB2HSV)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    image = np.clip(image, 0, 255)", "prediction_line": "    image = np.clip(image, 0, 255)", "ground_truth": "    image = np.clip(image, 0, 255)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    matrix[0, 2], matrix[1, 2] = translation", "prediction_line": "    matrix[0, 2], matrix[1, 2] = translation", "ground_truth": "    matrix[0, 2], matrix[1, 2] = translation", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    image = image.astype(np.float32)", "prediction_line": "    image = image.astype(np.float32)", "ground_truth": "    foreground, alpha = np.split(image, [3], -1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    image, alpha_mask = np.split(image, [3], -1)", "prediction_line": "    image, alpha_mask = np.split(image, [3], -1)", "ground_truth": "    image, alpha_channel = np.split(image, [3], -1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return warp_affine(image, matrix, fill_color)", "prediction_line": "    return warp_affine(image, matrix, fill_color)", "ground_truth": "    image = warp_affine(image, matrix, fill_color)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    image = cast_image(image, np.uint8)", "prediction_line": "    image = cast_image(image, np.uint8)", "ground_truth": "    image[:, :, 1] = np.clip(image[:, :, 1], 0, 255)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    H, W = image_shape", "prediction_line": "    H, W = image_shape", "ground_truth": "    x_delta_scale, y_delta_scale = delta_scale", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        image: Numpy array.", "prediction_line": "        image: Numpy array.", "ground_truth": "        image: Numpy array.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        delta: Float.", "prediction_line": "        delta: Float.", "ground_truth": "        delta: Int.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"Samples a random translation.", "prediction_line": "    \"\"\"Samples a random translation.", "ground_truth": "    \"\"\"Samples a scaled translation from a uniform distribution.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # Arguments", "prediction_line": "    # Arguments", "ground_truth": "    # Arguments", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    return image", "prediction_line": "    return image", "ground_truth": "    return image", "line_class": "random", "zero_context": true}
{"original_prediction": "    if (type(image) != np.ndarray):", "prediction_line": "    if (type(image) != np.ndarray):", "ground_truth": "    matrix = np.zeros((2, 3), dtype=np.float32)", "line_class": "random", "zero_context": true}
{"original_prediction": "        return image[crop_box[0]:crop_box[1], crop_box[2]:crop_box[3]]", "prediction_line": "        return image[crop_box[0]:crop_box[1], crop_box[2]:crop_box[3]]", "ground_truth": "        cropped_image = image[crop_box[0]:crop_box[2],", "line_class": "random", "zero_context": true}
{"original_prediction": "    return image, alpha_channel", "prediction_line": "    return image, alpha_channel", "ground_truth": "    return image, alpha_channel", "line_class": "random", "zero_context": true}
{"original_prediction": "            x_list = blocks_in_branch(x_list, stage=3, in_channels=32,", "prediction_line": "            x_list = blocks_in_branch(x_list, stage=3, in_channels=32,", "ground_truth": "            x_list = blocks_in_branch(x_list, stage=3,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x_list = fuse_layers(x_list, stage=3, output_branches=2,", "prediction_line": "        x_list = fuse_layers(x_list, stage=3, output_branches=2,", "ground_truth": "        x_list = fuse_layers(x_list, stage=3, output_branches=3,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            x_list = blocks_in_branch(x_list, stage=4,", "prediction_line": "            x_list = blocks_in_branch(x_list, stage=4,", "ground_truth": "            x_list = blocks_in_branch(x_list, stage=4,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                y = UpSampling2D(size=2, name=name0)(tensors[branch_arg])", "prediction_line": "                y = UpSampling2D(size=2, name=name0)(tensors[branch_arg])", "ground_truth": "                y = upsample(tensors[stage_arg], filters * (2 ** branch_arg),", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        name2 = get_names(name, branch_arg, stage_arg, 1.1)", "prediction_line": "                        name2 = get_names(name, branch_arg, stage_arg, 1.1)", "ground_truth": "                        y = downsample(y, filters * (2 ** stage_arg), name1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    x2 = deconv_layers(x2, 32, num_deconv=1)", "prediction_line": "    x2 = deconv_layers(x2, 32, num_deconv=1)", "ground_truth": "    x2 = deconv_layers(x2, 32)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    output = final_layers(num_keypoints, with_AE_loss=with_AE_loss)[1](x2)", "prediction_line": "    output = final_layers(num_keypoints, with_AE_loss=with_AE_loss)[1](x2)", "ground_truth": "    x2 = final_layers(num_keypoints, with_AE_loss=with_AE_loss)[1](x2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        y = downsample(tensors[branch_arg],", "prediction_line": "                        y = downsample(tensors[branch_arg],", "ground_truth": "                        y = downsample(tensors[stage_arg],", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if downsample is not None:", "prediction_line": "    if downsample is not None:", "ground_truth": "    if downsample is not None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    y = downsample(y, filters * (2 ** branch_arg), name4)", "prediction_line": "                    y = downsample(y, filters * (2 ** branch_arg), name4)", "ground_truth": "                    y = downsample(y, filters * (2 ** branch_arg), name4)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x = bottleneck(tensors[arg], filters, 4, name=name+'.branch{}'.format(arg))", "prediction_line": "        x = bottleneck(tensors[arg], filters, 4, name=name+'.branch{}'.format(arg))", "ground_truth": "        tensors[arg] = basic_block(tensors[arg], filters,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    x = Conv2D(256, 3, padding='same', use_bias=False, name='final.0')", "prediction_line": "    x = Conv2D(256, 3, padding='same', use_bias=False, name='final.0')", "ground_truth": "    final_layers = []", "line_class": "infile", "zero_context": true}
{"original_prediction": "    final_layers.append(x)", "prediction_line": "    final_layers.append(x)", "ground_truth": "    final_layers.append(x)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    stem_filters = 64", "prediction_line": "    stem_filters = 64", "ground_truth": "    x = stem(image, 64)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        final_layers.append(x1)", "prediction_line": "        final_layers.append(x1)", "ground_truth": "        final_layers.append(x1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return final_layers", "prediction_line": "    return final_layers", "ground_truth": "    return final_layers", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x = bottleneck(x, filters=64, expansion=4,", "prediction_line": "        x = bottleneck(x, filters=64, expansion=4,", "ground_truth": "        x = bottleneck(x, filters=64, expansion=4,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            x = Conv2D(output_channels, 3, padding='same',", "prediction_line": "            x = Conv2D(output_channels, 3, padding='same',", "ground_truth": "            x = basic_block(x, output_channels,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x = bottleneck(x, filters=64, expansion=4,", "prediction_line": "        x = bottleneck(x, filters=64, expansion=4,", "ground_truth": "        x_list = blocks_in_branch(x_list, stage=2, in_channels=32,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Stage 3 -----------------------------------------------------------------", "prediction_line": "    # Stage 3 -----------------------------------------------------------------", "ground_truth": "    x_list = fuse_layers(x_list, stage=2, output_branches=2,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    x = ReLU(name=name + '.relu1')(x)", "prediction_line": "    x = ReLU(name=name + '.relu1')(x)", "ground_truth": "    x = ReLU(name=name + '.relu')(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = BatchNormalization(momentum=0.1, epsilon=1e-05, name=name+'.bn2')(x)", "prediction_line": "    x = BatchNormalization(momentum=0.1, epsilon=1e-05, name=name+'.bn2')(x)", "ground_truth": "    x = BatchNormalization(momentum=0.1, epsilon=1e-05, name=name+'.bn2')(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = BatchNormalization(momentum=0.1, epsilon=1e-05,", "prediction_line": "    x = BatchNormalization(momentum=0.1, epsilon=1e-05,", "ground_truth": "    x = BatchNormalization(momentum=0.1, epsilon=1e-05, name='bn2')(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        model.load_weights(get_file('HigherHRNet_weights.hdf5', URL,", "prediction_line": "        model.load_weights(get_file('HigherHRNet_weights.hdf5', URL,", "ground_truth": "        filename = os.path.basename(URL)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return x", "prediction_line": "    return x", "ground_truth": "    x = ZeroPadding2D(padding=(1, 1), name='pad_1')(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Stem block of the network.", "prediction_line": "    \"\"\"", "ground_truth": "    x = ZeroPadding2D(padding=(1, 1), name='pad')(tensor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                             name=name0)", "prediction_line": "                             name=name0)", "ground_truth": "                             size=(2**steps, 2**steps), name=name0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = Conv2D(filters, 3, strides=2, use_bias=False, name=name + '.0')(tensor)", "prediction_line": "    x = Conv2D(filters, 3, strides=2, use_bias=False, name=name + '.0')(tensor)", "ground_truth": "    x = Conv2D(filters, 3, strides=2, use_bias=False, name=name[0])(tensor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "downsample=None, name='layer1.0')", "prediction_line": "downsample=None, name='layer1.0')", "ground_truth": "                   downsample=True, name='layer1' + '.0')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                use_bias=False, name='layer1.0.downsample.0')(x)", "prediction_line": "                use_bias=False, name='layer1.0.downsample.0')(x)", "ground_truth": "                use_bias=False, name='transition1.0.0')(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        name1, name2 = get_names(name, branch_arg, stage_arg,", "prediction_line": "                        name1, name2 = get_names(name, branch_arg, stage_arg,", "ground_truth": "                        name1 = get_names(name, branch_arg, stage_arg, 1.0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = ReLU(name=name+'.relu')(x)", "prediction_line": "    x = ReLU(name=name+'.relu')(x)", "ground_truth": "    x = ReLU(name=name+'.relu')(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    x = Conv2D(filters, 3, strides=2, use_bias=False, name='conv2')(x)", "prediction_line": "    x = Conv2D(filters, 3, strides=2, use_bias=False, name='conv2')(x)", "ground_truth": "    x = Conv2D(filters, 3, strides=2, use_bias=False, name='conv2')(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "use_bias=False, name=name + '.conv1')(tensor)", "prediction_line": "use_bias=False, name=name + '.conv1')(tensor)", "ground_truth": "               use_bias=False, name=name+'.conv1')(tensor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            name='deconv_layers.0')(tensor)", "prediction_line": "                            name='deconv_layers.0')(tensor)", "ground_truth": "                            name='deconv_layers.0.0.0')(tensor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def bottleneck(tensor, filters, cardinality, stride, name):", "prediction_line": "def bottleneck(tensor, filters, cardinality, stride, name):", "ground_truth": "def bottleneck(tensor, filters, expansion, downsample=None, name=None):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from tensorflow.keras.models import load_model", "prediction_line": "from tensorflow.keras.models import load_model", "ground_truth": "from tensorflow.keras.layers import Conv2D", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def _make_divisible(v, divisor, min_value=None):", "prediction_line": "def _make_divisible(v, divisor, min_value=None):", "ground_truth": "def stem(tensor, filters):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   # print(f\"check 1 stem TF ==> {x.shape}\")", "prediction_line": "   # print(f\"check 1 stem TF ==> {x.shape}\")", "ground_truth": "    # First group of bottleneck (resnet) modules", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    x = Conv2D(filters, 1, use_bias=False, name=f'{name}_conv1')(tensor)", "prediction_line": "    x = Conv2D(filters, 1, use_bias=False, name=f'{name}_conv1')(tensor)", "ground_truth": "    residual = tensor", "line_class": "random", "zero_context": true}
{"original_prediction": "        else:\n            output_channels = num_keypoints", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "    return x", "prediction_line": "    return x", "ground_truth": "    return x", "line_class": "random", "zero_context": true}
{"original_prediction": "   # print(f\"check 2 bottleneck TF ==> {x.get_shape()}\")", "prediction_line": "   # print(f\"check 2 bottleneck TF ==> {x.get_shape()}\")", "ground_truth": "    x_list = []", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.return_selection = return_selection", "prediction_line": "        self.return_selection = return_selection", "ground_truth": "        super().__init__(**{k: v for k, v in kwargs.items() if is_keras_kwarg(k)})", "line_class": "commited", "zero_context": true}
{"original_prediction": "    **Mode**: single, disjoint, mixed, batch.", "prediction_line": "    **Mode**: single, disjoint, mixed, batch.", "ground_truth": "    By extending this class, it is possible to create any pooling layer in the", "line_class": "common", "zero_context": true}
{"original_prediction": "    node indices.", "prediction_line": "    node indices.", "ground_truth": "    batch index;", "line_class": "common", "zero_context": true}
{"original_prediction": "    features and the adjacency matrix of the output.", "prediction_line": "    features and the adjacency matrix of the output.", "ground_truth": "    features and adjacency matrix. If the batch index `i` is not `None`, a", "line_class": "common", "zero_context": true}
{"original_prediction": "    `(K, )` representing the batch index of the output.", "prediction_line": "    `(K, )` representing the batch index of the output.", "ground_truth": "    `(K, )` representing the batch index of the output;", "line_class": "common", "zero_context": true}
{"original_prediction": "        s = self.select(x, a, i, **kwargs)", "prediction_line": "        s = self.select(x, a, i, **kwargs)", "ground_truth": "        sel_kwargs = self._get_kwargs(x, a, i, self.sel_signature, kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        s = self.select(x, a, i, **sel_kwargs)", "prediction_line": "        s = self.select(x, a, i, **sel_kwargs)", "ground_truth": "        s = self.select(x, a, i, **sel_kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        base_config = super().get_config()", "prediction_line": "        base_config = super().get_config()", "ground_truth": "        base_config = super().get_config()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        red_kwargs = self._get_kwargs(x, a, i, self.red_signature, kwargs)", "prediction_line": "        red_kwargs = self._get_kwargs(x, a, i, self.red_signature, kwargs)", "ground_truth": "        red_kwargs = self._get_kwargs(x, a, i, self.red_signature, kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x_pool = self.reduce(x, s, **red_kwargs)", "prediction_line": "        x_pool = self.reduce(x, s, **red_kwargs)", "ground_truth": "        x_pool = self.reduce(x, s, **red_kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if i is not None:", "prediction_line": "        if i is not None:", "ground_truth": "        i_red_kwargs = self._get_kwargs(x, a, i, self.i_red_signature, kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        i_pool = self.reduce_index(i, s, **i_red_kwargs)", "prediction_line": "        i_pool = self.reduce_index(i, s, **i_red_kwargs)", "ground_truth": "        i_pool = self.reduce_index(i, s, **i_red_kwargs) if i is not None else None", "line_class": "infile", "zero_context": true}
{"original_prediction": "        con_kwargs = self._get_kwargs(x, a, i, self.con_signature, kwargs)", "prediction_line": "        con_kwargs = self._get_kwargs(x, a, i, self.con_signature, kwargs)", "ground_truth": "        con_kwargs = self._get_kwargs(x, a, i, self.con_signature, kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        a_pool = self.connect(a, s, **con_kwargs)", "prediction_line": "        a_pool = self.connect(a, s, **con_kwargs)", "ground_truth": "        a_pool = self.connect(a, s, **con_kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "node\n    equivariant reduction function that computes the supernode features", "prediction_line": "node", "ground_truth": "    permutation-invariant function to reduce the supernodes into the new node", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self.return_selection:", "prediction_line": "        if self.return_selection:", "ground_truth": "        return self.get_outputs(x_pool, a_pool, i_pool, s)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @n_nodes.setter", "prediction_line": "    @n_nodes.setter", "ground_truth": "    @n_nodes.setter", "line_class": "infile", "zero_context": true}
{"original_prediction": "def sparse_connect(a, s, n_nodes):", "prediction_line": "def sparse_connect(a, s, n_nodes):", "ground_truth": "    @n_nodes.deleter", "line_class": "infile", "zero_context": true}
{"original_prediction": "    **Arguments**", "prediction_line": "    **Arguments**", "ground_truth": "    - `reduce_index(i, s, **kwargs)`: helper function to reduce the batch index", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return tf.gather(a, s, axis=1)", "prediction_line": "        return tf.gather(a, s, axis=1)", "ground_truth": "        return sparse_connect(a, s, self.n_nodes)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Create a trainable weight variable for this layer.", "prediction_line": "        # Create a trainable weight variable for this layer.", "ground_truth": "        super().build(input_shape)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x, a, i = self.get_inputs(inputs)", "prediction_line": "        x, a, i = self.get_inputs(inputs)", "ground_truth": "        x, a, i = self.get_inputs(inputs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Get the kwargs for the SRC functions", "prediction_line": "        # Get the kwargs for the SRC functions", "ground_truth": "        return self.pool(x, a, i)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._n_nodes = K.shape(x)[1]", "prediction_line": "        self._n_nodes = K.shape(x)[1]", "ground_truth": "        self.n_nodes = tf.shape(x)[-2]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if is_layer_kwarg(key):", "prediction_line": "            if is_layer_kwarg(key):", "ground_truth": "            if is_layer_kwarg(key):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for key in signature:", "prediction_line": "        for key in signature:", "ground_truth": "        for k in signature.keys():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if isinstance(attr, str):", "prediction_line": "                if isinstance(attr, str):", "ground_truth": "                attr = deserialize_kwarg(key, attr)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if k in kwargs:", "prediction_line": "            if k in kwargs:", "ground_truth": "            if signature[k].default is inspect.Parameter.empty or k == \"kwargs\":", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.select_signature = inspect.signature(self.select)", "prediction_line": "        self.select_signature = inspect.signature(self.select)", "ground_truth": "        self.sel_signature = inspect.signature(self.select).parameters", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.red_signature = inspect.signature(self.reduce).parameters", "prediction_line": "        self.red_signature = inspect.signature(self.reduce).parameters", "ground_truth": "        self.red_signature = inspect.signature(self.reduce).parameters", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    serialize_kwarg,", "prediction_line": "    serialize_kwarg,", "ground_truth": "    serialize_kwarg,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.con_signature = inspect.signature(self.connect).parameters", "prediction_line": "        self.con_signature = inspect.signature(self.connect).parameters", "ground_truth": "        self.con_signature = inspect.signature(self.connect).parameters", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def get_config(self):", "prediction_line": "    def get_config(self):", "ground_truth": "        self.i_red_signature = inspect.signature(self.reduce_index).parameters", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        config = super().get_config()", "prediction_line": "        config = super().get_config()", "ground_truth": "        config = {", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                raise ValueError(", "prediction_line": "                raise ValueError(", "ground_truth": "                raise ValueError(\"Missing key {} for signature {}\".format(k, signature))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            config[key] = serialize_kwarg(key, getattr(self, key))", "prediction_line": "            config[key] = serialize_kwarg(key, getattr(self, key))", "ground_truth": "            config[key] = serialize_kwarg(key, getattr(self, key))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return dict(list(base_config.items()) + list(config.items()))", "prediction_line": "        return dict(list(base_config.items()) + list(config.items()))", "ground_truth": "        return {**base_config, **config}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    > [Kipf & Welling, 2017](https://arxiv.org/abs/1606.09375)", "prediction_line": "    > [Kipf & Welling, 2017](https://arxiv.org/abs/1606.09375)", "ground_truth": "    > [Understanding Pooling in Graph Neural Networks.](https://arxiv.org/abs/2110.05292)<br>", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return output", "prediction_line": "    return output", "ground_truth": "    return tf.sparse.reorder(output)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            `(K, )`;", "prediction_line": "            `(K, )`;", "ground_truth": "            `(K, )`;", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\n        return x", "prediction_line": "        \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        :param s: Tensor representing supernode assignments, as computed by", "prediction_line": "        :param s: Tensor representing supernode assignments, as computed by", "ground_truth": "        :param s: Tensor representing supernode assignments, as computed by", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        :param x: Tensor of shape `([batch], N, F)`;", "prediction_line": "        :param x: Tensor of shape `([batch], N, F)`;", "ground_truth": "        Supernode assignments are usually represented as a dense matrix of shape", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        :param a: Tensor or SparseTensor of shape `([batch], N, N)`;", "prediction_line": "        :param a: Tensor or SparseTensor of shape `([batch], N, N)`;", "ground_truth": "        :param a: Tensor or SparseTensor of shape `([batch], N, N)`;", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    arguments of the pooling layer by calling `self.get_inputs(inputs)`.", "prediction_line": "    arguments of the pooling layer by calling `self.get_inputs(inputs)`.", "ground_truth": "    true number of nodes of the input (`n_nodes`) as a Tensor in the instance variable", "line_class": "random", "zero_context": true}
{"original_prediction": "def sparse_connect(a, s, n_nodes):", "prediction_line": "def sparse_connect(a, s, n_nodes):", "ground_truth": "    @property", "line_class": "random", "zero_context": true}
{"original_prediction": "    > *Ross Wightman, Xavier Bouthillier, Thomas Laurent, Quentin Fillon,", "prediction_line": "    > *Ross Wightman, Xavier Bouthillier, Thomas Laurent, Quentin Fillon,", "ground_truth": "    > Daniele Grattarola et al.", "line_class": "random", "zero_context": true}
{"original_prediction": "    - `a`: Tensor of shape `([batch], N, N)` representing adjacency matrices.", "prediction_line": "    - `a`: Tensor of shape `([batch], N, N)` representing adjacency matrices.", "ground_truth": "    - `a`: Tensor or SparseTensor of shape `([batch], N, N)` representing the", "line_class": "random", "zero_context": true}
{"original_prediction": "            x, a = inputs", "prediction_line": "            x, a = inputs", "ground_truth": "            x, a = inputs", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(**kwargs)\r", "prediction_line": "        super().__init__(**kwargs)\r", "ground_truth": "        super().__init__(\r", "line_class": "commited", "zero_context": true}
{"original_prediction": "        k = K.cast(self.k, K.floatx())\r", "prediction_line": "        k = K.cast(self.k, K.floatx())\r", "ground_truth": "        col_loss = self.collapse_loss(a, s)\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.built = True\r", "prediction_line": "        self.built = True\r", "ground_truth": "        super().build(input_shape)\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        base_config = super().get_config()\r", "prediction_line": "        base_config = super().get_config()\r", "ground_truth": "        base_config = super().get_config()\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "        mod_loss = self.modularity_loss(a, a_pool)\r", "prediction_line": "        mod_loss = self.modularity_loss(a, a_pool)\r", "ground_truth": "        mod_loss = self.modularity_loss(a, s, a_pool)\r", "line_class": "infile", "zero_context": true}
{"original_prediction": "    - `mlp_activation`: activation function to use in the MLP layers;\r", "prediction_line": "    - `mlp_activation`: activation function to use in the MLP layers;\r", "ground_truth": "    - `mlp_activation`: activation for the MLP layers;\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return normalizer - tf.matmul(s, a_pool, transpose_a=True)\r", "prediction_line": "        return normalizer - tf.matmul(s, a_pool, transpose_a=True)\r", "ground_truth": "        loss = -tf.linalg.trace(a_pool - normalizer) / 2 / n_edges\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                2 / n_edges\r", "prediction_line": "                2 / n_edges\r", "ground_truth": "                2 / n_edges\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            normalizer_left = K.sum(normalizer_left, axis=1)\r", "prediction_line": "            normalizer_left = K.sum(normalizer_left, axis=1)\r", "ground_truth": "            normalizer = ops.modal_dot(normalizer_left, normalizer_right) / \\\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        X, A = inputs\r", "prediction_line": "        X, A = inputs\r", "ground_truth": "        x, a, i = self.get_inputs(inputs)\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return ops.matmul_masked(s, x)\r", "prediction_line": "        return ops.matmul_masked(s, x)\r", "ground_truth": "        return ops.modal_dot(s, x, transpose_a=True)\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            tf.sqrt(tf.cast(self.k, s.dtype)) - n_nodes\r", "prediction_line": "            tf.sqrt(tf.cast(self.k, s.dtype)) - n_nodes\r", "ground_truth": "            n_nodes * tf.sqrt(float(self.k)) - 1\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return dict(list(base_config.items()) + list(config.items()))\r", "prediction_line": "        return dict(list(base_config.items()) + list(config.items()))\r", "ground_truth": "        return {**base_config, **config}\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # Compute the modularity loss\r", "prediction_line": "            # Compute the modularity loss\r", "ground_truth": "            degrees = tf.sparse.reduce_sum(a, axis=-1)\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        cluster_sizes = tf.reshape(cluster_sizes, (-1, 1))\r", "prediction_line": "        cluster_sizes = tf.reshape(cluster_sizes, (-1, 1))\r", "ground_truth": "        n_nodes = tf.cast(tf.shape(a)[-1], s.dtype)\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "\r\n            degrees = tf.reduce_sum(a, axis=(-2, -1))\r", "prediction_line": "\r", "ground_truth": "            degrees = tf.reduce_sum(a, axis=-1, keepdims=True)\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            n_edges = tf.cast(tf.reduce_sum(a), dtype=s.dtype)\r", "prediction_line": "            n_edges = tf.cast(tf.reduce_sum(a), dtype=s.dtype)\r", "ground_truth": "            n_edges = tf.cast(tf.math.count_nonzero(\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return ops.modal_dot(s, a, s)\r", "prediction_line": "        return ops.modal_dot(s, a, s)\r", "ground_truth": "        a_pool = ops.matmul_at_b_a(s, a)\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        config = super().get_config()\r", "prediction_line": "        config = super().get_config()\r", "ground_truth": "        config = {\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    - `activity_regularizer`: regularization applied to the output of the MLP;\r", "prediction_line": "    - `activity_regularizer`: regularization applied to the output of the MLP;\r", "ground_truth": "    - `kernel_constraint`: constraint applied to the weights of the MLP;\r", "line_class": "inproject", "zero_context": true}
{"original_prediction": "\r\n    **Input**\r", "prediction_line": "\r", "ground_truth": "\r", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def collapse_loss(self, a, s):\r", "prediction_line": "    def collapse_loss(self, a, s):\r", "ground_truth": "    def reduce(self, x, s, **kwargs):\r", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    **Arguments**\r", "prediction_line": "    **Arguments**\r", "ground_truth": "    **Arguments**\r", "line_class": "random", "zero_context": true}
{"original_prediction": "    \\mathcal{L}_{mod} = \\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N A_{ij} \\log \\frac{A_{ij}}{A'_{ij}}\r", "prediction_line": "    \\mathcal{L}_{mod} = \\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N A_{ij} \\log \\frac{A_{ij}}{A'_{ij}}\r", "ground_truth": "        L_m = - \\frac{1}{2m} \\mathrm{Tr}(\\C^\\top \\A \\C - \\C^\\top \\d^\\top \\d \\C)\r", "line_class": "random", "zero_context": true}
{"original_prediction": "    **Input**\r", "prediction_line": "    **Input**\r", "ground_truth": "    This layer is based on the original implementation found\r", "line_class": "random", "zero_context": true}
{"original_prediction": "    - Binary adjacency matrix of shape `(batch, n_nodes_in, n_nodes_in)`.\r", "prediction_line": "    - Binary adjacency matrix of shape `(batch, n_nodes_in, n_nodes_in)`.\r", "ground_truth": "    - Symmetrically normalized adjacency matrix of shape\r", "line_class": "random", "zero_context": true}
{"original_prediction": "        collapse_regularization=0.0,\r", "prediction_line": "        collapse_regularization=0.0,\r", "ground_truth": "        collapse_regularization=0.1,\r", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(", "prediction_line": "        super().__init__(", "ground_truth": "        super().__init__(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            x = self.activation(x)", "prediction_line": "            x = self.activation(x)", "ground_truth": "            output = self._call_single(x, a)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            output = self._call_batch(x, a)", "prediction_line": "            output = self._call_batch(x, a)", "ground_truth": "            output = self._call_batch(x, a)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Compute absolute differences between neighbouring nodes", "prediction_line": "        # Compute absolute differences between neighbouring nodes", "ground_truth": "        abs_diff = tf.reduce_sum(tf.math.abs(tf.expand_dims(x, 2) - ", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # Compute the new adjacency matrix", "prediction_line": "            # Compute the new adjacency matrix", "ground_truth": "            n_nodes = tf.shape(a, out_type=index_i.dtype)[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                             (n_nodes, n_nodes))", "prediction_line": "                                             (n_nodes, n_nodes))", "ground_truth": "                                             [n_nodes, n_nodes])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            abs_diff = tf.math.reduce_sum(abs_diff, axis=-1)", "prediction_line": "            abs_diff = tf.math.reduce_sum(abs_diff, axis=-1)", "ground_truth": "            abs_diff = tf.reduce_sum(abs_diff, axis=-1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        l = tf.eye(n_nodes, dtype=x.dtype) - self.delta_coeff * l", "prediction_line": "        l = tf.eye(n_nodes, dtype=x.dtype) - self.delta_coeff * l", "ground_truth": "        l = tf.eye(n_nodes, dtype=x.dtype) - self.delta_coeff * l", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \n            # Compute the adjacency matrix", "prediction_line": "    ", "ground_truth": "            abs_diff = tf.math.reduce_sum(abs_diff, axis=0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        l = tf.linalg.set_diag(l, degrees - tf.linalg.diag_part(gamma))", "prediction_line": "        l = tf.linalg.set_diag(l, degrees - tf.linalg.diag_part(gamma))", "ground_truth": "        l = tf.linalg.set_diag(l, degrees - tf.linalg.diag_part(gamma))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            l_adjusted = tf.sparse.add(tf.sparse.SparseTensor(", "prediction_line": "            l_adjusted = tf.sparse.add(tf.sparse.SparseTensor(", "ground_truth": "            l = tf.sparse.add(tf.sparse.eye(n_nodes, dtype=x.dtype), tf.sparse.map_values(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # Compute absolute differences between neighbouring nodes", "prediction_line": "            # Compute absolute differences between neighbouring nodes", "ground_truth": "            n_nodes = tf.shape(a)[-1]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            d = tf.sparse.reduce_sum(gamma, axis=1)", "prediction_line": "            d = tf.sparse.reduce_sum(gamma, axis=1)", "ground_truth": "            d_gamma = tf.sparse.SparseTensor(tf.stack([tf.range(n_nodes)] * 2, axis=1),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       x = K.dot(x, self.kernel)", "prediction_line": "       x = K.dot(x, self.kernel)", "ground_truth": "        mode = ops.autodetect_mode(x, a)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            output = tf.sparse.sparse_dense_matmul(l, x)", "prediction_line": "            output = tf.sparse.sparse_dense_matmul(l, x)", "ground_truth": "            output = ops.modal_dot(l, x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "tf.gather(x, index_j))", "prediction_line": "tf.gather(x, index_j))", "ground_truth": "                                   tf.transpose(tf.gather(x, index_j)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       if mode == \"disjoint\":", "prediction_line": "       if mode == \"disjoint\":", "ground_truth": "        x = K.dot(x, self.kernel)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            diff = tf.gather(x, index_i) - tf.gather(x, index_j)", "prediction_line": "            diff = tf.gather(x, index_i) - tf.gather(x, index_j)", "ground_truth": "            abs_diff = tf.math.abs(tf.transpose(tf.gather(x, index_i)) -", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def config(self):", "prediction_line": "    def config(self):", "ground_truth": "    def config(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def _call_single(self, x, a):", "prediction_line": "    def _call_single(self, x, a):", "ground_truth": "    def _call_single(self, x, a):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    r\"\"\"", "prediction_line": "    r\"\"\"", "ground_truth": "    r\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            # Compute new adjacency matrix", "prediction_line": "            # Compute new adjacency matrix", "ground_truth": "            # Compute adjusted laplacian: L_adjusted = I - delta*L", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                tf.multiply, l, self.delta_coeff))", "prediction_line": "                tf.multiply, l, self.delta_coeff))", "ground_truth": "                tf.multiply, l, -self.delta_coeff))", "line_class": "random", "zero_context": true}
{"original_prediction": "            )\n        else:", "prediction_line": "            )", "ground_truth": "            )", "line_class": "random", "zero_context": true}
{"original_prediction": "[5pt]\n            \\delta &= \\frac{1}{2} \\left(1 - \\mathbf{I}\\right)\\\\[5pt]", "prediction_line": "[5pt]", "ground_truth": "        \\end{align}", "line_class": "random", "zero_context": true}
{"original_prediction": "        l = -gamma", "prediction_line": "        l = -gamma", "ground_truth": "        l = -gamma", "line_class": "random", "zero_context": true}
{"original_prediction": "       elif mode == ops.modes.DISJOINT:", "prediction_line": "       elif mode == ops.modes.DISJOINT:", "ground_truth": "        elif mode == ops.modes.BATCH:", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(", "prediction_line": "        super().__init__(", "ground_truth": "        super().__init__(", "line_class": "commited", "zero_context": true}
{"original_prediction": "       self.mlp.build(input_shape)", "prediction_line": "       self.mlp.build(input_shape)", "ground_truth": "        super().build(input_shape)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        base_config = super().get_config()", "prediction_line": "        base_config = super().get_config()", "ground_truth": "        base_config = super().get_config()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        an_loss = self.asym_norm_loss(s)", "prediction_line": "        an_loss = self.asym_norm_loss(s)", "ground_truth": "        bal_loss = self.balance_loss(s)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        totvar_loss = self.totvar_coeff * self.total_variation(s, a)", "prediction_line": "        totvar_loss = self.totvar_coeff * self.total_variation(s, a)", "ground_truth": "        tv_loss = self.totvar_loss(a, s)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        config = super().get_config()", "prediction_line": "        config = super().get_config()", "ground_truth": "        config = {", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \\mathbf{z} &= \\mathbf{W} \\mathbf{x} \\\\", "prediction_line": "    \\mathbf{z} &= \\mathbf{W} \\mathbf{x} \\\\", "ground_truth": "        \\S &= \\textrm{MLP}(\\X); \\\\", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        loss = loss / (n_nodes * (self.k - 1))", "prediction_line": "        loss = loss / (n_nodes * (self.k - 1))", "ground_truth": "        loss = 1 / (n_nodes * (self.k - 1)) * (n_nodes * (self.k - 1) - loss)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                                                             tf.repeat(s[..., tf.newaxis, :],", "prediction_line": "                                                                             tf.repeat(s[..., tf.newaxis, :],", "ground_truth": "                                                                             tf.repeat(s[..., tf.newaxis, :],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        s_quant = tf.math.top_k(s, k=self.k - 1, sorted=True)[0]", "prediction_line": "        s_quant = tf.math.top_k(s, k=self.k - 1, sorted=True)[0]", "ground_truth": "        idx = tf.cast(tf.math.floor(n_nodes / self.k) + 1, dtype=tf.int32)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            n_edges = tf.cast(tf.math.count_nonzero(a), dtype=s.dtype)", "prediction_line": "            n_edges = tf.cast(tf.math.count_nonzero(a), dtype=s.dtype)", "ground_truth": "            n_edges = tf.cast(tf.math.count_nonzero(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "           a_values = a.values", "prediction_line": "           a_values = a.values", "ground_truth": "            n_edges = tf.cast(len(a.values), dtype=s.dtype)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        X, A = inputs", "prediction_line": "        X, A = inputs", "ground_truth": "        x, a, i = self.get_inputs(inputs)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    [Asymmetric Cheeger Cut Pooling for Graph Neural Networks](https://arxiv.org/abs/2006.16015).", "prediction_line": "    [Asymmetric Cheeger Cut Pooling for Graph Neural Networks](https://arxiv.org/abs/2006.16015).", "ground_truth": "    > [Total Variation Graph Neural Networks](https://arxiv.org/abs/2211.06218)<br>", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        i_mean = tf.math.argmax(i_mean, axis=1)", "prediction_line": "        i_mean = tf.math.argmax(i_mean, axis=1)", "ground_truth": "        i_pool = ops.repeat(i_mean, tf.ones_like(i_mean) * self.k)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "           n_nodes = tf.cast(tf.shape(s)[1], dtype=s.dtype)", "prediction_line": "           n_nodes = tf.cast(tf.shape(s)[1], dtype=s.dtype)", "ground_truth": "            loss = tf.math.reduce_sum(a.values[:, tf.newaxis] * ", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        loss = tf.math.reduce_sum(loss, axis=-1)", "prediction_line": "        loss = tf.math.reduce_sum(loss, axis=-1)", "ground_truth": "        loss = tf.math.reduce_sum(loss, axis=(-2, -1))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    - `bias_constraint`: constraint applied to the bias of the MLP;", "prediction_line": "    - `bias_constraint`: constraint applied to the bias of the MLP;", "ground_truth": "    - `bias_constraint`: constraint applied to the bias of the MLP;", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                n_edges = tf.math.reduce_sum(n_edges, axis=0)", "prediction_line": "                n_edges = tf.math.reduce_sum(n_edges, axis=0)", "ground_truth": "                loss = tf.math.reduce_sum(a * tf.math.reduce_sum(tf.math.abs(s[:, tf.newaxis, ...] -", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                                                                       n_nodes, axis=-2)), axis=-1),", "prediction_line": "                                                                                       n_nodes, axis=-2)), axis=-1),", "ground_truth": "                                                                                       n_nodes, axis=-2)), axis=-1),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       n_clusters = tf.cast(tf.shape(s, out_type=tf.int32)[-1], s.dtype)", "prediction_line": "       n_clusters = tf.cast(tf.shape(s, out_type=tf.int32)[-1], s.dtype)", "ground_truth": "        # k-quantile", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ", Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation", "prediction_line": ", Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation", "ground_truth": "import tensorflow.keras.backend as K", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "import tensorflow as tf", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def totvar_loss(self, a, s):", "prediction_line": "    def totvar_loss(self, a, s):", "ground_truth": "    def reduce(self, x, s, **kwargs):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        use_bias=True,", "prediction_line": "        use_bias=True,", "ground_truth": "        use_bias=True,", "line_class": "random", "zero_context": true}
{"original_prediction": "        \\S &= \\textrm{softmax}(\\S); \\\\", "prediction_line": "        \\S &= \\textrm{softmax}(\\S); \\\\", "ground_truth": "        \\X' &= \\S^\\top \\X \\\\", "line_class": "random", "zero_context": true}
{"original_prediction": "    $$\n    and a graph Cheeger cut component given by", "prediction_line": "    $$", "ground_truth": "    $$", "line_class": "random", "zero_context": true}
{"original_prediction": "        )\n        self.totvar_coeff = totvar_coeff", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "            s = ops.masked_softmax(s, mask)", "prediction_line": "            s = ops.masked_softmax(s, mask)", "ground_truth": "            s *= mask[0]", "line_class": "random", "zero_context": true}
{"original_prediction": "            config.reload_server = ChangeReload(", "prediction_line": "            config.reload_server = ChangeReload(", "ground_truth": "            supervisor = ChangeReload(config, target=server.run, sockets=[sock])", "line_class": "commited", "zero_context": true}
{"original_prediction": "            supervisor.run()", "prediction_line": "            supervisor.run()", "ground_truth": "            supervisor.run()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            supervisor = Multiprocess(config, target=server.run, sockets=[sock])", "prediction_line": "            supervisor = Multiprocess(config, target=server.run, sockets=[sock])", "ground_truth": "            supervisor = Multiprocess(config, target=server.run, sockets=[sock])", "line_class": "commited", "zero_context": true}
{"original_prediction": "            server.run()", "prediction_line": "            server.run()", "ground_truth": "            server.run()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    def stop(self) -> None:", "prediction_line": "    def stop(self) -> None:", "ground_truth": "    run_in_thread = threaded(run)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    async def deactivate_dispatcher() -> None:", "prediction_line": "    async def deactivate_dispatcher() -> None:", "ground_truth": "    async def deactivate_dispatcher() -> None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "    async def model_stream(socket: WebSocket) -> None:", "prediction_line": "    async def model_stream(socket: WebSocket) -> None:", "ground_truth": "    async def model_stream(socket: WebSocket) -> None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return sock_send, sock_recv", "prediction_line": "    return sock_send, sock_recv", "ground_truth": "    return sock_send, sock_recv", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def _server_did_stop(self, _: Any) -> None:", "prediction_line": "    def _server_did_stop(self, _: Any) -> None:", "ground_truth": "    async def _server_did_stop(self) -> None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "    config: Optional[Config], app: Optional[Starlette], app_type: type", "prediction_line": "    config: Optional[Config], app: Optional[Starlette], app_type: type", "ground_truth": "    config: Optional[Config],", "line_class": "infile", "zero_context": true}
{"original_prediction": ") -> Tuple[Config, _StarletteType]:", "prediction_line": ") -> Tuple[Config, _StarletteType]:", "ground_truth": ") -> Tuple[Config, _StarletteType]:", "line_class": "infile", "zero_context": true}
{"original_prediction": "    *,\n    config: Optional[Config] = None,", "prediction_line": "    *,", "ground_truth": "    config: Optional[Config] = None,", "line_class": "infile", "zero_context": true}
{"original_prediction": ") -> Starlette:", "prediction_line": ") -> Starlette:", "ground_truth": ") -> StarletteServer:", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return StarletteServer(", "prediction_line": "    return StarletteServer(", "ground_truth": "    config, app = _setup_config_and_app(config, app, Starlette)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _setup_common_routes(config, app)", "prediction_line": "    _setup_common_routes(config, app)", "ground_truth": "    _setup_common_routes(config, app)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return StarletteServer(app, config)", "prediction_line": "    return StarletteServer(app, config)", "ground_truth": "    return StarletteServer(app)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._server = UvicornServer(", "prediction_line": "        self._server = UvicornServer(", "ground_truth": "        app.on_event(\"shutdown\")(self._server_did_stop)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    async def startup() -> None:", "prediction_line": "    async def startup() -> None:", "ground_truth": "    async def activate_dispatcher() -> None:", "line_class": "infile", "zero_context": true}
{"original_prediction": ")\nfrom idom.core.layout import Layout", "prediction_line": ")", "ground_truth": "    dispatch_single_view,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    url_prefix: str, app: Starlette, constructor: ComponentConstructor", "prediction_line": "    url_prefix: str, app: Starlette, constructor: ComponentConstructor", "ground_truth": "    url_prefix: str, app: Starlette, constructor: ComponentConstructor", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ViewDispatcher,", "prediction_line": "    ViewDispatcher,", "ground_truth": "    VdomJsonPatch,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return StarletteServer(", "prediction_line": "    return StarletteServer(", "ground_truth": "    _setup_single_view_dispatcher_route(config[\"url_prefix\"], app, constructor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            await dispatch_coroutine(send, recv)", "prediction_line": "            await dispatch_coroutine(send, recv)", "ground_truth": "            await dispatch_coroutine(send, recv)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                directory=str(IDOM_WED_MODULES_DIR),", "prediction_line": "                directory=str(IDOM_WED_MODULES_DIR),", "ground_truth": "                directory=str(IDOM_WED_MODULES_DIR.current),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return LayoutEvent(**json.loads(await socket.receive_text()))", "prediction_line": "        return LayoutEvent(**json.loads(await socket.receive_text()))", "ground_truth": "        return LayoutEvent(**json.loads(await socket.receive_text()))", "line_class": "inproject", "zero_context": true}
{"original_prediction": ")\nfrom idom.core.layout import Layout", "prediction_line": ")", "ground_truth": "    ensure_shared_view_dispatcher_future,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"Wait until the server has started", "prediction_line": "        \"\"\"Wait until the server has started", "ground_truth": "        poll(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        try:\n            await dispatch_single_view(", "prediction_line": "        try:", "ground_truth": "        send, recv = _make_send_recv_callbacks(socket)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        dispatcher_future, dispatch_coroutine = ensure_shared_view_dispatcher_future(", "prediction_line": "        dispatcher_future, dispatch_coroutine = ensure_shared_view_dispatcher_future(", "ground_truth": "        dispatcher_future, dispatch_coroutine = ensure_shared_view_dispatcher_future(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        app or app_type(),", "prediction_line": "        app or app_type(),", "ground_truth": "        app or app_type(debug=IDOM_DEBUG_MODE.current),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    _setup_shared_view_dispatcher_route(config[\"url_prefix\"], app, constructor)", "prediction_line": "    _setup_shared_view_dispatcher_route(config[\"url_prefix\"], app, constructor)", "ground_truth": "    _setup_shared_view_dispatcher_route(config[\"url_prefix\"], app, constructor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            name=\"idom_modules\",", "prediction_line": "            name=\"idom_modules\",", "ground_truth": "            name=\"idom_web_module_files\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "constructor, send, recv)", "prediction_line": "constructor, send, recv)", "ground_truth": "                Layout(constructor(**dict(socket.query_params))), send, recv", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def stop(self) -> None:", "prediction_line": "    def stop(self) -> None:", "ground_truth": "    def wait_until_started(self, timeout: Optional[float] = 3.0) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    if cors_config:", "prediction_line": "    if cors_config:", "ground_truth": "    if cors_config:  # pragma: no cover", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    Implements the :class:`~idom.server.proto.Server` protocol", "prediction_line": "    Implements the :class:`~idom.server.proto.Server` protocol", "ground_truth": "    See :class:`idom.server.proto.Server` for more info", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def _setup_config_and_app(", "prediction_line": "def _setup_config_and_app(", "ground_truth": "def _setup_config_and_app(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def stop(self) -> None:", "prediction_line": "    def stop(self) -> None:", "ground_truth": "    def stop(self, timeout: Optional[float] = 3.0) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        app.add_middleware(CORSMiddleware, **cors_params)", "prediction_line": "        app.add_middleware(CORSMiddleware, **cors_params)", "ground_truth": "        app.add_middleware(CORSMiddleware, **cors_params)", "line_class": "random", "zero_context": true}
{"original_prediction": "        )\n        app.mount(", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"redirect_root_to_index\": False,", "prediction_line": "            \"redirect_root_to_index\": False,", "ground_truth": "            \"serve_static_files\": True,", "line_class": "random", "zero_context": true}
{"original_prediction": "    def __init__(self, app: Starlette) -> None:", "prediction_line": "    def __init__(self, app: Starlette) -> None:", "ground_truth": "    _server: UvicornServer", "line_class": "random", "zero_context": true}
{"original_prediction": "    if url_prefix:", "prediction_line": "    if url_prefix:", "ground_truth": "    if config[\"serve_static_files\"]:", "line_class": "random", "zero_context": true}
{"original_prediction": "                self.index[kwargs[self.index_by_kwarg]] = hook", "prediction_line": "                self.index[kwargs[self.index_by_kwarg]] = hook", "ground_truth": "                self.index[kwargs[self.index_by_kwarg]] = hook", "line_class": "common", "zero_context": true}
{"original_prediction": "                   await asyncio.sleep(0.01)", "prediction_line": "                   await asyncio.sleep(0.01)", "ground_truth": "            self.until = coro_until", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.function = function", "prediction_line": "        self.function = function", "ground_truth": "        self.until: _UntilFunc[_R]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return wrapper", "prediction_line": "        return wrapper", "ground_truth": "        return wrapper", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.until = sync_until", "prediction_line": "            self.until = sync_until", "ground_truth": "            self.until = sync_until", "line_class": "infile", "zero_context": true}
{"original_prediction": "           self.until = lambda condition, timeout: coro_function(*args, **kwargs)", "prediction_line": "           self.until = lambda condition, timeout: coro_function(*args, **kwargs)", "ground_truth": "            async def coro_until(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            sync_function = cast(Callable[_P, _R], function)", "prediction_line": "            sync_function = cast(Callable[_P, _R], function)", "ground_truth": "            sync_function = cast(Callable[_P, _R], function)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ) -> EventHandler:", "prediction_line": "    ) -> EventHandler:", "ground_truth": "    ) -> EventHandler:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"Decorator for capturing the target of an event handler", "prediction_line": "        \"\"\"Decorator for capturing the target of an event handler", "ground_truth": "        return EventHandler(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            to_event_handler_function(function),", "prediction_line": "            to_event_handler_function(function),", "ground_truth": "            to_event_handler_function(function),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    result = sync_function(*args, **kwargs)", "prediction_line": "                    result = sync_function(*args, **kwargs)", "ground_truth": "                    result = sync_function(*args, **kwargs)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "           hook = current_hook()", "prediction_line": "           hook = current_hook()", "ground_truth": "            hook = current_hook()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.target,", "prediction_line": "            self.target,", "ground_truth": "            self.target,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    shutil.rmtree(IDOM_WEB_MODULES_DIR, ignore_errors=True)", "prediction_line": "    shutil.rmtree(IDOM_WEB_MODULES_DIR, ignore_errors=True)", "ground_truth": "    for path in IDOM_WEB_MODULES_DIR.current.iterdir():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def __init__(self, index_by_kwarg: Optional[str] = None) -> None:", "prediction_line": "    def __init__(self, index_by_kwarg: Optional[str] = None) -> None:", "ground_truth": "    latest: LifeCycleHook", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.latest = LifeCycleHook(uuid4().hex)", "prediction_line": "        self.latest = LifeCycleHook(uuid4().hex)", "ground_truth": "        self.index: dict[Any, LifeCycleHook] = {}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.target: Optional[str] = None", "prediction_line": "        self.target: Optional[str] = None", "ground_truth": "        self.target = uuid4().hex", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"Wait until the result is equal to the given value\"\"\"", "prediction_line": "        \"\"\"Wait until the result is equal to the given value\"\"\"", "ground_truth": "        \"\"\"Wait until the result is equal to the given value\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from . import _core", "prediction_line": "from . import _core", "ground_truth": "from typing_extensions import ParamSpec, Protocol", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def use(self, event_handler: EventHandler) -> EventHandler:", "prediction_line": "    def use(self, event_handler: EventHandler) -> EventHandler:", "ground_truth": "    def use(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # we need to keep a weak reference to the component.", "prediction_line": "        # we need to keep a weak reference to the component.", "ground_truth": "        # we must use a `ref` here to ensure these checks pass once the catcher itself", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        def wrapped(*args: Any, **kwargs: Any) -> Any:", "prediction_line": "        def wrapped(*args: Any, **kwargs: Any) -> Any:", "ground_truth": "        def wrapper(*args: Any, **kwargs: Any) -> Any:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        timeout: float = _DEFAULT_TIMEOUT,", "prediction_line": "        timeout: float = _DEFAULT_TIMEOUT,", "ground_truth": "        **kwargs: _P.kwargs,", "line_class": "random", "zero_context": true}
{"original_prediction": "                        return\n                    if time.time() - started_at > timeout:", "prediction_line": "                        return", "ground_truth": "                        break", "line_class": "random", "zero_context": true}
{"original_prediction": "            return render_function(*args, **kwargs)", "prediction_line": "            return render_function(*args, **kwargs)", "ground_truth": "            return render_function(*args, **kwargs)", "line_class": "random", "zero_context": true}
{"original_prediction": "class _EventHandler(Protocol):", "prediction_line": "class _EventHandler(Protocol):", "ground_truth": "_R = TypeVar(\"_R\")", "line_class": "random", "zero_context": true}
{"original_prediction": "            stop_propagation=stop_propagation,", "prediction_line": "            stop_propagation=stop_propagation,", "ground_truth": "            stop_propagation,", "line_class": "random", "zero_context": true}
{"original_prediction": "    def _update_vdom_constructor_usages(node: ast.AST) -> None:", "prediction_line": "    def _update_vdom_constructor_usages(node: ast.AST) -> None:", "ground_truth": "    for parents, node in walk_with_parent(tree):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if not run_tests():", "prediction_line": "        if not run_tests():", "ground_truth": "        result = run_tests()", "line_class": "infile", "zero_context": true}
{"original_prediction": "arg=conv_attr_name(kw.arg), value=kw.value)", "prediction_line": "arg=conv_attr_name(kw.arg), value=kw.value)", "ground_truth": "                                        arg=conv_attr_name(kw.arg), value=kw.value", "line_class": "infile", "zero_context": true}
{"original_prediction": "        yield from walk_with_parent(child, parents)", "prediction_line": "        yield from walk_with_parent(child, parents)", "ground_truth": "        yield from walk_with_parent(child, parents)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if file.is_dir():", "prediction_line": "            if file.is_dir():", "ground_truth": "            result = update_vdom_constructor_usages(", "line_class": "infile", "zero_context": true}
{"original_prediction": "ast.keyword(arg=k.value, value=v))", "prediction_line": "ast.keyword(arg=k.value, value=v))", "ground_truth": "                                    ast.keyword(arg=conv_attr_name(k.value), value=v)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        source = dedent(source)", "prediction_line": "        source = dedent(source)", "ground_truth": "        actual = update_vdom_constructor_usages(dedent(source).strip(), \"test.py\")", "line_class": "infile", "zero_context": true}
{"original_prediction": ".string\n        for token in generate_tokens(iter_lines)", "prediction_line": ".string", "ground_truth": "        for token_type, token, _, _, _ in generate_tokens(lambda: next(iter_lines))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        *_", "prediction_line": "                        *_", "ground_truth": "                        *_,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if isinstance(node.func, ast.Name) and node.func.id == \"html\":", "prediction_line": "            if isinstance(node.func, ast.Name) and node.func.id == \"html\":", "ground_truth": "            func = node.func", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if isinstance(func, ast.Name) and func.id == \"html\":", "prediction_line": "            if isinstance(func, ast.Name) and func.id == \"html\":", "ground_truth": "            match func:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if func.attr == \"html\":", "prediction_line": "                    if func.attr == \"html\":", "ground_truth": "                    name = func.attr", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    name = func.id", "prediction_line": "                    name = func.id", "ground_truth": "                    name = func.id", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                case _:", "prediction_line": "                case _:", "ground_truth": "                case _:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    continue", "prediction_line": "                    continue", "ground_truth": "                    name = \"\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if name == \"html\":", "prediction_line": "            if name == \"html\":", "ground_truth": "            if hasattr(html, name):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    case [*args, ast.Name(id=\"children\", ctx=ast.Param())]:", "prediction_line": "                    case [*args, ast.Name(id=\"children\", ctx=ast.Param())]:", "ground_truth": "                    case [ast.Dict(keys, values), *_]:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return CAMEL_CASE_SUB_PATTERN.sub(\"-\", name).lower()", "prediction_line": "    return CAMEL_CASE_SUB_PATTERN.sub(\"-\", name).lower()", "ground_truth": "    new_name = CAMEL_CASE_SUB_PATTERN.sub(\"_\", name).replace(\"-\", \"_\").lower()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            func=ast.Attribute(", "prediction_line": "                            func=ast.Attribute(", "ground_truth": "                            func=ast.Name(id=\"dict\", ctx=ast.Load()),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"\"\",\n            \"\"\"", "prediction_line": "            \"\"\",", "ground_truth": "            \"\"\",", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                html.div({\"className\": \"inner\"}),", "prediction_line": "                html.div({\"className\": \"inner\"}),", "ground_truth": "                html.div({\"className\": \"inner\"}),", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        {\n            \"source\": \"\"\"", "prediction_line": "        {", "ground_truth": "        # simple conversions", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            if current_node.lineno == next_node.lineno:", "prediction_line": "            if current_node.lineno == next_node.lineno:", "ground_truth": "            if (", "line_class": "random", "zero_context": true}
{"original_prediction": "        # avoid unnecessary changes", "prediction_line": "        # avoid unnecessary changes", "ground_truth": "        (", "line_class": "random", "zero_context": true}
{"original_prediction": "                            if isinstance(k, ast.Str):", "prediction_line": "                            if isinstance(k, ast.Str):", "ground_truth": "                            if isinstance(k, ast.Constant) and isinstance(k.value, str):", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"\"\"\n            @deco(html.div(class_name='test'), html.div(class_name='test'))", "prediction_line": "            \"\"\"", "ground_truth": "            \"\"\"", "line_class": "random", "zero_context": true}
{"original_prediction": "    # unparse nodes to rewrite", "prediction_line": "    # unparse nodes to rewrite", "ground_truth": "    moved_comment_lines_from_end: list[int] = []", "line_class": "random", "zero_context": true}
{"original_prediction": "    for node in ast.walk(tree):", "prediction_line": "    for node in ast.walk(tree):", "ground_truth": "    for parents, node in walk_with_parent(tree):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                keywords.append(ast.keyword(arg=conv_attr_name(kw.arg), value=kw.value))", "prediction_line": "                keywords.append(ast.keyword(arg=conv_attr_name(kw.arg), value=kw.value))", "ground_truth": "                keywords.append(ast.keyword(arg=conv_attr_name(kw.arg), value=kw.value))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return KeywordInfo(keywords=keywords)", "prediction_line": "        return KeywordInfo(keywords=keywords)", "ground_truth": "        return KeywordInfo(replace=False, keywords=keywords)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # by moving them to the end of the file", "prediction_line": "        # by moving them to the end of the file", "ground_truth": "        comments = find_comments(lines[node.lineno - 1 : node.end_lineno])", "line_class": "infile", "zero_context": true}
{"original_prediction": "                keywords.append(ast.keyword(arg=k.value, value=v))", "prediction_line": "                keywords.append(ast.keyword(arg=k.value, value=v))", "ground_truth": "                keywords.append(ast.keyword(arg=conv_attr_name(k.value), value=v))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                return None\n        return KeywordInfo(keywords=keywords, replace=True)", "prediction_line": "                return None", "ground_truth": "                return KeywordInfo(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if not isinstance(maybe_attr_dict_node, ast.Dict):", "prediction_line": "        if not isinstance(maybe_attr_dict_node, ast.Dict):", "ground_truth": "        new_keyword_info = extract_keywords(maybe_attr_dict_node)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            print(f\"Updating {f}\")", "prediction_line": "            print(f\"Updating {f}\")", "ground_truth": "            result = generate_rewrite(file=f, source=f.read_text())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        yield from walk_with_parent(child, parents)", "prediction_line": "        yield from walk_with_parent(child, parents)", "ground_truth": "        yield from walk_with_parent(child, parents)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ):\n        return extract_keywords(node.args[0])", "prediction_line": "    ):", "ground_truth": "        and isinstance(node.func.ctx, ast.Load)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if name in kwlist:", "prediction_line": "    if name in kwlist:", "ground_truth": "    new_name = CAMEL_CASE_SUB_PATTERN.sub(\"_\", name).replace(\"-\", \"_\").lower()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if not isinstance(node.func, ast.Name):", "prediction_line": "        if not isinstance(node.func, ast.Name):", "ground_truth": "        func = node.func", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if not isinstance(func, ast.Name):", "prediction_line": "        if not isinstance(func, ast.Name):", "ground_truth": "        if isinstance(func, ast.Attribute):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if func.attr == \"div\":", "prediction_line": "            if func.attr == \"div\":", "ground_truth": "            name = func.attr", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if name == \"div\":", "prediction_line": "            if name == \"div\":", "ground_truth": "        elif isinstance(func, ast.Name):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            name = func.id", "prediction_line": "            name = func.id", "ground_truth": "            name = func.id", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if name not in (\"div\", \"span\", \"p\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"):", "prediction_line": "        if name not in (\"div\", \"span\", \"p\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"):", "ground_truth": "        if name == \"vdom\":", "line_class": "inproject", "zero_context": true}
{"original_prediction": ".string\n        for token in generate_tokens(iter_lines)", "prediction_line": ".string", "ground_truth": "        for token_type, token, _, _, _ in generate_tokens(lambda: next(iter_lines))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if isinstance(maybe_attr_dict_node, ast.Dict):", "prediction_line": "            if isinstance(maybe_attr_dict_node, ast.Dict):", "ground_truth": "        elif hasattr(html, name):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        and isinstance(node.func, ast.Name)", "prediction_line": "        and isinstance(node.func, ast.Name)", "ground_truth": "        and isinstance(node.func, ast.Name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        and node.func.id == \"dict\"", "prediction_line": "        and node.func.id == \"dict\"", "ground_truth": "        and node.func.id == \"dict\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from typing import Any, Dict, List, Optional, Tuple, Union", "prediction_line": "from typing import Any, Dict, List, Optional, Tuple, Union", "ground_truth": "from collections.abc import Sequence", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    This command will rewrite all files under the given paths to use the new", "prediction_line": "    This command will rewrite all files under the given paths to use the new", "ground_truth": "    The old API required users to pass a dictionary of attributes to html element", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    for node in sorted_nodes_to_unparse:", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    recommend that you review the changes made to your files before committing them.", "prediction_line": "    recommend that you review the changes made to your files before committing them.", "ground_truth": "    recommend running your code formatter like Black against your code after executing", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # that we need to preserve", "prediction_line": "        # that we need to preserve", "ground_truth": "        before_replacement = lines[node.lineno - 1][: node.col_offset].lstrip()", "line_class": "random", "zero_context": true}
{"original_prediction": "            if len(node.args) < 1:", "prediction_line": "            if len(node.args) < 1:", "ground_truth": "            if len(node.args) == 0:", "line_class": "random", "zero_context": true}
{"original_prediction": "        sorted(nodes_to_unparse, key=lambda n: n.lineno)", "prediction_line": "        sorted(nodes_to_unparse, key=lambda n: n.lineno)", "ground_truth": "        sorted(nodes_to_unparse, key=lambda n: n.lineno)", "line_class": "random", "zero_context": true}
{"original_prediction": "    if new_name in kwlist:", "prediction_line": "    if new_name in kwlist:", "ground_truth": "    return f\"{new_name}_\" if new_name in kwlist else new_name", "line_class": "random", "zero_context": true}
{"original_prediction": "    comments: list[str] = []", "prediction_line": "    comments: list[str] = []", "ground_truth": "    iter_lines = iter(lines)", "line_class": "random", "zero_context": true}
{"original_prediction": "        update_html_usages,", "prediction_line": "        update_html_usages,", "ground_truth": "        update_html_usages, args=[\"directory-does-no-exist\"], catch_exceptions=False", "line_class": "commited", "zero_context": true}
{"original_prediction": "update_html_usages, [str(tempfile)])", "prediction_line": "update_html_usages, [str(tempfile)])", "ground_truth": "        update_html_usages,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    if expected is None:", "prediction_line": "    if expected is None:", "ground_truth": "    actual = generate_rewrite(Path(\"test.py\"), dedent(source).strip())", "line_class": "commited", "zero_context": true}
{"original_prediction": "            def my_function():", "prediction_line": "            def my_function():", "ground_truth": "            if condition:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            ]\n            \"\"\",", "prediction_line": "            ]", "ground_truth": "            ]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                x = [", "prediction_line": "                x = [", "ground_truth": "                x = [", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            )\n            \"\"\",", "prediction_line": "            )", "ground_truth": "            )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        ),\n        (", "prediction_line": "        ),", "ground_truth": "        ),", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"html.div(class_name='outer', html.div(class_name='inner'))\",", "prediction_line": "            \"html.div(class_name='outer', html.div(class_name='inner'))\",", "ground_truth": "            \"html.div(html.div(class_name='inner'), class_name='outer')\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        (\n            'html.div({\"className\": \"test\"}, {\"className\": \"test\"})',", "prediction_line": "        (", "ground_truth": "        (", "line_class": "random", "zero_context": true}
{"original_prediction": "    result = runner.invoke(", "prediction_line": "    result = runner.invoke(", "ground_truth": "    result = runner.invoke(", "line_class": "random", "zero_context": true}
{"original_prediction": "            'html.div({\"className\": \"test\"}, {\"className\": \"test\"})',", "prediction_line": "            'html.div({\"className\": \"test\"}, {\"className\": \"test\"})',", "ground_truth": "            'html.div({variable: \"test\", **other, \"key\": value})',", "line_class": "random", "zero_context": true}
{"original_prediction": "    ops = (ast.Lt, ast.Le, ast.Gt, ast.Ge, ast.Eq, ast.Ne)", "prediction_line": "    ops = (ast.Lt, ast.Le, ast.Gt, ast.Ge, ast.Eq, ast.Ne)", "ground_truth": "    ops = (ast.Cmp,)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    ops = ast.Pow", "prediction_line": "    ops = ast.Pow", "ground_truth": "    ops = (ast.MathPowOp,)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    ops = ast.Div", "prediction_line": "    ops = ast.Div", "ground_truth": "    ops = (ast.Div, ast.FloorDiv)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    ops = ast.Mod", "prediction_line": "    ops = ast.Mod", "ground_truth": "    ops = ast.Mod", "line_class": "commited", "zero_context": true}
{"original_prediction": "    ops = (ast.And, ast.Or)", "prediction_line": "    ops = (ast.And, ast.Or)", "ground_truth": "    ops = (ast.And, ast.Or)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    ops = (ast.Mul,)", "prediction_line": "    ops = (ast.Mul,)", "ground_truth": "    ops = ast.Mul", "line_class": "commited", "zero_context": true}
{"original_prediction": "    def rule(ast_node, type_dict):", "prediction_line": "    def rule(ast_node, type_dict):", "ground_truth": "    ops = (ast.Add, ast.Sub, ast.SelectOp)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    ops = (ast.Shl, ast.Shr)", "prediction_line": "    ops = (ast.Shl, ast.Shr)", "ground_truth": "    ops = (ast.LeftShiftOp, ast.RightShiftOp)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    ops = (ast.Not,)", "prediction_line": "    ops = (ast.Not,)", "ground_truth": "    ops = (ast.LogicalAnd, ast.LogicalOr, ast.LogicalXOr)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    rules.append(pow_rule())", "prediction_line": "    rules.append(pow_rule())", "ground_truth": "    rules.append(cmp_rule())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rules.append(shift_rule())", "prediction_line": "    rules.append(shift_rule())", "ground_truth": "    rules.append(div_rule())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rules.append(shift_rule())", "prediction_line": "    rules.append(shift_rule())", "ground_truth": "    rules.append(pow_rule())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rules.append(shift_rule())", "prediction_line": "    rules.append(shift_rule())", "ground_truth": "    rules.append(shift_rule())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rules.append(add_rule())", "prediction_line": "    rules.append(add_rule())", "ground_truth": "    rules.append(add_sub_rule())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rules.append(mul_rule())", "prediction_line": "    rules.append(mul_rule())", "ground_truth": "    rules.append(mul_rule())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rules.append(div_rule())", "prediction_line": "    rules.append(div_rule())", "ground_truth": "    rules.append(mod_rule())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rules.append(div_rule())", "prediction_line": "    rules.append(div_rule())", "ground_truth": "    rules.append(and_or_rule())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rules.append(logic_op_rule())", "prediction_line": "    rules.append(logic_op_rule())", "ground_truth": "    rules.append(logic_op_rule())", "line_class": "infile", "zero_context": true}
{"original_prediction": "            max(t1.bits, t2.bits) + t1.fracs + 1, t1.fracs", "prediction_line": "            max(t1.bits, t2.bits) + t1.fracs + 1, t1.fracs", "ground_truth": "            max(t1.bits - t1.fracs, t2.bits) + t1.fracs + 1, t1.fracs", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (Index, UFixed): lambda t1, t2: UFixed(", "prediction_line": "        (Index, UFixed): lambda t1, t2: UFixed(", "ground_truth": "        (Index, UFixed): lambda t1, t2: UFixed(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (Int, UInt): lambda t1, t2: (Int(max(t1.bits, t2.bits)), UInt(1)),", "prediction_line": "        (Int, UInt): lambda t1, t2: (Int(max(t1.bits, t2.bits)), UInt(1)),", "ground_truth": "        (Int, UInt): lambda t1, t2: (Int(max(t1.bits, t2.bits + 1)), UInt(1)),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (UFixed, UInt): lambda t1, t2: UFixed(t1.bits + t2.bits, t2.bits + t1.fracs),", "prediction_line": "        (UFixed, UInt): lambda t1, t2: UFixed(t1.bits + t2.bits, t2.bits + t1.fracs),", "ground_truth": "        (UFixed, UInt): lambda t1, t2: UFixed(t1.bits + t2.bits, t2.bits + t1.fracs),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Fixed(max(t1.bits - t1.fracs, t2.bits + 1) + t1.fracs, t1.fracs),", "prediction_line": "            Fixed(max(t1.bits - t1.fracs, t2.bits + 1) + t1.fracs, t1.fracs),", "ground_truth": "            Fixed(max(t1.bits - t1.fracs, t2.bits + 1) + t1.fracs, t1.fracs),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (Fixed, Float): lambda t1, t2: t2,", "prediction_line": "        (Fixed, Float): lambda t1, t2: t2,", "ground_truth": "        (Fixed, Float): lambda t1, t2: t2,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (Float, UFixed): lambda t1, t2: (t1, UInt(1)),", "prediction_line": "        (Float, UFixed): lambda t1, t2: (t1, UInt(1)),", "ground_truth": "        (Float, UFixed): lambda t1, t2: (t1, UInt(1)),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (Fixed, Float): lambda t1, t2: (t2, UInt(1)),", "prediction_line": "        (Fixed, Float): lambda t1, t2: (t2, UInt(1)),", "ground_truth": "        (Fixed, Float): lambda t1, t2: (t2, UInt(1)),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (UInt, Fixed): lambda t1, t2: Fixed(t1.bits + t2.bits, max(t1.fracs, t2.fracs)),", "prediction_line": "        (UInt, Fixed): lambda t1, t2: Fixed(t1.bits + t2.bits, max(t1.fracs, t2.fracs)),", "ground_truth": "        (UInt, Fixed): lambda t1, t2: Fixed(t1.bits + t2.bits, max(t1.fracs, t2.fracs)),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (Int, UInt): lambda t1, t2: Int(max(t1.bits, t2.bits)),", "prediction_line": "        (Int, UInt): lambda t1, t2: Int(max(t1.bits, t2.bits)),", "ground_truth": "        (Int, UInt): lambda t1, t2: Int(max(t1.bits, t2.bits + 1)),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (Int, Index): lambda t1, t2: Int(t1.bits + t2.bits),", "prediction_line": "        (Int, Index): lambda t1, t2: Int(t1.bits + t2.bits),", "ground_truth": "        (Int, Index): lambda t1, t2: Int(t1.bits + t2.bits),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (UInt, Index): lambda t1, t2: UInt(max(t1.bits, t2.bits) + 1),", "prediction_line": "        (UInt, Index): lambda t1, t2: UInt(max(t1.bits, t2.bits) + 1),", "ground_truth": "        (UInt, Index): lambda t1, t2: UInt(max(t1.bits, t2.bits) + 1),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            UFixed(max(t1.bits - t1.fracs, t2.bits) + t1.fracs, t1.fracs),", "prediction_line": "            UFixed(max(t1.bits - t1.fracs, t2.bits) + t1.fracs, t1.fracs),", "ground_truth": "            UFixed(max(t1.bits - t1.fracs, t2.bits) + t1.fracs, t1.fracs),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        (Fixed, Int): lambda t1, t2: Fixed(t1.bits + t2.bits, t1.bits - t2.fracs),", "prediction_line": "        (Fixed, Int): lambda t1, t2: Fixed(t1.bits + t2.bits, t1.bits - t2.fracs),", "ground_truth": "        (Fixed, Int): lambda t1, t2: Fixed(t1.bits + t2.bits, t2.bits + t1.fracs),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            max(t1.bits, t2.bits - t2.fracs) + t2.fracs + 1, t2.fracs", "prediction_line": "            max(t1.bits, t2.bits - t2.fracs) + t2.fracs + 1, t2.fracs", "ground_truth": "            max(t1.bits, t2.bits - t2.fracs + 1) + t2.fracs + 1, t2.fracs", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    }\n    ufixed_rules = {", "prediction_line": "    }", "ground_truth": "    }", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # (UFixed, Fixed) covered by (Fixed, UFixed)", "prediction_line": "        # (UFixed, Fixed) covered by (Fixed, UFixed)", "ground_truth": "        # (UFixed, Fixed) covered by (Fixed, UFixed)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "# ===----------------------------------------------------------------------=== #", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        ),\n        (UFixed, Fixed): lambda t1, t2: Fixed(", "prediction_line": "        ),", "ground_truth": "        ),", "line_class": "random", "zero_context": true}
{"original_prediction": "    uint_rules = {", "prediction_line": "    uint_rules = {", "ground_truth": "    float_rules = {", "line_class": "random", "zero_context": true}
{"original_prediction": "        outline_op = hcl_d.OutlineOp(hdl_results, ip=ip, loc=loc)", "prediction_line": "        outline_op = hcl_d.OutlineOp(hdl_results, ip=ip, loc=loc)", "ground_truth": "        outline_op = hcl_d.OutlineOp(hdl_results, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self.build_visitor(op.unify, ip)", "prediction_line": "            self.build_visitor(op.unify, ip)", "ground_truth": "            outline_op.attributes[\"unify\"] = StringAttr.get(op.unify)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            outline_op.attributes[\"axis\"] = StringAttr.get(op.axis)", "prediction_line": "            outline_op.attributes[\"axis\"] = StringAttr.get(op.axis)", "ground_truth": "            outline_op.attributes[\"axis\"] = StringAttr.get(op.axis)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        loc = Location.file(op.loc.filename, op.loc.lineno, 0)", "prediction_line": "        loc = Location.file(op.loc.filename, op.loc.lineno, 0)", "ground_truth": "        loc = Location.file(op.loc.filename, op.loc.lineno, 0)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        reorder_op = hcl_d.ReorderOp(arg_results, ip=ip, loc=loc)", "prediction_line": "        reorder_op = hcl_d.ReorderOp(arg_results, ip=ip, loc=loc)", "ground_truth": "        reorder_op = hcl_d.ReorderOp(arg_results, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        factor = IntegerAttr.get(i32, op.factor)", "prediction_line": "        factor = IntegerAttr.get(i32, op.factor)", "ground_truth": "        factor = IntegerAttr.get(i32, op.factor)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                cast_op.attributes[\"unsigned\"] = UnitAttr.get()", "prediction_line": "                cast_op.attributes[\"unsigned\"] = UnitAttr.get()", "ground_truth": "                cast_op.attributes[\"unsigned\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        split_op = hcl_d.SplitOp(op.parent.result, factor, ip=ip, loc=loc)", "prediction_line": "        split_op = hcl_d.SplitOp(op.parent.result, factor, ip=ip, loc=loc)", "ground_truth": "        split_op = hcl_d.SplitOp(op.parent.result, factor, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        factor = IntegerAttr.get(i32, op.factor)", "prediction_line": "        factor = IntegerAttr.get(i32, op.factor)", "ground_truth": "        x_factor = IntegerAttr.get(i32, op.x_factor)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        y_factor = IntegerAttr.get(i32, op.y_factor)", "prediction_line": "        y_factor = IntegerAttr.get(i32, op.y_factor)", "ground_truth": "        y_factor = IntegerAttr.get(i32, op.y_factor)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        tile_op = hcl_d.TileOp(", "prediction_line": "        tile_op = hcl_d.TileOp(", "ground_truth": "        tile_op = hcl_d.TileOp(", "line_class": "commited", "zero_context": true}
{"original_prediction": "expr, ast.BinaryOp):", "prediction_line": "expr, ast.BinaryOp):", "ground_truth": "            expr, (ast.IterVar, ast.ConstantOp, ast.CastOp, ast.BinaryOp)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    if op == \"add\":", "prediction_line": "    if op == \"add\":", "ground_truth": "    if isinstance(op, ast.Add):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if isinstance(expr, ast.IterVar):", "prediction_line": "        if isinstance(expr, ast.IterVar):", "ground_truth": "        if isinstance(expr, ast.IterVar):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if expr.parent_loop.iv_name not in self.iv:", "prediction_line": "            if expr.parent_loop.iv_name not in self.iv:", "ground_truth": "            if isinstance(expr.parent_loop, scf_d.ForOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            loop = scf_d.WhileOp(", "prediction_line": "            loop = scf_d.WhileOp(", "ground_truth": "            while_op = scf_d.WhileOp([], [], ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.Sub):", "prediction_line": "    elif isinstance(op, ast.Sub):", "ground_truth": "    elif isinstance(op, ast.Sub):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        factor = IntegerAttr.get(i32, op.factor)", "prediction_line": "        factor = IntegerAttr.get(i32, op.factor)", "ground_truth": "        ii = IntegerAttr.get(i32, op.ii)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        pipeline_op = hcl_d.PipelineOp(op.target.result, ii, ip=ip, loc=loc)", "prediction_line": "        pipeline_op = hcl_d.PipelineOp(op.target.result, ii, ip=ip, loc=loc)", "ground_truth": "        pipeline_op = hcl_d.PipelineOp(op.target.result, ii=ii, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(expr, ast.ConstantOp):", "prediction_line": "        elif isinstance(expr, ast.ConstantOp):", "ground_truth": "        elif isinstance(expr, ast.ConstantOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(expr, ast.CastOp):", "prediction_line": "        elif isinstance(expr, ast.CastOp):", "ground_truth": "        elif isinstance(expr, ast.CastOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.Mul):", "prediction_line": "    elif isinstance(op, ast.Mul):", "ground_truth": "    elif isinstance(op, ast.Mul):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        unroll_op = hcl_d.UnrollOp(op.target.result, factor, ip=ip, loc=loc)", "prediction_line": "        unroll_op = hcl_d.UnrollOp(op.target.result, factor, ip=ip, loc=loc)", "ground_truth": "        unroll_op = hcl_d.UnrollOp(op.target.result, factor=factor, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if isinstance(expr, ast.AddOp):", "prediction_line": "        if isinstance(expr, ast.AddOp):", "ground_truth": "        if isinstance(expr, ast.Add):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(expr, ast.Sub):", "prediction_line": "        elif isinstance(expr, ast.Sub):", "ground_truth": "        elif isinstance(expr, ast.Sub):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(expr, ast.Mul):", "prediction_line": "        elif isinstance(expr, ast.Mul):", "ground_truth": "        elif isinstance(expr, ast.Mul):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        memref_type = MemRefType.get(op.shape, ele_type)", "prediction_line": "        memref_type = MemRefType.get(op.shape, ele_type)", "ground_truth": "        memref_type = MemRefType.get(op.shape, ele_type)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.Div):", "prediction_line": "    elif isinstance(op, ast.Div):", "ground_truth": "    elif isinstance(op, ast.Div):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        alloc_op = memref_d.AllocOp(memref_type, op.name, ip=ip, loc=loc)", "prediction_line": "        alloc_op = memref_d.AllocOp(memref_type, op.name, ip=ip, loc=loc)", "ground_truth": "        alloc_op = memref_d.AllocOp(memref_type, [], [], ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        op.result = alloc_op", "prediction_line": "        op.result = alloc_op", "ground_truth": "        alloc_op.attributes[\"name\"] = StringAttr.get(op.name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(expr, ast.Div):", "prediction_line": "        elif isinstance(expr, ast.Div):", "ground_truth": "        elif isinstance(expr, ast.Div):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(expr, ast.Mod):", "prediction_line": "        elif isinstance(expr, ast.Mod):", "ground_truth": "        elif isinstance(expr, ast.Mod):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        i32 = IntegerType.get_unsigned(32)", "prediction_line": "        i32 = IntegerType.get_unsigned(32)", "ground_truth": "        parallel_op = hcl_d.ParallelOp(op.target.result, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        fuse_op = hcl_d.FuseOp(arg_results, ip=ip, loc=loc)", "prediction_line": "        fuse_op = hcl_d.FuseOp(arg_results, ip=ip, loc=loc)", "ground_truth": "        fuse_op = hcl_d.FuseOp(arg_results, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.Mod):", "prediction_line": "    elif isinstance(op, ast.Mod):", "ground_truth": "    elif isinstance(op, ast.FloorDiv):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        op.cond.result = None", "prediction_line": "        op.cond.result = None", "ground_truth": "        self.cleaner.visit(op.cond)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if_op = scf_d.IfOp(", "prediction_line": "        if_op = scf_d.IfOp(", "ground_truth": "        if_op = scf_d.IfOp(op.cond.result, hasElse=has_else, results_=[], ip=ip)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        compute_at_op = hcl_d.ComputeAtOp(", "prediction_line": "        compute_at_op = hcl_d.ComputeAtOp(", "ground_truth": "        compute_at_op = hcl_d.ComputeAtOp(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.LSh):", "prediction_line": "    elif isinstance(op, ast.LSh):", "ground_truth": "    elif isinstance(op, ast.Mod):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        lhs = ast.CastOp(op.lhs, t, op.loc)", "prediction_line": "        lhs = ast.CastOp(op.lhs, t, op.loc)", "ground_truth": "        lhs = ast.CastOp(op.lhs, t, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        rhs = ast.CastOp(op.rhs, t, loc)", "prediction_line": "        rhs = ast.CastOp(op.rhs, t, loc)", "ground_truth": "        rhs = ast.CastOp(op.rhs, t, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        loc = Location.file(op.loc.filename, op.loc.lineno, 0)", "prediction_line": "        loc = Location.file(op.loc.filename, op.loc.lineno, 0)", "ground_truth": "        op.target.ir_op.attributes[\"systolic\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.FloorMod):", "prediction_line": "    elif isinstance(op, ast.FloorMod):", "ground_truth": "    elif isinstance(op, ast.And):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if isinstance(op, ast.LeftShiftOp) and isinstance(t, htypes.Int):", "prediction_line": "        if isinstance(op, ast.LeftShiftOp) and isinstance(t, htypes.Int):", "ground_truth": "        if isinstance(op, ast.LeftShiftOp) and isinstance(t, (htypes.Int, htypes.UInt)):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            attr = IntegerAttr.get(attr_type, 0)", "prediction_line": "            attr = IntegerAttr.get(attr_type, 0)", "ground_truth": "            value_attr = IntegerAttr.get(attr_type, 0)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.Or):", "prediction_line": "    elif isinstance(op, ast.Or):", "ground_truth": "    elif isinstance(op, ast.Or):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            const_op = arith_d.ConstantOp(value_attr, ip=ip, loc=loc)", "prediction_line": "            const_op = arith_d.ConstantOp(value_attr, ip=ip, loc=loc)", "ground_truth": "            const_op = arith_d.ConstantOp(attr_type, value_attr, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.init, ip)", "prediction_line": "        self.build_visitor(op.init, ip)", "ground_truth": "        init = ast.immediate_to_constant(op.init, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            const_op.attributes[\"unsigned\"] = UnitAttr.get()", "prediction_line": "            const_op.attributes[\"unsigned\"] = UnitAttr.get()", "ground_truth": "            const_op.attributes[\"unsigned\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.Xor):", "prediction_line": "    elif isinstance(op, ast.Xor):", "ground_truth": "    elif isinstance(op, ast.XOr):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        scf_d.StoreOp(init.result, op.scalar.result, [], ip=ip)", "prediction_line": "        scf_d.StoreOp(init.result, op.scalar.result, [], ip=ip)", "ground_truth": "        zero_idx = ast.ConstantOp(0, htypes.Index(), op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        store_op = memref_d.StoreOp(", "prediction_line": "        store_op = memref_d.StoreOp(", "ground_truth": "        store_op = ast.StoreOp(op.scalar, (zero_idx,), init, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            binary_op.attributes[\"unsigned\"] = UnitAttr.get()", "prediction_line": "            binary_op.attributes[\"unsigned\"] = UnitAttr.get()", "ground_truth": "            binary_op.attributes[\"unsigned\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.Lt):", "prediction_line": "    elif isinstance(op, ast.Lt):", "ground_truth": "    elif isinstance(op, ast.LogicalAnd):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        math_tanh_op = math_d.TanhOp(op.expr.result, ip=ip, loc=loc)", "prediction_line": "        math_tanh_op = math_d.TanhOp(op.expr.result, ip=ip, loc=loc)", "ground_truth": "        casted = ast.CastOp(op.expr, htypes.Float(64), loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.LogicalOr):", "prediction_line": "    elif isinstance(op, ast.LogicalOr):", "ground_truth": "    elif isinstance(op, ast.LogicalOr):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.scalar, body_ip)", "prediction_line": "        self.build_visitor(op.scalar, body_ip)", "ground_truth": "        load_scalar = ast.LoadOp(op.scalar, (zero_idx,), op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.LogicalXOr):", "prediction_line": "    elif isinstance(op, ast.LogicalXOr):", "ground_truth": "    elif isinstance(op, ast.LogicalXOr):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            op_class = arith_d.AddIOp", "prediction_line": "            op_class = arith_d.AddIOp", "ground_truth": "            reduce_op = ast.Add(op.expr, load_scalar, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.LShift):", "prediction_line": "    elif isinstance(op, ast.LShift):", "ground_truth": "    elif isinstance(op, ast.MathPowOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            # We just need to cast the result to the same type", "prediction_line": "            # We just need to cast the result to the same type", "ground_truth": "            neg_one = ast.ConstantOp(-1, t, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.MathExpOp):", "prediction_line": "    elif isinstance(op, ast.MathExpOp):", "ground_truth": "    elif isinstance(op, ast.LeftShiftOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        store_op = ast.StoreOp(op.scalar, (zero_idx,), reduce_op, op.loc)", "prediction_line": "        store_op = ast.StoreOp(op.scalar, (zero_idx,), reduce_op, op.loc)", "ground_truth": "        store_res = ast.StoreOp(op.scalar, (zero_idx,), reduce_op, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            raise APIError(\"Unsupported type for NegOp: {}\".format(t))", "prediction_line": "            raise APIError(\"Unsupported type for NegOp: {}\".format(t))", "ground_truth": "            mul_neg_one = ast.Mul(op.expr, -1, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self.build_visitor(mul_neg_one, ip)", "prediction_line": "            self.build_visitor(mul_neg_one, ip)", "ground_truth": "            casted = ast.CastOp(mul_neg_one, t, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        load_res = ast.LoadOp(op.scalar, (zero_idx,), op.loc)", "prediction_line": "        load_res = ast.LoadOp(op.scalar, (zero_idx,), op.loc)", "ground_truth": "        load_op = ast.LoadOp(op.scalar, (zero_idx,), op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    elif isinstance(op, ast.RightShiftOp):", "prediction_line": "    elif isinstance(op, ast.RightShiftOp):", "ground_truth": "    elif isinstance(op, ast.RightShiftOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            neg_op.attributes[\"unsigned\"] = UnitAttr.get()", "prediction_line": "            neg_op.attributes[\"unsigned\"] = UnitAttr.get()", "ground_truth": "            neg_op.attributes[\"unsigned\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.cond, ip)", "prediction_line": "        self.build_visitor(op.cond, ip)", "ground_truth": "        cond = ast.immediate_to_constant(op.cond, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        true_value = ast.immediate_to_constant(op.true_value, op.loc)", "prediction_line": "        true_value = ast.immediate_to_constant(op.true_value, op.loc)", "ground_truth": "        true_value = ast.immediate_to_constant(op.true_value, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        false_value = ast.immediate_to_constant(op.false_value, op.loc)", "prediction_line": "        false_value = ast.immediate_to_constant(op.false_value, op.loc)", "ground_truth": "        false_value = ast.immediate_to_constant(op.false_value, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        cond = ast.CastOp(cond, htypes.UInt(1), loc)", "prediction_line": "        cond = ast.CastOp(cond, htypes.UInt(1), loc)", "ground_truth": "        if not isinstance(cond, ast.Cmp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            cond = ast.CastOp(cond, htypes.UInt(1), loc)", "prediction_line": "            cond = ast.CastOp(cond, htypes.UInt(1), loc)", "ground_truth": "            cond = ast.CastOp(cond, htypes.UInt(1), op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if not isinstance(true_value, ast.CastOp):", "prediction_line": "        if not isinstance(true_value, ast.CastOp):", "ground_truth": "        true_value = ast.CastOp(true_value, res_type, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        false_value = ast.CastOp(false_value, res_type, op.loc)", "prediction_line": "        false_value = ast.CastOp(false_value, res_type, op.loc)", "ground_truth": "        false_value = ast.CastOp(false_value, res_type, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        select_op = arith_d.SelectOp(", "prediction_line": "        select_op = arith_d.SelectOp(", "ground_truth": "        select_op = arith_d.SelectOp(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.tinf_engine.visit(self._ast)", "prediction_line": "        self.tinf_engine.visit(self._ast)", "ground_truth": "        self.cleaner = build_cleaner.ASTCleaner()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        print_op = hcl_d.PrintOp(op.args, op.fmt, signedness_str, ip=ip, loc=loc)", "prediction_line": "        print_op = hcl_d.PrintOp(op.args, op.fmt, signedness_str, ip=ip, loc=loc)", "ground_truth": "        operands = [v.result for v in op.args]", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if op.result in self.tensor_dict:", "prediction_line": "            if op.result in self.tensor_dict:", "ground_truth": "        if isinstance(op, ast.ComputeOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        print_op.attributes[\"fmt\"] = StringAttr.get(op.fmt)", "prediction_line": "        print_op.attributes[\"fmt\"] = StringAttr.get(op.fmt)", "ground_truth": "        fmt_str = StringAttr.get(op.fmt)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ForOp):", "prediction_line": "        elif isinstance(op, ast.ForOp):", "ground_truth": "        elif isinstance(op, ast.IterVar):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ForOp):", "prediction_line": "        elif isinstance(op, ast.ForOp):", "ground_truth": "        elif isinstance(op, ast.ReduceOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        print_op.attributes[\"fmt\"] = fmt_str", "prediction_line": "        print_op.attributes[\"fmt\"] = fmt_str", "ground_truth": "        signedness_str = StringAttr.get(signedness_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ForOp):", "prediction_line": "        elif isinstance(op, ast.ForOp):", "ground_truth": "        elif isinstance(op, ast.AllocOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.FreeOp):", "prediction_line": "        elif isinstance(op, ast.FreeOp):", "ground_truth": "        elif isinstance(op, ast.Cmp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.SelectOp):", "prediction_line": "        elif isinstance(op, ast.SelectOp):", "ground_truth": "        elif isinstance(op, ast.BinaryOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.UnaryOp):", "prediction_line": "        elif isinstance(op, ast.UnaryOp):", "ground_truth": "        elif isinstance(op, ast.MathTanhOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.MathSigmoidOp):", "prediction_line": "        elif isinstance(op, ast.MathSigmoidOp):", "ground_truth": "        elif isinstance(op, ast.BitCastOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.BitExtractOp):", "prediction_line": "        elif isinstance(op, ast.BitExtractOp):", "ground_truth": "        elif isinstance(op, ast.LoadOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.StoreOp):", "prediction_line": "        elif isinstance(op, ast.StoreOp):", "ground_truth": "        elif isinstance(op, ast.StoreOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ForOp):", "prediction_line": "        elif isinstance(op, ast.ForOp):", "ground_truth": "        elif isinstance(op, ast.ConstantOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.index, ip)", "prediction_line": "        self.build_visitor(op.index, ip)", "ground_truth": "        index = ast.CastOp(op.index, htypes.Index(), op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.CastOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.IfOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.WhileOp):", "prediction_line": "        elif isinstance(op, ast.WhileOp):", "ground_truth": "        elif isinstance(op, ast.ForOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.WhileOp):", "prediction_line": "        elif isinstance(op, ast.WhileOp):", "ground_truth": "        elif isinstance(op, ast.WhileOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReturnOp):", "prediction_line": "        elif isinstance(op, ast.ReturnOp):", "ground_truth": "        elif isinstance(op, ast.SelectOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.PrintOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.PrintTensorOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.GetBitOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.SetBitOp):", "prediction_line": "        elif isinstance(op, ast.SetBitOp):", "ground_truth": "        elif isinstance(op, ast.GetSliceOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        start = ast.CastOp(op.start, htypes.Index(), op.loc)", "prediction_line": "        start = ast.CastOp(op.start, htypes.Index(), op.loc)", "ground_truth": "        start = ast.CastOp(op.start, htypes.Index(), op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.SetBitOp):", "prediction_line": "        elif isinstance(op, ast.SetBitOp):", "ground_truth": "        elif isinstance(op, ast.SetBitOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        end = ast.CastOp(op.end, htypes.Index(), op.loc)", "prediction_line": "        end = ast.CastOp(op.end, htypes.Index(), op.loc)", "ground_truth": "        end = ast.CastOp(op.end, htypes.Index(), op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.SetSliceOp):", "prediction_line": "        elif isinstance(op, ast.SetSliceOp):", "ground_truth": "        elif isinstance(op, ast.SetSliceOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        attr_type = IntegerAttr.get(dtype, attr)", "prediction_line": "        attr_type = IntegerAttr.get(dtype, attr)", "ground_truth": "        cmp_attr = IntegerAttr.get(IntegerType.get_signless(64), attr)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.GetFieldOp):", "prediction_line": "        elif isinstance(op, ast.GetFieldOp):", "ground_truth": "        elif isinstance(op, ast.BitReverseOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.BitConcatOp):", "prediction_line": "        elif isinstance(op, ast.BitConcatOp):", "ground_truth": "        elif isinstance(op, ast.ConstantTensorOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            cmp_op.attributes[\"unsigned\"] = UnitAttr.get()", "prediction_line": "            cmp_op.attributes[\"unsigned\"] = UnitAttr.get()", "ground_truth": "            cmp_op.attributes[\"unsigned\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.TensorSliceOp):", "prediction_line": "        elif isinstance(op, ast.TensorSliceOp):", "ground_truth": "        elif isinstance(op, ast.StructConstructOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.StructGetOp):", "prediction_line": "        elif isinstance(op, ast.StructGetOp):", "ground_truth": "        elif isinstance(op, ast.StructGetOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.StructSetOp):", "prediction_line": "        elif isinstance(op, ast.StructSetOp):", "ground_truth": "        elif isinstance(op, ast.FuncOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReturnOp):", "prediction_line": "        elif isinstance(op, ast.ReturnOp):", "ground_truth": "        elif isinstance(op, ast.CallOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReturnOp):", "prediction_line": "        elif isinstance(op, ast.ReturnOp):", "ground_truth": "        elif isinstance(op, ast.Neg):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.Not):", "prediction_line": "        elif isinstance(op, ast.Not):", "ground_truth": "        elif isinstance(op, ast.OpHandle):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReturnOp):", "prediction_line": "        elif isinstance(op, ast.ReturnOp):", "ground_truth": "        elif isinstance(op, ast.LoopHandle):", "line_class": "commited", "zero_context": true}
{"original_prediction": "type\n        value = ast.CastOp(op.value, htypes.UInt(1), op.loc)", "prediction_line": "type", "ground_truth": "        value = ast.CastOp(op.value, htypes.UInt(1), op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReturnOp):", "prediction_line": "        elif isinstance(op, ast.ReturnOp):", "ground_truth": "        elif isinstance(op, ast.ReuseAtOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReturnOp):", "prediction_line": "        elif isinstance(op, ast.ReturnOp):", "ground_truth": "        elif isinstance(op, ast.PartitionOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            affine_map = AffineMap.get(", "prediction_line": "            affine_map = AffineMap.get(", "ground_truth": "            affine_map = AffineMap.get(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.PartitionedTensor):", "prediction_line": "        elif isinstance(op, ast.PartitionedTensor):", "ground_truth": "        elif isinstance(op, ast.ReplaceOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            affine_attr = AffineMapAttr.get(affine_map)", "prediction_line": "            affine_attr = AffineMapAttr.get(affine_map)", "ground_truth": "            affine_attr = AffineMapAttr.get(affine_map)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReturnOp):", "prediction_line": "        elif isinstance(op, ast.ReturnOp):", "ground_truth": "        elif isinstance(op, ast.ReshapeOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.SplitOp):", "prediction_line": "        elif isinstance(op, ast.SplitOp):", "ground_truth": "        elif isinstance(op, ast.ReformOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if isinstance(op.expr, ast.LoadOp):", "prediction_line": "        if isinstance(op.expr, ast.LoadOp):", "ground_truth": "        if isinstance(op.expr, ast.LoadOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.FlattenOp):", "prediction_line": "        elif isinstance(op, ast.FlattenOp):", "ground_truth": "        elif isinstance(op, ast.BufferAtOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.BufferLoadOp):", "prediction_line": "        elif isinstance(op, ast.BufferLoadOp):", "ground_truth": "        elif isinstance(op, ast.InterKernelToOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            store_op = ast.StoreOp(load_op.tensor, load_op.index, op, op.loc)", "prediction_line": "            store_op = ast.StoreOp(load_op.tensor, load_op.index, op, op.loc)", "ground_truth": "            store_op = ast.StoreOp(load_op.tensor, load_op.index, op, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.InterKernelFromOp):", "prediction_line": "        elif isinstance(op, ast.InterKernelFromOp):", "ground_truth": "        elif isinstance(op, ast.OutlineOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.OutlineFuncOp):", "prediction_line": "        elif isinstance(op, ast.OutlineFuncOp):", "ground_truth": "        elif isinstance(op, ast.ReorderOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                itmd_loc = ast.Location(\"unknown\", 0)", "prediction_line": "                itmd_loc = ast.Location(\"unknown\", 0)", "ground_truth": "                index = ast.CastOp(index, htypes.Index(), loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.FlattenOp):", "prediction_line": "        elif isinstance(op, ast.FlattenOp):", "ground_truth": "        elif isinstance(op, ast.SplitOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            load_op = memref_d.LoadOp(op.tensor.result, new_indices, ip=ip, loc=loc)", "prediction_line": "            load_op = memref_d.LoadOp(op.tensor.result, new_indices, ip=ip, loc=loc)", "ground_truth": "            load_op = memref_d.LoadOp(op.tensor.result, new_indices, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.FlattenOp):", "prediction_line": "        elif isinstance(op, ast.FlattenOp):", "ground_truth": "        elif isinstance(op, ast.TileOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.FlattenOp):", "prediction_line": "        elif isinstance(op, ast.FlattenOp):", "ground_truth": "        elif isinstance(op, ast.PipelineOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "    def build_store_op(self, op: ast.StoreOp, ip):", "prediction_line": "    def build_store_op(self, op: ast.StoreOp, ip):", "ground_truth": "        load_op.attributes[\"from\"] = StringAttr.get(op.tensor.name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.PipelineStageOp):", "prediction_line": "        elif isinstance(op, ast.PipelineStageOp):", "ground_truth": "        elif isinstance(op, ast.UnrollOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            load_op.attributes[\"unsigned\"] = UnitAttr.get()", "prediction_line": "            load_op.attributes[\"unsigned\"] = UnitAttr.get()", "ground_truth": "            load_op.attributes[\"unsigned\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.UnrollVectorOp):", "prediction_line": "        elif isinstance(op, ast.UnrollVectorOp):", "ground_truth": "        elif isinstance(op, ast.ParallelOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ParallelToOp):", "prediction_line": "        elif isinstance(op, ast.ParallelToOp):", "ground_truth": "        elif isinstance(op, ast.FuseOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.FlattenOp):", "prediction_line": "        elif isinstance(op, ast.FlattenOp):", "ground_truth": "        elif isinstance(op, ast.ComputeAtOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ComputeInlineOp):", "prediction_line": "        elif isinstance(op, ast.ComputeInlineOp):", "ground_truth": "        elif isinstance(op, ast.SystolicOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.iv.clear()  # clear iv", "prediction_line": "        self.iv.clear()  # clear iv", "ground_truth": "        casted_expr = ast.CastOp(op.value, op.tensor.dtype, op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            input_types.append(hcl_dtype_to_mlir(arg.dtype))", "prediction_line": "            input_types.append(hcl_dtype_to_mlir(arg.dtype))", "ground_truth": "            if isinstance(arg, ast.AllocOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                input_types.append(", "prediction_line": "                input_types.append(", "ground_truth": "                memref_type = MemRefType.get(arg.shape, ele_type)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                # cast to index type", "prediction_line": "                # cast to index type", "ground_truth": "                index = ast.CastOp(index, htypes.Index(), op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if isinstance(ret, ast.AllocOp):", "prediction_line": "            if isinstance(ret, ast.AllocOp):", "ground_truth": "            if isinstance(ret, ast.AllocOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            store_op = memref_d.StoreOp(", "prediction_line": "            store_op = memref_d.StoreOp(", "ground_truth": "            store_op = memref_d.StoreOp(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        expr_dtype = hcl_dtype_to_mlir(expr_dtype, signless=True)", "prediction_line": "        expr_dtype = hcl_dtype_to_mlir(expr_dtype, signless=True)", "ground_truth": "        bitreverse_op = hcl_d.BitReverseOp(op.expr.result, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                memref_type = MemRefType.get(ret.shape, ele_type)", "prediction_line": "                memref_type = MemRefType.get(ret.shape, ele_type)", "ground_truth": "                memref_type = MemRefType.get(ret.shape, ele_type)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        op.ir_op = store_op", "prediction_line": "        op.ir_op = store_op", "ground_truth": "        store_op.attributes[\"to\"] = StringAttr.get(op.tensor.name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            store_op.attributes[\"unsigned\"] = UnitAttr.get()", "prediction_line": "            store_op.attributes[\"unsigned\"] = UnitAttr.get()", "ground_truth": "            store_op.attributes[\"unsigned\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if isinstance(val, list):", "prediction_line": "        if isinstance(val, list):", "ground_truth": "        value_attr = DenseElementsAttr.get(val)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        const_op = arith_d.ConstantOp(dtype, value_attr, ip=ip, loc=loc)", "prediction_line": "        const_op = arith_d.ConstantOp(dtype, value_attr, ip=ip, loc=loc)", "ground_truth": "        sym_name = StringAttr.get(op.name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        func_type = FunctionType.get(input_types, output_types)", "prediction_line": "        func_type = FunctionType.get(input_types, output_types)", "ground_truth": "        func_type = FunctionType.get(input_types, output_types)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        func_op = func_d.FuncOp(", "prediction_line": "        func_op = func_d.FuncOp(", "ground_truth": "        func_op = func_d.FuncOp(name=op.name, type=func_type, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        constant_tensor_op = hcl_d.ConstantTensorOp(", "prediction_line": "        constant_tensor_op = hcl_d.ConstantTensorOp(", "ground_truth": "        sym_visibility = StringAttr.get(\"private\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "            # TODO: support fixed point", "prediction_line": "            # TODO: support fixed point", "ground_truth": "            memref_type = MemRefType.get(op.shape, IntegerType.get_signless(64))", "line_class": "commited", "zero_context": true}
{"original_prediction": "                value_attr = IntegerAttr.get(dtype, op.value)", "prediction_line": "                value_attr = IntegerAttr.get(dtype, op.value)", "ground_truth": "                value_attr = IntegerAttr.get(IndexType.get(), op.value)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            func_op.attributes[\"sym_visibility\"] = StringAttr.get(\"private\")", "prediction_line": "            func_op.attributes[\"sym_visibility\"] = StringAttr.get(\"private\")", "ground_truth": "            func_op.attributes[\"sym_visibility\"] = StringAttr.get(\"private\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "                value_attr = IntegerAttr.get(IntegerType.get_signless(1), op.value)", "prediction_line": "                value_attr = IntegerAttr.get(IntegerType.get_signless(1), op.value)", "ground_truth": "                value_attr = BoolAttr.get(op.value)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            memref_type = MemRefType.get(op.shape, dtype)", "prediction_line": "            memref_type = MemRefType.get(op.shape, dtype)", "ground_truth": "            memref_type = MemRefType.get(op.shape, dtype)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        constant_op = arith_d.ConstantOp(", "prediction_line": "        constant_op = arith_d.ConstantOp(", "ground_truth": "        type_attr = TypeAttr.get(memref_type)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                value_attr = IntegerAttr.get(attr_type, op.value)", "prediction_line": "                value_attr = IntegerAttr.get(attr_type, op.value)", "ground_truth": "                value_attr = IntegerAttr.get(attr_type, op.value)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            const_op = hcl_d.ConstantFixedOp(dtype, value_attr, ip=ip, loc=loc)", "prediction_line": "            const_op = hcl_d.ConstantFixedOp(dtype, value_attr, ip=ip, loc=loc)", "ground_truth": "            const_op = arith_d.ConstantOp(dtype, value_attr, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                attr_type = FloatType.get_f16()", "prediction_line": "                attr_type = FloatType.get_f16()", "ground_truth": "                value_attr = FloatAttr.get(F16Type.get(), op.value)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                value_attr = FloatAttr.get(F32Type.get(), op.value)", "prediction_line": "                value_attr = FloatAttr.get(F32Type.get(), op.value)", "ground_truth": "                value_attr = FloatAttr.get(F32Type.get(), op.value)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        op.ir_op = const_tensor", "prediction_line": "        op.ir_op = const_tensor", "ground_truth": "        const_tensor.attributes[\"constant\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "                value_attr = FloatAttr.get(F64Type.get(), op.value)", "prediction_line": "                value_attr = FloatAttr.get(F64Type.get(), op.value)", "ground_truth": "                value_attr = FloatAttr.get(F64Type.get(), op.value)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            const_tensor.attributes[\"unsigned\"] = UnitAttr.get()", "prediction_line": "            const_tensor.attributes[\"unsigned\"] = UnitAttr.get()", "ground_truth": "            const_tensor.attributes[\"unsigned\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        func_op.entry_block.terminator = func_d.ReturnOp(", "prediction_line": "        func_op.entry_block.terminator = func_d.ReturnOp(", "ground_truth": "        func_d.ReturnOp(returns, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    def build_call_op(self, op: ast.CallOp, ip):", "prediction_line": "    def build_call_op(self, op: ast.CallOp, ip):", "ground_truth": "        func_op.attributes[\"function_type\"] = TypeAttr.get(func_type)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            # TODO: support fixed point", "prediction_line": "            # TODO: support fixed point", "ground_truth": "            fixed_memref_type = MemRefType.get(val.shape, dtype)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                fixed_memref_type, sym_name, ip=ip, loc=loc", "prediction_line": "                fixed_memref_type, sym_name, ip=ip, loc=loc", "ground_truth": "                fixed_memref_type, FlatSymbolRefAttr.get(op.name), ip=ip, loc=loc", "line_class": "commited", "zero_context": true}
{"original_prediction": "        func_op.attributes[\"type_hints\"] = StringAttr.get(otypes + itypes)", "prediction_line": "        func_op.attributes[\"type_hints\"] = StringAttr.get(otypes + itypes)", "ground_truth": "        func_op.attributes[\"otypes\"] = StringAttr.get(otypes)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        func_op.attributes[\"itypes\"] = StringAttr.get(itypes)", "prediction_line": "        func_op.attributes[\"itypes\"] = StringAttr.get(itypes)", "ground_truth": "        func_op.attributes[\"itypes\"] = StringAttr.get(itypes)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                memref_type, FlatSymbolRefAttr.get(op.name), ip=ip, loc=loc", "prediction_line": "                memref_type, FlatSymbolRefAttr.get(op.name), ip=ip, loc=loc", "ground_truth": "                memref_type, FlatSymbolRefAttr.get(op.name), ip=ip, loc=loc", "line_class": "commited", "zero_context": true}
{"original_prediction": "            func_op.attributes[\"bit\"] = BoolAttr.get(True)", "prediction_line": "            func_op.attributes[\"bit\"] = BoolAttr.get(True)", "ground_truth": "            func_op.attributes[\"bit\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        # use global insetion point instead", "prediction_line": "        # use global insetion point instead", "ground_truth": "        func = FlatSymbolRefAttr.get(op.name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            field_dtype = op.dtype.dtype_dict[type_key]", "prediction_line": "            field_dtype = op.dtype.dtype_dict[type_key]", "ground_truth": "            field = ast.CastOp(field, op.dtype.dtype_dict[type_key], op.loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        struct_type = hcl_dtype_to_mlir(op.dtype, signless=True)", "prediction_line": "        struct_type = hcl_dtype_to_mlir(op.dtype, signless=True)", "ground_truth": "        struct_type = hcl_d.StructType.get(field_types)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        struct_op = arith_d.StructOp(struct_type, field_results, ip=ip, loc=loc)", "prediction_line": "        struct_op = arith_d.StructOp(struct_type, field_results, ip=ip, loc=loc)", "ground_truth": "        struct_op = hcl_d.StructConstructOp(struct_type, field_results, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        struct_get_op = hcl_d.StructGetOp(", "prediction_line": "        struct_get_op = hcl_d.StructGetOp(", "ground_truth": "        attr = IntegerAttr.get(IntegerType.get_signless(64), op.field)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        call_op = func_d.CallOp(", "prediction_line": "        call_op = func_d.CallOp(", "ground_truth": "        call_op = func_d.CallOp(return_types, func, args, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        struct_get_op = hcl_d.StructGetOp(dtype, op.struct.result, attr, ip=ip, loc=loc)", "prediction_line": "        struct_get_op = hcl_d.StructGetOp(dtype, op.struct.result, attr, ip=ip, loc=loc)", "ground_truth": "        struct_get_op = hcl_d.StructGetOp(dtype, op.struct.result, attr, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            struct_get_op.attributes[\"unsigned\"] = UnitAttr.get()", "prediction_line": "            struct_get_op.attributes[\"unsigned\"] = UnitAttr.get()", "ground_truth": "            struct_get_op.attr[\"unsigned\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.op, ip)", "prediction_line": "        self.build_visitor(op.op, ip)", "ground_truth": "        hdl_op = hcl_d.CreateOpHandleOp(StringAttr.get(op.name), ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            op.op_hdl.result, StringAttr.get(op.name), ip=ip, loc=loc", "prediction_line": "            op.op_hdl.result, StringAttr.get(op.name), ip=ip, loc=loc", "ground_truth": "            op.op_hdl.result, StringAttr.get(op.name), ip=ip, loc=loc", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    isinstance(src_type, htypes.UInt)", "prediction_line": "                    isinstance(src_type, htypes.UInt)", "ground_truth": "                    isinstance(op.expr, (ast.GetBitOp, ast.GetSliceOp, ast.LeftShiftOp))", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.expr, ip)", "prediction_line": "        self.build_visitor(op.expr, ip)", "ground_truth": "        partition_type = IntegerAttr.get(i32, op.kind)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        partition_op = hcl_d.CreatePartitionOp(", "prediction_line": "        partition_op = hcl_d.CreatePartitionOp(", "ground_truth": "        dim = IntegerAttr.get(ui32, op.dim)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        factor = IntegerAttr.get(ui32, op.factor)", "prediction_line": "        factor = IntegerAttr.get(ui32, op.factor)", "ground_truth": "        factor = IntegerAttr.get(ui32, op.factor)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        partition_op = hcl_d.PartitionOp(", "prediction_line": "        partition_op = hcl_d.PartitionOp(", "ground_truth": "        partition_op = hcl_d.PartitionOp(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.dst, ip)", "prediction_line": "        self.build_visitor(op.dst, ip)", "ground_truth": "        replace_op = hcl_d.ReplaceOp(op.target.result, op.src.result, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        shape = [IntegerAttr.get(IntegerType.get_signless(64), s) for s in op.shape]", "prediction_line": "        shape = [IntegerAttr.get(IntegerType.get_signless(64), s) for s in op.shape]", "ground_truth": "        memref_type = MemRefType.get(op.shape, eletype, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        reshape_op = memref_d.ReshapeOp(", "prediction_line": "        reshape_op = memref_d.ReshapeOp(", "ground_truth": "        reshape_op = hcl_d.ReshapeOp(memref_type, op.tensor.result, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if lb < 0 or ub < 0:", "prediction_line": "            if lb < 0 or ub < 0:", "ground_truth": "            lbCst = AffineConstantExpr.get(lb)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ubCst = AffineConstantExpr.get(ub)", "prediction_line": "            ubCst = AffineConstantExpr.get(ub)", "ground_truth": "            lbMap = AffineMap.get(dim_count=0, symbol_count=0, exprs=[lbCst])", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ubCst = AffineConstantExpr.get(ub)", "prediction_line": "            ubCst = AffineConstantExpr.get(ub)", "ground_truth": "            lbMapAttr = AffineMapAttr.get(lbMap)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ubCst = AffineConstantExpr.get(ub)", "prediction_line": "            ubCst = AffineConstantExpr.get(ub)", "ground_truth": "            ubCst = AffineConstantExpr.get(ub)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ubMap = AffineMap.get(dim_count=0, symbol_count=0, exprs=[ubCst])", "prediction_line": "            ubMap = AffineMap.get(dim_count=0, symbol_count=0, exprs=[ubCst])", "ground_truth": "            ubMap = AffineMap.get(dim_count=0, symbol_count=0, exprs=[ubCst])", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ubMapAttr = AffineMapAttr.get(ubMap)", "prediction_line": "            ubMapAttr = AffineMapAttr.get(ubMap)", "ground_truth": "            ubMapAttr = AffineMapAttr.get(ubMap)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            stepCst = AffineConstantExpr.get(step)", "prediction_line": "            stepCst = AffineConstantExpr.get(step)", "ground_truth": "            step = IntegerAttr.get(IntegerType.get_signless(32), step)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        attr = AffineMapAttr.get(attr)", "prediction_line": "        attr = AffineMapAttr.get(attr)", "ground_truth": "        memref_type = MemRefType.get(op.target.shape, op.target.ir_op.dtype)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        reform_op = hcl_d.ReformOp(", "prediction_line": "        reform_op = hcl_d.ReformOp(", "ground_truth": "        reform_op = hcl_d.ReformOp(memref_type, op.target.result, ip=ip, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        op.ir_op = reform_op", "prediction_line": "        op.ir_op = reform_op", "ground_truth": "        reform_op.attributes[\"layout\"] = AffineMapAttr.get(attr)", "line_class": "commited", "zero_context": true}
{"original_prediction": "name if name else \"\"),", "prediction_line": "name if name else \"\"),", "ground_truth": "                    StringAttr.get(\"\") if name in [\"\", None] else StringAttr.get(name)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        f32 = F32Type.get()", "prediction_line": "        f32 = F32Type.get()", "ground_truth": "        f32 = F32Type.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "                stage=(\"\" if stage == \"\" else StringAttr.get(stage)),", "prediction_line": "                stage=(\"\" if stage == \"\" else StringAttr.get(stage)),", "ground_truth": "                stage=(\"\" if stage == \"\" else StringAttr.get(stage)),", "line_class": "commited", "zero_context": true}
{"original_prediction": "                reduction=BoolAttr.get(reduction),", "prediction_line": "                reduction=BoolAttr.get(reduction),", "ground_truth": "                reduction=(UnitAttr.get() if reduction else None),", "line_class": "commited", "zero_context": true}
{"original_prediction": "        memref_type = MemRefType.get(op.target.shape, f32, loc=loc)", "prediction_line": "        memref_type = MemRefType.get(op.target.shape, f32, loc=loc)", "ground_truth": "        memref_type = MemRefType.get((1,), f32, loc=loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        reuse_at_op = hcl_d.ReuseAtOp(", "prediction_line": "        reuse_at_op = hcl_d.ReuseAtOp(", "ground_truth": "        reuse_at_op = hcl_d.ReuseAtOp(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lb = arith_d.IndexCastOp(lb, ip=ip, loc=loc)", "prediction_line": "            lb = arith_d.IndexCastOp(lb, ip=ip, loc=loc)", "ground_truth": "            itmd_loc = ast.Location(\"unknown\", 0)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lb = ast.CastOp(", "prediction_line": "            lb = ast.CastOp(", "ground_truth": "            lb = ast.immediate_to_constant(lb, itmd_loc, htypes.Index())", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ub = ast.immediate_to_constant(ub, itmd_loc, htypes.Index())", "prediction_line": "            ub = ast.immediate_to_constant(ub, itmd_loc, htypes.Index())", "ground_truth": "            ub = ast.immediate_to_constant(ub, itmd_loc, htypes.Index())", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lb = lb.result", "prediction_line": "            lb = lb.result", "ground_truth": "            lb = ast.CastOp(lb, htypes.Index(), loc=itmd_loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ub = ast.CastOp(ub, htypes.Index(), loc=itmd_loc)", "prediction_line": "            ub = ast.CastOp(ub, htypes.Index(), loc=itmd_loc)", "ground_truth": "            ub = ast.CastOp(ub, htypes.Index(), loc=itmd_loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            lb = lb.result", "prediction_line": "            lb = lb.result", "ground_truth": "            step = ast.immediate_to_constant(step, itmd_loc, htypes.Index())", "line_class": "commited", "zero_context": true}
{"original_prediction": "            step = ast.CastOp(step, htypes.Index(), loc=itmd_loc)", "prediction_line": "            step = ast.CastOp(step, htypes.Index(), loc=itmd_loc)", "ground_truth": "            for_op = scf_d.ForOp(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        ui32 = IntegerType.get_unsigned(32)", "prediction_line": "        ui32 = IntegerType.get_unsigned(32)", "ground_truth": "        fifo_depth = IntegerAttr.get(i32, op.fifo_depth)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        inter_kernel_to_op = hcl_d.InterKernelToOp(", "prediction_line": "        inter_kernel_to_op = hcl_d.InterKernelToOp(", "ground_truth": "        top_func.attributes[\"dataflow\"] = UnitAttr.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        inter_kernel_to_op = hcl_d.InterKernelToOp(", "prediction_line": "        inter_kernel_to_op = hcl_d.InterKernelToOp(", "ground_truth": "        to_op = hcl_d.InterKernelToOp(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            res_dtype, op.expr.result, start.result, end.result, ip=ip, loc=loc", "prediction_line": "            res_dtype, op.expr.result, start.result, end.result, ip=ip, loc=loc", "ground_truth": "            res_dtype, op.expr.result, end.result, start.result, ip=ip, loc=loc", "line_class": "common", "zero_context": true}
{"original_prediction": "list\n        for i, idx in enumerate(op.indices):", "prediction_line": "list", "ground_truth": "        for index in op.index:", "line_class": "common", "zero_context": true}
{"original_prediction": "                new_indices.append(index.result)", "prediction_line": "                new_indices.append(index.result)", "ground_truth": "                new_indices.append(index.result)", "line_class": "common", "zero_context": true}
{"original_prediction": "            res_dtype, op.expr.result, index.result, ip=ip, loc=loc", "prediction_line": "            res_dtype, op.expr.result, index.result, ip=ip, loc=loc", "ground_truth": "            res_dtype, op.expr.result, index.result, ip=ip, loc=loc", "line_class": "common", "zero_context": true}
{"original_prediction": "self.iv.index(expr.parent_loop.induction_variable))", "prediction_line": "self.iv.index(expr.parent_loop.induction_variable))", "ground_truth": "                    self.iv.index(expr.parent_loop.induction_variable)", "line_class": "common", "zero_context": true}
{"original_prediction": "            expr_dtype, op.expr.result, index.result, value.result, ip=ip, loc=loc", "prediction_line": "            expr_dtype, op.expr.result, index.result, value.result, ip=ip, loc=loc", "ground_truth": "            expr_dtype, op.expr.result, index.result, value.result, ip=ip, loc=loc", "line_class": "common", "zero_context": true}
{"original_prediction": "            start.result,", "prediction_line": "            start.result,", "ground_truth": "            start.result,", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.build_visitor(start, ip)", "prediction_line": "        self.build_visitor(start, ip)", "ground_truth": "        self.build_visitor(start, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.build_affine_expr(expr.expr)", "prediction_line": "            return self.build_affine_expr(expr.expr)", "ground_truth": "            return self.build_affine_expr(expr.expr)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.rhs, ip)", "prediction_line": "        self.build_visitor(op.rhs, ip)", "ground_truth": "        self.build_visitor(op.rhs, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_reuse_at_op(op, ip)", "prediction_line": "            self.build_reuse_at_op(op, ip)", "ground_truth": "            self.build_reuse_at_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if ret.result is None:", "prediction_line": "            if ret.result is None:", "ground_truth": "            self.build_visitor(ret, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_visitor(neg_one, ip)", "prediction_line": "            self.build_visitor(neg_one, ip)", "ground_truth": "            self.build_visitor(neg_one, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_select_op(op, ip)", "prediction_line": "            self.build_select_op(op, ip)", "ground_truth": "            self.build_select_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            lb.result = lb.result.value", "prediction_line": "            lb.result = lb.result.value", "ground_truth": "            self.build_visitor(lb, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_split_op(op, ip)", "prediction_line": "            self.build_split_op(op, ip)", "ground_truth": "            self.build_split_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_fuse_op(op, ip)", "prediction_line": "            self.build_fuse_op(op, ip)", "ground_truth": "            self.build_fuse_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_visitor(store_op, ip)", "prediction_line": "            self.build_visitor(store_op, ip)", "ground_truth": "            self.build_visitor(store_op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        i32 = IntegerType.get_unsigned(32)", "prediction_line": "        i32 = IntegerType.get_unsigned(32)", "ground_truth": "        self.build_visitor(op.target, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_bitcast_op(op, ip)", "prediction_line": "            self.build_bitcast_op(op, ip)", "ground_truth": "            self.build_bitcast_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_outline_op(op, ip)", "prediction_line": "            self.build_outline_op(op, ip)", "ground_truth": "            self.build_outline_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_while_op(op, ip)", "prediction_line": "            self.build_while_op(op, ip)", "ground_truth": "            self.build_while_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.build_visitor(body_op, body_ip)", "prediction_line": "                self.build_visitor(body_op, body_ip)", "ground_truth": "                self.build_visitor(body_op, body_ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.build_visitor(store_res, body_ip)", "prediction_line": "        self.build_visitor(store_res, body_ip)", "ground_truth": "        self.build_visitor(store_res, body_ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_math_tanh_op(op, ip)", "prediction_line": "            self.build_math_tanh_op(op, ip)", "ground_truth": "            self.build_math_tanh_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_replace_op(op, ip)", "prediction_line": "            self.build_replace_op(op, ip)", "ground_truth": "            self.build_replace_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.lhs, ip)", "prediction_line": "        self.build_visitor(op.lhs, ip)", "ground_truth": "        self.build_visitor(op.lhs, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.struct, ip)", "prediction_line": "        self.build_visitor(op.struct, ip)", "ground_truth": "        self.build_visitor(op.struct, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_constant_tensor_op(op, ip)", "prediction_line": "            self.build_constant_tensor_op(op, ip)", "ground_truth": "            self.build_constant_tensor_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.cond, ip)", "prediction_line": "        self.build_visitor(op.cond, ip)", "ground_truth": "        self.build_visitor(op.cond, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.replacer, ip)", "prediction_line": "        self.build_visitor(op.replacer, ip)", "ground_truth": "        self.build_visitor(op.src, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.value, ip)", "prediction_line": "        self.build_visitor(op.value, ip)", "ground_truth": "        self.build_visitor(op.value, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_compute(op, ip)", "prediction_line": "            self.build_compute(op, ip)", "ground_truth": "            self.build_compute(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_visitor(ub, ip)", "prediction_line": "            self.build_visitor(ub, ip)", "ground_truth": "            self.build_visitor(ub, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.y_parent, ip)", "prediction_line": "        self.build_visitor(op.y_parent, ip)", "ground_truth": "        self.build_visitor(op.y_parent, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            # We don't actually cast between struct types,", "prediction_line": "            # We don't actually cast between struct types,", "ground_truth": "            if not is_all_field_int(res_type):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.build_visitor(rhs, ip)", "prediction_line": "        self.build_visitor(rhs, ip)", "ground_truth": "        self.build_visitor(rhs, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.build_visitor(end, ip)", "prediction_line": "        self.build_visitor(end, ip)", "ground_truth": "        self.build_visitor(end, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.build_visitor(zero_idx, ip)", "prediction_line": "        self.build_visitor(zero_idx, ip)", "ground_truth": "        self.build_visitor(zero_idx, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_struct_get_op(op, ip)", "prediction_line": "            self.build_struct_get_op(op, ip)", "ground_truth": "            self.build_struct_get_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_reorder_op(op, ip)", "prediction_line": "            self.build_reorder_op(op, ip)", "ground_truth": "            self.build_reorder_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_unroll_op(op, ip)", "prediction_line": "            self.build_unroll_op(op, ip)", "ground_truth": "            self.build_unroll_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if not is_all_field_width_equal(res_type):", "prediction_line": "            if not is_all_field_width_equal(res_type):", "ground_truth": "            total_width = get_struct_bitwidth(res_type)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_binary_op(op, ip)", "prediction_line": "            self.build_binary_op(op, ip)", "ground_truth": "            self.build_binary_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.build_partition_op(op, ip)", "prediction_line": "            self.build_partition_op(op, ip)", "ground_truth": "            self.build_partition_op(op, ip)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if isinstance(field_type, htypes.Struct):", "prediction_line": "        if isinstance(field_type, htypes.Struct):", "ground_truth": "        if isinstance(field_type, htypes.Struct):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif not isinstance(field_type, (htypes.Int, htypes.UInt)):", "prediction_line": "        elif not isinstance(field_type, (htypes.Int, htypes.UInt)):", "ground_truth": "        elif not isinstance(field_type, (htypes.Int, htypes.UInt)):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise APIError(\"Unsupported type for RightShiftOp: {}\".format(typ))", "prediction_line": "            raise APIError(\"Unsupported type for RightShiftOp: {}\".format(typ))", "ground_truth": "            raise APIError(\"Unsupported type for RightShiftOp: {}\".format(typ))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise APIError(\"Bit reverse operation only supports integer type\")", "prediction_line": "            raise APIError(\"Bit reverse operation only supports integer type\")", "ground_truth": "            raise APIError(\"Bit reverse operation only supports integer type\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        else:\n            mlir_type = hcl_dtype_to_mlir(res_type)", "prediction_line": "        else:", "ground_truth": "            if isinstance(res_type, (htypes.UInt, htypes.Struct)):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # build set bit op", "prediction_line": "        # build set bit op", "ground_truth": "        expr_dtype = hcl_dtype_to_mlir(expr_dtype, signless=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self._context = _ast.context", "prediction_line": "        self._context = _ast.context", "ground_truth": "        self.module = Module.create(get_location())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif isinstance(src_type, htypes.UInt) and isinstance(res_type, htypes.Float):", "prediction_line": "        elif isinstance(src_type, htypes.UInt) and isinstance(res_type, htypes.Float):", "ground_truth": "        elif isinstance(src_type, htypes.UInt) and isinstance(res_type, htypes.Float):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # build loop", "prediction_line": "        # build loop", "ground_truth": "        with get_context(), loc:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if isinstance(op.dtype, (htypes.UInt, htypes.UFixed)):", "prediction_line": "        if isinstance(op.dtype, (htypes.UInt, htypes.UFixed)):", "ground_truth": "        if isinstance(op.dtype, (htypes.UInt, htypes.UFixed)):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if not isinstance(expr_dtype, (htypes.Int, htypes.UInt)):", "prediction_line": "        if not isinstance(expr_dtype, (htypes.Int, htypes.UInt)):", "ground_truth": "        if not isinstance(expr_dtype, (htypes.Int, htypes.UInt)):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        raise APIError(\"Unsupported op: {}\".format(op))", "prediction_line": "        raise APIError(\"Unsupported op: {}\".format(op))", "ground_truth": "        raise APIError(\"Unsupported op in get_op_class: {}\".format(op))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if isinstance(field, htypes.Struct):", "prediction_line": "        if isinstance(field, htypes.Struct):", "ground_truth": "        if isinstance(field, htypes.Struct):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                input_types.append(memref_d.MemRefType.get(", "prediction_line": "                input_types.append(memref_d.MemRefType.get(", "ground_truth": "                input_typehints.append(get_extra_type_hints(arg.dtype))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.build_visitor(op.shape, ip)", "prediction_line": "        self.build_visitor(op.shape, ip)", "ground_truth": "        eletype = hcl_dtype_to_mlir(op.tensor.dtype)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # check if expr is int type", "prediction_line": "        # check if expr is int type", "ground_truth": "        # check if expr is int type", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # for the list of supported comparison operators", "prediction_line": "        # for the list of supported comparison operators", "ground_truth": "        # s/u: signed/unsigned", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # as it is a void op", "prediction_line": "        # as it is a void op", "ground_truth": "        # because store op doesn't have a result", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # build reduction body", "prediction_line": "        # build reduction body", "ground_truth": "        # store the init value to the scalar", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            Lower bound of the loop.", "prediction_line": "            Lower bound of the loop.", "ground_truth": "            Lower bound of the loop.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                \"Casting from struct to integer is not supported yet\"", "prediction_line": "                \"Casting from struct to integer is not supported yet\"", "ground_truth": "                \"Struct -> Int Cast is not implemented yet. \"", "line_class": "random", "zero_context": true}
{"original_prediction": "            attr = ATTR_MAP[\"fixed\"][", "prediction_line": "            attr = ATTR_MAP[\"fixed\"][", "ground_truth": "            attr = ATTR_MAP[\"fixed\"][", "line_class": "random", "zero_context": true}
{"original_prediction": "            expr_dtype, op.expr.result, end.result, start.result, op.value.result, ip=ip, loc=loc", "prediction_line": "            expr_dtype, op.expr.result, end.result, start.result, op.value.result, ip=ip, loc=loc", "ground_truth": "            expr_dtype,", "line_class": "random", "zero_context": true}
{"original_prediction": "        if isinstance(res_type, htypes.UInt):", "prediction_line": "        if isinstance(res_type, htypes.UInt):", "ground_truth": "        src_type = self.tinf_engine.infer(op.expr)", "line_class": "random", "zero_context": true}
{"original_prediction": "                op.tensor.result, affine_attr, [], ip=ip, loc=loc", "prediction_line": "                op.tensor.result, affine_attr, [], ip=ip, loc=loc", "ground_truth": "                op.tensor.result, self.iv, affine_attr, ip=ip, loc=loc", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(\"split\", loc)", "prediction_line": "        super().__init__(\"split\", loc)", "ground_truth": "        super().__init__(\"split\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"&\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"&\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"&\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"|\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"|\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"|\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"^\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"^\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"^\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"tile\", loc)", "prediction_line": "        super().__init__(\"tile\", loc)", "ground_truth": "        super().__init__(\"tile\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"~\", expr, loc)", "prediction_line": "        super().__init__(\"~\", expr, loc)", "ground_truth": "        super().__init__(\"~\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"if\", loc)", "prediction_line": "        super().__init__(\"if\", loc)", "ground_truth": "        super().__init__(\"if\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"-\", expr, loc)", "prediction_line": "        super().__init__(\"-\", expr, loc)", "ground_truth": "        super().__init__(\"neg\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"bitreverse\", expr, loc)", "prediction_line": "        super().__init__(\"bitreverse\", expr, loc)", "ground_truth": "        super().__init__(\"bit_reverse\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"bit_cast\", expr, loc)", "prediction_line": "        super().__init__(\"bit_cast\", expr, loc)", "ground_truth": "        super().__init__(\"bit_cast\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"pipeline\", loc)", "prediction_line": "        super().__init__(\"pipeline\", loc)", "ground_truth": "        super().__init__(\"pipeline\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"else\", loc)", "prediction_line": "        super().__init__(\"else\", loc)", "ground_truth": "        super().__init__(\"else\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"exp\", expr, loc)", "prediction_line": "        super().__init__(\"exp\", expr, loc)", "ground_truth": "        super().__init__(\"exp\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"pow\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"pow\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"pow\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"unroll\", loc)", "prediction_line": "        super().__init__(\"unroll\", loc)", "ground_truth": "        super().__init__(\"unroll\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"else_if\", loc)", "prediction_line": "        super().__init__(\"else_if\", loc)", "ground_truth": "        super().__init__(\"elseif\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"log\", expr, loc)", "prediction_line": "        super().__init__(\"log\", expr, loc)", "ground_truth": "        super().__init__(\"log\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"log2\", expr, loc)", "prediction_line": "        super().__init__(\"log2\", expr, loc)", "ground_truth": "        super().__init__(\"log2\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"parallel\", loc)", "prediction_line": "        super().__init__(\"parallel\", loc)", "ground_truth": "        super().__init__(\"parallel\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"log10\", expr, loc)", "prediction_line": "        super().__init__(\"log10\", expr, loc)", "ground_truth": "        super().__init__(\"log10\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(name, loc)", "prediction_line": "        super().__init__(name, loc)", "ground_truth": "        super().__init__(name, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"fuse\", loc)", "prediction_line": "        super().__init__(\"fuse\", loc)", "ground_truth": "        super().__init__(\"fuse\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"sqrt\", expr, loc)", "prediction_line": "        super().__init__(\"sqrt\", expr, loc)", "ground_truth": "        super().__init__(\"sqrt\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(name, parent_loop, loc)", "prediction_line": "        super().__init__(name, parent_loop, loc)", "ground_truth": "        super().__init__(name, parent_loop, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"sin\", expr, loc)", "prediction_line": "        super().__init__(\"sin\", expr, loc)", "ground_truth": "        super().__init__(\"sin\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"compute_at\", loc)", "prediction_line": "        super().__init__(\"compute_at\", loc)", "ground_truth": "        super().__init__(\"compute_at\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"cos\", expr, loc)", "prediction_line": "        super().__init__(\"cos\", expr, loc)", "ground_truth": "        super().__init__(\"cos\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"return\", loc)", "prediction_line": "        super().__init__(\"return\", loc)", "ground_truth": "        super().__init__(\"return\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"tanh\", expr, loc)", "prediction_line": "        super().__init__(\"tanh\", expr, loc)", "ground_truth": "        super().__init__(\"tanh\", expr, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"systolic\", loc)", "prediction_line": "        super().__init__(\"systolic\", loc)", "ground_truth": "        super().__init__(\"systolic\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"&&\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"&&\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"&&\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "class Operation(object):", "prediction_line": "class Operation(object):", "ground_truth": "scope.reset()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(tag, loc)", "prediction_line": "        super().__init__(tag, loc)", "ground_truth": "        super().__init__(\"for\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"||\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"||\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"||\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"^^\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"^^\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"^^\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"while\", loc)", "prediction_line": "        super().__init__(\"while\", loc)", "ground_truth": "        super().__init__(\"while\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"func\", loc)", "prediction_line": "        super().__init__(\"func\", loc)", "ground_truth": "        super().__init__(\"func\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(str(value), loc)", "prediction_line": "        super().__init__(str(value), loc)", "ground_truth": "        super().__init__(str(value), loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(tensor.name, loc)", "prediction_line": "        super().__init__(tensor.name, loc)", "ground_truth": "        super().__init__(\"getitem\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"select\", loc)", "prediction_line": "        super().__init__(\"select\", loc)", "ground_truth": "        super().__init__(\"select\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"store\", loc)", "prediction_line": "        super().__init__(\"store\", loc)", "ground_truth": "        super().__init__(\"setitem\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"struct_construct\", loc)", "prediction_line": "        super().__init__(\"struct_construct\", loc)", "ground_truth": "        super().__init__(\"struct\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"getbit\", loc)", "prediction_line": "        super().__init__(\"getbit\", loc)", "ground_truth": "        super().__init__(\"getbit\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"struct_get\", loc)", "prediction_line": "        super().__init__(\"struct_get\", loc)", "ground_truth": "        super().__init__(\"struct_get\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"setbit\", loc)", "prediction_line": "        super().__init__(\"setbit\", loc)", "ground_truth": "        super().__init__(\"setbit\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(name, loc)", "prediction_line": "        super().__init__(name, loc)", "ground_truth": "        super().__init__(\"reduce\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"getslice\", loc)", "prediction_line": "        super().__init__(\"getslice\", loc)", "ground_truth": "        super().__init__(\"getslice\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(name, expr, \"sum\", axis, dtype, 0, loc)", "prediction_line": "        super().__init__(name, expr, \"sum\", axis, dtype, 0, loc)", "ground_truth": "        super().__init__(name, expr, \"sum\", axis, dtype, 0, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(name, expr, \"min\", axis, dtype, 0x3F3F3F3F, loc)", "prediction_line": "        super().__init__(name, expr, \"min\", axis, dtype, 0x3F3F3F3F, loc)", "ground_truth": "        super().__init__(name, expr, \"min\", axis, dtype, 0x3F3F3F3F, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            region = scope.get()", "prediction_line": "            region = scope.get()", "ground_truth": "            region = scope.get()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        # TODO(Niansong): why init is 0xC0C0C0C0?", "prediction_line": "        # TODO(Niansong): why init is 0xC0C0C0C0?", "ground_truth": "        super().__init__(name, expr, \"max\", axis, dtype, 0x3F3F3F3F, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"setslice\", loc)", "prediction_line": "        super().__init__(\"setslice\", loc)", "ground_truth": "        super().__init__(\"setslice\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(name, loc)", "prediction_line": "        super().__init__(name, loc)", "ground_truth": "        super().__init__(\"op_handle\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"loop_handle\", loc)", "prediction_line": "        super().__init__(\"loop_handle\", loc)", "ground_truth": "        super().__init__(\"loop_handle\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"partition\", loc)", "prediction_line": "        super().__init__(\"partition\", loc)", "ground_truth": "        super().__init__(\"partition\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(UnaryOp, self).__init__(op, loc)", "prediction_line": "        super(UnaryOp, self).__init__(op, loc)", "ground_truth": "        super().__init__(op, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"replace\", loc)", "prediction_line": "        super().__init__(\"replace\", loc)", "ground_truth": "        super().__init__(\"replace\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"reshape\", loc)", "prediction_line": "        super().__init__(\"reshape\", loc)", "ground_truth": "        super().__init__(\"reshape\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"reform\", loc)", "prediction_line": "        super().__init__(\"reform\", loc)", "ground_truth": "        super().__init__(\"reform\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"reuse_at\", loc)", "prediction_line": "        super().__init__(\"reuse_at\", loc)", "ground_truth": "        super().__init__(\"reuse_at\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"cast\", loc)", "prediction_line": "        super().__init__(\"cast\", loc)", "ground_truth": "        super().__init__(dtype_to_str(dtype), loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"buffer_at\", loc)", "prediction_line": "        super().__init__(\"buffer_at\", loc)", "ground_truth": "        super().__init__(\"buffer_at\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"+\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"+\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"+\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"-\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"-\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"-\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"inter_kernel_to\", loc)", "prediction_line": "        super().__init__(\"inter_kernel_to\", loc)", "ground_truth": "        super().__init__(\"inter_kernel_to\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"*\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"*\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"*\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"/\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"/\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"/\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"outline\", loc)", "prediction_line": "        super().__init__(\"outline\", loc)", "ground_truth": "        super().__init__(\"outline\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"floordiv\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"floordiv\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"//\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"%\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"%\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"%\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"<<\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\"<<\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\"<<\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\"reorder\", loc)", "prediction_line": "        super().__init__(\"reorder\", loc)", "ground_truth": "        super().__init__(\"reorder\", loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(\">>\", lhs, rhs, loc)", "prediction_line": "        super().__init__(\">>\", lhs, rhs, loc)", "ground_truth": "        super().__init__(\">>\", lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(op, lhs, rhs, loc)", "prediction_line": "        super().__init__(op, lhs, rhs, loc)", "ground_truth": "        super().__init__(op, lhs, rhs, loc)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return f\"{self.expr}[{self.index}]\"", "prediction_line": "        return f\"{self.expr}[{self.index}]\"", "ground_truth": "        return f\"{self.expr}[{self.index}]\"", "line_class": "common", "zero_context": true}
{"original_prediction": "            start = indices.start", "prediction_line": "            start = indices.start", "ground_truth": "            lo, hi = indices.start, indices.stop", "line_class": "common", "zero_context": true}
{"original_prediction": "        code_str += f\"{self.expr}[{self.index}] = {self.value}\"", "prediction_line": "        code_str += f\"{self.expr}[{self.index}] = {self.value}\"", "ground_truth": "        code_str += f\"{self.expr}[{self.index}] = {self.value}\"", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.dtype = expr.dtype", "prediction_line": "        self.dtype = expr.dtype", "ground_truth": "        bitwidth = self.end - self.start + 1", "line_class": "common", "zero_context": true}
{"original_prediction": "            return GetBitOp(self, indices[0], self.loc)", "prediction_line": "            return GetBitOp(self, indices[0], self.loc)", "ground_truth": "            index = indices[0]", "line_class": "common", "zero_context": true}
{"original_prediction": "        return f\"{self.expr}[{self.start}:{self.end}]\"", "prediction_line": "        return f\"{self.expr}[{self.start}:{self.end}]\"", "ground_truth": "        return f\"{self.expr}[{self.start}:{self.end}]\"", "line_class": "common", "zero_context": true}
{"original_prediction": "            for index in indices:", "prediction_line": "            for index in indices:", "ground_truth": "            for index in indices:", "line_class": "common", "zero_context": true}
{"original_prediction": "        code_str += f\"{self.expr}[{self.start}:{self.end}] = {self.value}\"", "prediction_line": "        code_str += f\"{self.expr}[{self.start}:{self.end}] = {self.value}\"", "ground_truth": "        code_str += f\"{self.expr}[{self.start}:{self.end}] = {self.value}\"", "line_class": "common", "zero_context": true}
{"original_prediction": "                new_indices.append(index)", "prediction_line": "                new_indices.append(index)", "ground_truth": "                new_indices.append(index)", "line_class": "common", "zero_context": true}
{"original_prediction": "            return load\n        else:", "prediction_line": "            return load", "ground_truth": "            return load", "line_class": "common", "zero_context": true}
{"original_prediction": "            if isinstance(index, IterVar):", "prediction_line": "            if isinstance(index, IterVar):", "ground_truth": "            if isinstance(index, int):", "line_class": "common", "zero_context": true}
{"original_prediction": "            else:\n                shape.append(index)", "prediction_line": "            else:", "ground_truth": "            elif isinstance(index, slice):", "line_class": "common", "zero_context": true}
{"original_prediction": "        return tensor.fcompute(expr.indices)", "prediction_line": "        return tensor.fcompute(expr.indices)", "ground_truth": "        index = expr.index", "line_class": "common", "zero_context": true}
{"original_prediction": "                dims += 1", "prediction_line": "                dims += 1", "ground_truth": "                step = index.step if index.step is not None else 1", "line_class": "common", "zero_context": true}
{"original_prediction": "                if step < 0:", "prediction_line": "                if step < 0:", "ground_truth": "                dim_size = (index.stop - index.start) / step", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.index = index", "prediction_line": "        self.index = index", "ground_truth": "        self.index = index", "line_class": "common", "zero_context": true}
{"original_prediction": "        return f\"{self.tensor}[{self.index}]\"", "prediction_line": "        return f\"{self.tensor}[{self.index}]\"", "ground_truth": "        return f\"{self.tensor.name}{self.index}\"", "line_class": "common", "zero_context": true}
{"original_prediction": "            return LoadOp(self.tensor, self.indices, key, self.loc)", "prediction_line": "            return LoadOp(self.tensor, self.indices, key, self.loc)", "ground_truth": "            key_idx = key_list.index(key)", "line_class": "common", "zero_context": true}
{"original_prediction": "            for index in self.indices + indices:", "prediction_line": "            for index in self.indices + indices:", "ground_truth": "            for index in self.indices + indices:", "line_class": "common", "zero_context": true}
{"original_prediction": "        code_str += f\"{self.tensor.name}{self.index} = {self.value}\"", "prediction_line": "        code_str += f\"{self.tensor.name}{self.index} = {self.value}\"", "ground_truth": "        code_str += f\"{self.tensor.name}{self.index} = {self.value}\"", "line_class": "common", "zero_context": true}
{"original_prediction": "            for index in self.indices + indices:", "prediction_line": "            for index in self.indices + indices:", "ground_truth": "            for index in list(self.indices) + list(indices):", "line_class": "common", "zero_context": true}
{"original_prediction": "        return RightShiftOp(self, other, self.loc)", "prediction_line": "        return RightShiftOp(self, other, self.loc)", "ground_truth": "        return RightShiftOp(self, other, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "stage_hdl]", "prediction_line": "stage_hdl]", "ground_truth": "            LoopHandle(stage_hdl, parent.name + \".outer\", loc),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    elif isinstance(expr, Mod):", "prediction_line": "    elif isinstance(expr, Mod):", "ground_truth": "    elif isinstance(expr, Mod):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if isinstance(expr, sp.Symbol):", "prediction_line": "    if isinstance(expr, sp.Symbol):", "ground_truth": "    if isinstance(expr, ConstantOp):", "line_class": "infile", "zero_context": true}
{"original_prediction": "class Operation(object):", "prediction_line": "class Operation(object):", "ground_truth": "scope = Scope()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return sp.simplify(simplify(expr.lhs) * simplify(expr.rhs))", "prediction_line": "        return sp.simplify(simplify(expr.lhs) * simplify(expr.rhs))", "ground_truth": "        return sp.simplify(simplify(expr.lhs) * simplify(expr.rhs))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return Xor(self, other, self.loc)", "prediction_line": "        return Xor(self, other, self.loc)", "ground_truth": "        return XOr(self, other, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if isinstance(v, Tensor):", "prediction_line": "                if isinstance(v, Tensor):", "ground_truth": "                replace_all_uses_with(v, old_tensor, new_tensor)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        code_str += \"hcl.fuse({})\".format(\", \".join([v.name for v in self.arg_list]))", "prediction_line": "        code_str += \"hcl.fuse({})\".format(\", \".join([v.name for v in self.arg_list]))", "ground_truth": "        code_str += \"hcl.fuse({})\".format(\", \".join([str(v) for v in self.arg_list]))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def __repr__(self):", "prediction_line": "    def __repr__(self):", "ground_truth": "        self.tensor = AllocOp(name, shape, dtype, loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return Add(other, self, self.loc)", "prediction_line": "        return Add(other, self, self.loc)", "ground_truth": "        return Add(other, self, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return Sub(other, self, self.loc)", "prediction_line": "        return Sub(other, self, self.loc)", "ground_truth": "        return Sub(other, self, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return Or(self, other, self.loc)", "prediction_line": "        return Or(self, other, self.loc)", "ground_truth": "        return Or(self, other, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if not isinstance(index, int):", "prediction_line": "            if not isinstance(index, int):", "ground_truth": "            return GetBitOp(self, index, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.expr = expr", "prediction_line": "        self.expr = expr", "ground_truth": "        self.expr = immediate_to_constant(expr, loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.value = immediate_to_constant(value, loc, UInt(1))", "prediction_line": "        self.value = immediate_to_constant(value, loc, UInt(1))", "ground_truth": "        self.value = immediate_to_constant(value, loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if isinstance(expr, Sub):", "prediction_line": "    if isinstance(expr, Sub):", "ground_truth": "    elif isinstance(expr, Sub):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        lhs = immediate_to_constant(lhs, loc)", "prediction_line": "        lhs = immediate_to_constant(lhs, loc)", "ground_truth": "        lhs = immediate_to_constant(lhs, loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            store = StoreOp(self.parent, new_indices, expr, self.loc)", "prediction_line": "            store = StoreOp(self.parent, new_indices, expr, self.loc)", "ground_truth": "            store_op = StoreOp(self.parent, new_indices, expr, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            LoopHandle(stage_hdl, x_parent.name + \".inner\", loc),", "prediction_line": "            LoopHandle(stage_hdl, x_parent.name + \".inner\", loc),", "ground_truth": "            LoopHandle(stage_hdl, x_parent.name + \".inner\", loc),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return Div(other, self, self.loc)", "prediction_line": "        return Div(other, self, self.loc)", "ground_truth": "        return Div(other, self, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return Cmp(\"gt\", self, other, self.loc)", "prediction_line": "        return Cmp(\"gt\", self, other, self.loc)", "ground_truth": "        return Cmp(\"gt\", self, other, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        cond = immediate_to_constant(cond, loc)", "prediction_line": "        cond = immediate_to_constant(cond, loc)", "ground_truth": "        cond = immediate_to_constant(cond, loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.name, \", \".join([str(v.name) for v in self.args])", "prediction_line": "            self.name, \", \".join([str(v.name) for v in self.args])", "ground_truth": "            self.name, \", \".join([str(v.name) for v in self.args])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            store_op = StoreOp(self, new_indices, expr, self.loc)", "prediction_line": "            store_op = StoreOp(self, new_indices, expr, self.loc)", "ground_truth": "            store_op = StoreOp(self, new_indices, expr, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return GetFieldOp(self, key, self.loc)", "prediction_line": "        return GetFieldOp(self, key, self.loc)", "ground_truth": "        elif isinstance(self, LoadOp):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            replace_all_uses_with(value, old_tensor, new_tensor)", "prediction_line": "            replace_all_uses_with(value, old_tensor, new_tensor)", "ground_truth": "            replace_all_uses_with(value, old_tensor, new_tensor)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.level = len(scope)", "prediction_line": "        self.level = len(scope)", "ground_truth": "        self.iter_var = IterVar(name, self, loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        return SetBitOp(self, expr, lo, self.loc)", "prediction_line": "                        return SetBitOp(self, expr, lo, self.loc)", "ground_truth": "                        store_op = StoreOp(expr, self.tensor, self.indices, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if isinstance(expr, sp.Symbol):", "prediction_line": "    if isinstance(expr, sp.Symbol):", "ground_truth": "    if isinstance(expr, IterVar):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if isinstance(index, list):", "prediction_line": "        if isinstance(index, list):", "ground_truth": "        return sp.simplify(simplify(tensor.fcompute(*index)))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    return BitSlice(self, lo, hi, self.loc)", "prediction_line": "                    return BitSlice(self, lo, hi, self.loc)", "ground_truth": "                    return GetSliceOp(self, lo, hi - 1, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for i, v in enumerate(value):", "prediction_line": "            for i, v in enumerate(value):", "ground_truth": "            for v in value:", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if isinstance(expr, Tensor):", "prediction_line": "    if isinstance(expr, Tensor):", "ground_truth": "    if isinstance(expr, Add):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                index = immediate_to_constant(index, self.loc)", "prediction_line": "                index = immediate_to_constant(index, self.loc)", "ground_truth": "                index = immediate_to_constant(index, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            code_str += \"{} = \".format(\", \".join([v.name for v in self.rets]))", "prediction_line": "            code_str += \"{} = \".format(\", \".join([v.name for v in self.rets]))", "ground_truth": "            code_str += \"{} = \".format(\", \".join([str(v.name) for v in self.rets]))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            LoopHandle(stage_hdl, y_parent.name + \".outer\", loc),", "prediction_line": "            LoopHandle(stage_hdl, y_parent.name + \".outer\", loc),", "ground_truth": "            LoopHandle(stage_hdl, y_parent.name + \".outer\", loc),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            load = LoadOp(self, new_indices, self.loc)", "prediction_line": "            load = LoadOp(self, new_indices, self.loc)", "ground_truth": "            load = LoadOp(self, new_indices, self.loc)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        code_str += \"hcl.reuse_at({}, {})\".format(self.target.name, self.axis)", "prediction_line": "        code_str += \"hcl.reuse_at({}, {})\".format(self.target.name, self.axis)", "ground_truth": "        code_str += \"hcl.reuse_at({}, {})\".format(self.target.name, self.axis)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.stage.name, self.parent.name, self.axis", "prediction_line": "            self.stage.name, self.parent.name, self.axis", "ground_truth": "            self.stage.name, self.parent.name, self.axis", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return ConstantOp(value, Float(64), loc)", "prediction_line": "        return ConstantOp(value, Float(64), loc)", "ground_truth": "        return ConstantOp(value, Float(64), loc)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return ConstantOp(value, Int32, loc)", "prediction_line": "            return ConstantOp(value, Int32, loc)", "ground_truth": "            return ConstantOp(value, Int(32), loc)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.dtype = self.tinf_engine.infer(self)", "prediction_line": "        self.dtype = self.tinf_engine.infer(self)", "ground_truth": "        self.dtype = UInt(1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        code_str += \"hcl.buffer_at({}, {})\".format(self.target.name, self.axis)", "prediction_line": "        code_str += \"hcl.buffer_at({}, {})\".format(self.target.name, self.axis)", "ground_truth": "        code_str += \"hcl.buffer_at({}, {})\".format(self.target.name, self.axis)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.init = init", "prediction_line": "        self.init = init", "ground_truth": "        self.init = init", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return ConstantOp(value, Int(64), loc)", "prediction_line": "            return ConstantOp(value, Int(64), loc)", "ground_truth": "            return ConstantOp(value, Int(64), loc)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise TensorError(\".v can only be used on scalars\")", "prediction_line": "            raise TensorError(\".v can only be used on scalars\")", "ground_truth": "            raise TensorError(\".v can only be used on scalars\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        raise NotImplementedError(", "prediction_line": "        raise NotImplementedError(", "ground_truth": "        raise HCLError(\"Unsupported expression type: {}\".format(type(expr)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise TensorError(\"Indices length > # of array dimensions\")", "prediction_line": "            raise TensorError(\"Indices length > # of array dimensions\")", "ground_truth": "            raise TensorError(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.dtype = UInt(bitwidth.value)", "prediction_line": "            self.dtype = UInt(bitwidth.value)", "ground_truth": "            self.dtype = UInt(int(bitwidth))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "of the tensor\n        self.axes = list()", "prediction_line": "of the tensor", "ground_truth": "        self.axis = list()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.reduce_op = reduce_op", "prediction_line": "        self.reduce_op = reduce_op", "ground_truth": "        self.scalar = AllocOp(name, (1,), dtype, loc)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.value = immediate_to_constant(value, loc)", "prediction_line": "        self.value = immediate_to_constant(value, loc)", "ground_truth": "        self.value = immediate_to_constant(value, loc, UInt(1))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def __init__(self, expr, dtype, loc):", "prediction_line": "    def __init__(self, expr, dtype, loc):", "ground_truth": "    def __init__(self, expr, dtype, loc):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        code_str = print_indent(code_str, self.level)", "prediction_line": "        code_str = print_indent(code_str, self.level)", "ground_truth": "        code_str = print_indent(code_str, self.level)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        super().__init__(\"print\", loc)", "prediction_line": "        super().__init__(\"print\", loc)", "ground_truth": "        super().__init__(\"print\", loc)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __init__(self, lhs, rhs, loc):", "prediction_line": "    def __init__(self, lhs, rhs, loc):", "ground_truth": "    def __init__(self, lhs, rhs, loc):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __repr__(self):", "prediction_line": "    def __repr__(self):", "ground_truth": "    def __setitem__(self, indices, expr):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self.fcompute = None", "prediction_line": "        self.fcompute = None", "ground_truth": "        self.fcompute = None", "line_class": "random", "zero_context": true}
{"original_prediction": "        code_str = \"\"", "prediction_line": "        code_str = \"\"", "ground_truth": "        code_str = \"\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        # instead of one load operation with two uses", "prediction_line": "        # instead of one load operation with two uses", "ground_truth": "        self.reusable = False", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.expr = expr", "prediction_line": "        self.expr = expr", "ground_truth": "        self.expr = expr", "line_class": "random", "zero_context": true}
{"original_prediction": "            if isinstance(lo, int) and isinstance(hi, int):", "prediction_line": "            if isinstance(lo, int) and isinstance(hi, int):", "ground_truth": "            if isinstance(lo, int) and isinstance(hi, int):", "line_class": "random", "zero_context": true}
{"original_prediction": "       return hcl.compute(", "prediction_line": "       return hcl.compute(", "ground_truth": "        return hcl.compute((height, width), lambda x, y: R[x][y] * norm.v, \"F\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "    f = hcl.build(s, target=target)", "prediction_line": "    f = hcl.build(s, target=target)", "ground_truth": "    f = hcl.build(s, target)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                out.v = imgF[x - 1, y - 1, z]", "prediction_line": "                out.v = imgF[x - 1, y - 1, z]", "ground_truth": "                out.v = imgF[x - 1, y - 1, z]", "line_class": "commited", "zero_context": true}
{"original_prediction": "                out.v = 0", "prediction_line": "                out.v = 0", "ground_truth": "                out.v = 0", "line_class": "commited", "zero_context": true}
{"original_prediction": "            return out.v", "prediction_line": "            return out.v", "ground_truth": "            return out.v", "line_class": "commited", "zero_context": true}
{"original_prediction": "        expected = get_expected(alg_name, \"get_max\")", "prediction_line": "        expected = get_expected(alg_name, \"get_max\")", "ground_truth": "        assert res_dict == get_expected(alg_name, \"GetMax\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        lst = refine(res)", "prediction_line": "        lst = refine(res)", "ground_truth": "        lst = refine(res)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert lst == get_expected(alg_name, loop_query[\"name\"])", "prediction_line": "        assert lst == get_expected(alg_name, loop_query[\"name\"])", "ground_truth": "        assert lst == get_expected(alg_name, loop_query[\"name\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert lst == get_expected(alg_name, column_query[\"name\"])", "prediction_line": "        assert lst == get_expected(alg_name, column_query[\"name\"])", "ground_truth": "        assert lst == get_expected(alg_name, column_query[\"name\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert lst == get_expected(alg_name, level_query[\"name\"])", "prediction_line": "        assert lst == get_expected(alg_name, level_query[\"name\"])", "ground_truth": "        assert lst == get_expected(alg_name, level_query[\"name\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "   f = hcl.build(s, target=\"vhls\")", "prediction_line": "   f = hcl.build(s, target=\"vhls\")", "ground_truth": "    sA = sobel_kernel.A", "line_class": "infile", "zero_context": true}
{"original_prediction": "    sP = sobel_kernel.P", "prediction_line": "    sP = sobel_kernel.P", "ground_truth": "    sX = sobel_kernel.X", "line_class": "infile", "zero_context": true}
{"original_prediction": "    sY = sobel_kernel.Y", "prediction_line": "    sY = sobel_kernel.Y", "ground_truth": "    sY = sobel_kernel.Y", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert lst == get_expected(alg_name, level_out_of_bound[\"name\"])", "prediction_line": "        assert lst == get_expected(alg_name, level_out_of_bound[\"name\"])", "ground_truth": "        assert lst == get_expected(alg_name, level_out_of_bound[\"name\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_knn_digitrec(0)", "prediction_line": "    test_knn_digitrec(0)", "ground_truth": "    test_knn_digitrec(False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_kmeans(False)", "prediction_line": "    test_kmeans(False)", "ground_truth": "    test_kmeans(False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_sobel(False)", "prediction_line": "    test_sobel(False)", "ground_truth": "    test_sobel(False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_sobel_partial(False)", "prediction_line": "    test_sobel_partial(False)", "ground_truth": "    test_sobel_partial(False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_canny(False)", "prediction_line": "    test_canny(False)", "ground_truth": "    test_canny(False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_spam_filter(False)", "prediction_line": "    test_spam_filter(False)", "ground_truth": "    test_spam_filter(False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return s", "prediction_line": "    return s", "ground_truth": "    sP = sobel_kernel.P", "line_class": "infile", "zero_context": true}
{"original_prediction": "    s.partition(sP, dim=0)", "prediction_line": "    s.partition(sP, dim=0)", "ground_truth": "    sR = sobel_kernel.R", "line_class": "infile", "zero_context": true}
{"original_prediction": "    sF = sobel_kernel.F", "prediction_line": "    sF = sobel_kernel.F", "ground_truth": "    sF = sobel_kernel.F", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert lst == get_expected(alg_name, multi_query[\"name\"])", "prediction_line": "        assert lst == get_expected(alg_name, multi_query[\"name\"])", "ground_truth": "        assert lst == get_expected(alg_name, multi_query[\"name\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert lst == get_expected(alg_name, all_query[\"name\"])", "prediction_line": "        assert lst == get_expected(alg_name, all_query[\"name\"])", "ground_truth": "        assert lst == get_expected(alg_name, all_query[\"name\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_get_max()", "prediction_line": "    test_get_max()", "ground_truth": "    test_get_max()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_col()", "prediction_line": "    test_col()", "ground_truth": "    test_col()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_info()", "prediction_line": "    test_info()", "ground_truth": "    test_info()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_loop_query()", "prediction_line": "    test_loop_query()", "ground_truth": "    test_loop_query()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_column_query()", "prediction_line": "    test_column_query()", "ground_truth": "    test_column_query()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_level_query()", "prediction_line": "    test_level_query()", "ground_truth": "    test_level_query()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_level_oob_query()", "prediction_line": "    test_level_oob_query()", "ground_truth": "    test_level_oob_query()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_multi_query()", "prediction_line": "    test_multi_query()", "ground_truth": "    test_multi_query()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    test_all_query()", "prediction_line": "    test_all_query()", "ground_truth": "    test_all_query()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return res", "prediction_line": "    return res", "ground_truth": "    res[0] = res[0].replace(\", \", \"\", 1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        level_query = config[\"level_query\"]", "prediction_line": "        level_query = config[\"level_query\"]", "ground_truth": "        level_out_of_bound = config[\"level_out_of_bound\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    s.partition(sP, dim=1)", "prediction_line": "    s.partition(sP, dim=1)", "ground_truth": "    s[sX].pipeline(sX.axis[1])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        col_query = config[\"column_query\"]", "prediction_line": "        col_query = config[\"column_query\"]", "ground_truth": "        column_query = config[\"column_query\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    config = {", "prediction_line": "    config = {", "ground_truth": "    config = {", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        res = rpt.display(loops=row_query, cols=col_query, level=lev_query)", "prediction_line": "        res = rpt.display(loops=row_query, cols=col_query, level=lev_query)", "ground_truth": "        res = rpt.display(loops=row_query, level=lev_query, cols=col_query)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return R", "prediction_line": "        return R", "ground_truth": "        norm = hcl.scalar(255 / 4328)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        rpt = get_rpt(config)", "prediction_line": "        rpt = get_rpt(config)", "ground_truth": "        loop_query = config[\"loop_query\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    s.partition(sA, dim=0, factor=16)", "prediction_line": "    s.partition(sA, dim=0, factor=16)", "ground_truth": "    s.partition(LBX, dim=1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        multi_query = config[\"multi_query\"]", "prediction_line": "        multi_query = config[\"multi_query\"]", "ground_truth": "        multi_query = config[\"multi_query\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    _test_rpt(config)", "prediction_line": "    _test_rpt(config)", "ground_truth": "    _test_rpt(config)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        path = str(path) + \"/test_report_data/rose-grayscale.rpt\"", "prediction_line": "        path = str(path) + \"/test_report_data/rose-grayscale.rpt\"", "ground_truth": "        xml_file = str(path) + config[\"algorithm\"][\"report_path\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        c = hcl.reduce_axis(0, 3)", "prediction_line": "        c = hcl.reduce_axis(0, 3)", "ground_truth": "        c = hcl.reduce_axis(0, 3)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   wd = config[\"work_dir\"]", "prediction_line": "   wd = config[\"work_dir\"]", "ground_truth": "    if vhls and config[\"has_algorithm\"]:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        max_latency = rpt.get_max()", "prediction_line": "        max_latency = rpt.get_max()", "ground_truth": "        res = rpt.get_max(config[\"get_max\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_spam_filter(vhls):", "prediction_line": "def test_spam_filter(vhls):", "ground_truth": "def test_spam_filter(vhls):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "import heterocl as hcl", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   expected = get_expected(config[\"version\"], alg_name)", "prediction_line": "   expected = get_expected(config[\"version\"], alg_name)", "ground_truth": "    def test_get_max():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# from . import sobel", "prediction_line": "# from . import sobel", "ground_truth": "def sobel():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        )\n\n        B = hcl.compute(", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"has_algorithm\": True,", "prediction_line": "        \"has_algorithm\": True,", "ground_truth": "        \"has_algorithm\": 1,", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"column_query\": {\"query\": [\"Latency\"], \"name\": \"ColumnQuery\"},", "prediction_line": "        \"column_query\": {\"query\": [\"Latency\"], \"name\": \"ColumnQuery\"},", "ground_truth": "        \"column_query\": {", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"get_max\": \"Latency\",", "prediction_line": "        \"get_max\": \"Latency\",", "ground_truth": "        \"get_max\": \"Latency\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        return vhls[\"report\"]", "prediction_line": "        return vhls[\"report\"]", "ground_truth": "        rpt = eval(alg[\"name\"] + \"()\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        method_name = 'visit_' + op.__class__.__name__", "prediction_line": "        method_name = 'visit_' + op.__class__.__name__", "ground_truth": "        if isinstance(op, ast.AST):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, list):", "prediction_line": "        elif isinstance(op, list):", "ground_truth": "        elif isinstance(op, ast.ComputeOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ForOp):", "prediction_line": "        elif isinstance(op, ast.ForOp):", "ground_truth": "        elif isinstance(op, ast.IterVar):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.Var):", "prediction_line": "        elif isinstance(op, ast.Var):", "ground_truth": "        elif isinstance(op, ast.ReduceOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.Attr):", "prediction_line": "        elif isinstance(op, ast.Attr):", "ground_truth": "        elif isinstance(op, ast.AllocOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.Attr):", "prediction_line": "        elif isinstance(op, ast.Attr):", "ground_truth": "        elif isinstance(op, ast.Cmp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.Call):", "prediction_line": "        elif isinstance(op, ast.Call):", "ground_truth": "        elif isinstance(op, ast.BinaryOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.UnaryOp):", "prediction_line": "        elif isinstance(op, ast.UnaryOp):", "ground_truth": "        elif isinstance(op, ast.MathTanhOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.MathSinhOp):", "prediction_line": "        elif isinstance(op, ast.MathSinhOp):", "ground_truth": "        elif isinstance(op, ast.BitCastOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.SelectOp):", "prediction_line": "        elif isinstance(op, ast.SelectOp):", "ground_truth": "        elif isinstance(op, ast.LoadOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.StoreOp):", "prediction_line": "        elif isinstance(op, ast.StoreOp):", "ground_truth": "        elif isinstance(op, ast.StoreOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.ConstantOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.CastOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.IfOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ForOp):", "prediction_line": "        elif isinstance(op, ast.ForOp):", "ground_truth": "        elif isinstance(op, ast.ForOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.WhileOp):", "prediction_line": "        elif isinstance(op, ast.WhileOp):", "ground_truth": "        elif isinstance(op, ast.WhileOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.SelectOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.PrintOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.PrintTensorOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.GetBitOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.GetItemOp):", "prediction_line": "        elif isinstance(op, ast.GetItemOp):", "ground_truth": "        elif isinstance(op, ast.GetSliceOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.GetItemOp):", "prediction_line": "        elif isinstance(op, ast.GetItemOp):", "ground_truth": "        elif isinstance(op, ast.SetBitOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.SetSliceOp):", "prediction_line": "        elif isinstance(op, ast.SetSliceOp):", "ground_truth": "        elif isinstance(op, ast.SetSliceOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.BitReverseOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.BitConcatOp):", "prediction_line": "        elif isinstance(op, ast.BitConcatOp):", "ground_truth": "        elif isinstance(op, ast.ConstantTensorOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ConstantTensorSliceOp):", "prediction_line": "        elif isinstance(op, ast.ConstantTensorSliceOp):", "ground_truth": "        elif isinstance(op, ast.StructConstructOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.StructExtractOp):", "prediction_line": "        elif isinstance(op, ast.StructExtractOp):", "ground_truth": "        elif isinstance(op, ast.StructGetOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.StructSetOp):", "prediction_line": "        elif isinstance(op, ast.StructSetOp):", "ground_truth": "        elif isinstance(op, ast.FuncOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.CallOp):", "prediction_line": "        elif isinstance(op, ast.CallOp):", "ground_truth": "        elif isinstance(op, ast.CallOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReturnOp):", "prediction_line": "        elif isinstance(op, ast.ReturnOp):", "ground_truth": "        elif isinstance(op, ast.Neg):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.Not):", "prediction_line": "        elif isinstance(op, ast.Not):", "ground_truth": "        elif isinstance(op, ast.OpHandle):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReturnOp):", "prediction_line": "        elif isinstance(op, ast.ReturnOp):", "ground_truth": "        elif isinstance(op, ast.LoopHandle):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.BlockHandle):", "prediction_line": "        elif isinstance(op, ast.BlockHandle):", "ground_truth": "        elif isinstance(op, ast.ReuseAtOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReuseOp):", "prediction_line": "        elif isinstance(op, ast.ReuseOp):", "ground_truth": "        elif isinstance(op, ast.PartitionOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.PartitionedTensor):", "prediction_line": "        elif isinstance(op, ast.PartitionedTensor):", "ground_truth": "        elif isinstance(op, ast.ReplaceOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReturnOp):", "prediction_line": "        elif isinstance(op, ast.ReturnOp):", "ground_truth": "        elif isinstance(op, ast.ReshapeOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.RampOp):", "prediction_line": "        elif isinstance(op, ast.RampOp):", "ground_truth": "        elif isinstance(op, ast.ReformOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.RampOp):", "prediction_line": "        elif isinstance(op, ast.RampOp):", "ground_truth": "        elif isinstance(op, ast.BufferAtOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.BufferLoadOp):", "prediction_line": "        elif isinstance(op, ast.BufferLoadOp):", "ground_truth": "        elif isinstance(op, ast.InterKernelToOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.InterKernelFromOp):", "prediction_line": "        elif isinstance(op, ast.InterKernelFromOp):", "ground_truth": "        elif isinstance(op, ast.OutlineOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.KernelOp):", "prediction_line": "        elif isinstance(op, ast.KernelOp):", "ground_truth": "        elif isinstance(op, ast.ReorderOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ReorderTensorOp):", "prediction_line": "        elif isinstance(op, ast.ReorderTensorOp):", "ground_truth": "        elif isinstance(op, ast.SplitOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ConcatOp):", "prediction_line": "        elif isinstance(op, ast.ConcatOp):", "ground_truth": "        elif isinstance(op, ast.TileOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.FlattenOp):", "prediction_line": "        elif isinstance(op, ast.FlattenOp):", "ground_truth": "        elif isinstance(op, ast.PipelineOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.PipelineStageOp):", "prediction_line": "        elif isinstance(op, ast.PipelineStageOp):", "ground_truth": "        elif isinstance(op, ast.UnrollOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.UnrollParallelOp):", "prediction_line": "        elif isinstance(op, ast.UnrollParallelOp):", "ground_truth": "        elif isinstance(op, ast.ParallelOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.BlockOp):", "prediction_line": "        elif isinstance(op, ast.BlockOp):", "ground_truth": "        elif isinstance(op, ast.FuseOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.BlockOp):", "prediction_line": "        elif isinstance(op, ast.BlockOp):", "ground_truth": "        elif isinstance(op, ast.ComputeAtOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        elif isinstance(op, ast.ComputeInOp):", "prediction_line": "        elif isinstance(op, ast.ComputeInOp):", "ground_truth": "        elif isinstance(op, ast.SystolicOp):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self.visit_partition(op, *args, **kwargs)", "prediction_line": "            self.visit_partition(op, *args, **kwargs)", "ground_truth": "            self.visit_partition(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_itervar(op, *args, **kwargs)", "prediction_line": "            self.visit_itervar(op, *args, **kwargs)", "ground_truth": "            self.visit_iter_var(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_unroll(op, *args, **kwargs)", "prediction_line": "            self.visit_unroll(op, *args, **kwargs)", "ground_truth": "            self.visit_unroll(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_store(op, *args, **kwargs)", "prediction_line": "            self.visit_store(op, *args, **kwargs)", "ground_truth": "            self.visit_store(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_get_slice(op, *args, **kwargs)", "prediction_line": "            self.visit_get_slice(op, *args, **kwargs)", "ground_truth": "            self.visit_get_slice(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_reform(op, *args, **kwargs)", "prediction_line": "            self.visit_reform(op, *args, **kwargs)", "ground_truth": "            self.visit_reform(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_split(op, *args, **kwargs)", "prediction_line": "            self.visit_split(op, *args, **kwargs)", "ground_truth": "            self.visit_split(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_for(op, *args, **kwargs)", "prediction_line": "            self.visit_for(op, *args, **kwargs)", "ground_truth": "            self.visit_for(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_systolic(op, *args, **kwargs)", "prediction_line": "            self.visit_systolic(op, *args, **kwargs)", "ground_truth": "            self.visit_systolic(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_inter_kernel_to(op, *args, **kwargs)", "prediction_line": "            self.visit_inter_kernel_to(op, *args, **kwargs)", "ground_truth": "            self.visit_inter_kernel_to(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_reuse_at(op, *args, **kwargs)", "prediction_line": "            self.visit_reuse_at(op, *args, **kwargs)", "ground_truth": "            self.visit_reuse_at(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_get_bit(op, *args, **kwargs)", "prediction_line": "            self.visit_get_bit(op, *args, **kwargs)", "ground_truth": "            self.visit_get_bit(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_loop_handle(op, *args, **kwargs)", "prediction_line": "            self.visit_loop_handle(op, *args, **kwargs)", "ground_truth": "            self.visit_loop_handle(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_if(op, *args, **kwargs)", "prediction_line": "            self.visit_if(op, *args, **kwargs)", "ground_truth": "            self.visit_if(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_math_tanh(op, *args, **kwargs)", "prediction_line": "            self.visit_math_tanh(op, *args, **kwargs)", "ground_truth": "            self.visit_math_tanh(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            method_name = 'visit_' + type(op).__name__", "prediction_line": "            method_name = 'visit_' + type(op).__name__", "ground_truth": "            self.visit_ast(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_func(op, *args, **kwargs)", "prediction_line": "            self.visit_func(op, *args, **kwargs)", "ground_truth": "            self.visit_func(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_bit_reverse(op, *args, **kwargs)", "prediction_line": "            self.visit_bit_reverse(op, *args, **kwargs)", "ground_truth": "            self.visit_bit_reverse(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_while(op, *args, **kwargs)", "prediction_line": "            self.visit_while(op, *args, **kwargs)", "ground_truth": "            self.visit_while(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_constant(op, *args, **kwargs)", "prediction_line": "            self.visit_constant(op, *args, **kwargs)", "ground_truth": "            self.visit_constant(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_set_bit(op, *args, **kwargs)", "prediction_line": "            self.visit_set_bit(op, *args, **kwargs)", "ground_truth": "            self.visit_set_bit(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_parallel(op, *args, **kwargs)", "prediction_line": "            self.visit_parallel(op, *args, **kwargs)", "ground_truth": "            self.visit_parallel(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_struct_get(op, *args, **kwargs)", "prediction_line": "            self.visit_struct_get(op, *args, **kwargs)", "ground_truth": "            self.visit_struct_get(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_compute_at(op, *args, **kwargs)", "prediction_line": "            self.visit_compute_at(op, *args, **kwargs)", "ground_truth": "            self.visit_compute_at(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_set_slice(op, *args, **kwargs)", "prediction_line": "            self.visit_set_slice(op, *args, **kwargs)", "ground_truth": "            self.visit_set_slice(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_binary_op(op, *args, **kwargs)", "prediction_line": "            self.visit_binary_op(op, *args, **kwargs)", "ground_truth": "            self.visit_binary(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_alloc(op, *args, **kwargs)", "prediction_line": "            self.visit_alloc(op, *args, **kwargs)", "ground_truth": "            self.visit_alloc(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_reorder(op, *args, **kwargs)", "prediction_line": "            self.visit_reorder(op, *args, **kwargs)", "ground_truth": "            self.visit_reorder(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_tile(op, *args, **kwargs)", "prediction_line": "            self.visit_tile(op, *args, **kwargs)", "ground_truth": "            self.visit_tile(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_load(op, *args, **kwargs)", "prediction_line": "            self.visit_load(op, *args, **kwargs)", "ground_truth": "            self.visit_load(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_neg(op, *args, **kwargs)", "prediction_line": "            self.visit_neg(op, *args, **kwargs)", "ground_truth": "            self.visit_neg(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_constant_tensor(op, *args, **kwargs)", "prediction_line": "            self.visit_constant_tensor(op, *args, **kwargs)", "ground_truth": "            self.visit_constant_tensor(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_select(op, *args, **kwargs)", "prediction_line": "            self.visit_select(op, *args, **kwargs)", "ground_truth": "            self.visit_select(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_cmp(op, *args, **kwargs)", "prediction_line": "            self.visit_cmp(op, *args, **kwargs)", "ground_truth": "            self.visit_cmp(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_call(op, *args, **kwargs)", "prediction_line": "            self.visit_call(op, *args, **kwargs)", "ground_truth": "            self.visit_call(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_replace(op, *args, **kwargs)", "prediction_line": "            self.visit_replace(op, *args, **kwargs)", "ground_truth": "            self.visit_replace(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_fuse(op, *args, **kwargs)", "prediction_line": "            self.visit_fuse(op, *args, **kwargs)", "ground_truth": "            self.visit_fuse(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.visit_outline(op, *args, **kwargs)", "prediction_line": "            self.visit_outline(op, *args, **kwargs)", "ground_truth": "            self.visit_outline(op, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def visit_bitcast(self, op, *args, **kwargs):", "prediction_line": "    def visit_bitcast(self, op, *args, **kwargs):", "ground_truth": "    def visit_bitcast(self, op, *args, **kwargs):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def visit_print_tensor(self, op, *args, **kwargs):", "prediction_line": "    def visit_print_tensor(self, op, *args, **kwargs):", "ground_truth": "    def visit_print_tensor(self, op, *args, **kwargs):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def visit_compute(self, _compute, *args, **kwargs):", "prediction_line": "    def visit_compute(self, _compute, *args, **kwargs):", "ground_truth": "    def visit_compute(self, op, *args, **kwargs):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        return\n\n    def visit_bit_reverse(self, op, *args, **kwargs):", "prediction_line": "        return", "ground_truth": "        return", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"ASTVisitor.visit: unsupported op type %s\" % type(op))", "prediction_line": "                \"ASTVisitor.visit: unsupported op type %s\" % type(op))", "ground_truth": "                f\"{type(op)}'s {self.name} visitor is not implemented yet.\"", "line_class": "random", "zero_context": true}
{"original_prediction": "            b_chunk = preprocess_chunk(b_chunk, b_metadata)", "prediction_line": "            b_chunk = preprocess_chunk(b_chunk, b_metadata)", "ground_truth": "            b_chunk.index = pd.to_datetime(b_chunk.index, utc=True, infer_datetime_format=True)", "line_class": "common", "zero_context": true}
{"original_prediction": "            nilmtk_metadata[b_id][\"appliances\"].append(app_metadata)", "prediction_line": "            nilmtk_metadata[b_id][\"appliances\"].append(app_metadata)", "ground_truth": "            app_metadata.update(COL_MAPPING[meter])", "line_class": "common", "zero_context": true}
{"original_prediction": "        nilmtk_b_id = b_id", "prediction_line": "        nilmtk_b_id = b_id", "ground_truth": "        nilmtk_b_id = tuple(nilmtk_metadata).index(b_id) + 1", "line_class": "common", "zero_context": true}
{"original_prediction": "            csv_b_cache[csv_filename] = csv_b_cache[csv_filename].union(b_list)", "prediction_line": "            csv_b_cache[csv_filename] = csv_b_cache[csv_filename].union(b_list)", "ground_truth": "            csv_b_cache[csv_filename].update(b_list)", "line_class": "common", "zero_context": true}
{"original_prediction": "        # Compute the electrical consumption based on grid and photovoltaic readings.", "prediction_line": "        # Compute the electrical consumption based on grid and photovoltaic readings.", "ground_truth": "        gen = pd.Series(data=np.zeros(cleaned[\"grid\"].shape), index=cleaned.index)", "line_class": "common", "zero_context": true}
{"original_prediction": "            b_chunk = preprocess_chunk(b_chunk, b_metadata)", "prediction_line": "            b_chunk = preprocess_chunk(b_chunk, b_metadata)", "ground_truth": "            b_chunk = preprocess_chunk(b_chunk, b_metadata)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    nilmtk_metadata = OrderedDict()", "prediction_line": "    nilmtk_metadata = OrderedDict()", "ground_truth": "    metadata_dir = create_tmp_metadata_dir()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    dataport_metadata = load_dataport_metadata(metadata_path)", "prediction_line": "    dataport_metadata = load_dataport_metadata(metadata_path)", "ground_truth": "    dataport_metadata = load_dataport_metadata(metadata_path)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    csvs = [ os.path.join(\"data\", i) for i in csvs ]", "prediction_line": "    csvs = [ os.path.join(\"data\", i) for i in csvs ]", "ground_truth": "    convert_dataport(csvs, \"metadata.csv\", \"dataport.h5\", 3e6)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        print(\"Building {}...\".format(b_id))", "prediction_line": "        print(\"Building {}...\".format(b_id))", "ground_truth": "        b_metadata = create_nilmtk_metadata(b_id, dataport_metadata)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                b_data = extract_building_data(csv_file, b_id, b_metadata, chunksize, csv_building_cache)", "prediction_line": "                b_data = extract_building_data(csv_file, b_id, b_metadata, chunksize, csv_building_cache)", "ground_truth": "                b_data = extract_building_data(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    write_meter_data(store, b_id, b_data, nilmtk_metadata)", "prediction_line": "                    write_meter_data(store, b_id, b_data, nilmtk_metadata)", "ground_truth": "                    write_meter_data(store, b_id, b_data, nilmtk_metadata)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            os.remove(os.path.join(metadata_dir, f))", "prediction_line": "            os.remove(os.path.join(metadata_dir, f))", "ground_truth": "            os.remove(join(metadata_dir, f))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Write metadata", "prediction_line": "        # Write metadata", "ground_truth": "    store.close()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            b_data = b_data.append(b_chunk)", "prediction_line": "            b_data = b_data.append(b_chunk)", "ground_truth": "            if b_data.empty:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        m_data.index.name = nilmtk.measurement.DATETIME_COLUMN", "prediction_line": "        m_data.index.name = nilmtk.measurement.DATETIME_COLUMN", "ground_truth": "        hdf_store.put(str(key), m_data, format=\"table\", append=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        with open(yml_filename, \"w\") as yml_file:", "prediction_line": "        with open(yml_filename, \"w\") as yml_file:", "ground_truth": "        with open(yml_filename, \"w\") as yml_file:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                b_data = b_data.append(b_chunk)", "prediction_line": "                b_data = b_data.append(b_chunk)", "ground_truth": "                b_data = b_data.append(b_chunk)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            nilmtk_metadata[b_id][\"appliances\"].append(app_metadata)", "prediction_line": "            nilmtk_metadata[b_id][\"appliances\"].append(app_metadata)", "ground_truth": "            nilmtk_metadata[b_id][\"appliances\"].append(app_metadata)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "               if not b_data.empty:", "prediction_line": "               if not b_data.empty:", "ground_truth": "                if not b_data.empty:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        cleaned.drop(\"grid\", axis=1, inplace=True)", "prediction_line": "        cleaned.drop(\"grid\", axis=1, inplace=True)", "ground_truth": "        use.name = \"use\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if meter not in nilmtk_metadata[b_id][\"elec_meters\"]:", "prediction_line": "        if meter not in nilmtk_metadata[b_id][\"elec_meters\"]:", "ground_truth": "        key = nilmtk.datastore.Key(building=nilmtk_b_id, meter=m_id + 1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        hdf_store.put(key, b_data[meter])", "prediction_line": "        hdf_store.put(key, b_data[meter])", "ground_truth": "        msg = \"\\tWriting {}\".format(str(key))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "get_module_directory(), \"dataset.yaml\")", "prediction_line": "get_module_directory(), \"dataset.yaml\")", "ground_truth": "            get_module_directory(), 'dataset_converters', 'dataport', 'metadata')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # Drop NaN columns", "prediction_line": "    # Drop NaN columns", "ground_truth": "    cleaned = chunk_data.dropna(axis=1, how=\"all\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    for f in os.listdir(metadata_dir):", "prediction_line": "    for f in os.listdir(metadata_dir):", "ground_truth": "    for f in os.listdir(metadata_dir):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if f.endswith(\".yaml\"):", "prediction_line": "        if f.endswith(\".yaml\"):", "ground_truth": "        if re.search('^building', f):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    b_data: pandas.DataFrame", "prediction_line": "    b_data: pandas.DataFrame", "ground_truth": "    b_data: pandas.DataFrame", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    print(msg, end='\\r')", "prediction_line": "    print(msg, end='\\r')", "ground_truth": "    print(\"\\t\" + \" \" * len(msg), end='\\r')", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            This would require a lot of memory to store all the data.", "prediction_line": "            This would require a lot of memory to store all the data.", "ground_truth": "            Besides, the CSV are too big to fit in memory.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        cleaned.drop([\"grid\", \"solar\", \"solar2\"], axis=1, inplace=True)", "prediction_line": "        cleaned.drop([\"grid\", \"solar\", \"solar2\"], axis=1, inplace=True)", "ground_truth": "        cleaned.drop(\"grid\", axis=1, inplace=True)", "line_class": "random", "zero_context": true}
{"original_prediction": "    # Read metadata.csv file.", "prediction_line": "    # Read metadata.csv file.", "ground_truth": "    metadata = pd.read_csv(csv_metadata_path,", "line_class": "random", "zero_context": true}
{"original_prediction": "            if app_type not in nilmtk_metadata[b_id][\"appliances\"]:", "prediction_line": "            if app_type not in nilmtk_metadata[b_id][\"appliances\"]:", "ground_truth": "            for other in nilmtk_metadata[b_id][\"appliances\"]:", "line_class": "random", "zero_context": true}
{"original_prediction": "        nilmtk_metadata[b_id][\"elec_meters\"][m_id + 1] = meter_metadata", "prediction_line": "        nilmtk_metadata[b_id][\"elec_meters\"][m_id + 1] = meter_metadata", "ground_truth": "        nilmtk_metadata[b_id][\"elec_meters\"][m_id + 1] = meter_metadata", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"pool1\": {\"type\": \"electric pool heater\"},", "prediction_line": "        \"pool1\": {\"type\": \"electric pool heater\"},", "ground_truth": "        \"oven2\": {\"type\": \"oven\"},", "line_class": "random", "zero_context": true}
{"original_prediction": "                    # todo: need to generalize the following section", "prediction_line": "                    # todo: need to generalize the following section", "ground_truth": "                    mapped_intensity = round(map_value(percent_active, 0, 100, 1, 255))", "line_class": "commited", "zero_context": true}
{"original_prediction": "                        block_with_max_activity = activity_report[device][0].index(max(activity_report[device][0]))", "prediction_line": "                        block_with_max_activity = activity_report[device][0].index(max(activity_report[device][0]))", "ground_truth": "                        block_with_max_z = activity_report[device][0].index(max(activity_report[device][0]))", "line_class": "common", "zero_context": true}
{"original_prediction": "                        block_with_max_y = activity_report[device][0].index(max(tmp_list))", "prediction_line": "                        block_with_max_y = activity_report[device][0].index(max(tmp_list))", "ground_truth": "                        block_with_2nd_max = activity_report[device][0].index(max(tmp_list))", "line_class": "common", "zero_context": true}
{"original_prediction": "                movement.activate_motor(motor_data)", "prediction_line": "                movement.activate_motor(motor_data)", "ground_truth": "                movement.activate_device(device_type='motor', device_data=motor_data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                led.set_led_state(active_led_neurons)", "prediction_line": "                led.set_led_state(active_led_neurons)", "ground_truth": "                led_data = led.convert_neuron_activity_to_rgb_intensities(active_led_neurons)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    motor.motor_operator(device_data)", "prediction_line": "                    motor.motor_operator(device_data)", "ground_truth": "                    motor.motor_operator(device_data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                led.set_led_intensities(led_data)", "prediction_line": "                led.set_led_intensities(led_data)", "ground_truth": "                led.activate_leds(led_data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    servo.servo_operator(device_data)", "prediction_line": "                    servo.servo_operator(device_data)", "ground_truth": "                    servo.servo_operator(device_data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                controller.activate_leds(led_data)", "prediction_line": "                controller.activate_leds(led_data)", "ground_truth": "                led = controller.LED()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                movement.activate_device(device_type='servo', device_data=device_data)", "prediction_line": "                movement.activate_device(device_type='servo', device_data=device_data)", "ground_truth": "                movement.activate_device(device_type='servo', device_data=device_data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                led.led_handler()", "prediction_line": "                led.led_handler()", "ground_truth": "                active_led_neurons = active_neurons_in_blocks(cortical_area='led_opu')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                activity_report = opu_activity_report(cortical_area='servo_opu')", "prediction_line": "                activity_report = opu_activity_report(cortical_area='servo_opu')", "ground_truth": "                activity_report = opu_activity_report(cortical_area='servo_opu')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    runtime_data.opu_pub.send(message=message_to_router)", "prediction_line": "                    runtime_data.opu_pub.send(message=message_to_router)", "ground_truth": "                    runtime_data.opu_pub.send(message=message_to_router)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    block_id = block_ref_2_id(block_ref)", "prediction_line": "                    block_id = block_ref_2_id(block_ref)", "ground_truth": "                    block_id = block_ref_2_id(block_ref)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                   led_data[led_id][block_z_idx] = percent_active_neurons_in_block(block_ref, cortical_area)", "prediction_line": "                   led_data[led_id][block_z_idx] = percent_active_neurons_in_block(block_ref, cortical_area)", "ground_truth": "                    percent_active = percent_active_neurons_in_block(block_ref, cortical_area='led_opu')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                pass\n\n            # todo: need a better differentiation between movement and motor modules", "prediction_line": "                pass", "ground_truth": "                activity_report = opu_activity_report(cortical_area='motor_opu')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    led.activate_led(led_id, R, G, B)", "prediction_line": "                    led.activate_led(led_id, R, G, B)", "ground_truth": "                    led.LED_on(led_id, R, G, B)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "socket.bind(socket_address)", "prediction_line": "socket.bind(socket_address)", "ground_truth": "            # # todo: Figure a way to externalize the binding port. feagi_configuration.ini captures it on FEAGI side.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                        'speed': speed_value", "prediction_line": "                        'speed': speed_value", "ground_truth": "                        \"direction\": 'F',", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            # # todo: export socket address to config file", "prediction_line": "            # # todo: export socket address to config file", "ground_truth": "            # socket_address = 'tcp://0.0.0.0:21000'", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# You may obtain a copy of the License at", "prediction_line": "# You may obtain a copy of the License at", "ground_truth": "# You may obtain a copy of the License at", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                - Y direction captures the motor_id.", "prediction_line": "                - Y direction captures the motor_id.", "ground_truth": "                - Y direction does not have any operational significance and cortical columns of the motor cortex are to be created-", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                elif move_index == 2:", "prediction_line": "                elif move_index == 2:", "ground_truth": "                elif move_index == 2:", "line_class": "random", "zero_context": true}
{"original_prediction": "                    return 'F'", "prediction_line": "                    return 'F'", "ground_truth": "                    movement_direction = 'w'", "line_class": "random", "zero_context": true}
{"original_prediction": "            led.handler()", "prediction_line": "            led.handler()", "ground_truth": "            if 'led_opu' in runtime_data.fire_candidate_list and runtime_data.hardware == 'raspberry_pi':", "line_class": "random", "zero_context": true}
{"original_prediction": "                activity_history = activity_history[-100:]", "prediction_line": "                activity_history = activity_history[-100:]", "ground_truth": "                collection_span_counter = len(activity_history) - 1", "line_class": "random", "zero_context": true}
{"original_prediction": "                return chr(char)", "prediction_line": "                return chr(char)", "ground_truth": "                activity_history = list(runtime_data.brain[cortical_area][neuron_id]['activity_history'])", "line_class": "random", "zero_context": true}
{"original_prediction": "            ret, frame = cam.read()", "prediction_line": "            ret, frame = cam.read()", "ground_truth": "            check, pixels = cam.read()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    aptr_size = check_aptr(size=None)", "prediction_line": "    aptr_size = check_aptr(size=None)", "ground_truth": "    raw_aptr = requests.get(get_size_for_aptr_cortical).json()", "line_class": "common", "zero_context": true}
{"original_prediction": "capabilities)).start()\n    while True:", "prediction_line": "capabilities)).start()", "ground_truth": "        capabilities), daemon=True).start()", "line_class": "common", "zero_context": true}
{"original_prediction": "            for x in range(frame_row_count):", "prediction_line": "            for x in range(frame_row_count):", "ground_truth": "            for index in range(frame_len):", "line_class": "common", "zero_context": true}
{"original_prediction": "                if index % 3 == 0:", "prediction_line": "                if index % 3 == 0:", "ground_truth": "                if frame[index] != 128:", "line_class": "common", "zero_context": true}
{"original_prediction": "                                aptr_cortical_size = check_aptr(size=message_from_feagi[\"opu_data\"][\"o_aptr\"][i])", "prediction_line": "                                aptr_cortical_size = check_aptr(size=message_from_feagi[\"opu_data\"][\"o_aptr\"][i])", "ground_truth": "                                aptr_cortical_size = check_aptr(aptr_cortical_size)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    print(\"aptr_cortical_size: \", aptr_cortical_size)", "prediction_line": "    print(\"aptr_cortical_size: \", aptr_cortical_size)", "ground_truth": "    threading.Thread(target=process_video, args=(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    rgb['camera'][i] = retina_data[i]", "prediction_line": "                    rgb['camera'][i] = retina_data[i]", "ground_truth": "                    retina_data[i] = retina.center_data_compression(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        try:\n            feagi_flag = feagi.feagi_connect(feagi_auth_url, feagi_settings, agent_settings,", "prediction_line": "        try:", "ground_truth": "        feagi_flag = feagi.is_FEAGI_reachable(feagi_settings[\"feagi_host\"], 30000)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    print(\"FEAGI is reachable\")", "prediction_line": "    print(\"FEAGI is reachable\")", "ground_truth": "    burst_counter_endpoint = feagi.feagi_api_burst_counter()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    feagi_state = feagi.feagi_state(feagi_auth_url, feagi_settings[\"feagi_host\"],", "prediction_line": "    feagi_state = feagi.feagi_state(feagi_auth_url, feagi_settings[\"feagi_host\"],", "ground_truth": "    runtime_data[\"feagi_state\"] = feagi.feagi_registration(feagi_auth_url=feagi_auth_url,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if name in previous_data_frame:", "prediction_line": "                    if name in previous_data_frame:", "ground_truth": "                    data = retina.ndarray_to_list(retina_data[i])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            retina.data_compression(data, previous_data_frame[previous_name],", "prediction_line": "                            retina.data_compression(data, previous_data_frame[previous_name],", "ground_truth": "                            retina.get_rgb(data,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    feagi_opu_channel = feagi.sub_initializer(opu_channel_address, bind=False)", "prediction_line": "    feagi_opu_channel = feagi.sub_initializer(opu_channel_address, bind=False)", "ground_truth": "    feagi_opu_channel = feagi.sub_initializer(opu_address=opu_channel_address)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                compressed_data = lz4.frame.compress(serialized_data)", "prediction_line": "                compressed_data = lz4.frame.compress(serialized_data)", "ground_truth": "                feagi_ipu_channel.send(message=lz4.frame.compress(serialized_data))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ipu_channel_address = feagi.feagi_inbound(agent_data_port)", "prediction_line": "    ipu_channel_address = feagi.feagi_inbound(agent_data_port)", "ground_truth": "    ipu_channel_address = feagi.feagi_outbound(feagi_settings['feagi_host'], agent_data_port)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # todo: to obtain this info directly from FEAGI as part of registration", "prediction_line": "    # todo: to obtain this info directly from FEAGI as part of registration", "ground_truth": "    opu_channel_address = feagi.feagi_outbound(feagi_settings['feagi_host'],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   print(\"OPU_channel_address=\", opu_channel_address)", "prediction_line": "   print(\"OPU_channel_address=\", opu_channel_address)", "ground_truth": "    feagi_ipu_channel = feagi.pub_initializer(ipu_channel_address, bind=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if pixels is not None:", "prediction_line": "            if pixels is not None:", "ground_truth": "            retina_data = retina.frame_split(pixels, capabilities['camera']['retina_width_percent'],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                feagi_ipu_channel.send(message=message_to_feagi)", "prediction_line": "                feagi_ipu_channel.send(message=message_to_feagi)", "ground_truth": "                feagi_ipu_channel.send(message_to_feagi)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    y_vision = 0  # column counter", "prediction_line": "    y_vision = 0  # column counter", "ground_truth": "    y_vision = 0  # col counter", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            #     pass", "prediction_line": "            #     pass", "ground_truth": "            #     pass", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   feagi_settings['feagi_burst_id'] = runtime_data[\"feagi_state\"]['burst_id']", "prediction_line": "   feagi_settings['feagi_burst_id'] = runtime_data[\"feagi_state\"]['burst_id']", "ground_truth": "    # todo: to obtain this info directly from FEAGI as part of registration", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def get_screen_size():", "prediction_line": "def get_screen_size():", "ground_truth": "def chroma_keyer(frame, size, name_id):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    frame_col_count = size[1]  # height", "prediction_line": "    frame_col_count = size[1]  # height", "ground_truth": "    frame_col_count = size[1]  # height", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    previous_data_frame_len = 0", "prediction_line": "    previous_data_frame_len = 0", "ground_truth": "    runtime_data = {\"vision\": {}, \"current_burst_id\": None, \"stimulation_period\": None,", "line_class": "random", "zero_context": true}
{"original_prediction": "                                             capabilities['camera']['retina_height_percent'],", "prediction_line": "                                             capabilities['camera']['retina_height_percent'],", "ground_truth": "                                             capabilities['camera']['retina_height_percent'])", "line_class": "random", "zero_context": true}
{"original_prediction": "                if message_from_feagi['burst_counter'] == msg_counter:", "prediction_line": "                if message_from_feagi['burst_counter'] == msg_counter:", "ground_truth": "                if 'genome_num' in message_from_feagi:", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"\"\"\n    This function checks if the aptr is still running. If it is not, it will restart it.", "prediction_line": "    \"\"\"", "ground_truth": "    try:", "line_class": "random", "zero_context": true}
{"original_prediction": "== size[0] and raw_aptr['cortical_dimensions'][3] == size[1]", "prediction_line": "== size[0] and raw_aptr['cortical_dimensions'][3] == size[1]", "ground_truth": "    except Exception as error:", "line_class": "random", "zero_context": true}
{"original_prediction": "    asyncio.run(main())", "prediction_line": "    asyncio.run(main())", "ground_truth": "    asyncio.run(main())", "line_class": "commited", "zero_context": true}
{"original_prediction": "def bridge_to_microbit():", "prediction_line": "def bridge_to_microbit():", "ground_truth": "async def main():", "line_class": "commited", "zero_context": true}
{"original_prediction": "agent_settings[\"feagi_ip\"],", "prediction_line": "agent_settings[\"feagi_ip\"],", "ground_truth": "                os.environ.get('FEAGI_HOST_INTERNAL', \"127.0.0.1\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "                os.environ.get('FEAGI_PORT_INTERNAL', \"8000\"))", "prediction_line": "                os.environ.get('FEAGI_PORT_INTERNAL', \"8000\"))", "ground_truth": "                int(os.environ.get('FEAGI_OPU_PORT', \"3000\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "def get_data(data):", "prediction_line": "def get_data(data):", "ground_truth": "async def bridge_to_godot():", "line_class": "infile", "zero_context": true}
{"original_prediction": "    async with websockets.serve(echo, \"localhost\", 8765):", "prediction_line": "    async with websockets.serve(echo, \"localhost\", 8765):", "ground_truth": "    async with websockets.serve(echo, agent_settings[\"godot_websocket_ip\"],", "line_class": "infile", "zero_context": true}
{"original_prediction": "    runtime_data = {}", "prediction_line": "    runtime_data = {}", "ground_truth": "    threading.Thread(target=websocket_operation, daemon=True).start()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    while True:", "prediction_line": "    while True:", "ground_truth": "    threading.Thread(target=bridge_operation, daemon=True).start()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    while True:", "prediction_line": "    while True:", "ground_truth": "    asyncio.run(bridge_to_godot())", "line_class": "infile", "zero_context": true}
{"original_prediction": "def bridge_to_feagi(data):", "prediction_line": "def bridge_to_feagi(data):", "ground_truth": "async def echo(websocket):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        feagi_auth_response = requests.post(feagi_auth_url, json=feagi_settings)", "prediction_line": "        feagi_auth_response = requests.post(feagi_auth_url, json=feagi_settings)", "ground_truth": "        runtime_data[\"feagi_state\"] = feagi.feagi_registration(feagi_auth_url=feagi_auth_url,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        if ws_operation.pop() == \"send\":", "prediction_line": "                        if ws_operation.pop() == \"send\":", "ground_truth": "                    await ws_operation[0].send(str(ws[0]))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        print(\"FEAGI API address: \", api_address)", "prediction_line": "        print(\"FEAGI API address: \", api_address)", "ground_truth": "        stimulation_period_endpoint = feagi.feagi_api_burst_engine()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        print(\"FEAGI API address: \", api_address)", "prediction_line": "        print(\"FEAGI API address: \", api_address)", "ground_truth": "        burst_counter_endpoint = feagi.feagi_api_burst_counter()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    if message_from_feagi['burst_counter'] == msg_counter:", "prediction_line": "                    if message_from_feagi['burst_counter'] == msg_counter:", "ground_truth": "                    opu_data = feagi.opu_processor(message_from_feagi)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    compressed_data = lz4.frame.compress(serialized_data)", "prediction_line": "                    compressed_data = lz4.frame.compress(serialized_data)", "ground_truth": "                    feagi_ipu_channel.send(message=lz4.frame.compress(serialized_data))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -", "prediction_line": "        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -", "ground_truth": "        ipu_channel_address = feagi.feagi_outbound(feagi_settings['feagi_host'], agent_data_port)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "                    feagi_ipu_channel.send(message_to_feagi)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -", "prediction_line": "        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -", "ground_truth": "        opu_channel_address = feagi.feagi_outbound(feagi_settings['feagi_host'],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "            feagi_flag = feagi.is_FEAGI_reachable(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                accelerator_data = microbit_data['accelerator']", "prediction_line": "                accelerator_data = microbit_data['accelerator']", "ground_truth": "                message_to_feagi, battery = feagi.compose_message_to_feagi(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       print(\"OPU_channel_address=\", opu_channel_address)", "prediction_line": "       print(\"OPU_channel_address=\", opu_channel_address)", "ground_truth": "        feagi_ipu_channel = feagi.pub_initializer(ipu_channel_address, bind=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        feagi_opu_channel = feagi.pub_initializer(opu_channel_address, bind=False)", "prediction_line": "        feagi_opu_channel = feagi.pub_initializer(opu_channel_address, bind=False)", "ground_truth": "        feagi_opu_channel = feagi.sub_initializer(opu_address=opu_channel_address)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "# -*- coding: utf-8 -*-", "prediction_line": "# -*- coding: utf-8 -*-", "ground_truth": "\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    Echoes websocket messages back to the client.", "prediction_line": "    Echoes websocket messages back to the client.", "ground_truth": "    The function echoes the data it receives from other connected websockets", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "Licensed under the Apache License, Version 2.0 (the \"License\");", "prediction_line": "Licensed under the Apache License, Version 2.0 (the \"License\");", "ground_truth": "Licensed under the Apache License, Version 2.0 (the \"License\");", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                        WS_STRING += str(data_point)", "prediction_line": "                        WS_STRING += str(data_point)", "ground_truth": "                        if data_point == 0:", "line_class": "random", "zero_context": true}
{"original_prediction": "                else:\n                    sleep(0.001)", "prediction_line": "                else:", "ground_truth": "            except Exception as error:", "line_class": "random", "zero_context": true}
{"original_prediction": "\"feagi_flag\": feagi_flag}", "prediction_line": "\"feagi_flag\": feagi_flag}", "ground_truth": "                        \"feagi_network\": None}", "line_class": "random", "zero_context": true}
{"original_prediction": "            ir1 = 1", "prediction_line": "            ir1 = 1", "ground_truth": "            ir1 = 1", "line_class": "random", "zero_context": true}
{"original_prediction": "                except Exception as error:", "prediction_line": "                except Exception as error:", "ground_truth": "                except Exception as ERROR:", "line_class": "random", "zero_context": true}
{"original_prediction": "       if len(rgb_array['current']) == 10:", "prediction_line": "       if len(rgb_array['current']) == 10:", "ground_truth": "async def main():", "line_class": "commited", "zero_context": true}
{"original_prediction": "    asyncio.run(main())", "prediction_line": "    asyncio.run(main())", "ground_truth": "    asyncio.run(main())", "line_class": "commited", "zero_context": true}
{"original_prediction": "        aptr_response = requests.get(APTR_URL)", "prediction_line": "        aptr_response = requests.get(APTR_URL)", "ground_truth": "        raw_aptr = requests.get(get_size_for_aptr_cortical).json()", "line_class": "common", "zero_context": true}
{"original_prediction": "        if message == 'close':", "prediction_line": "        if message == 'close':", "ground_truth": "        test = message", "line_class": "common", "zero_context": true}
{"original_prediction": "        if message == \"get_size_for_aptr_cortical\":", "prediction_line": "        if message == \"get_size_for_aptr_cortical\":", "ground_truth": "        rgb_array['current'] = list(test)", "line_class": "common", "zero_context": true}
{"original_prediction": "'localhost'),\n                                                   os.environ.get('FEAGI_PORT_INTERNAL', '8000'))", "prediction_line": "'localhost'),", "ground_truth": "                                                                 \"127.0.0.1\"), int(os.environ.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "                                    aptr_cortical_size = check_aptr(aptr_cortical_size)", "prediction_line": "                                    aptr_cortical_size = check_aptr(aptr_cortical_size)", "ground_truth": "                                    aptr_cortical_size = check_aptr(aptr_cortical_size)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    # new_rgb = rgba2rgb(new_rgb)", "prediction_line": "                    # new_rgb = rgba2rgb(new_rgb)", "ground_truth": "                    new_rgb = rgba2rgb(new_rgb)", "line_class": "infile", "zero_context": true}
{"original_prediction": "def check_bptr():", "prediction_line": "def check_bptr():", "ground_truth": "async def echo(websocket):", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rgb_array['previous'] = {}", "prediction_line": "    rgb_array['previous'] = {}", "ground_truth": "    BGSK = threading.Thread(target=websocket_operation, daemon=True).start()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    if message_from_feagi['burst_counter'] == msg_counter:", "prediction_line": "                    if message_from_feagi['burst_counter'] == msg_counter:", "ground_truth": "                    start_time = utc_time()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    async with websockets.serve(echo, \"localhost\", 8765):", "prediction_line": "    async with websockets.serve(echo, \"localhost\", 8765):", "ground_truth": "    async with websockets.serve(echo, agent_settings[\"godot_websocket_ip\"],", "line_class": "infile", "zero_context": true}
{"original_prediction": "        feagi_auth_token = feagi.get_feagi_auth_token(feagi_auth_url)", "prediction_line": "        feagi_auth_token = feagi.get_feagi_auth_token(feagi_auth_url)", "ground_truth": "        runtime_data[\"feagi_state\"] = feagi.feagi_registration(feagi_auth_url=feagi_auth_url,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                    retina.retina_data_compression(data,", "prediction_line": "                                    retina.retina_data_compression(data,", "ground_truth": "                                    retina.get_rgb(data,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       print(\"FEAGI API address ------- \", api_address)", "prediction_line": "       print(\"FEAGI API address ------- \", api_address)", "ground_truth": "        stimulation_period_endpoint = feagi.feagi_api_burst_engine()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        runtime_data[\"stimulation_period\"] = feagi.feagi_api_call(api_address,", "prediction_line": "        runtime_data[\"stimulation_period\"] = feagi.feagi_api_call(api_address,", "ground_truth": "        burst_counter_endpoint = feagi.feagi_api_burst_counter()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    rgb['camera'] = new_rgb", "prediction_line": "                    rgb['camera'] = new_rgb", "ground_truth": "                    retina_data = retina.frame_split(new_rgb,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                retina.edge_data_compression(retina_data[i],", "prediction_line": "                                retina.edge_data_compression(retina_data[i],", "ground_truth": "                                retina.center_data_compression(retina_data[i],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        ipu_channel_address = feagi.feagi_inbound(agent_data_port)", "prediction_line": "        ipu_channel_address = feagi.feagi_inbound(agent_data_port)", "ground_truth": "        ipu_channel_address = feagi.feagi_outbound(feagi_settings['feagi_host'], agent_data_port)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    compressed_data = lz4.frame.compress(serialized_data)", "prediction_line": "                    compressed_data = lz4.frame.compress(serialized_data)", "ground_truth": "                    feagi_ipu_channel.send(message=lz4.frame.compress(serialized_data))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            try:\n                feagi_flag = feagi.feagi_flag", "prediction_line": "            try:", "ground_truth": "            feagi_flag = feagi.is_FEAGI_reachable(os.environ.get('FEAGI_HOST_INTERNAL',", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # todo: to obtain this info directly from FEAGI as part of registration", "prediction_line": "        # todo: to obtain this info directly from FEAGI as part of registration", "ground_truth": "        opu_channel_address = feagi.feagi_outbound(feagi_settings['feagi_host'],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       print(\"OPU_channel_address=\", opu_channel_address)", "prediction_line": "       print(\"OPU_channel_address=\", opu_channel_address)", "ground_truth": "        feagi_ipu_channel = feagi.pub_initializer(ipu_channel_address, bind=False)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        feagi_opu_channel = feagi.sub_initializer(opu_channel_address, bind=False)", "prediction_line": "        feagi_opu_channel = feagi.sub_initializer(opu_channel_address, bind=False)", "ground_truth": "        feagi_opu_channel = feagi.sub_initializer(opu_address=opu_channel_address)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    feagi_ipu_channel.send(message=message_to_feagi)", "prediction_line": "                    feagi_ipu_channel.send(message=message_to_feagi)", "ground_truth": "                    feagi_ipu_channel.send(message_to_feagi)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            if 'C' in i:", "prediction_line": "                            if 'C' in i:", "ground_truth": "                            data = retina.ndarray_to_list(retina_data[i])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                print(e)", "prediction_line": "                print(e)", "ground_truth": "                print(\"ERROR: \", e)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def rgb2rgba(rgb, background=(255, 255, 255)):", "prediction_line": "def rgb2rgba(rgb, background=(255, 255, 255)):", "ground_truth": "def utc_time():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "input\n    image with the background color.", "prediction_line": "input", "ground_truth": "    input image with a specified background color using the alpha channel as a weighting factor.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    :param rgba: The input image in the form of a numpy array with shape (row, col, 4).", "prediction_line": "    :param rgba: The input image in the form of a numpy array with shape (row, col, 4).", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    elif len(rgb_array['current']) == 1000000:", "prediction_line": "                    elif len(rgb_array['current']) == 1000000:", "ground_truth": "                    elif len(rgb_array['current']) == 65536:", "line_class": "random", "zero_context": true}
{"original_prediction": "                pass\n            # print(\"Time taken: \", time.time() - start_time)", "prediction_line": "                pass", "ground_truth": "                break", "line_class": "random", "zero_context": true}
{"original_prediction": "                        new_rgb = new_rgb.reshape(16, 16, 4)", "prediction_line": "                        new_rgb = new_rgb.reshape(16, 16, 4)", "ground_truth": "                        new_rgb = new_rgb.reshape(128, 128, 4)", "line_class": "random", "zero_context": true}
{"original_prediction": "                                                   previous_data_frame[PREVIOUS_NAME])", "prediction_line": "                                                   previous_data_frame[PREVIOUS_NAME])", "ground_truth": "                                                   previous_data_frame[", "line_class": "random", "zero_context": true}
{"original_prediction": "        feagi_state = feagi.get_feagi_state()", "prediction_line": "        feagi_state = feagi.get_feagi_state()", "ground_truth": "        feagi_auth_url = feagi_settings.pop('feagi_auth_url', None)", "line_class": "random", "zero_context": true}
{"original_prediction": "    main()", "prediction_line": "    main()", "ground_truth": "    main()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        GPIO.setup(self.IR01, GPIO.IN)", "prediction_line": "        GPIO.setup(self.IR01, GPIO.IN)", "ground_truth": "        GPIO.setup(self.IR01, GPIO.IN)", "line_class": "common", "zero_context": true}
{"original_prediction": "        GPIO.setup(self.IR02, GPIO.IN)", "prediction_line": "        GPIO.setup(self.IR02, GPIO.IN)", "ground_truth": "        GPIO.setup(self.IR02, GPIO.IN)", "line_class": "common", "zero_context": true}
{"original_prediction": "        GPIO.setup(self.IR03, GPIO.IN)", "prediction_line": "        GPIO.setup(self.IR03, GPIO.IN)", "ground_truth": "        GPIO.setup(self.IR03, GPIO.IN)", "line_class": "common", "zero_context": true}
{"original_prediction": "            start = time.time()", "prediction_line": "            start = time.time()", "ground_truth": "            start = time.time()", "line_class": "common", "zero_context": true}
{"original_prediction": "            pulse_len = finish-start", "prediction_line": "            pulse_len = finish-start", "ground_truth": "            pulse_len = finish-start", "line_class": "common", "zero_context": true}
{"original_prediction": "        GPIO.setup(self.trigger_pin, GPIO.OUT)", "prediction_line": "        GPIO.setup(self.trigger_pin, GPIO.OUT)", "ground_truth": "        GPIO.setup(self.trigger_pin,GPIO.OUT)", "line_class": "common", "zero_context": true}
{"original_prediction": "        GPIO.setup(self.echo_pin,GPIO.IN)", "prediction_line": "        GPIO.setup(self.echo_pin,GPIO.IN)", "ground_truth": "        GPIO.setup(self.echo_pin,GPIO.IN)", "line_class": "common", "zero_context": true}
{"original_prediction": "            self.send_trigger_pulse()", "prediction_line": "            self.send_trigger_pulse()", "ground_truth": "            self.send_trigger_pulse()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.wait_for_echo(True,10000)", "prediction_line": "            self.wait_for_echo(True,10000)", "ground_truth": "            self.wait_for_echo(True,10000)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.wait_for_echo(False,10000)", "prediction_line": "            self.wait_for_echo(False,10000)", "ground_truth": "            self.wait_for_echo(False,10000)", "line_class": "infile", "zero_context": true}
{"original_prediction": "   led = LED()", "prediction_line": "   led = LED()", "ground_truth": "    motor = Motor()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    led = LED()", "prediction_line": "    led = LED()", "ground_truth": "    ir = IR()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ultrasonic = Ultrasonic()", "prediction_line": "    ultrasonic = Ultrasonic()", "ground_truth": "    ultrasonic = Ultrasonic()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    battery = Battery()", "prediction_line": "    battery = Battery()", "ground_truth": "    battery = Battery()", "line_class": "infile", "zero_context": true}
{"original_prediction": "SUB\n            # todo: to obtain this info directly from FEAGI as part of registration", "prediction_line": "SUB", "ground_truth": "            ir_data = ir.read()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            ultrasonic_data = ultrasonic.get_distance()", "prediction_line": "            ultrasonic_data = ultrasonic.get_distance()", "ground_truth": "            ultrasonic_data = ultrasonic.get_distance()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            battery_data = battery.battery_total()", "prediction_line": "            battery_data = battery.battery_total()", "ground_truth": "            battery_data = battery.battery_total()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            data_to_send = {", "prediction_line": "            data_to_send = {", "ground_truth": "            send_to_feagi(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        duty1, duty2, duty3, duty4 = self.duty_range(duty1, duty2, duty3, duty4)", "prediction_line": "        duty1, duty2, duty3, duty4 = self.duty_range(duty1, duty2, duty3, duty4)", "ground_truth": "        duty1, duty2, duty3, duty4 = self.duty_range(duty1, duty2, duty3, duty4)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.pwm.setMotorPwm(0, duty1)", "prediction_line": "        self.pwm.setMotorPwm(0, duty1)", "ground_truth": "        self.left_Upper_Wheel(duty1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.left_Lower_Wheel(duty2)", "prediction_line": "        self.left_Lower_Wheel(duty2)", "ground_truth": "        self.left_Lower_Wheel(duty2)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.right_Upper_Wheel(duty3)", "prediction_line": "        self.right_Upper_Wheel(duty3)", "ground_truth": "        self.right_Upper_Wheel(duty3)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.right_Lower_Wheel(duty4)", "prediction_line": "        self.right_Lower_Wheel(duty4)", "ground_truth": "        self.right_Lower_Wheel(duty4)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        motor.setMotorModel(", "prediction_line": "                        motor.setMotorModel(", "ground_truth": "                        avg_motor_activity = window_average(rolling_window[motor_id]) * 100", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.pwm.setMotorPwm(0, 4095)", "prediction_line": "        self.pwm.setMotorPwm(0, 4095)", "ground_truth": "        self.setMotorModel(0, 0, 0, 0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        motor.move(motor_id, motor_val)", "prediction_line": "                        motor.move(motor_id, motor_val)", "ground_truth": "                        motor.move(motor_id, motor_val)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        motor.stop()", "prediction_line": "        motor.stop()", "ground_truth": "        motor.stop()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    feagi_ipu_channel.send_pyobj(message)", "prediction_line": "    feagi_ipu_channel.send_pyobj(message)", "ground_truth": "    feagi_ipu_channel.send(message)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "to the motor\n            while True:", "prediction_line": "to the motor", "ground_truth": "            opu_data = feagi_opu_channel.receive()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "print(\"OPU_channel_address=\", opu_channel_address)", "prediction_line": "print(\"OPU_channel_address=\", opu_channel_address)", "ground_truth": "feagi_ipu_channel = Pub(address=ipu_channel_address)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "feagi_opu_channel = Sub(address=opu_channel_address)", "prediction_line": "feagi_opu_channel = Sub(address=opu_channel_address)", "ground_truth": "feagi_opu_channel = Sub(address=opu_channel_address, flags=zmq.NOBLOCK)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Green_intensity: 1 to 255, from dimmest to brightest", "prediction_line": "        Green_intensity: 1 to 255, from dimmest to brightest", "ground_truth": "        Green_intensity: 1 to 255, from dimmest to brightest", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "See the License for the specific language governing permissions and", "prediction_line": "See the License for the specific language governing permissions and", "ground_truth": "See the License for the specific language governing permissions and", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                formatted_ir_data = {'ir': {sensor: False for sensor in range(3)}}", "prediction_line": "                formatted_ir_data = {'ir': {sensor: False for sensor in range(3)}}", "ground_truth": "                formatted_ir_data = {}", "line_class": "random", "zero_context": true}
{"original_prediction": "        count = timeout", "prediction_line": "        count = timeout", "ground_truth": "        count = timeout", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.pwm.setPWMFreq(50)", "prediction_line": "        self.pwm.setPWMFreq(50)", "ground_truth": "        self.pwm.setPWMFreq(50)", "line_class": "random", "zero_context": true}
{"original_prediction": "class Feagi(object):", "prediction_line": "class Feagi(object):", "ground_truth": "if sys.platform == 'win32':", "line_class": "random", "zero_context": true}
{"original_prediction": "            duty4 = -4095", "prediction_line": "            duty4 = -4095", "ground_truth": "            duty4 = -4095", "line_class": "random", "zero_context": true}
{"original_prediction": "        super(ExtractedLicense, self).__init__(None, identifier)", "prediction_line": "        super(ExtractedLicense, self).__init__(None, identifier)", "ground_truth": "        super(ExtractedLicense, self).__init__(None, identifier)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(LicenseDisjunction, self).__init__(self.full_name, self.identifier)", "prediction_line": "        super(LicenseDisjunction, self).__init__(self.full_name, self.identifier)", "ground_truth": "        super(LicenseDisjunction, self).__init__(self.full_name, self.identifier)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.full_name = \"({0} AND {1})\".format(", "prediction_line": "        self.full_name = \"({0} AND {1})\".format(", "ground_truth": "        super(LicenseConjunction, self).__init__(self.full_name, self.identifier)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            _add_parens(license_1_complex, self.license_1.identifier),", "prediction_line": "            _add_parens(license_1_complex, self.license_1.identifier),", "ground_truth": "            _add_parens(license_1_complex, self.license_1.identifier),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            _add_parens(license_2_complex, self.license_2.identifier),", "prediction_line": "            _add_parens(license_2_complex, self.license_2.identifier),", "ground_truth": "            _add_parens(license_2_complex, self.license_2.identifier),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        license_1_complex = type(self.license_1) == LicenseDisjunction", "prediction_line": "        license_1_complex = type(self.license_1) == LicenseDisjunction", "ground_truth": "        license_1_complex = type(self.license_1) == LicenseConjunction", "line_class": "infile", "zero_context": true}
{"original_prediction": "        license_2_complex = type(self.license_2) == LicenseConjunction", "prediction_line": "        license_2_complex = type(self.license_2) == LicenseConjunction", "ground_truth": "        license_2_complex = type(self.license_2) == LicenseConjunction", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.license_1.full_name, self.license_2.full_name", "prediction_line": "            self.license_1.full_name, self.license_2.full_name", "ground_truth": "            _add_parens(license_1_complex, self.license_1.full_name),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._is_deprecated = None", "prediction_line": "        self._is_deprecated = None", "ground_truth": "        self.set_full_name(full_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.set_identifier(identifier)", "prediction_line": "        self.set_identifier(identifier)", "ground_truth": "        self.set_identifier(identifier)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            _add_parens(license_2_complex, self.license_2.full_name),", "prediction_line": "            _add_parens(license_2_complex, self.license_2.full_name),", "ground_truth": "            _add_parens(license_2_complex, self.license_2.full_name),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if identifier in config.LICENSE_MAP:", "prediction_line": "        if identifier in config.LICENSE_MAP:", "ground_truth": "        return cls(None, identifier)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return cls(full_name, None)", "prediction_line": "        return cls(full_name, None)", "ground_truth": "        return cls(full_name, None)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Return the url of the license.", "prediction_line": "        \"\"\"", "ground_truth": "        return \"http://spdx.org/licenses/{0}\".format(self.identifier)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @property\n    def identifier(self):", "prediction_line": "    @property", "ground_truth": "    @full_name.setter", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.set_full_name(value)", "prediction_line": "        self.set_full_name(value)", "ground_truth": "        self.set_full_name(value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            isinstance(other, ExtractedLicense)", "prediction_line": "            isinstance(other, ExtractedLicense)", "ground_truth": "            isinstance(other, ExtractedLicense)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            and self.full_name == other.full_name", "prediction_line": "            and self.full_name == other.full_name", "ground_truth": "            and self.identifier == other.identifier", "line_class": "infile", "zero_context": true}
{"original_prediction": "            and self.full_name == other.full_name", "prediction_line": "            and self.full_name == other.full_name", "ground_truth": "            and self.full_name == other.full_name", "line_class": "infile", "zero_context": true}
{"original_prediction": "            isinstance(other, ExtractedLicense)", "prediction_line": "            isinstance(other, ExtractedLicense)", "ground_truth": "            isinstance(other, ExtractedLicense) and self.identifier < other.identifier", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @identifier.setter", "prediction_line": "    @identifier.setter", "ground_truth": "    @identifier.setter", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.set_identifier(value)", "prediction_line": "        self.set_identifier(value)", "ground_truth": "        self.set_identifier(value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "self.full_name == other.full_name and", "prediction_line": "self.full_name == other.full_name and", "ground_truth": "            isinstance(other, License)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.identifier < other.identifier", "prediction_line": "        return self.identifier < other.identifier", "ground_truth": "        return isinstance(other, License) and self.identifier < other.identifier", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.identifier", "prediction_line": "        return self.identifier", "ground_truth": "        return self.identifier", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return hash(self.identifier)", "prediction_line": "        return hash(self.identifier)", "ground_truth": "        return self.identifier.__hash__()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return \"({0} AND {1})\".format(self.license_1.full_name, self.license_2.full_name)", "prediction_line": "        return \"({0} AND {1})\".format(self.license_1.full_name, self.license_2.full_name)", "ground_truth": "        license_1_complex = type(self.license_1) == LicenseDisjunction", "line_class": "infile", "zero_context": true}
{"original_prediction": "        license_2_complex = type(self.license_2) == LicenseDisjunction", "prediction_line": "        license_2_complex = type(self.license_2) == LicenseDisjunction", "ground_truth": "        license_2_complex = type(self.license_2) == LicenseDisjunction", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.cross_ref.append(ref)", "prediction_line": "        self.cross_ref.append(ref)", "ground_truth": "        self.cross_ref.append(ref)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            messages.append(\"Extracted license {0} has no text\".format(self.identifier))", "prediction_line": "            messages.append(\"Extracted license {0} has no text\".format(self.identifier))", "ground_truth": "            messages.append(\"ExtractedLicense text can not be None\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@total_ordering", "prediction_line": "@total_ordering", "ground_truth": "from spdx import config", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __str__(self):", "prediction_line": "    def __str__(self):", "ground_truth": "    def add_xref(self, ref):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"If full_name exists in config.LICENSE_MAP", "prediction_line": "        \"\"\"If full_name exists in config.LICENSE_MAP", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def identifier(self):", "prediction_line": "    def identifier(self):", "ground_truth": "    def identifier(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        return \"{0} OR {1}\".format(", "prediction_line": "        return \"{0} OR {1}\".format(", "ground_truth": "        return \"{0} OR {1}\".format(", "line_class": "random", "zero_context": true}
{"original_prediction": "        )", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "        if self.text is None:", "prediction_line": "        if self.text is None:", "ground_truth": "        if self.text is None:", "line_class": "random", "zero_context": true}
{"original_prediction": "                self._identifier = value", "prediction_line": "                self._identifier = value", "ground_truth": "                self._identifier = value", "line_class": "random", "zero_context": true}
{"original_prediction": "    @property\n    def full_name(self):", "prediction_line": "    @property", "ground_truth": "    @property", "line_class": "random", "zero_context": true}
{"original_prediction": "                      \"annotations\", \"attribution_text\", \"download_location\", \"files_analyzed\",", "prediction_line": "                      \"annotations\", \"attribution_text\", \"download_location\", \"files_analyzed\",", "ground_truth": "                      [ext_ref, ext_ref], [\"text\"], PackagePurpose.OTHER, datetime(2022, 1, 1), None, None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert package.checksums == [checksum]", "prediction_line": "    assert package.checksums == [checksum]", "ground_truth": "    assert package.checksums == [checksum]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert package.attribution_texts == []", "prediction_line": "    assert package.attribution_texts == []", "ground_truth": "    assert package.attribution_texts == []", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert package.external_references == [ext_ref, ext_ref]", "prediction_line": "    assert package.external_references == [ext_ref, ext_ref]", "ground_truth": "    assert package.external_references == [ext_ref, ext_ref]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Package(\"id\", \"name\", \"location\", primary_package_purpose=42)", "prediction_line": "        Package(\"id\", \"name\", \"location\", primary_package_purpose=42)", "ground_truth": "        Package(\"id\", \"name\", \"location\", primary_package_purpose=[])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert package.annotations == [\"text\"]", "prediction_line": "    assert package.annotations == [\"text\"]", "ground_truth": "    assert package.attribution_texts == [\"text\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert package.license_info_from_files == []", "prediction_line": "    assert package.license_info_from_files == []", "ground_truth": "    assert package.license_info_from_files == []", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert package.spdx_license_expression == SpdxNoAssertion()", "prediction_line": "    assert package.spdx_license_expression == SpdxNoAssertion()", "ground_truth": "    assert package.download_location == SpdxNoAssertion()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Package(\"id\", \"name\", \"location\", valid_until_date=\"2022-01-01\")", "prediction_line": "        Package(\"id\", \"name\", \"location\", valid_until_date=\"2022-01-01\")", "ground_truth": "        Package(\"id\", \"name\", \"location\", valid_until_date=SpdxNone())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "is True\n    assert package.verification_code == verif_code", "prediction_line": "is True", "ground_truth": "    assert package.verification_code == verif_code", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Package(\"id\", \"name\", \"location\", source_info=42)", "prediction_line": "        Package(\"id\", \"name\", \"location\", source_info=42)", "ground_truth": "        Package(\"id\", \"name\", \"location\", source_info=42)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Package(\"id\", \"name\", \"location\", summary=42)", "prediction_line": "        Package(\"id\", \"name\", \"location\", summary=42)", "ground_truth": "        Package(\"id\", \"name\", \"location\", summary=42)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert package.homepage == \"homepage\"", "prediction_line": "    assert package.homepage == \"homepage\"", "ground_truth": "    assert package.homepage == \"homepage\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert package.package_file_name == \"file_name\"", "prediction_line": "    assert package.package_file_name == \"file_name\"", "ground_truth": "    assert package.files_analyzed", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert package.external_references == []", "prediction_line": "    assert package.external_references == []", "ground_truth": "    assert package.external_references == []", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_wrong_type_in_file_name():", "prediction_line": "def test_wrong_type_in_file_name():", "ground_truth": "def test_wrong_type_in_file_name():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_wrong_type_in_download_location():", "prediction_line": "def test_wrong_type_in_download_location():", "ground_truth": "def test_wrong_type_in_download_location():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from src.model.spdx_relationship import SpdxRelationship", "prediction_line": "from src.model.spdx_relationship import SpdxRelationship", "ground_truth": "from src.model.spdx_none import SpdxNone", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "@mock.patch('src.model.package.PackageExternalReference', autospec=True)", "prediction_line": "@mock.patch('src.model.package.PackageExternalReference', autospec=True)", "ground_truth": "@mock.patch('src.model.checksum.Checksum', autospec=True)", "line_class": "random", "zero_context": true}
{"original_prediction": "@mock.patch('src.model.license_expression.LicenseExpression', autospec=True)", "prediction_line": "@mock.patch('src.model.license_expression.LicenseExpression', autospec=True)", "ground_truth": "@mock.patch('src.model.package.ExternalPackageReference', autospec=True)", "line_class": "random", "zero_context": true}
{"original_prediction": "@pytest.fixture", "prediction_line": "@pytest.fixture", "ground_truth": "@mock.patch('src.model.actor.Actor', autospec=True)", "line_class": "random", "zero_context": true}
{"original_prediction": "@mock.patch('src.model.package.Package', autospec=True)", "prediction_line": "@mock.patch('src.model.package.Package', autospec=True)", "ground_truth": "@mock.patch('src.model.package.PackageVerificationCode', autospec=True)", "line_class": "random", "zero_context": true}
{"original_prediction": "    return SPDXLexer()", "prediction_line": "    return SPDXLexer()", "ground_truth": "    lexer = SPDXLexer()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return lexer", "prediction_line": "    return lexer", "ground_truth": "    lexer.build()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert token.type == token_type", "prediction_line": "    assert token.type == token_type", "ground_truth": "    assert token.type == token_type", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert token.value == value", "prediction_line": "    assert token.value == value", "ground_truth": "    assert token.value == value", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert token.line_number == line_number", "prediction_line": "    assert token.line_number == line_number", "ground_truth": "    assert token.lineno == line_number", "line_class": "commited", "zero_context": true}
{"original_prediction": "    tokens = lexer.tokenize(document_str)", "prediction_line": "    tokens = lexer.tokenize(document_str)", "ground_truth": "    lexer.input(document_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token = lexer.token()", "prediction_line": "    token = lexer.token()", "ground_truth": "    token_assert_helper(lexer.token(), 'DOC_VERSION', 'SPDXVersion', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'COLON', ':', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'COLON', ':', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'SPDX-2.1', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DOC_LICENSE', 'DataLicense', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'DOC_LICENSE', 'DataLicense', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'DOC_LICENSE', 'DataLicense', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'CC0-1.0', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'CC0-1.0', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'CC0-1.0', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DOC_NAME', 'DocumentName', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'DOC_NAME', 'DocumentName', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'DOC_NAME', 'DocumentName', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'Sample_Document-V2.1', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'Sample_Document-V2.1', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'Sample_Document-V2.1', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DOC_SPDX_ID', 'SPDXID', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'DOC_SPDX_ID', 'SPDXID', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'SPDX_ID', 'SPDXID', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DOCUMENT', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DOCUMENT', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DOCUMENT', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DOC_COMMENT', 'DocumentComment', 5)", "prediction_line": "    token_assert_helper(lexer.token(), 'DOC_COMMENT', 'DocumentComment', 5)", "ground_truth": "    token_assert_helper(lexer.token(), 'DOC_COMMENT', 'DocumentComment', 5)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', '<text>Sample Comment</text>', 5)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', '<text>Sample Comment</text>', 5)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Sample Comment</text>', 5)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DOC_NAMESPACE', 'DocumentNamespace', 6)", "prediction_line": "    token_assert_helper(lexer.token(), 'DOC_NAMESPACE', 'DocumentNamespace', 6)", "ground_truth": "    token_assert_helper(lexer.token(), 'DOC_NAMESPACE', 'DocumentNamespace', 6)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'https://spdx.org/spdxdocs/spdx-example-444504E0-4F89-41D3-9A0C-0305E82C3301', 6)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'https://spdx.org/spdxdocs/spdx-example-444504E0-4F89-41D3-9A0C-0305E82C3301', 6)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE',", "line_class": "commited", "zero_context": true}
{"original_prediction": "    lexer.input(data)", "prediction_line": "    lexer.input(data)", "ground_truth": "    lexer.input(data)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'EXTERNAL_DOC_REF', 'ExternalDocumentRef', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'EXTERNAL_DOC_REF', 'ExternalDocumentRef', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'EXT_DOC_REF', 'ExternalDocumentRef', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'DocumentRef-spdx-tool-2.1', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'DocumentRef-spdx-tool-2.1', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'DOC_REF_ID', 'DocumentRef-spdx-tool-2.1', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DOC_REF_URI', 'http://spdx.org/spdxdocs/spdx-tools-v2.1-3F2504E0-4F89-41D3-9A0C-0305E82C3301', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'DOC_REF_URI', 'http://spdx.org/spdxdocs/spdx-tools-v2.1-3F2504E0-4F89-41D3-9A0C-0305E82C3301', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'DOC_URI', 'http://spdx.org/spdxdocs/spdx-tools-v2.1-3F25'", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DOC_CHECKSUM', 'SHA1', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'DOC_CHECKSUM', 'SHA1', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'EXT_DOC_REF_CHECKSUM', 'SHA1: d6a770ba38583ed4bb4525bd96e50461655d2759', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "   lexer.input(file_str)", "prediction_line": "   lexer.input(file_str)", "ground_truth": "    lexer.input(file_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'FILE_NAME', 'FileName', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'FILE_NAME', 'FileName', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'FILE_NAME', 'FileName', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'testfile.java', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'testfile.java', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'testfile.java', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SPDX_ID', 'SPDXID', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'SPDX_ID', 'SPDXID', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'SPDX_ID', 'SPDXID', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-File', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-File', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-File', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'FILE_TYPE', 'FileType', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'FILE_TYPE', 'FileType', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'FILE_TYPE', 'FileType', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'SOURCE', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'SOURCE', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'SOURCE', 'SOURCE', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'FILE_TYPE', 'FileType', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'FILE_TYPE', 'FileType', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'FILE_TYPE', 'FileType', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', 'TEXT', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', 'TEXT', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'FILETYPE_TEXT', 'TEXT', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'FILE_CHECKSUM', 'FileChecksum', 5)", "prediction_line": "    token_assert_helper(lexer.token(), 'FILE_CHECKSUM', 'FileChecksum', 5)", "ground_truth": "    token_assert_helper(lexer.token(), 'FILE_CHECKSUM', 'FileChecksum', 5)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SHA1', 'SHA1: 2fd4e1c67a2d28fced849ee1bb76e7391b93eb12', 5)", "prediction_line": "    token_assert_helper(lexer.token(), 'SHA1', 'SHA1: 2fd4e1c67a2d28fced849ee1bb76e7391b93eb12', 5)", "ground_truth": "    token_assert_helper(lexer.token(), 'CHECKSUM', 'SHA1: 2fd4e1c67a2d28fced849ee1bb76e7391b93eb12', 5)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LIC_CONCLUDED', 'LicenseConcluded', 6)", "prediction_line": "    token_assert_helper(lexer.token(), 'LIC_CONCLUDED', 'LicenseConcluded', 6)", "ground_truth": "    token_assert_helper(lexer.token(), 'FILE_LICS_CONC', 'LicenseConcluded', 6)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 6)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 6)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 6)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'FILE_LICS_INFO', 'LicenseInfoInFile', 7)", "prediction_line": "    token_assert_helper(lexer.token(), 'FILE_LICS_INFO', 'LicenseInfoInFile', 7)", "ground_truth": "    token_assert_helper(lexer.token(), 'FILE_LICS_INFO', 'LicenseInfoInFile', 7)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 7)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 7)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 7)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'FILE_COPYRIGHT', 'FileCopyrightText', 8)", "prediction_line": "    token_assert_helper(lexer.token(), 'FILE_COPYRIGHT', 'FileCopyrightText', 8)", "ground_truth": "    token_assert_helper(lexer.token(), 'FILE_CR_TEXT', 'FileCopyrightText', 8)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Copyright 2014 Acme Inc.</text>', 8)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Copyright 2014 Acme Inc.</text>', 8)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Copyright 2014 Acme Inc.</text>', 8)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'FILE_COMMENT', 'FileComment', 9)", "prediction_line": "    token_assert_helper(lexer.token(), 'FILE_COMMENT', 'FileComment', 9)", "ground_truth": "    token_assert_helper(lexer.token(), 'FILE_COMMENT', 'FileComment', 9)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Very long file</text>', 9)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Very long file</text>', 9)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Very long file</text>', 9)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'FILE_ATTRIBUTION_TEXT', 'FileAttributionText', 10)", "prediction_line": "    token_assert_helper(lexer.token(), 'FILE_ATTRIBUTION_TEXT', 'FileAttributionText', 10)", "ground_truth": "    token_assert_helper(lexer.token(), 'FILE_ATTRIBUTION_TEXT', 'FileAttributionText', 10)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Acknowledgements that might be required to be communicated in some contexts.</text>', 10)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Acknowledgements that might be required to be communicated in some contexts.</text>', 10)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT',", "line_class": "commited", "zero_context": true}
{"original_prediction": "   lexer.input(creation_str)", "prediction_line": "   lexer.input(creation_str)", "ground_truth": "    lexer.input(creation_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'CREATOR', 'Creator', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'CREATOR', 'Creator', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'CREATOR', 'Creator', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PERSON', 'Person: Bob (bob@example.com)', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'PERSON', 'Person: Bob (bob@example.com)', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'PERSON_VALUE', \"Person: Bob (bob@example.com)\", 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'CREATOR', 'Creator', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'CREATOR', 'Creator', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'CREATOR', 'Creator', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'ORG_VALUE', \"Organization: Acme.\", 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'ORG_VALUE', \"Organization: Acme.\", 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'ORG_VALUE', 'Organization: Acme.', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'CREATED', 'Created', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'CREATED', 'Created', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'CREATED', 'Created', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DATE', '2010-02-03T00:00:00Z', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'DATE', '2010-02-03T00:00:00Z', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'DATE', '2010-02-03T00:00:00Z', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'CREATOR_COMMENT', 'CreatorComment', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'CREATOR_COMMENT', 'CreatorComment', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'CREATOR_COMMENT', 'CreatorComment', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Sample Comment</text>', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Sample Comment</text>', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Sample Comment</text>', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    lexer.input(package_str)", "prediction_line": "    lexer.input(package_str)", "ground_truth": "    lexer.input(package_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_NAME', 'PackageName', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_NAME', 'PackageName', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_NAME', 'PackageName', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'Test', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'Test', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'Test', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-Package', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-Package', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-Package', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_VERSION', 'PackageVersion', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_VERSION', 'PackageVersion', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_VERSION', 'PackageVersion', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'Version 0.9.2', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'Version 0.9.2', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'Version 0.9.2', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_DOWNLOAD_LOC', 'PackageDownloadLocation', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_DOWNLOAD_LOC', 'PackageDownloadLocation', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_DOWN', 'PackageDownloadLocation', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'http://example.com/test', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'http://example.com/test', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'http://example.com/test', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_FILES_ANALYZED', 'FilesAnalyzed', 5)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_FILES_ANALYZED', 'FilesAnalyzed', 5)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_FILES_ANALYZED', 'FilesAnalyzed', 5)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'True', 5)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'True', 5)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'True', 5)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_SUMMARY', 'PackageSummary', 6)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_SUMMARY', 'PackageSummary', 6)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_SUM', 'PackageSummary', 6)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Test package</text>', 6)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Test package</text>', 6)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Test package</text>', 6)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_SOURCE_INFO', 'PackageSourceInfo', 7)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_SOURCE_INFO', 'PackageSourceInfo', 7)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_SRC_INFO', 'PackageSourceInfo', 7)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Version 1.0 of test</text>', 7)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Version 1.0 of test</text>', 7)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Version 1.0 of test</text>', 7)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_FILE_NAME', 'PackageFileName', 8)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_FILE_NAME', 'PackageFileName', 8)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_FILE_NAME', 'PackageFileName', 8)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'test-1.0.zip', 8)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'test-1.0.zip', 8)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'test-1.0.zip', 8)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_SUPPLIER', 'PackageSupplier', 9)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_SUPPLIER', 'PackageSupplier', 9)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_SUPPL', 'PackageSupplier', 9)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'ORG_VALUE', 'Organization:ACME', 9)", "prediction_line": "    token_assert_helper(lexer.token(), 'ORG_VALUE', 'Organization:ACME', 9)", "ground_truth": "    token_assert_helper(lexer.token(), 'ORG_VALUE', 'Organization:ACME', 9)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_ORIGINATOR', 'PackageOriginator', 10)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_ORIGINATOR', 'PackageOriginator', 10)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_ORIG', 'PackageOriginator', 10)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'ORG_VALUE', 'Organization:ACME', 10)", "prediction_line": "    token_assert_helper(lexer.token(), 'ORG_VALUE', 'Organization:ACME', 10)", "ground_truth": "    token_assert_helper(lexer.token(), 'ORG_VALUE', 'Organization:ACME', 10)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_CHKSUM', 'PackageChecksum', 11)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_CHKSUM', 'PackageChecksum', 11)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_CHECKSUM', 'PackageChecksum', 11)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'CHECKSUM', 'SHA1: 2fd4e1c67a2d28fced849ee1bb76e7391b93eb12', 11)", "prediction_line": "    token_assert_helper(lexer.token(), 'CHECKSUM', 'SHA1: 2fd4e1c67a2d28fced849ee1bb76e7391b93eb12', 11)", "ground_truth": "    token_assert_helper(lexer.token(), 'CHECKSUM', 'SHA1: 2fd4e1c67a2d28fced849ee1bb76e7391b93eb12', 11)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_VERIF_CODE', 'PackageVerificationCode', 12)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_VERIF_CODE', 'PackageVerificationCode', 12)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_VERF_CODE', 'PackageVerificationCode', 12)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_DESC', 'PackageDescription', 13)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_DESC', 'PackageDescription', 13)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_DESC', 'PackageDescription', 13)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>A package.</text>', 13)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>A package.</text>', 13)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>A package.</text>', 13)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_COMMENT', 'PackageComment', 14)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_COMMENT', 'PackageComment', 14)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_COMMENT', 'PackageComment', 14)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Comment on the package.</text>', 14)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Comment on the package.</text>', 14)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Comment on the package.</text>', 14)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_CR_TEXT', 'PackageCopyrightText', 15)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_CR_TEXT', 'PackageCopyrightText', 15)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_CPY_TEXT', 'PackageCopyrightText', 15)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text> Copyright 2014 Acme Inc.</text>', 15)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text> Copyright 2014 Acme Inc.</text>', 15)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text> Copyright 2014 Acme Inc.</text>', 15)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_LICS_DECL', 'PackageLicenseDeclared', 16)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_LICS_DECL', 'PackageLicenseDeclared', 16)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_LICS_DECL', 'PackageLicenseDeclared', 16)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 16)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 16)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 16)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_LICS_CONC', 'PackageLicenseConcluded', 17)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_LICS_CONC', 'PackageLicenseConcluded', 17)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_LICS_CONC', 'PackageLicenseConcluded', 17)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', '(LicenseRef-2.0 and Apache-2.0)', 17)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', '(LicenseRef-2.0 and Apache-2.0)', 17)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', '(LicenseRef-2.0 and Apache-2.0)', 17)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_LICS_INFO_FROM_FILES', 'PackageLicenseInfoFromFiles', 18)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_LICS_INFO_FROM_FILES', 'PackageLicenseInfoFromFiles', 18)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_LICS_FFILE', 'PackageLicenseInfoFromFiles', 18)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-1.0', 18)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-1.0', 18)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-1.0', 18)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_LICS_FFILE', 'PackageLicenseInfoFromFiles', 19)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_LICS_FFILE', 'PackageLicenseInfoFromFiles', 19)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_LICS_FFILE', 'PackageLicenseInfoFromFiles', 19)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 19)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 19)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 19)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_LICS_COMMENT', 'PackageLicenseComments', 20)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_LICS_COMMENT', 'PackageLicenseComments', 20)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_LICS_COMMENT', 'PackageLicenseComments', 20)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>License Comments</text>', 20)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>License Comments</text>', 20)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>License Comments</text>', 20)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'EXT_REF', 'ExternalRef', 21)", "prediction_line": "    token_assert_helper(lexer.token(), 'EXT_REF', 'ExternalRef', 21)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_EXT_REF', 'ExternalRef', 21)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_EXT_REF_COMMENT', 'ExternalRefComment', 22)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_EXT_REF_COMMENT', 'ExternalRefComment', 22)", "ground_truth": "    token_assert_helper(lexer.token(), 'PKG_EXT_REF_COMMENT', 'ExternalRefComment', 22)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Some comment about the package.</text>', 22)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Some comment about the package.</text>', 22)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Some comment about the package.</text>', 22)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PKG_PURP', 'PrimaryPackagePurpose', 23)", "prediction_line": "    token_assert_helper(lexer.token(), 'PKG_PURP', 'PrimaryPackagePurpose', 23)", "ground_truth": "    token_assert_helper(lexer.token(), 'PRIMARY_PACKAGE_PURPOSE', 'PrimaryPackagePurpose', 23)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'OPERATING-SYSTEM', 23)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'OPERATING-SYSTEM', 23)", "ground_truth": "    token_assert_helper(lexer.token(), 'OPERATING_SYSTEM', 'OPERATING-SYSTEM', 23)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'BUILT_DATE', 'BuiltDate', 24)", "prediction_line": "    token_assert_helper(lexer.token(), 'BUILT_DATE', 'BuiltDate', 24)", "ground_truth": "    token_assert_helper(lexer.token(), 'BUILT_DATE', 'BuiltDate', 24)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DATE', '2020-01-01T12:00:00Z', 24)", "prediction_line": "    token_assert_helper(lexer.token(), 'DATE', '2020-01-01T12:00:00Z', 24)", "ground_truth": "    token_assert_helper(lexer.token(), 'DATE', '2020-01-01T12:00:00Z', 24)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'RELEASE_DATE', 'ReleaseDate', 25)", "prediction_line": "    token_assert_helper(lexer.token(), 'RELEASE_DATE', 'ReleaseDate', 25)", "ground_truth": "    token_assert_helper(lexer.token(), 'RELEASE_DATE', 'ReleaseDate', 25)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DATE', '2021-01-01T12:00:00Z', 25)", "prediction_line": "    token_assert_helper(lexer.token(), 'DATE', '2021-01-01T12:00:00Z', 25)", "ground_truth": "    token_assert_helper(lexer.token(), 'DATE', '2021-01-01T12:00:00Z', 25)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'VALID_UNTIL_DATE', 'ValidUntilDate', 26)", "prediction_line": "    token_assert_helper(lexer.token(), 'VALID_UNTIL_DATE', 'ValidUntilDate', 26)", "ground_truth": "    token_assert_helper(lexer.token(), 'VALID_UNTIL_DATE', 'ValidUntilDate', 26)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DATE', '2022-01-01T12:00:00Z', 26)", "prediction_line": "    token_assert_helper(lexer.token(), 'DATE', '2022-01-01T12:00:00Z', 26)", "ground_truth": "    token_assert_helper(lexer.token(), 'DATE', '2022-01-01T12:00:00Z', 26)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    lexer.input(unknown_tag_str)", "prediction_line": "    lexer.input(unknown_tag_str)", "ground_truth": "    lexer.input(unknown_tag_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'UNKNOWN_TAG', 'SomeUnknownTag', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'UNKNOWN_TAG', 'SomeUnknownTag', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'UNKNOWN_TAG', 'SomeUnknownTag', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'UNKNOWN_VALUE', 'SomeUnknownValue', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'UNKNOWN_VALUE', 'SomeUnknownValue', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'SomeUnknownValue', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    lexer.input(snippet_str)", "prediction_line": "    lexer.input(snippet_str)", "ground_truth": "    lexer.input(snippet_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SNIPPET_SPDX_ID', 'SnippetSPDXID', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'SNIPPET_SPDX_ID', 'SnippetSPDXID', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'SNIPPET_SPDX_ID', 'SnippetSPDXID', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-Snippet', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-Snippet', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-Snippet', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SNIPPET_LICS_COMMENT', 'SnippetLicenseComments', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'SNIPPET_LICS_COMMENT', 'SnippetLicenseComments', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'SNIPPET_LICS_COMMENT', 'SnippetLicenseComments', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Some lic comment.</text>', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Some lic comment.</text>', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Some lic comment.</text>', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SNIPPET_CPY_TEXT', 'SnippetCopyrightText', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'SNIPPET_CPY_TEXT', 'SnippetCopyrightText', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'SNIPPET_CR_TEXT', 'SnippetCopyrightText', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text> Copyright 2008-2010 John Smith </text>', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text> Copyright 2008-2010 John Smith </text>', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text> Copyright 2008-2010 John Smith </text>', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SNIPPET_COMMENT', 'SnippetComment', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'SNIPPET_COMMENT', 'SnippetComment', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'SNIPPET_COMMENT', 'SnippetComment', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Some snippet comment.</text>', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Some snippet comment.</text>', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Some snippet comment.</text>', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SNIPPET_NAME', 'SnippetName', 5)", "prediction_line": "    token_assert_helper(lexer.token(), 'SNIPPET_NAME', 'SnippetName', 5)", "ground_truth": "    token_assert_helper(lexer.token(), 'SNIPPET_NAME', 'SnippetName', 5)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'from linux kernel', 5)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'from linux kernel', 5)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'from linux kernel', 5)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SNIPPET_FROM_FILE_SPDX_ID', 'SnippetFromFileSPDXID', 6)", "prediction_line": "    token_assert_helper(lexer.token(), 'SNIPPET_FROM_FILE_SPDX_ID', 'SnippetFromFileSPDXID', 6)", "ground_truth": "    token_assert_helper(lexer.token(), 'SNIPPET_FILE_SPDXID', 'SnippetFromFileSPDXID', 6)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DoapSource', 6)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DoapSource', 6)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DoapSource', 6)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SNIPPET_LICS_CONC', 'SnippetLicenseConcluded', 7)", "prediction_line": "    token_assert_helper(lexer.token(), 'SNIPPET_LICS_CONC', 'SnippetLicenseConcluded', 7)", "ground_truth": "    token_assert_helper(lexer.token(), 'SNIPPET_LICS_CONC',", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SNIPPET_LICS_INFO', 'LicenseInfoInSnippet', 8)", "prediction_line": "    token_assert_helper(lexer.token(), 'SNIPPET_LICS_INFO', 'LicenseInfoInSnippet', 8)", "ground_truth": "    token_assert_helper(lexer.token(), 'SNIPPET_LICS_INFO', 'LicenseInfoInSnippet', 8)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 8)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 8)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'Apache-2.0', 8)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SNIPPET_BYTE_RANGE', 'SnippetByteRange', 9)", "prediction_line": "    token_assert_helper(lexer.token(), 'SNIPPET_BYTE_RANGE', 'SnippetByteRange', 9)", "ground_truth": "    token_assert_helper(lexer.token(), 'SNIPPET_BYTE_RANGE', 'SnippetByteRange', 9)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', '310:420', 9)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', '310:420', 9)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', '310:420', 9)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SNIPPET_LINE_RANGE', 'SnippetLineRange', 10)", "prediction_line": "    token_assert_helper(lexer.token(), 'SNIPPET_LINE_RANGE', 'SnippetLineRange', 10)", "ground_truth": "    token_assert_helper(lexer.token(), 'SNIPPET_LINE_RANGE', 'SnippetLineRange', 10)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', '5:23', 10)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', '5:23', 10)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', '5:23', 10)", "line_class": "commited", "zero_context": true}
{"original_prediction": "   lexer.input(annotation_str)", "prediction_line": "   lexer.input(annotation_str)", "ground_truth": "    lexer.input(annotation_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'ANNOTATOR', 'Annotator', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'ANNOTATOR', 'Annotator', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'ANNOTATOR', 'Annotator', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'PERSON_VALUE', 'Person: Jane Doe()', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'PERSON_VALUE', 'Person: Jane Doe()', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'PERSON_VALUE', 'Person: Jane Doe()', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'ANNOTATION_DATE', 'AnnotationDate', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'ANNOTATION_DATE', 'AnnotationDate', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'ANNOTATION_DATE', 'AnnotationDate', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'DATE', '2010-01-29T18:30:22Z', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'DATE', '2010-01-29T18:30:22Z', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'DATE', '2010-01-29T18:30:22Z', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'ANNOTATION_COMMENT', 'AnnotationComment', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'ANNOTATION_COMMENT', 'AnnotationComment', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'ANNOTATION_COMMENT', 'AnnotationComment', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Document level annotation</text>', 3)", "prediction_line": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Document level annotation</text>', 3)", "ground_truth": "    token_assert_helper(lexer.token(), 'TEXT', '<text>Document level annotation</text>', 3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'ANNOTATION_TYPE', 'AnnotationType', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'ANNOTATION_TYPE', 'AnnotationType', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'ANNOTATION_TYPE', 'AnnotationType', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'OTHER', 'OTHER', 4)", "prediction_line": "    token_assert_helper(lexer.token(), 'OTHER', 'OTHER', 4)", "ground_truth": "    token_assert_helper(lexer.token(), 'OTHER', 'OTHER', 4)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'SPDX_REF', 'SPDXREF', 5)", "prediction_line": "    token_assert_helper(lexer.token(), 'SPDX_REF', 'SPDXREF', 5)", "ground_truth": "    token_assert_helper(lexer.token(), 'ANNOTATION_SPDX_ID', 'SPDXREF', 5)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DOCUMENT', 5)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DOCUMENT', 5)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DOCUMENT', 5)", "line_class": "commited", "zero_context": true}
{"original_prediction": "   lexer.input(relationship_str)", "prediction_line": "   lexer.input(relationship_str)", "ground_truth": "    lexer.input(relationship_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'RELATIONSHIP', 'Relationship', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'RELATIONSHIP', 'Relationship', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'RELATIONSHIP', 'Relationship', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DOCUMENT DESCRIBES NONE', 1)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DOCUMENT DESCRIBES NONE', 1)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'SPDXRef-DOCUMENT DESCRIBES NONE', 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'RELATIONSHIP_COMMENT', 'RelationshipComment', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'RELATIONSHIP_COMMENT', 'RelationshipComment', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'RELATIONSHIP_COMMENT', 'RelationshipComment', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    token_assert_helper(lexer.token(), 'LINE', 'This is a comment.', 2)", "prediction_line": "    token_assert_helper(lexer.token(), 'LINE', 'This is a comment.', 2)", "ground_truth": "    token_assert_helper(lexer.token(), 'LINE', 'This is a comment.', 2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    return lexer", "prediction_line": "    return lexer", "ground_truth": "    return lexer", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ExternalDocumentRef: <text>DocumentRef-spdx-tool-1.2</text>", "prediction_line": "    ExternalDocumentRef: <text>DocumentRef-spdx-tool-1.2</text>", "ground_truth": "    ExternalDocumentRef:DocumentRef-spdx-tool-2.1 http://spdx.org/spdxdocs/spdx-tools-v2.1-3F2504E0-4F89-41D3-9A0C-0305E82C3301 SHA1: d6a770ba38583ed4bb4525bd96e50461655d2759", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from spdx.creationinfo import CreationInfo", "prediction_line": "from spdx.creationinfo import CreationInfo", "ground_truth": "import pytest", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                        10)", "prediction_line": "                        10)", "ground_truth": "                        10)", "line_class": "random", "zero_context": true}
{"original_prediction": "        'PackageHomePage: http://example.com/test',", "prediction_line": "        'PackageHomePage: http://example.com/test',", "ground_truth": "        'PrimaryPackagePurpose: OPERATING-SYSTEM',", "line_class": "random", "zero_context": true}
{"original_prediction": "        'Created: 2014-09-13T00:00:00Z',", "prediction_line": "        'Created: 2014-09-13T00:00:00Z',", "ground_truth": "        'Creator: Organization: Acme.',", "line_class": "random", "zero_context": true}
{"original_prediction": "    data = '''", "prediction_line": "    data = '''", "ground_truth": "    file_str = '\\n'.join([", "line_class": "random", "zero_context": true}
{"original_prediction": "        'FileComment: <text>File comment</text>',", "prediction_line": "        'FileComment: <text>File comment</text>',", "ground_truth": "        'FileComment: <text>Very long file</text>',", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.current_element[\"license_id\"] = p[2]", "prediction_line": "        self.current_element[\"license_id\"] = p[2]", "ground_truth": "        self.construct_current_element()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        p[0] = get_spdx_licensing().get_license_by_id(p[1])", "prediction_line": "        p[0] = get_spdx_licensing().get_license_by_id(p[1])", "ground_truth": "        p[0] = get_spdx_licensing().parse(p[1])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.parser = yacc.yacc(module=self, debug=False, write_tables=False, **kwargs)", "prediction_line": "        self.parser = yacc.yacc(module=self, debug=False, write_tables=False, **kwargs)", "ground_truth": "        self.lex.build(reflags=re.UNICODE)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.logger.append(f\"Error while parsing SnippetFileSPDXID: Token did not match specified grammar rule. \"", "prediction_line": "        self.logger.append(f\"Error while parsing SnippetFileSPDXID: Token did not match specified grammar rule. \"", "ground_truth": "        self.logger.append(f\"Error while parsing SnippetFromFileSPDXID: Token did not match specified grammar rule. \"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.current_element[\"checksum\"] = Checksum(algorithm, value)", "prediction_line": "        self.current_element[\"checksum\"] = Checksum(algorithm, value)", "ground_truth": "        self.current_element.setdefault(\"checksums\", []).append(Checksum(algorithm, value))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.logger = Logger()", "prediction_line": "        self.logger = Logger()", "ground_truth": "        self.tokens = SPDXLexer.tokens", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.current_element[\"relationship_type\"] = RelationshipType[splitted_relationship[0]]", "prediction_line": "        self.current_element[\"relationship_type\"] = RelationshipType[splitted_relationship[0]]", "ground_truth": "        self.current_element[\"relationship_type\"] = RelationshipType[splitted_relationship[1]]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   def parse_file(self, file_path):", "prediction_line": "   def parse_file(self, file_path):", "ground_truth": "CLASS_MAPPING = dict(File=\"files\", Annotation=\"annotations\", Relationship=\"relationships\", Snippet=\"snippets\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.logger.append(f\"Error while parsing SnippetLicenseComments: Token did not match specified grammar rule. \"", "prediction_line": "        self.logger.append(f\"Error while parsing SnippetLicenseComments: Token did not match specified grammar rule. \"", "ground_truth": "        self.logger.append(f\"Error while parsing SnippetLicenseComments: Token did not match specified grammar rule. \"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.current_element[\"built_date\"] = datetime_from_str(p[2])", "prediction_line": "        self.current_element[\"built_date\"] = datetime_from_str(p[2])", "ground_truth": "        self.current_element[\"built_date\"] = datetime_from_str(p[2])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.current_element.setdefault(\"cross_ref\", []).append(p[2])", "prediction_line": "        self.current_element.setdefault(\"cross_ref\", []).append(p[2])", "ground_truth": "        self.current_element.setdefault(\"cross_references\", []).append(p[2])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.current_element[\"class\"] = Annotation", "prediction_line": "        self.current_element[\"class\"] = Annotation", "ground_truth": "        self.current_element[\"annotator\"] = ActorParser.parse_actor(p[2])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        algorithm = ChecksumAlgorithm[split_checksum[0]]", "prediction_line": "        algorithm = ChecksumAlgorithm[split_checksum[0]]", "ground_truth": "        algorithm = ChecksumAlgorithm[split_checksum[0]]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        p[0] = SpdxNone()", "prediction_line": "        p[0] = SpdxNone()", "ground_truth": "        p[0] = SpdxNone()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        external_package_ref = ExternalPackageRef(category, reference_type, locator, comment)", "prediction_line": "        external_package_ref = ExternalPackageRef(category, reference_type, locator, comment)", "ground_truth": "        external_package_ref = ExternalPackageRef(ExternalPackageRefCategory[category], reference_type, locator,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.current_element[\"verification_code\"] = VerificationCode(value, excluded_files)", "prediction_line": "        self.current_element[\"verification_code\"] = VerificationCode(value, excluded_files)", "ground_truth": "        self.current_element[\"verification_code\"] = PackageVerificationCode(value, excluded_files)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if class_name == Annotation:", "prediction_line": "            if class_name == Annotation:", "ground_truth": "            self.elements_build.setdefault(CLASS_MAPPING[class_name.__name__], []).append(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.logger.append(", "prediction_line": "        self.logger.append(", "ground_truth": "        self.logger.append(f\"Error while parsing LicenseConcluded in file: Token did not match specified grammar rule. \"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    @grammar_rule(\"spdx_version : SPDX_VERSION :'SPDXVersion' ':' SPDX_VERSION_VALUE\")", "prediction_line": "    @grammar_rule(\"spdx_version : SPDX_VERSION :'SPDXVersion' ':' SPDX_VERSION_VALUE\")", "ground_truth": "    # general parsing methods", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import sys\nimport os", "prediction_line": "import sys", "ground_truth": "from typing import Optional", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # is defined.", "prediction_line": "        # is defined.", "ground_truth": "        # information. If this is not the case the parser will behave unexpectedly as the spdx_ids are assigned falsy.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def p_file_lics_comment_2(self, p):", "prediction_line": "    def p_file_lics_comment_2(self, p):", "ground_truth": "    def p_file_lics_comment_2(self, p):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            self.creation_info[\"spdx_id\"] = p[2]", "prediction_line": "            self.creation_info[\"spdx_id\"] = p[2]", "ground_truth": "            self.creation_info[\"spdx_id\"] = p[2]", "line_class": "random", "zero_context": true}
{"original_prediction": "    @grammar_rule(\"creator : CREATOR LINE\")", "prediction_line": "    @grammar_rule(\"creator : CREATOR LINE\")", "ground_truth": "    @grammar_rule(\"ext_doc_ref : EXT_DOC_REF DOC_REF_ID DOC_URI EXT_DOC_REF_CHECKSUM\")", "line_class": "random", "zero_context": true}
{"original_prediction": "    @grammar_rule(\"pkg_supplier_values : PERSON_VALUE\\n | ORG_VALUE\\n | NOASSERTION\\n | NONE\")", "prediction_line": "    @grammar_rule(\"pkg_supplier_values : PERSON_VALUE\\n | ORG_VALUE\\n | NOASSERTION\\n | NONE\")", "ground_truth": "    @grammar_rule(\"pkg_supplier : PKG_SUPPL pkg_supplier_values\")", "line_class": "random", "zero_context": true}
{"original_prediction": "            return\n        self.current_element.setdefault(\"license_info_from_files\", []).append(p[2])", "prediction_line": "            return", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "    @grammar_rule(\"pkg_lic_decl : PKG_LICS_DECL error\")", "prediction_line": "    @grammar_rule(\"pkg_lic_decl : PKG_LICS_DECL error\")", "ground_truth": "    @grammar_rule(\"pkg_lic_decl : PKG_LICS_DECL error\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.p.parse(creation_str)", "prediction_line": "        self.p.parse(creation_str)", "ground_truth": "        document, _ = self.p.parse(self.complete_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.parser = Parser()", "prediction_line": "        self.parser = Parser()", "ground_truth": "        self.p = Parser()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    def test_parse_document(self):", "prediction_line": "    def test_parse_document(self):", "ground_truth": "        self.p.build()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        document, _ = self.p.parse(self.complete_str)", "prediction_line": "        document, _ = self.p.parse(self.complete_str)", "ground_truth": "        document, messages = self.p.parse(self.complete_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert spdx_file.checksums == [Checksum(ChecksumAlgorithm.SHA1,", "prediction_line": "        assert spdx_file.checksums == [Checksum(ChecksumAlgorithm.SHA1,", "ground_truth": "        assert spdx_file.license_info_in_file == [get_spdx_licensing().parse(\"Apache-2.0\")]", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert spdx_file.copyright_text == 'Copyright 2014 Acme Inc.'", "prediction_line": "        assert spdx_file.copyright_text == 'Copyright 2014 Acme Inc.'", "ground_truth": "        assert spdx_file.license_concluded == get_spdx_licensing().parse(\"Apache-2.0\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert snippet.license_concluded == get_spdx_licensing().parse(\"Apache-2.0\")", "prediction_line": "        assert snippet.license_concluded == get_spdx_licensing().parse(\"Apache-2.0\")", "ground_truth": "        assert snippet.license_concluded == get_spdx_licensing().parse('Apache-2.0')", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert snippet.license_info_in_snippet == [get_spdx_licensing().parse('Apache-2.0')]", "prediction_line": "        assert snippet.license_info_in_snippet == [get_spdx_licensing().parse('Apache-2.0')]", "ground_truth": "        assert snippet.license_info_in_snippet == [get_spdx_licensing().parse('Apache-2.0')]", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert package.license_info_from_files[0] == 'Apache-1.0'", "prediction_line": "        assert package.license_info_from_files[0] == 'Apache-1.0'", "ground_truth": "        assert package.license_concluded == get_spdx_licensing().parse('LicenseRef-2.0 AND Apache-2.0')", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert relationship.relationship_type == RelationshipType.DESCRIBES", "prediction_line": "        assert relationship.relationship_type == RelationshipType.DESCRIBES", "ground_truth": "        assert relationship.relationship_type == RelationshipType.DESCRIBES", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        assert annotation.annotation_type == AnnotationType.OTHER", "prediction_line": "        assert annotation.annotation_type == AnnotationType.OTHER", "ground_truth": "        assert annotation.annotation_type == AnnotationType.OTHER", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        assert spdx_file.file_type == [FileType.SOURCE, FileType.TEXT]", "prediction_line": "        assert spdx_file.file_type == [FileType.SOURCE, FileType.TEXT]", "ground_truth": "        assert spdx_file.file_type == [FileType.SOURCE, FileType.TEXT]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "[\n            Actor(type=ActorType.PERSON, name='Bob', email='bob@example.com'),", "prediction_line": "[", "ground_truth": "                                    [Actor(ActorType.PERSON, \"Bob\", \"bob@example.com\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                     Actor(ActorType.ORGANIZATION, \"Acme.\")])", "prediction_line": "                                     Actor(ActorType.ORGANIZATION, \"Acme.\")])", "ground_truth": "                                     Actor(ActorType.ORGANIZATION, \"Acme.\")])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        assert creation_info.license_list_version == '3.17'", "prediction_line": "        assert creation_info.license_list_version == '3.17'", "ground_truth": "        assert creation_info.license_list_version == Version(3, 17)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def test_package(self):", "prediction_line": "    def test_package(self):", "ground_truth": "        self.assertCountEqual(creation_info.external_document_refs, [ExternalDocumentRef(\"DocumentRef-spdx-tool-1.2\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                              [ExternalPackageRef(ExternalPackageRefCategory.SECURITY, 'cpe23Type',", "prediction_line": "                              [ExternalPackageRef(ExternalPackageRefCategory.SECURITY, 'cpe23Type',", "ground_truth": "                              [ExternalPackageRef(ExternalPackageRefCategory.SECURITY, \"cpe23Type\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                                                                         Checksum(ChecksumAlgorithm.SHA1,", "prediction_line": "                                                                                         Checksum(ChecksumAlgorithm.SHA1,", "ground_truth": "                                                                                         Checksum(ChecksumAlgorithm.SHA1,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                               ExternalPackageRef(ExternalPackageRefCategory.OTHER, \"LocationRef-acmeforge\",", "prediction_line": "                               ExternalPackageRef(ExternalPackageRefCategory.OTHER, \"LocationRef-acmeforge\",", "ground_truth": "                               ExternalPackageRef(ExternalPackageRefCategory.OTHER, \"LocationRef-acmeforge\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        assert package.package_purpose == PackagePurpose.OPERATING_SYSTEM", "prediction_line": "        assert package.package_purpose == PackagePurpose.OPERATING_SYSTEM", "ground_truth": "        assert package.primary_package_purpose == PackagePurpose.OPERATING_SYSTEM", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from spdx.model.review import ReviewType", "prediction_line": "from spdx.model.review import ReviewType", "ground_truth": "from spdx.model.version import Version", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "])\n\nsnippet_str = '\\n'.join([", "prediction_line": "])", "ground_truth": "])", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from spdx.creationinfo import CreationInfo", "prediction_line": "from spdx.creationinfo import CreationInfo", "ground_truth": "from license_expression import get_spdx_licensing", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# SPDX-License-Identifier: CC-BY-4.0", "prediction_line": "# SPDX-License-Identifier: CC-BY-4.0", "ground_truth": "# Licensed under the Apache License, Version 2.0 (the \"License\");", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        snippet = document.snippets[0]", "prediction_line": "        snippet = document.snippets[0]", "ground_truth": "        snippet = document.snippets[0]", "line_class": "random", "zero_context": true}
{"original_prediction": "    'PackageLicenseComments: <text>Comment on the license.</text>',", "prediction_line": "    'PackageLicenseComments: <text>Comment on the license.</text>',", "ground_truth": "    'PackageLicenseComments: <text>License Comments</text>',", "line_class": "random", "zero_context": true}
{"original_prediction": "        extracted_licensing_info = document.extracted_licensing_info", "prediction_line": "        extracted_licensing_info = document.extracted_licensing_info", "ground_truth": "        assert len(document.extracted_licensing_info) == 1", "line_class": "random", "zero_context": true}
{"original_prediction": "        assert package.valid_until == datetime(2022, 1, 1, 12, 0, 0)", "prediction_line": "        assert package.valid_until == datetime(2022, 1, 1, 12, 0, 0)", "ground_truth": "        assert package.valid_until_date == datetime(2022, 1, 1, 12, 0, 0)", "line_class": "random", "zero_context": true}
{"original_prediction": "class TestParser(TestCase):", "prediction_line": "class TestParser(TestCase):", "ground_truth": "creation_str = '\\n'.join([", "line_class": "random", "zero_context": true}
{"original_prediction": "NERSample(\n                            chunk=' '.join(curr_chunk),", "prediction_line": "NERSample(", "ground_truth": "                            NERSample(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            unique_entities = list(set(", "prediction_line": "            unique_entities = list(set(", "ground_truth": "            unique_entities = self.__get_unique_entities()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            entity_instances_mx = self.__get_entity_instances_mx()", "prediction_line": "            entity_instances_mx = self.__get_entity_instances_mx()", "ground_truth": "            entity_instances_mx = self.__create_ent_instance_mx()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            spark_data.append(NERDataHandler.samples_to_spark_rows(sentence_sample))", "prediction_line": "            spark_data.append(NERDataHandler.samples_to_spark_rows(sentence_sample))", "ground_truth": "            sentence_rows = self.samples_to_spark_rows(sentence_sample)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            data: List[NERSample],", "prediction_line": "            data: List[NERSample],", "ground_truth": "            data_container: List[List[NERSample]],", "line_class": "infile", "zero_context": true}
{"original_prediction": "       \"\"\"\n        self.chunk = chunk", "prediction_line": "       \"\"\"", "ground_truth": "        \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            A deep copy of the NERDataHandler instance.", "prediction_line": "            A deep copy of the NERDataHandler instance.", "ground_truth": "            A deep copy of the NERDataHandler instance.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"Create entity instances matrix.\"\"\"", "prediction_line": "        \"\"\"Create entity instances matrix.\"\"\"", "ground_truth": "        \"\"\"Create entity instance matrix to optimize filtering and keeping track of entity instances.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        with open(filepath, 'r') as f:", "prediction_line": "        with open(filepath, 'r') as f:", "ground_truth": "        curr_sentence = []", "line_class": "random", "zero_context": true}
{"original_prediction": "        if entity_instances_mx is None:", "prediction_line": "        if entity_instances_mx is None:", "ground_truth": "        self.label2id = {label: i for i, label in enumerate(self.entities)}", "line_class": "random", "zero_context": true}
{"original_prediction": "        chunk_pos_tags = self.pos_tags", "prediction_line": "        chunk_pos_tags = self.pos_tags", "ground_truth": "        for i in range(len(self)):", "line_class": "random", "zero_context": true}
{"original_prediction": "                entity_instances[sent_indx, token_indx] += 1", "prediction_line": "                entity_instances[sent_indx, token_indx] += 1", "ground_truth": "                entity_instances[sent_indx][token_indx] += 1", "line_class": "random", "zero_context": true}
{"original_prediction": "        for sent_indx, sent_samples in enumerate(self.data_container):", "prediction_line": "        for sent_indx, sent_samples in enumerate(self.data_container):", "ground_truth": "        for sentence_sample in self.data_container:", "line_class": "random", "zero_context": true}
{"original_prediction": "                    NERPrediction(entity=\"PROD\", span=Span(start=40, end=43, word=\"KFC\")),", "prediction_line": "                    NERPrediction(entity=\"PROD\", span=Span(start=40, end=43, word=\"KFC\")),", "ground_truth": "                    NERPrediction(entity=\"PROD\", span=Span(start=44, end=47, word=\"KFC\")),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    original_span=Span(start=39, end=39, word=\"\"),", "prediction_line": "                    original_span=Span(start=39, end=39, word=\"\"),", "ground_truth": "                    original_span=Span(start=33, end=33, word=\"\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=14, end=17, word=\"KFC\"))]", "prediction_line": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=14, end=17, word=\"KFC\"))]", "ground_truth": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=12, end=15, word=\"KFC\"))]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=10, end=13, word=\"KFC\"))]", "prediction_line": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=10, end=13, word=\"KFC\"))]", "ground_truth": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=14, end=17, word=\"KFC\"))]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    original_span=Span(start=4, end=7, word=\"not\"),", "prediction_line": "                    original_span=Span(start=4, end=7, word=\"not\"),", "ground_truth": "                    original_span=Span(start=4, end=8, word=\" not\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=17, end=20, word=\"KFC\"))]", "prediction_line": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=17, end=20, word=\"KFC\"))]", "ground_truth": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=23, end=26, word=\"KFC\"))]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    new_span=Span(start=33, end=39, word=\"a good \"),", "prediction_line": "                    new_span=Span(start=33, end=39, word=\"a good \"),", "ground_truth": "                    new_span=Span(start=33, end=40, word=\"a good \"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    ignore=True", "prediction_line": "                    ignore=True", "ground_truth": "                    ignore=True", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                Transformation(", "prediction_line": "                Transformation(", "ground_truth": "                Transformation(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=10, end=13, word=\"KFC\"))]", "prediction_line": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=10, end=13, word=\"KFC\"))]", "ground_truth": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=10, end=13, word=\"KFC\"))]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    original_span=Span(start=13, end=13, word=\"\"),", "prediction_line": "                    original_span=Span(start=13, end=13, word=\"\"),", "ground_truth": "                    original_span=Span(start=13, end=13, word=\"\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=10, end=13, word=\"KFC\"))]", "prediction_line": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=10, end=13, word=\"KFC\"))]", "ground_truth": "                predictions=[NERPrediction(entity=\"PROD\", span=Span(start=16, end=19, word=\"KFC\"))]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    new_span=Span(start=13, end=18, word=\" Bye\"),", "prediction_line": "                    new_span=Span(start=13, end=18, word=\" Bye\"),", "ground_truth": "                    new_span=Span(start=13, end=17, word=\" Bye\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def test_entity_swap_with_context(self):", "prediction_line": "    def test_entity_swap_with_context(self):", "ground_truth": "        sample = Sample(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    original_span=Span(start=10, end=13, word=\"KFC\"),", "prediction_line": "                    original_span=Span(start=10, end=13, word=\"KFC\"),", "ground_truth": "                    original_span=Span(start=10, end=13, word=\"KFC\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def test_sample_init(self):", "prediction_line": "    def test_sample_init(self):", "ground_truth": "    def test_add_context_left(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_add_context_both(self):", "prediction_line": "    def test_add_context_both(self):", "ground_truth": "    def test_add_context_middle(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"\"\"\"", "prediction_line": "        \"\"\"\"\"\"", "ground_truth": "        \"\"\"\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_add_context_multiple(self):", "prediction_line": "    def test_add_context_multiple(self):", "ground_truth": "    def test_add_two_contexts(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ",\n                )\n            ],", "prediction_line": ",", "ground_truth": "                )", "line_class": "random", "zero_context": true}
{"original_prediction": "            test_case=\"I do love KFC\",", "prediction_line": "            test_case=\"I do love KFC\",", "ground_truth": "            test_case=\"I do love KFC\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        assert realigned_actual_results == sample.expected_results.predictions", "prediction_line": "        assert realigned_actual_results == sample.expected_results.predictions", "ground_truth": "        assert realigned_actual_results == sample.expected_results.predictions", "line_class": "random", "zero_context": true}
{"original_prediction": "            ],\n            expected_results=NEROutput(", "prediction_line": "            ],", "ground_truth": "            ],", "line_class": "random", "zero_context": true}
{"original_prediction": "            return cls(nlp.load(path))", "prediction_line": "            return cls(nlp.load(path))", "ground_truth": "            loaded_model = nlp.load(path)", "line_class": "common", "zero_context": true}
{"original_prediction": "            raise ImportError('johnsnowlabs is not installed.')", "prediction_line": "            raise ImportError('johnsnowlabs is not installed.')", "ground_truth": "            loaded_model = PipelineModel.load(path)", "line_class": "common", "zero_context": true}
{"original_prediction": "            start=pred.metadata['start'],", "prediction_line": "            start=pred.metadata['start'],", "ground_truth": "            start=pred.begin,", "line_class": "common", "zero_context": true}
{"original_prediction": "            if isinstance(annotator, NerDLModel):", "prediction_line": "            if isinstance(annotator, NerDLModel):", "ground_truth": "            if self.is_instance_supported(annotator):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return [NEROutput(entity=entity.result,", "prediction_line": "        return [NEROutput(entity=entity.result,", "ground_truth": "        return [NEROutput(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return SequenceClassificationOutput(", "prediction_line": "        return SequenceClassificationOutput(", "ground_truth": "        return SequenceClassificationOutput(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            label=prediction.result,", "prediction_line": "            label=prediction.result,", "ground_truth": "            labels=prediction[0]['class'][0].result", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                The model to use for inference.", "prediction_line": "                The model to use for inference.", "ground_truth": "                Loaded SparkNLP Light Pipeline for inference.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def predict(self, text: str) -> List[SequenceClassificationOutput]:", "prediction_line": "    def predict(self, text: str) -> List[SequenceClassificationOutput]:", "ground_truth": "    def predict(self, text: str) -> SequenceClassificationOutput:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    from sparknlp.annotator import *", "prediction_line": "    from sparknlp.annotator import *", "ground_truth": "    from johnsnowlabs import nlp", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        #   we need to find the ner model", "prediction_line": "        #   we need to find the ner model", "ground_truth": "        #   but at first I will set first as default one. Later we can adjust Harness to test multiple model", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        XlnetForTokenClassification,", "prediction_line": "        XlnetForTokenClassification,", "ground_truth": "        XlnetForTokenClassification,", "line_class": "random", "zero_context": true}
{"original_prediction": "            _pipeline = nlp.Pipeline().setStages(stages)", "prediction_line": "            _pipeline = nlp.Pipeline().setStages(stages)", "ground_truth": "            _pipeline = nlp.Pipeline().setStages(stages)", "line_class": "random", "zero_context": true}
{"original_prediction": "                break\n\n        if ner_model is None:", "prediction_line": "                break", "ground_truth": "                break", "line_class": "random", "zero_context": true}
{"original_prediction": "            raise ValueError(f'Invalid SparkNLP model object: {type(model)}. '", "prediction_line": "            raise ValueError(f'Invalid SparkNLP model object: {type(model)}. '", "ground_truth": "            raise ValueError('Invalid model for JSL.')", "line_class": "random", "zero_context": true}
{"original_prediction": "        for test in tests:", "prediction_line": "        for test in tests:", "ground_truth": "        for test in tests:", "line_class": "common", "zero_context": true}
{"original_prediction": "           self._tests[test] = PERTURB_CLASS_MAP[test](data_handler)", "prediction_line": "           self._tests[test] = PERTURB_CLASS_MAP[test](data_handler)", "ground_truth": "            if isinstance(test, str):", "line_class": "common", "zero_context": true}
{"original_prediction": "                test = test.lower()", "prediction_line": "                test = test.lower()", "ground_truth": "                if test not in DEFAULT_PERTURBATIONS:", "line_class": "common", "zero_context": true}
{"original_prediction": "f\"{test} is not a valid perturbation\")", "prediction_line": "f\"{test} is not a valid perturbation\")", "ground_truth": "                        f'Invalid test specification: {test}. Available tests are: {DEFAULT_PERTURBATIONS}')", "line_class": "common", "zero_context": true}
{"original_prediction": "                test = PERTURB_CLASS_MAP[test]", "prediction_line": "                test = PERTURB_CLASS_MAP[test]", "ground_truth": "                self._tests[test] = dict()", "line_class": "common", "zero_context": true}
{"original_prediction": "            elif isinstance(test, dict):", "prediction_line": "            elif isinstance(test, dict):", "ground_truth": "            elif isinstance(test, dict):", "line_class": "common", "zero_context": true}
{"original_prediction": "                if test['name'] not in DEFAULT_PERTURBATIONS:", "prediction_line": "                if test['name'] not in DEFAULT_PERTURBATIONS:", "ground_truth": "                test_name = list(test.keys())[0]", "line_class": "common", "zero_context": true}
{"original_prediction": "                self._tests[test_name] = test[test_name]", "prediction_line": "                self._tests[test_name] = test[test_name]", "ground_truth": "                self._tests[test_name] = reduce(lambda x, y: {**x, **y}, test[test_name])", "line_class": "common", "zero_context": true}
{"original_prediction": "                    if char in char_list:", "prediction_line": "                    if char in char_list:", "ground_truth": "                    if TYPO_FREQUENCY.get(char.lower(), None):", "line_class": "common", "zero_context": true}
{"original_prediction": "            if token in CONTRACTION_MAP:", "prediction_line": "            if token in CONTRACTION_MAP:", "ground_truth": "            contracted_token = CONTRACTION_MAP.get(token, CONTRACTION_MAP.get(token.lower()))", "line_class": "common", "zero_context": true}
{"original_prediction": "            converted_tokens = [accent_map.get(token, token) for token in tokens]", "prediction_line": "            converted_tokens = [accent_map.get(token, token) for token in tokens]", "ground_truth": "            tokens = [accent_map[t.lower()] if accent_map.get(t.lower(), None) else t for t in tokens]", "line_class": "common", "zero_context": true}
{"original_prediction": "            replaced_string = sample.original.replace(replace_token, get_cohyponyms_wordnet(replace_token))", "prediction_line": "            replaced_string = sample.original.replace(replace_token, get_cohyponyms_wordnet(replace_token))", "ground_truth": "            chosen_ent = get_cohyponyms_wordnet(replace_token)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            test_class = PERTURB_CLASS_MAP[test_name]", "prediction_line": "            test_class = PERTURB_CLASS_MAP[test_name]", "ground_truth": "            transformed_samples = globals()[PERTURB_CLASS_MAP[test_name]].transform(data_handler_copy, **params)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    string = re.sub(contraction, custom_replace, string, flags=re.IGNORECASE | re.DOTALL)", "prediction_line": "                    string = re.sub(contraction, custom_replace, string, flags=re.IGNORECASE | re.DOTALL)", "ground_truth": "                    string = re.sub(contraction, custom_replace, sample.original, flags=re.IGNORECASE | re.DOTALL)", "line_class": "infile", "zero_context": true}
{"original_prediction": "sample_list: List[Sample]) -> List[Sample]:", "prediction_line": "sample_list: List[Sample]) -> List[Sample]:", "ground_truth": "            sample_list: List[Sample],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            terminology: Dict[str, List[str]],", "prediction_line": "            terminology: Dict[str, List[str]],", "ground_truth": "            labels: List[List[str]] = None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if labels is None:", "prediction_line": "        if labels is None:", "ground_truth": "        if labels is None:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        new_span=Span(start=to_start, end=to_end, word=add_string),", "prediction_line": "                        new_span=Span(start=to_start, end=to_end, word=add_string),", "ground_truth": "                        new_span=Span(start=to_start, end=to_end, word=string[to_start:to_end]),", "line_class": "inproject", "zero_context": true}
{"original_prediction": ",\n            **kwargs", "prediction_line": ",", "ground_truth": "    ) -> List[Sample]:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        ignore=True", "prediction_line": "                        ignore=True", "ground_truth": "                        ignore=True", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            sent_labels = labels[idx]", "prediction_line": "            sent_labels = labels[idx]", "ground_truth": "            sent_labels = labels[idx]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            perturbations: List[Transformation] = DEFAULT_PERTURBATIONS,", "prediction_line": "            perturbations: List[Transformation] = DEFAULT_PERTURBATIONS,", "ground_truth": "            data_handler: List[Sample],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self._tests['swap_entities']['terminology'] = create_terminology(df, 'label')", "prediction_line": "            self._tests['swap_entities']['terminology'] = create_terminology(df, 'label')", "ground_truth": "            self._tests['swap_entities']['terminology'] = create_terminology(df)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            test_class = PERTURB_CLASS_MAP[test_name]", "prediction_line": "            test_class = PERTURB_CLASS_MAP[test_name]", "ground_truth": "            data_handler_copy = [x.copy() for x in self._data_handler]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "Transformation(\n                    transformation_type=\"add_starting_context\",", "prediction_line": "Transformation(", "ground_truth": "                    Transformation(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        transformation_type=\"add_context\",", "prediction_line": "                        transformation_type=\"add_context\",", "ground_truth": "                        original_span=Span(start=0, end=0, word=\"\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        transformed_span=Span(start=0, end=len(add_tokens) - 1, word=add_string),", "prediction_line": "                        transformed_span=Span(start=0, end=len(add_tokens) - 1, word=add_string),", "ground_truth": "                        new_span=Span(start=0, end=len(add_string) + 1, word=add_string),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        original_span=Span(start=from_start, end=from_end, word=\"\"),", "prediction_line": "                        original_span=Span(start=from_start, end=from_end, word=\"\"),", "ground_truth": "                        original_span=Span(start=from_start, end=from_end, word=\"\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "class SwapEntities(BaseRobustness):", "prediction_line": "class SwapEntities(BaseRobustness):", "ground_truth": "class AddPunctuation(BaseRobustness):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            if len(ent_idx) == 0:", "prediction_line": "            if len(ent_idx) == 0:", "ground_truth": "            #  no swaps since there is no entity in the sentence", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            labels: Corresponding labels to make changes according to sentences.", "prediction_line": "            labels: Corresponding labels to make changes according to sentences.", "ground_truth": "            labels: Corresponding labels to make changes according to sentences.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "           if contracted_token is None:", "prediction_line": "           if contracted_token is None:", "ground_truth": "            is_upper_case = token[0]", "line_class": "random", "zero_context": true}
{"original_prediction": "                string = re.sub(contraction, custom_replace, string)", "prediction_line": "                string = re.sub(contraction, custom_replace, string)", "ground_truth": "                if re.search(contraction, sample.original, flags=re.IGNORECASE | re.DOTALL):", "line_class": "random", "zero_context": true}
{"original_prediction": "            if len(proper_entities) == 0:", "prediction_line": "            if len(proper_entities) == 0:", "ground_truth": "            chosen_ent = random.choice(proper_entities)", "line_class": "random", "zero_context": true}
{"original_prediction": "            else:\n                sample.test_case = sample.original", "prediction_line": "            else:", "ground_truth": "            else:", "line_class": "random", "zero_context": true}
{"original_prediction": "   \"\"\"\n    Base class for robustness tests.", "prediction_line": "   \"\"\"", "ground_truth": "    @staticmethod", "line_class": "random", "zero_context": true}
{"original_prediction": "                if item in norm_original_items:", "prediction_line": "                if item in norm_original_items:", "ground_truth": "                if item in norm_original_items and jdx >= norm_original_items.index(item):", "line_class": "common", "zero_context": true}
{"original_prediction": "                    oitem_index = norm_original_items.index(item)", "prediction_line": "                    oitem_index = norm_original_items.index(item)", "ground_truth": "                    oitem_index = norm_original_items.index(item)", "line_class": "common", "zero_context": true}
{"original_prediction": "        if isinstance(sample.results, SequenceClassificationOutput):", "prediction_line": "        if isinstance(sample.results, SequenceClassificationOutput):", "ground_truth": "        formats = {cls.__name__: cls for cls in BaseFormatter.__subclasses__()}", "line_class": "infile", "zero_context": true}
{"original_prediction": "            original = test_case", "prediction_line": "            original = test_case", "ground_truth": "            return f\"{test_case}{delimiter}{sample.expected_results.to_str_list()[0]}\\n\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return f\"{original}{delimiter}{sample.expected_results.to_str_list()[0]}\\n\"", "prediction_line": "            return f\"{original}{delimiter}{sample.expected_results.to_str_list()[0]}\\n\"", "ground_truth": "            return f\"{original}{delimiter}{sample.expected_results.to_str_list()[0]}\\n\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    Returns:\n        The CSV string representation of the `SequenceClassificationOutput` object.", "prediction_line": "    Returns:", "ground_truth": "    Returns:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   \"\"\"\n    Base class for all formatters.", "prediction_line": "   \"\"\"", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    Raises:", "prediction_line": "    Raises:", "ground_truth": "        format: The output format to convert to, either \"csv\" or \"conll\".", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            for i, item in enumerate(test_case_items):", "prediction_line": "            for i, item in enumerate(test_case_items):", "ground_truth": "            for jdx, item in enumerate(norm_test_case_items):", "line_class": "random", "zero_context": true}
{"original_prediction": "            raise NameError(f\"No formatter defined for {class_name}.\")", "prediction_line": "            raise NameError(f\"No formatter defined for {class_name}.\")", "ground_truth": "            raise NameError(f\"Class '{class_name}Formatter' not yet implemented.\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        if class_name not in formats:", "prediction_line": "        if class_name not in formats:", "ground_truth": "        try:", "line_class": "random", "zero_context": true}
{"original_prediction": "            text+=\"\\n\"", "prediction_line": "            text+=\"\\n\"", "ground_truth": "            text+=\"\\n\"", "line_class": "random", "zero_context": true}
{"original_prediction": "            text = \" \".join(test_case_items[:-1])", "prediction_line": "            text = \" \".join(test_case_items[:-1])", "ground_truth": "            norm_test_case_items = test_case.lower().split()", "line_class": "random", "zero_context": true}
{"original_prediction": "        self._session, self._s3, self._s3_ctx = self._async.run(setup, s3_cfg)", "prediction_line": "        self._session, self._s3, self._s3_ctx = self._async.run(setup, s3_cfg)", "ground_truth": "        session, s3, s3_ctx = self._async.submit(setup, s3_cfg).result()", "line_class": "commited", "zero_context": true}
{"original_prediction": "       self._region_name = region_name", "prediction_line": "       self._region_name = region_name", "ground_truth": "        async def setup(s3_cfg):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            for d in o.get(\"CommonPrefixes\", []):", "prediction_line": "            for d in o.get(\"CommonPrefixes\", []):", "ground_truth": "            for d in o.get(\"CommonPrefixes\", []):", "line_class": "common", "zero_context": true}
{"original_prediction": "    return result(data=data, last_modified=obj.get(\"LastModified\", None))", "prediction_line": "    return result(data=data, last_modified=obj.get(\"LastModified\", None))", "ground_truth": "    last_modified = obj.get(\"LastModified\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "            last_modified=rr.get(\"LastModified\", None),", "prediction_line": "            last_modified=rr.get(\"LastModified\", None),", "ground_truth": "            size=rr.get(\"ContentLength\", 0),", "line_class": "common", "zero_context": true}
{"original_prediction": "            last_modified=rr.get(\"LastModified\", None),", "prediction_line": "            last_modified=rr.get(\"LastModified\", None),", "ground_truth": "            etag=rr.get(\"ETag\", \"\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "            last_modified=rr.get(\"LastModified\", None),", "prediction_line": "            last_modified=rr.get(\"LastModified\", None),", "ground_truth": "            last_modified=rr.get(\"LastModified\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "        )\n\n    bucket, key = s3_url_parse(url)", "prediction_line": "        )", "ground_truth": "            expiration=rr.get(\"Expiration\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "                d = d.get(\"Prefix\")", "prediction_line": "                d = d.get(\"Prefix\")", "ground_truth": "                d = d.get(\"Prefix\")", "line_class": "common", "zero_context": true}
{"original_prediction": "       nonlocal work_q", "prediction_line": "       nonlocal work_q", "ground_truth": "        x = await work_q.get()", "line_class": "common", "zero_context": true}
{"original_prediction": "        n_total += 1", "prediction_line": "        n_total += 1", "ground_truth": "        for f in o.get(\"Contents\", []):", "line_class": "common", "zero_context": true}
{"original_prediction": "    except botocore.exceptions.ClientError as e:", "prediction_line": "    except botocore.exceptions.ClientError as e:", "ground_truth": "        stream = obj.get(\"Body\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "            )\n            return s3_ctx", "prediction_line": "            )", "ground_truth": "                endpoint_url=os.environ.get(\"AWS_S3_ENDPOINT\"),", "line_class": "common", "zero_context": true}
{"original_prediction": "            return await s3_dir(url, s3, **kw)", "prediction_line": "            return await s3_dir(url, s3, **kw)", "ground_truth": "            return await s3_dir(url, s3=s3, **kw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            await s3_dir_dir(url, depth, work_q, s3=s3, pred=pred, **kw)", "prediction_line": "            await s3_dir_dir(url, depth, work_q, s3=s3, pred=pred, **kw)", "ground_truth": "            _files = await s3_find(url, s3=s3, pred=pred, glob=glob)", "line_class": "infile", "zero_context": true}
{"original_prediction": "url, s3, glob, **kw):", "prediction_line": "url, s3, glob, **kw):", "ground_truth": "    glob_pattern: str, skip_check: bool = False, s3: Optional[S3Fetcher] = None, **kw", "line_class": "infile", "zero_context": true}
{"original_prediction": "            await s3.__aexit__(None, None, None)", "prediction_line": "            await s3.__aexit__(None, None, None)", "ground_truth": "            await s3.close()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            _s3_fetch_object, url, s3=self._s3, _range=_range, **kw", "prediction_line": "            _s3_fetch_object, url, s3=self._s3, _range=_range, **kw", "ground_truth": "            _s3_fetch_object, url, s3=self._s3, range=_range, **kw", "line_class": "infile", "zero_context": true}
{"original_prediction": "        yield from do_dir_query(qq, dirs_pred=qq.pred)", "prediction_line": "        yield from do_dir_query(qq, dirs_pred=qq.pred)", "ground_truth": "        stream = s3.find(qq.base, **kw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        s3 = S3Fetcher()", "prediction_line": "        s3 = S3Fetcher()", "ground_truth": "        s3 = S3Fetcher()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                await s3_dir_dir(url, depth, q, s3=s3, pred=pred, **kw)", "prediction_line": "                await s3_dir_dir(url, depth, q, s3=s3, pred=pred, **kw)", "ground_truth": "                await s3_dir_dir(url, depth, q, s3, pred=pred, **kw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "generate_requests(urls, self._s3, **kw)):", "prediction_line": "generate_requests(urls, self._s3, **kw)):", "ground_truth": "            generate_requests(urls, self._s3, **kw), self._nconcurrent * 2", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def s3_head_object_async(url, s3, **kw):", "prediction_line": "async def s3_head_object_async(url, s3, **kw):", "ground_truth": "async def s3_dir(url, s3, pred=None, glob=None, **kw):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        raise ValueError(f\"Unknown action: {action}\")", "prediction_line": "                        raise ValueError(f\"Unknown action: {action}\")", "ground_truth": "                        raise ValueError(f\"Expect skip|dir|deep got: {action}\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.close()", "prediction_line": "        self.close()", "ground_truth": "        self.close()", "line_class": "infile", "zero_context": true}
{"original_prediction": "       for d in s3.dir_dir(qq.base, qq.depth, pred=dirs_pred, **kw):", "prediction_line": "       for d in s3.dir_dir(qq.base, qq.depth, pred=dirs_pred, **kw):", "ground_truth": "        stream = s3.dir_dir(qq.base, qq.depth, pred=dirs_pred, **kw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return future_results(step, nconcurrent)", "prediction_line": "    return future_results(step, nconcurrent)", "ground_truth": "    return step", "line_class": "infile", "zero_context": true}
{"original_prediction": "   except Exception as e:  # pylint:disable=broad-except", "prediction_line": "   except Exception as e:  # pylint:disable=broad-except", "ground_truth": "    return (unpack(url, rr), None)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            _dirs, _files = await s3_dir(url, s3, pred=pred, glob=glob, **kw)", "prediction_line": "            _dirs, _files = await s3_dir(url, s3, pred=pred, glob=glob, **kw)", "ground_truth": "            _dirs, _files = await s3_dir(url, s3=s3, pred=pred, glob=glob, **kw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            clean_exit = True", "prediction_line": "            clean_exit = True", "ground_truth": "            raise_error = not ff.result()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        async def _list_dir(url, s3, **kw):", "prediction_line": "        async def _list_dir(url, s3, **kw):", "ground_truth": "        async def action(url, s3, **kw):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            stream = do_file_query(qq, pred, dirs_pred=dirs_pred)", "prediction_line": "            stream = do_file_query(qq, pred, dirs_pred=dirs_pred)", "ground_truth": "            stream = do_file_query(qq, pred, dirs_pred=dirs_pred)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        guide = default_guide", "prediction_line": "        guide = default_guide", "ground_truth": "        guide = default_guide", "line_class": "infile", "zero_context": true}
{"original_prediction": "        rr = await s3.head_object(Bucket=bucket, Key=key, **kw)", "prediction_line": "        rr = await s3.head_object(Bucket=bucket, Key=key, **kw)", "ground_truth": "        rr = await s3.head_object(Bucket=bucket, Key=key, **kw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    await work_q.put((d, depth, action))", "prediction_line": "                    await work_q.put((d, depth, action))", "ground_truth": "                    work_q.put_nowait((d, depth, action))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self._closed:", "prediction_line": "        if self._closed:", "ground_truth": "        async def _close(s3):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                action = guide(d, depth, url)", "prediction_line": "                action = guide(d, depth, url)", "ground_truth": "                action = guide(d, depth=depth, base=url)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"Find directories certain depth from the base", "prediction_line": "        \"\"\"Find directories certain depth from the base", "ground_truth": "        async def action(q, s3, **kw):", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def s3_find_one(url, s3, pred=None, glob=None, **kw):", "prediction_line": "async def s3_find_one(url, s3, pred=None, glob=None, **kw):", "ground_truth": "async def s3_head_object(url, s3, **kw):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        elif action == \"deep\":", "prediction_line": "        elif action == \"deep\":", "ground_truth": "        elif action == \"deep\":", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for f in s3.find(d, pred=pred, **kw):", "prediction_line": "            for f in s3.find(d, pred=pred, **kw):", "ground_truth": "            _, _files = s3.list_dir(d, **kw).result()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    bucket, prefix = s3_url_parse(url)", "prediction_line": "    bucket, prefix = s3_url_parse(url)", "ground_truth": "    async def step(bucket, prefix, depth, work_q, dst_q):", "line_class": "infile", "zero_context": true}
{"original_prediction": "   n_total = 0", "prediction_line": "   n_total = 0", "ground_truth": "    async def step(idx):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    _s3_fetch_object, url, s3=s3, range=_range, **kw", "prediction_line": "                    _s3_fetch_object, url, s3=s3, range=_range, **kw", "ground_truth": "                    _s3_fetch_object, url, s3=s3, _range=_range, **kw", "line_class": "infile", "zero_context": true}
{"original_prediction": "        async def _do_file_query(qq, pred, dirs_pred=None):", "prediction_line": "        async def _do_file_query(qq, pred, dirs_pred=None):", "ground_truth": "        for d in s3.dir_dir(qq.base, qq.depth, pred=dirs_pred, **kw):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _dirs = []", "prediction_line": "        _dirs = []", "ground_truth": "        if action == \"dir\":", "line_class": "infile", "zero_context": true}
{"original_prediction": "            raise_error = not ff.result()", "prediction_line": "            raise_error = not ff.result()", "ground_truth": "            ff.result()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        async def action(url, s3, **kw):", "prediction_line": "        async def action(url, s3, **kw):", "ground_truth": "        async def find_to_queue(url, s3, q, **kw):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            stream = do_file_query(qq, fnmatch, dirs_pred=qq.pred)", "prediction_line": "            stream = do_file_query(qq, fnmatch, dirs_pred=qq.pred)", "ground_truth": "            stream = s3.find(qq.base, glob=qq.glob, **kw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return await s3_find(url, s3=s3, pred=pred, glob=glob, **kw)", "prediction_line": "            return await s3_find(url, s3=s3, pred=pred, glob=glob, **kw)", "ground_truth": "            return await s3_find(url, s3=s3, pred=pred, glob=glob, **kw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def s3_find_dir(url, s3, pred=None, glob=None, **kw):", "prediction_line": "async def s3_find_dir(url, s3, pred=None, glob=None, **kw):", "ground_truth": "async def s3_walker(url, nconcurrent, s3, guide=None, pred=None, glob=None, **kw):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self._async.gather(generate_requests(urls, self._s3, **kw))", "prediction_line": "        return self._async.gather(generate_requests(urls, self._s3, **kw))", "ground_truth": "        for rr, ee in future_results(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    auto_find_session,", "prediction_line": "    auto_find_session,", "ground_truth": "    norm_predicate,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    await step(bucket, d, depth - 1, work_q, dst_q)", "prediction_line": "                    await step(bucket, d, depth - 1, work_q, dst_q)", "ground_truth": "                    await work_q.put((d, depth - 1))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    _aws_s3_client,", "prediction_line": "    _aws_s3_client,", "ground_truth": "    _aws_unsigned_check_env,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return result(error=f\"Invalid range: {_range}\")", "prediction_line": "            return result(error=f\"Invalid range: {_range}\")", "ground_truth": "            return result(error=\"Bad range passed in: \" + str(_range))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    s3_client_builder,", "prediction_line": "    s3_client_builder,", "ground_truth": "    s3_file_info,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "async def _s3_fetch_object_range(url, s3, range, **kw):", "prediction_line": "async def _s3_fetch_object_range(url, s3, range, **kw):", "ground_truth": "async def _s3_find_via_cbk(url, cbk, s3, pred=None, glob=None, **kw):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def result(data=None, last_modified=None, error=None):", "prediction_line": "    def result(data=None, last_modified=None, error=None):", "ground_truth": "    pred = norm_predicate(pred=pred, glob=glob)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    bucket, prefix = s3_url_parse(url)", "prediction_line": "    bucket, prefix = s3_url_parse(url)", "ground_truth": "    bucket, prefix = s3_url_parse(url)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                await q.put(x)", "prediction_line": "                await q.put(x)", "ground_truth": "                await q.put(x)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        qq = parse_query(glob_pattern)", "prediction_line": "        qq = parse_query(glob_pattern)", "ground_truth": "        qq = parse_query(glob_pattern)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    bucket, key = s3_url_parse(url)", "prediction_line": "    bucket, key = s3_url_parse(url)", "ground_truth": "    bucket, key = s3_url_parse(url)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "               yield _s3_fetch_object(url, s3=s3, range=_range, **kw)", "prediction_line": "               yield _s3_fetch_object(url, s3=s3, range=_range, **kw)", "ground_truth": "                yield self._async.submit(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self._async.submit(_close, self._s3).result()", "prediction_line": "            self._async.submit(_close, self._s3).result()", "ground_truth": "            self._async.submit(_close, self._s3).result()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        f = self._async.submit(find_to_queue, url, self._s3, q, **kw)", "prediction_line": "        f = self._async.submit(find_to_queue, url, self._s3, q, **kw)", "ground_truth": "        ff = self._async.submit(find_to_queue, url, self._s3, q, **kw)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        .key = key", "prediction_line": "        .key = key", "ground_truth": "        .data = bytes", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    each s3 object is represented by a SimpleNamespace with attributes:", "prediction_line": "    each s3 object is represented by a SimpleNamespace with attributes:", "ground_truth": "    each s3 object is represented by a SimpleNamespace with attributes:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            .url = url", "prediction_line": "            .url = url", "ground_truth": "          .url = url", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        self._session = session", "prediction_line": "        self._session = session", "ground_truth": "        self._closed = False", "line_class": "random", "zero_context": true}
{"original_prediction": "    if len(prefix) > 0 and not prefix.endswith(\"/\"):", "prediction_line": "    if len(prefix) > 0 and not prefix.endswith(\"/\"):", "ground_truth": "    if len(prefix) > 0 and not prefix.endswith(\"/\"):", "line_class": "random", "zero_context": true}
{"original_prediction": "        return future_results(q, ff)", "prediction_line": "        return future_results(q, ff)", "ground_truth": "        clean_exit = False", "line_class": "random", "zero_context": true}
{"original_prediction": "            for url in urls:", "prediction_line": "            for url in urls:", "ground_truth": "            for url in urls:", "line_class": "random", "zero_context": true}
{"original_prediction": "       try:\n            if action == \"dir\":", "prediction_line": "       try:", "ground_truth": "        _files = []", "line_class": "random", "zero_context": true}
{"original_prediction": "@inventory_group.command(", "prediction_line": "@inventory_group.command(", "ground_truth": "@inventory_group.command(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        click.echo(yaml.dump(inv, default_flow_style=False))", "prediction_line": "        click.echo(yaml.dump(inv, default_flow_style=False))", "ground_truth": "        click.echo(yaml.safe_dump(inv))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    verbose,\n    global_config: str,", "prediction_line": "    verbose,", "ground_truth": "    verbose,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    config: Config,", "prediction_line": "    config: Config,", "ground_truth": "    config: Config,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        packages = extract_packages(", "prediction_line": "        packages = extract_packages(", "ground_truth": "        pkgs = extract_packages(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                global_config,", "prediction_line": "                global_config,", "ground_truth": "                global_config,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    name=\"lint\",", "prediction_line": "    name=\"lint\",", "ground_truth": "    name=\"show\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Interact with a Commodore inventory", "prediction_line": "    \"\"\"", "ground_truth": "    config.update_verbosity(verbose)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    extract_releases,", "prediction_line": "    extract_releases,", "ground_truth": "    extract_parameters,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    render_inventory,", "prediction_line": "    render_inventory,", "ground_truth": "    extract_components,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    render_inventory,", "prediction_line": "    render_inventory,", "ground_truth": "    extract_packages,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            global_config,", "prediction_line": "            global_config,", "ground_truth": "            config,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        inv = extract_components(", "prediction_line": "        inv = extract_components(", "ground_truth": "        components = extract_components(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            linter_class = LINTERS[lint]", "prediction_line": "            linter_class = LINTERS[lint]", "ground_truth": "            error_counts.append(LINTERS[lint](config, lint_target, ignore_patterns))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                tenant_config,", "prediction_line": "                tenant_config,", "ground_truth": "                tenant_config,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            InventoryFacts(", "prediction_line": "            InventoryFacts(", "ground_truth": "            InventoryFacts(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    directory levels.", "prediction_line": "    directory levels.", "ground_truth": "    subdirectories. Patterns which start with `/` are treated as anchored in the target", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import click\n\nfrom commodore.config import Config", "prediction_line": "import click", "ground_truth": "import click", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from commodore.inventory import Inventory", "prediction_line": "from commodore.inventory import Inventory", "ground_truth": "from commodore.inventory.lint import LINTERS", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from commodore.inventory.model import Inventory", "prediction_line": "from commodore.inventory.model import Inventory", "ground_truth": "from commodore.inventory.parameters import InventoryFacts", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    linter: tuple[str, ...],", "prediction_line": "    linter: tuple[str, ...],", "ground_truth": "    linter: tuple[str, ...],", "line_class": "random", "zero_context": true}
{"original_prediction": "@click.argument(\"global-config\")", "prediction_line": "@click.argument(\"global-config\")", "ground_truth": "@click.argument(\"global-config\")", "line_class": "random", "zero_context": true}
{"original_prediction": "    values: Iterable[str],", "prediction_line": "    values: Iterable[str],", "ground_truth": "    values: Iterable[str],", "line_class": "random", "zero_context": true}
{"original_prediction": "    multiple=True,", "prediction_line": "    multiple=True,", "ground_truth": "    multiple=True,", "line_class": "random", "zero_context": true}
{"original_prediction": "                extra_values,", "prediction_line": "                extra_values,", "ground_truth": "                extra_values,", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert test.working_tree_dir == target_dir", "prediction_line": "    assert test.working_tree_dir == target_dir", "ground_truth": "    assert not test.head.is_detached", "line_class": "common", "zero_context": true}
{"original_prediction": "    setup_remote(tmp_path, repo_url)", "prediction_line": "    setup_remote(tmp_path, repo_url)", "ground_truth": "    path = multi_dependency.dependency_dir(tmp_path, repo_url)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        assert not (package_dir / \"branch.txt\").exists()", "prediction_line": "        assert not (package_dir / \"branch.txt\").exists()", "ground_truth": "        assert not (package_dir / \"branch.txt\").exists()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    md.deregister(\"test\")", "prediction_line": "    md.deregister(\"test\")", "ground_truth": "    md.register_package(\"test\", tmp_path / \"tp\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    multi_dependency.init(tmp_path, repo_url)", "prediction_line": "    multi_dependency.init(tmp_path, repo_url)", "ground_truth": "    _ = multi_dependency.MultiDependency(repo_url, tmp_path)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert test.head.ref == \"master\"", "prediction_line": "    assert test.head.ref == \"master\"", "ground_truth": "    assert test.head.commit.hexsha == ri.commit_shas[\"master\"]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   assert (tmp_path / \".repos\").exists()", "prediction_line": "   assert (tmp_path / \".repos\").exists()", "ground_truth": "    repo_url_parts = deconstruct_url(repo_url)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert md.get_component(\"test\") == tmp_path / \"tc\"", "prediction_line": "    assert md.get_component(\"test\") == tmp_path / \"tc\"", "ground_truth": "    assert md.get_component(\"test\") == tmp_path / \"tc\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert target_dir.is_dir()", "prediction_line": "    assert target_dir.is_dir()", "ground_truth": "    assert target_dir.is_dir()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert md.get_component(\"test\") is None", "prediction_line": "    assert md.get_component(\"test\") is None", "ground_truth": "    assert md.get_component(\"test\") is None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    md = multi_dependency.MultiDependency(repo_url, tmp_path)", "prediction_line": "    md = multi_dependency.MultiDependency(repo_url, tmp_path)", "ground_truth": "    md = multi_dependency.MultiDependency(repo_url, tmp_path)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    test = Repo.init(component_dir)", "prediction_line": "    test = Repo.init(component_dir)", "ground_truth": "    assert not package_dir.is_dir()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert (component_dir / \".git\").is_file()", "prediction_line": "    assert (component_dir / \".git\").is_file()", "ground_truth": "    assert (component_dir / \".git\").is_file()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    md.register_component(\"component-argocd\", \"v0.0.1\")", "prediction_line": "    md.register_component(\"component-argocd\", \"v0.0.1\")", "ground_truth": "    assert md.get_component(\"test-component\") is None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        md.register_package(\"test-package\", tmp_path / \"tp2\")", "prediction_line": "        md.register_package(\"test-package\", tmp_path / \"tp2\")", "ground_truth": "        md.register_package(\"test-package\", tmp_path / \"tp2\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    md.register_component(\"test\", target_dir)", "prediction_line": "    md.register_component(\"test\", target_dir)", "ground_truth": "    md.register_component(\"test\", target_dir)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert bare_clone_path.joinpath(\".git\").is_dir()", "prediction_line": "    assert bare_clone_path.joinpath(\".git\").is_dir()", "ground_truth": "    # Smoke test that the directory is actually a bare clone", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   md.register_package(\"test-component\", tmp_path / \"tp\")", "prediction_line": "   md.register_package(\"test-component\", tmp_path / \"tp\")", "ground_truth": "def test_multi_dependency_register_package(tmp_path: Path):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   assert bare_clone_path.exists()", "prediction_line": "   assert bare_clone_path.exists()", "ground_truth": "    assert bare_clone_path.is_dir()", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert md.get_package(\"test\") == tmp_path / \"tp\"", "prediction_line": "    assert md.get_package(\"test\") == tmp_path / \"tp\"", "ground_truth": "    assert md.get_package(\"test\") == tmp_path / \"tp\"", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert md.get_package(\"test\") is None", "prediction_line": "    assert md.get_package(\"test\") is None", "ground_truth": "    assert md.get_package(\"test\") is None", "line_class": "random", "zero_context": true}
{"original_prediction": "    dc_exist = md.deregister_component(\"test\")", "prediction_line": "    dc_exist = md.deregister_component(\"test\")", "ground_truth": "    dc = md.deregister_component(\"test\")", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"github.com/projectsyn/component-argocd.git\",", "prediction_line": "            \"github.com/projectsyn/component-argocd.git\",", "ground_truth": "            \"github.com/projectsyn/component-argocd.git\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    tmp_path: Path,", "prediction_line": "    tmp_path: Path,", "ground_truth": "    cli_runner: RunnerFunc,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    expected_inv = {", "prediction_line": "    expected_inv = {", "ground_truth": "    expected_pkgs = parameters.get(\"packages\", {})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    result = cli_runner([\"inventory\", \"show\", str(global_config)] + args)", "prediction_line": "    result = cli_runner([\"inventory\", \"show\", str(global_config)] + args)", "ground_truth": "    result = cli_runner([\"inventory\", \"show\", str(global_config)] + args)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        yaml.safe_dump({\"classes\": [\"foo.bar\"], \"parameters\": parameters}, f)", "prediction_line": "        yaml.safe_dump({\"classes\": [\"foo.bar\"], \"parameters\": parameters}, f)", "ground_truth": "        yaml.safe_dump({\"classes\": [\"foo.bar\"], \"parameters\": parameters}, f)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    global_config.mkdir()", "prediction_line": "    global_config.mkdir()", "ground_truth": "    global_config.mkdir()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    global_config = tmp_path / \"global\"", "prediction_line": "    global_config = tmp_path / \"global\"", "ground_truth": "    global_config = tmp_path / \"global\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    result = cli_runner([\"component\", \"versions\", str(global_config)] + args)", "prediction_line": "    result = cli_runner([\"component\", \"versions\", str(global_config)] + args)", "ground_truth": "    result = cli_runner([\"inventory\", \"components\", str(global_config)] + args)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    parameters: dict[str, Any],", "prediction_line": "    parameters: dict[str, Any],", "ground_truth": "    parameters: dict[str, Any],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    expected_components = parameters.get(\"components\", {})", "prediction_line": "    expected_components = parameters.get(\"components\", {})", "ground_truth": "    expected_components = parameters.get(\"components\", {})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with open(global_config / \"commodore.yml\", \"w\") as f:", "prediction_line": "    with open(global_config / \"commodore.yml\", \"w\") as f:", "ground_truth": "    with open(global_config / \"commodore.yml\", \"w\") as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with open(global_config / \"test.yml\", \"w\") as f:", "prediction_line": "    with open(global_config / \"test.yml\", \"w\") as f:", "ground_truth": "    with open(global_config / \"test.yml\", \"w\") as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        inventory = json.loads(result.stdout)", "prediction_line": "        inventory = json.loads(result.stdout)", "ground_truth": "        inv = json.loads(result.stdout)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    result = cli_runner([\"inventory\", \"packages\", str(global_config)] + args)", "prediction_line": "    result = cli_runner([\"inventory\", \"packages\", str(global_config)] + args)", "ground_truth": "    result = cli_runner([\"inventory\", \"packages\", str(global_config)] + args)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    result = cli_runner([\"inventory\", \"lint\", str(tmp_path)])", "prediction_line": "    result = cli_runner([\"inventory\", \"lint\", str(tmp_path)])", "ground_truth": "    result = cli_runner([\"inventory\", \"lint\", str(tmp_path)])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        inv = yaml.safe_load(result.stdout)", "prediction_line": "        inv = yaml.safe_load(result.stdout)", "ground_truth": "        inv = yaml.safe_load(result.stdout)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from typing import Any, Dict, List, Optional, Tuple, Union", "prediction_line": "from typing import Any, Dict, List, Optional, Tuple, Union", "ground_truth": "from typing import Any", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_versions_cli(", "prediction_line": "def test_versions_cli(", "ground_truth": "def test_show_inventory_cli(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from . import utils", "prediction_line": "from . import utils", "ground_truth": "import pytest", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    args: list[str],", "prediction_line": "    args: list[str],", "ground_truth": "    args: list[str],", "line_class": "random", "zero_context": true}
{"original_prediction": "        (\n            {", "prediction_line": "        (", "ground_truth": "        (", "line_class": "random", "zero_context": true}
{"original_prediction": "                }\n            },", "prediction_line": "                }", "ground_truth": "                }", "line_class": "random", "zero_context": true}
{"original_prediction": "            yaml.dump(data, fh)", "prediction_line": "            yaml.dump(data, fh)", "ground_truth": "            yaml.safe_dump(data, fh)", "line_class": "random", "zero_context": true}
{"original_prediction": "    help=_get_help_string(_commands.create),", "prediction_line": "    help=_get_help_string(_commands.create),", "ground_truth": "    help=_get_help_string(_commands.create),", "line_class": "commited", "zero_context": true}
{"original_prediction": "    _commands.create(", "prediction_line": "    _commands.create(", "ground_truth": "    _commands.create(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    help=_get_help_string(_commands.update),", "prediction_line": "    help=_get_help_string(_commands.update),", "ground_truth": "    help=_get_help_string(_commands.update),", "line_class": "commited", "zero_context": true}
{"original_prediction": "    _commands.update(", "prediction_line": "    _commands.update(", "ground_truth": "    if not _commands.update(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    help=_get_help_string(_commands.link),", "prediction_line": "    help=_get_help_string(_commands.link),", "ground_truth": "    help=_get_help_string(_commands.link),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    help=_get_help_string(_commands.check),", "prediction_line": "    help=_get_help_string(_commands.check),", "ground_truth": "    help=_get_help_string(_commands.check),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _commands.link(", "prediction_line": "    _commands.link(", "ground_truth": "    _commands.link(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if not _commands.diff(project_dir=project_dir, exit_code=exit_code, checkout=checkout):", "prediction_line": "    if not _commands.diff(project_dir=project_dir, exit_code=exit_code, checkout=checkout):", "ground_truth": "    if not _commands.diff(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    help=_get_help_string(_commands.diff),", "prediction_line": "    help=_get_help_string(_commands.diff),", "ground_truth": "    help=_get_help_string(_commands.diff),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    checkout: Optional[str] = typer.Option(", "prediction_line": "    checkout: Optional[str] = typer.Option(", "ground_truth": "    checkout: Optional[str] = typer.Option(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        checkout=checkout,", "prediction_line": "        checkout=checkout,", "ground_truth": "        checkout=checkout,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    directory: Optional[str] = typer.Option(", "prediction_line": "    directory: Optional[str] = typer.Option(", "ground_truth": "    config_file: Optional[Path] = typer.Option(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"\"\"Check if the linked Cookiecutter template has been updated.", "prediction_line": "    \"\"\"Check if the linked Cookiecutter template has been updated.", "ground_truth": "    if not _commands.check(project_dir=project_dir, checkout=checkout, strict=strict):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    checkout: Optional[str] = typer.Option(", "prediction_line": "    checkout: Optional[str] = typer.Option(", "ground_truth": "    directory: Optional[str] = typer.Option(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "project_dir=project_dir, exit_code=exit_code, checkout=checkout):", "prediction_line": "project_dir=project_dir, exit_code=exit_code, checkout=checkout):", "ground_truth": "        project_dir=project_dir, exit_code=exit_code, checkout=checkout", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    checkout: Optional[str] = typer.Option(", "prediction_line": "    checkout: Optional[str] = typer.Option(", "ground_truth": "    output_dir: Path = typer.Option(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        no_input=no_input,", "prediction_line": "        no_input=no_input,", "ground_truth": "        config_file=config_file,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        directory=directory,", "prediction_line": "        directory=directory,", "ground_truth": "        directory=directory,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        output_dir,", "prediction_line": "        output_dir,", "ground_truth": "        output_dir=output_dir,", "line_class": "inproject", "zero_context": true}
{"original_prediction": ")\ndef diff(", "prediction_line": ")", "ground_truth": ")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def link(\n    project_dir: Path = typer.Option(", "prediction_line": "def link(", "ground_truth": "def link(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def create(\n    template: str = typer.Argument(", "prediction_line": "def create(", "ground_truth": "def create(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "\"\"\"This module defines CLI interactions when using `cruft`.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    ),\n    verbose: bool = typer.Option(", "prediction_line": "    ),", "ground_truth": "    ),", "line_class": "random", "zero_context": true}
{"original_prediction": "        show_default=False,", "prediction_line": "        show_default=False,", "ground_truth": "        show_default=False,", "line_class": "random", "zero_context": true}
{"original_prediction": "        strict=strict,", "prediction_line": "        strict=strict,", "ground_truth": "        strict=strict,", "line_class": "random", "zero_context": true}
{"original_prediction": "    strict: bool = typer.Option(", "prediction_line": "    strict: bool = typer.Option(", "ground_truth": "    strict: bool = typer.Option(", "line_class": "random", "zero_context": true}
{"original_prediction": "    type=click.Choice(Migration.choices()),", "prediction_line": "    type=click.Choice(Migration.choices()),", "ground_truth": "    type=click.Choice([m.value for m in Migration], case_sensitive=False),", "line_class": "common", "zero_context": true}
{"original_prediction": "@catalog_group.command(", "prediction_line": "@catalog_group.command(", "ground_truth": "@catalog_group.command(short_help=\"Delete generated files.\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"\"\"Compile the catalog for a cluster.\"\"\"", "prediction_line": "    \"\"\"Compile the catalog for a cluster.\"\"\"", "ground_truth": "    config.update_verbosity(verbose)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    config.dynamic_facts = parse_dynamic_facts_from_cli(dynamic_fact)", "prediction_line": "    config.dynamic_facts = parse_dynamic_facts_from_cli(dynamic_fact)", "ground_truth": "    config.dynamic_facts = parse_dynamic_facts_from_cli(dynamic_fact)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    config.fetch_dependencies = fetch_dependencies", "prediction_line": "    config.fetch_dependencies = fetch_dependencies", "ground_truth": "    config.migration = migration", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    migration,\n    dynamic_fact,", "prediction_line": "    migration,", "ground_truth": "    migration,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "config.username is None or config.usermail is None):", "prediction_line": "config.username is None or config.usermail is None):", "ground_truth": "        config.global_repo_revision_override or config.tenant_repo_revision_override", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            login(config)", "prediction_line": "            login(config)", "ground_truth": "            login(config)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    local,\n    push,", "prediction_line": "    local,", "ground_truth": "    local,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    git_author_name,", "prediction_line": "    git_author_name,", "ground_truth": "    verbose,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    config.api_url = api_url", "prediction_line": "    config.api_url = api_url", "ground_truth": "    config.api_url = api_url", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    clean_working_tree(config)", "prediction_line": "    clean_working_tree(config)", "ground_truth": "    clean_working_tree(config)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    login(config)", "prediction_line": "    login(config)", "ground_truth": "    if config.push and (", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@catalog_group.command(short_help=\"List clusters.\")", "prediction_line": "@catalog_group.command(short_help=\"List clusters.\")", "ground_truth": "@catalog_group.command(name=\"list\", short_help=\"List available catalog cluster IDs\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    fetch_dependencies,", "prediction_line": "    fetch_dependencies,", "ground_truth": "    fetch_dependencies,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    login(config)", "prediction_line": "    login(config)", "ground_truth": "    if config.api_token is None and not local:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    config.global_repo_revision_override = global_repo_revision_override", "prediction_line": "    config.global_repo_revision_override = global_repo_revision_override", "ground_truth": "    config.global_repo_revision_override = global_repo_revision_override", "line_class": "inproject", "zero_context": true}
{"original_prediction": "):\n    config.update_verbosity(verbose)", "prediction_line": "):", "ground_truth": "):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def clean(config: Config, verbose):", "prediction_line": "def clean(config: Config, verbose):", "ground_truth": "def clean(config: Config, verbose):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ")\n@click.option(", "prediction_line": ")", "ground_truth": ")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from commodore.config import Config", "prediction_line": "from commodore.config import Config", "ground_truth": "from commodore.config import Config, parse_dynamic_facts_from_cli", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "@click.option(", "prediction_line": "@click.option(", "ground_truth": "@click.option(", "line_class": "random", "zero_context": true}
{"original_prediction": "    help=(\n        \"Set a dynamic fact for the cluster catalog. \"", "prediction_line": "    help=(", "ground_truth": "    help=(", "line_class": "random", "zero_context": true}
{"original_prediction": "        + \"use the first value provided for each key.\"", "prediction_line": "        + \"use the first value provided for each key.\"", "ground_truth": "        + \"parse values as JSON if they're prefixed by `json:`. If the same key is \"", "line_class": "random", "zero_context": true}
{"original_prediction": "@options.pass_config", "prediction_line": "@options.pass_config", "ground_truth": "@options.pass_config", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"--skip-lint\",", "prediction_line": "    \"--skip-lint\",", "ground_truth": "    \"-m\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(*args, **kwargs)", "prediction_line": "        super().__init__(*args, **kwargs)", "ground_truth": "        super().__init__(*args, **kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "tableref.alias, tableref.select)", "prediction_line": "tableref.alias, tableref.select)", "ground_truth": "                    tableref.alias, tableref.select_statement.target_list)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            tve.table_alias = 'table_alias'", "prediction_line": "            tve.table_alias = 'table_alias'", "ground_truth": "            tve.col_name = 'col_name'", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        load_statement.table_ref = table_ref_obj", "prediction_line": "        load_statement.table_ref = table_ref_obj", "ground_truth": "        load_statement.table_ref.table.table_obj = table_ref_obj", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                'table_alias', 'table_name', 'table_alias', column)", "prediction_line": "                'table_alias', 'table_name', 'table_alias', column)", "ground_truth": "                col_name=column.name,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        udf_obj.output_objs = func_ouput_objs", "prediction_line": "        udf_obj.output_objs = func_ouput_objs", "ground_truth": "        mock_get_name = mock_catalog().get_udf_by_name = MagicMock()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            select_statement.union_link = MagicMock()", "prediction_line": "            select_statement.union_link = MagicMock()", "ground_truth": "            select_statement.union_link = None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            select_statement.from_table_refs = mocks", "prediction_line": "            select_statement.from_table_refs = mocks", "ground_truth": "            select_statement.target_list = mocks[:2]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            tableref.table_name = 'table_name'", "prediction_line": "            tableref.table_name = 'table_name'", "ground_truth": "            tableref.is_select.return_value = False", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            mock_bind_tabe_info.assert_called_with(tableref.table)", "prediction_line": "            mock_bind_tabe_info.assert_called_with(tableref.table)", "ground_truth": "            mock_bind_tabe_info.assert_called_once_with(tableref.table)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        func_expr.output = None", "prediction_line": "        func_expr.output = None", "ground_truth": "        func_expr.output = None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            tableref.is_select.return_value = True", "prediction_line": "            tableref.is_select.return_value = True", "ground_truth": "            tableref.is_select.return_value = True", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                                              udf_obj.impl_class_name)", "prediction_line": "                                              udf_obj.impl_class_name)", "ground_truth": "                                              udf_obj.name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.assertEqual(tve.col_alias, col_alias)", "prediction_line": "            self.assertEqual(tve.col_alias, col_alias)", "ground_truth": "            mock.assert_called_with(tve.col_name, tve.table_alias)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    @patch('eva.binder.statement_binder.create_video_metadata')", "prediction_line": "    @patch('eva.binder.statement_binder.create_video_metadata')", "ground_truth": "            self.assertEqual(load_statement.column_list, [tve_return_value])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                col_object=column,", "prediction_line": "                col_object=column,", "ground_truth": "                col_object=column)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "#     http://www.apache.org/licenses/LICENSE-2.0", "prediction_line": "#     http://www.apache.org/licenses/LICENSE-2.0", "ground_truth": "#     http://www.apache.org/licenses/LICENSE-2.0", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# You may obtain a copy of the License at", "prediction_line": "# You may obtain a copy of the License at", "ground_truth": "# You may obtain a copy of the License at", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from eva.conf import load_conf", "prediction_line": "from eva.conf import load_conf", "ground_truth": "from eva.binder.statement_binder import StatementBinder", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#\n#     http://www.apache.org/licenses/LICENSE-2.0", "prediction_line": "#", "ground_truth": "#", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        binder = StatementBinder()", "prediction_line": "        binder = StatementBinder()", "ground_truth": "        with patch.object(StatementBinderContext, 'get_binded_column') as mock:", "line_class": "random", "zero_context": true}
{"original_prediction": "            binder = StatementBinder(StatementBinderContext())", "prediction_line": "            binder = StatementBinder(StatementBinderContext())", "ground_truth": "            binder = StatementBinder(StatementBinderContext())", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.assertEqual(func_expr.output_objs, func_ouput_objs)", "prediction_line": "        self.assertEqual(func_expr.output_objs, func_ouput_objs)", "ground_truth": "        self.assertEqual(func_expr.output_objs, func_ouput_objs)", "line_class": "random", "zero_context": true}
{"original_prediction": "            binder._bind_select_statement(select_statement)", "prediction_line": "            binder._bind_select_statement(select_statement)", "ground_truth": "            binder._bind_select_statement(select_statement)", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.assertEqual(func_expr.output_col_aliases, ['out1'])", "prediction_line": "        self.assertEqual(func_expr.output_col_aliases, ['out1'])", "ground_truth": "        self.assertEqual(func_expr.output_col_aliases,", "line_class": "random", "zero_context": true}
{"original_prediction": "    report = init_dwi_report_wf()", "prediction_line": "    report = init_dwi_report_wf()", "ground_truth": "    dwi_report_wf = init_dwi_report_wf()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            (inputnode, hmc, [(\"in_file\", \"in_file\")]),", "prediction_line": "            (inputnode, hmc, [(\"in_file\", \"in_file\")]),", "ground_truth": "            (inputnode, hmc, [(\"in_file\", \"in_file\")]),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    epi_mni_align = epi_mni_align(", "prediction_line": "    epi_mni_align = epi_mni_align(", "ground_truth": "    ema = epi_mni_align()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    volreg = pe.Node(", "prediction_line": "    volreg = pe.Node(", "ground_truth": "    hmc = pe.Node(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            (deoblique_node, hmc, [(\"out_file\", \"in_file\")]),", "prediction_line": "            (deoblique_node, hmc, [(\"out_file\", \"in_file\")]),", "ground_truth": "            (deoblique_node, hmc, [(\"out_file\", \"in_file\")]),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # fmt: off", "prediction_line": "        # fmt: off", "ground_truth": "        skullstrip_epi = dmri_bmsk_workflow()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        (measures, datasink, [(\"out_json\", \"in_iqms\")]),", "prediction_line": "        (measures, datasink, [(\"out_json\", \"in_iqms\")]),", "ground_truth": "        (outliers, datasink, [((\"out_file\", _parse_tout), \"aor\")]),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        (quality, datasink, [((\"out_file\", _parse_qout), \"qc\")]),", "prediction_line": "        (quality, datasink, [((\"out_file\", _parse_qout), \"qc\")]),", "ground_truth": "        (quality, datasink, [((\"out_file\", _parse_tqual), \"aqi\")]),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    iqms = compute_iqms()", "prediction_line": "    iqms = compute_iqms()", "ground_truth": "    iqmswf = compute_iqms()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            (despike_node, hmc, [(\"out_file\", \"in_file\")]),", "prediction_line": "            (despike_node, hmc, [(\"out_file\", \"in_file\")]),", "ground_truth": "            (despike_node, hmc, [(\"out_file\", \"in_file\")]),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        (inputnode, hmc, [(\"in_file\", \"in_file\")]),", "prediction_line": "        (inputnode, hmc, [(\"in_file\", \"in_file\")]),", "ground_truth": "        (hmc, outputnode, [(\"out_file\", \"out_file\")]),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        (fdnode, outputnode, [(\"out_file\", \"out_fd\")]),", "prediction_line": "        (fdnode, outputnode, [(\"out_file\", \"out_fd\")]),", "ground_truth": "        (hmc, fdnode, [(\"oned_file\", \"in_file\")]),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    hmc = hmc_workflow(", "prediction_line": "    hmc = hmc_workflow(", "ground_truth": "    hmcwf = hmc()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        (datalad_get, hmcwf, [(\"in_file\", \"inputnode.in_file\")]),", "prediction_line": "        (datalad_get, hmcwf, [(\"in_file\", \"inputnode.in_file\")]),", "ground_truth": "        (meta, dwi_reference_wf, [((\"out_bmatrix\", _lowbmask), \"inputnode.t_masks\")]),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # fmt: off", "prediction_line": "        # fmt: off", "ground_truth": "        workflow.connect([(inputnode, norm, [(\"epi_mask\", \"moving_mask\")])])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # fmt: off", "prediction_line": "    # fmt: off", "ground_truth": "    final_inu = pe.Node(niu.Function(function=_apply_bias_correction), name=\"final_inu\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    workflow.__desc__ = message", "prediction_line": "    workflow.__desc__ = message", "ground_truth": "    config.loggers.workflow.info(message)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    elif config.workflow.despike:", "prediction_line": "    elif config.workflow.despike:", "ground_truth": "    elif config.workflow.despike:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    fd_thres = pe.Node(niu.Function(function=_tofloat), name=\"fd_thres\")", "prediction_line": "    fd_thres = pe.Node(niu.Function(function=_tofloat), name=\"fd_thres\")", "ground_truth": "    inputnode.inputs.fd_thres = config.workflow.fd_thres", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        DataladGet(", "prediction_line": "        DataladGet(", "ground_truth": "        DataladIdentityInterface(fields=[\"in_file\"], dataset_path=config.execution.bids_dir),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            template=get_template(\"MNI152NLin6Asym\", resolution=2),", "prediction_line": "            template=get_template(\"MNI152NLin6Asym\", resolution=2),", "ground_truth": "            template=config.workflow.template_id,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # 1. HMC", "prediction_line": "    # 1. HMC", "ground_truth": "    sanitize.inputs.max_32bit = config.execution.float32", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    elif config.workflow.deoblique:", "prediction_line": "    elif config.workflow.deoblique:", "ground_truth": "    elif config.workflow.deoblique:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        omp_nthreads=config.nipype.omp_nthreads,", "prediction_line": "        omp_nthreads=config.nipype.omp_nthreads,", "ground_truth": "        omp_nthreads=config.nipype.omp_nthreads,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if config.workflow.fft_spikes_detector:", "prediction_line": "    if config.workflow.fft_spikes_detector:", "ground_truth": "    if config.workflow.fft_spikes_detector:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if config.execution.upload_metrics:", "prediction_line": "    if config.execution.upload_metrics:", "ground_truth": "    if not config.execution.no_sub:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    omp_nthreads = config.nipype.omp_nthreads", "prediction_line": "    omp_nthreads = config.nipype.omp_nthreads", "ground_truth": "    n_procs = config.nipype.nprocs", "line_class": "inproject", "zero_context": true}
{"original_prediction": "AddProvenance(), name=\"AddProvenance\")", "prediction_line": "AddProvenance(), name=\"AddProvenance\")", "ground_truth": "        AddProvenance(modality=\"bold\"),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if config.workflow.population_reject:", "prediction_line": "    if config.workflow.population_reject:", "ground_truth": "    if config.workflow.species == \"human\":", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # fmt: off", "prediction_line": "    # fmt: off", "ground_truth": "    # Upload metrics", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        from mriqc.workflows.diffusion.base import hmc", "prediction_line": "        from mriqc.workflows.diffusion.base import hmc", "ground_truth": "        from mriqc.workflows.diffusion.base import hmc", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # 1. Compute DVARS", "prediction_line": "    # 1. Compute DVARS", "ground_truth": "    # Set FD threshold", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from mriqc.interfaces.nipype import (", "prediction_line": "from mriqc.interfaces.nipype import (", "ground_truth": "from mriqc.workflows.diffusion.output import init_dwi_report_wf", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        mem_gb=mem_gb * 4.0,", "prediction_line": "        mem_gb=mem_gb * 4.0,", "ground_truth": "        mem_gb=mem_gb * 1.5,", "line_class": "random", "zero_context": true}
{"original_prediction": "            (sanitize, iqmswf, [(\"out_file\", \"inputnode.in_ras\")]),", "prediction_line": "            (sanitize, iqmswf, [(\"out_file\", \"inputnode.in_ras\")]),", "ground_truth": "            (iqmswf, dwi_report_wf, [", "line_class": "random", "zero_context": true}
{"original_prediction": "files\n    read_metadata = pe.Node(", "prediction_line": "files", "ground_truth": "    meta = pe.Node(ReadDWIMetadata(", "line_class": "random", "zero_context": true}
{"original_prediction": "        (mean, dwi_report_wf, [(\"out_file\", \"inputnode.in_mean\")]),", "prediction_line": "        (mean, dwi_report_wf, [(\"out_file\", \"inputnode.in_mean\")]),", "ground_truth": "        (mean, dwi_report_wf, [(\"out_file\", \"inputnode.epi_mean\")]),", "line_class": "random", "zero_context": true}
{"original_prediction": "                                      (\"out_fft\", \"out_fft\")]),", "prediction_line": "                                      (\"out_fft\", \"out_fft\")]),", "ground_truth": "                                      (\"out_fft\", \"out_fft\")]),", "line_class": "random", "zero_context": true}
{"original_prediction": "    main()", "prediction_line": "    main()", "ground_truth": "    main()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    img = nb.load(args.image)", "prediction_line": "    img = nb.load(args.image)", "ground_truth": "    image = nb.load(args.image)", "line_class": "common", "zero_context": true}
{"original_prediction": "    model.load_state_dict(torch.load(modelfile, map_location=device))", "prediction_line": "    model.load_state_dict(torch.load(modelfile, map_location=device))", "ground_truth": "    checkpoint = torch.load(modelfile, map_location=device)", "line_class": "common", "zero_context": true}
{"original_prediction": "    sdt = unconform(sdt, conformed.affine, conformed.header)", "prediction_line": "    sdt = unconform(sdt, conformed.affine, conformed.header)", "ground_truth": "    sdt_target = resample_like(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    image = image.get_fdata(dtype=np.float32)", "prediction_line": "    image = image.get_fdata(dtype=np.float32)", "ground_truth": "    conformed = conform(image)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    parser.add_argument(", "prediction_line": "    parser.add_argument(", "ground_truth": "    args = parser.parse_args()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        nb.Nifti1Image(img_data, image.affine, image.header).to_filename(args.out)", "prediction_line": "        nb.Nifti1Image(img_data, image.affine, image.header).to_filename(args.out)", "ground_truth": "        nb.Nifti1Image(img_data, image.affine, image.header).to_filename(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        nb.Nifti1Image(mask.astype(\"uint8\"), image.affine, hdr).to_filename(", "prediction_line": "        nb.Nifti1Image(mask.astype(\"uint8\"), image.affine, hdr).to_filename(", "ground_truth": "        nb.Nifti1Image(mask, image.affine, hdr).to_filename(args.mask)", "line_class": "inproject", "zero_context": true}
{"original_prediction": " NeuroImage, 2022.", "prediction_line": " NeuroImage, 2022.", "ground_truth": "\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    from nipreps.synthstrip.synthstrip import SynthStrip", "prediction_line": "    from nipreps.synthstrip.synthstrip import SynthStrip", "ground_truth": "    from .model import StripModel", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    print(\n        \"  SynthStrip: Skull-Stripping for Any Brain Image.\"", "prediction_line": "    print(", "ground_truth": "    print(\"----------------------------------------------------\")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    from niworkflows.utils.spaces import format_reference", "prediction_line": "    from niworkflows.utils.spaces import format_reference", "ground_truth": "    import numpy as np", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    import nibabel as nb", "prediction_line": "    import nibabel as nb", "ground_truth": "    import nibabel as nb", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   model = StripModel(device=device, model_path=args.model)", "prediction_line": "   model = StripModel(device=device, model_path=args.model)", "ground_truth": "    with torch.no_grad():", "line_class": "random", "zero_context": true}
{"original_prediction": "    target_shape = np.ceil(target_shape / 64.0) * 64", "prediction_line": "    target_shape = np.ceil(target_shape / 64.0) * 64", "ground_truth": "    target_shape = np.clip(", "line_class": "random", "zero_context": true}
{"original_prediction": "target_affine, input_nii.header.get_xyzt_units())", "prediction_line": "target_affine, input_nii.header.get_xyzt_units())", "ground_truth": "        reference=nb.Nifti1Image(np.zeros(target_shape), target_affine, None),", "line_class": "random", "zero_context": true}
{"original_prediction": "conformed, sdt)", "prediction_line": "conformed, sdt)", "ground_truth": "        nb.Nifti1Image(sdt, conformed.affine, None),", "line_class": "random", "zero_context": true}
{"original_prediction": "    parser.add_argument(", "prediction_line": "    parser.add_argument(", "ground_truth": "    parser.add_argument(", "line_class": "random", "zero_context": true}
{"original_prediction": "    workflow.connect([", "prediction_line": "    workflow.connect([", "ground_truth": "    workflow.connect([", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    wf = pe.Workflow(name=name)", "prediction_line": "    wf = pe.Workflow(name=name)", "ground_truth": "    verbose = config.execution.verbose_reports", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    wf = pe.Workflow(name=name)", "prediction_line": "    wf = pe.Workflow(name=name)", "ground_truth": "    reportlets_dir = config.execution.output_dir", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    mosaic_noise_zoom = pe.Node(", "prediction_line": "    mosaic_noise_zoom = pe.Node(", "ground_truth": "    if config.workflow.species.lower() in (\"rat\", \"mouse\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    wf = pe.Workflow(name=name)", "prediction_line": "    wf = pe.Workflow(name=name)", "ground_truth": "    workflow = pe.Workflow(name=name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        workflow.connect([(mosaic_zoom, ds_report_zoomed, [(\"out_file\", \"in_file\")])])", "prediction_line": "        workflow.connect([(mosaic_zoom, ds_report_zoomed, [(\"out_file\", \"in_file\")])])", "ground_truth": "        return workflow", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    mosaic_contours = pe.Node(", "prediction_line": "    mosaic_contours = pe.Node(", "ground_truth": "    display_mode = \"y\" if config.workflow.species.lower() in (\"rat\", \"mouse\") else \"z\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    plot_headmask = pe.Node(", "prediction_line": "    plot_headmask = pe.Node(", "ground_truth": "    display_mode = \"y\" if config.workflow.species.lower() in (\"rat\", \"mouse\") else \"x\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    )\n\n    ds_report_artmask = pe.Node(", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def init_anat_reports_wf(", "prediction_line": "def init_anat_reports_wf(", "ground_truth": "def init_anat_report_wf(name: str = \"anat_report_wf\"):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from nipype.interfaces import utility as niu", "prediction_line": "from nipype.interfaces import utility as niu", "ground_truth": "from nipype.interfaces import utility as niu", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "https://github.com/nipreps/nipreps/blob/master/CONTRIBUTING.md", "prediction_line": "https://github.com/nipreps/nipreps/blob/master/CONTRIBUTING.md", "ground_truth": "#", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            colors=[\"r\"],", "prediction_line": "            colors=[\"r\"],", "ground_truth": "            colors=[\"r\"],", "line_class": "random", "zero_context": true}
{"original_prediction": "                                   (\"artmask\", \"in_contours\")]),", "prediction_line": "                                   (\"artmask\", \"in_contours\")]),", "ground_truth": "                                   (\"artmask\", \"in_contours\")]),", "line_class": "random", "zero_context": true}
{"original_prediction": "            fields=[\n                \"source_file\",", "prediction_line": "            fields=[", "ground_truth": "            fields=[", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"out_ras\",", "prediction_line": "                \"out_ras\",", "ground_truth": "                \"headmask\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            suffix=\"mosaic\",", "prediction_line": "            suffix=\"mosaic\",", "ground_truth": "            desc=\"zoomed\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        in_mask_nii = nb.load(in_mask)", "prediction_line": "        in_mask_nii = nb.load(in_mask)", "ground_truth": "        mask_data = np.asanyarray(nb.load(in_mask).dataobj)", "line_class": "common", "zero_context": true}
{"original_prediction": "    \"\"\"Get the TR from the metadata.\"\"\"", "prediction_line": "    \"\"\"Get the TR from the metadata.\"\"\"", "ground_truth": "    return meta_dict.get(\"RepetitionTime\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "    seg_nii = nb.load(segmentation)", "prediction_line": "    seg_nii = nb.load(segmentation)", "ground_truth": "    img = nb.load(segmentation)", "line_class": "common", "zero_context": true}
{"original_prediction": "    # Mask out the crown", "prediction_line": "    # Mask out the crown", "ground_truth": "    seg[np.asanyarray(nb.load(crown_mask).dataobj, dtype=int) > 0] = 5", "line_class": "common", "zero_context": true}
{"original_prediction": "    img = nb.load(in_file)", "prediction_line": "    img = nb.load(in_file)", "ground_truth": "    in_4d_nii = nb.load(in_file)", "line_class": "common", "zero_context": true}
{"original_prediction": "            function=Spikes,", "prediction_line": "            function=Spikes,", "ground_truth": "            function=spikes_mask,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                              (\"in_spikes\", \"spikes\"),", "prediction_line": "                              (\"in_spikes\", \"spikes\"),", "ground_truth": "                              ((\"meta_sidecar\", _get_tr), \"tr\")]),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Generate the reportlets", "prediction_line": "    # Generate the reportlets", "ground_truth": "    parcels = pe.Node(niu.Function(function=_carpet_parcellation), name=\"parcels\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "    nb.save(mask_nii, out_file)", "prediction_line": "    nb.save(mask_nii, out_file)", "ground_truth": "    mask_nii.to_filename(out_file)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            out_file=\"plot_brainmask.svg\",", "prediction_line": "            out_file=\"plot_brainmask.svg\",", "ground_truth": "            display_mode=\"y\" if config.workflow.species.lower() in (\"rat\", \"mouse\") else \"z\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    outimg.to_filename(out_file)", "prediction_line": "    outimg.to_filename(out_file)", "ground_truth": "    outimg.to_filename(out_file)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    workflow.connect([", "prediction_line": "    workflow.connect([", "ground_truth": "    workflow.connect([", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    wf = pe.Workflow(name=name)", "prediction_line": "    wf = pe.Workflow(name=name)", "ground_truth": "    verbose = config.execution.verbose_reports", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    wf = pe.Workflow(name=name)", "prediction_line": "    wf = pe.Workflow(name=name)", "ground_truth": "    mem_gb = config.workflow.biggest_file_gb", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # Create workflow", "prediction_line": "    # Create workflow", "ground_truth": "    reportlets_dir = config.execution.output_dir", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    workflow = pe.Workflow(name=name)", "prediction_line": "    workflow = pe.Workflow(name=name)", "ground_truth": "    workflow = pe.Workflow(name=name)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if verbose:", "prediction_line": "    if verbose:", "ground_truth": "    if config.workflow.fft_spikes_detector:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        workflow.__desc__ = \"\"\"\\", "prediction_line": "        workflow.__desc__ = \"\"\"\\", "ground_truth": "        return workflow", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    fd_thres = pe.Node(", "prediction_line": "    fd_thres = pe.Node(", "ground_truth": "    inputnode.inputs.fd_thres = config.workflow.fd_thres", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return workflow", "prediction_line": "    return workflow", "ground_truth": "    if config.workflow.ica:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Spikes(", "prediction_line": "        Spikes(", "ground_truth": "        Spikes(no_zscore=True, detrend=False),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    mosaic_noise_zoom = pe.Node(", "prediction_line": "    mosaic_noise_zoom = pe.Node(", "ground_truth": "    if config.workflow.species.lower() in (\"rat\", \"mouse\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "# distributed under the License is distributed on an \"AS IS\" BASIS,", "prediction_line": "# distributed under the License is distributed on an \"AS IS\" BASIS,", "ground_truth": "# distributed under the License is distributed on an \"AS IS\" BASIS,", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "   outputnode = pe.Node(", "prediction_line": "   outputnode = pe.Node(", "ground_truth": "    # Set FD threshold", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    from niworkflows.interfaces.reportlets.registration import (", "prediction_line": "    from niworkflows.interfaces.reportlets.registration import (", "ground_truth": "    from niworkflows.interfaces.morphology import BinaryDilation, BinarySubtraction", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    import numpy as np", "prediction_line": "    import numpy as np", "ground_truth": "    import os.path as op", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "https://github.com/nipreps/nipreps/blob/main/CONTRIBUTING.md", "prediction_line": "https://github.com/nipreps/nipreps/blob/main/CONTRIBUTING.md", "ground_truth": "#     https://www.nipreps.org/community/licensing/", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                \"hmc_fd_pv\",", "prediction_line": "                \"hmc_fd_pv\",", "ground_truth": "                \"epi_parc\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        bbox = (", "prediction_line": "        bbox = (", "ground_truth": "        longest_axis = np.argmax(bbox)", "line_class": "random", "zero_context": true}
{"original_prediction": "        )\n\n        # fmt: off", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "        mask_data = np.logical_and(mask_data, new_mask_3d)", "prediction_line": "        mask_data = np.logical_and(mask_data, new_mask_3d)", "ground_truth": "    else:", "line_class": "random", "zero_context": true}
{"original_prediction": "    mean_img(in_file).to_filename(out_file.replace(\".nii.gz\", \"_mean.nii.gz\"))", "prediction_line": "    mean_img(in_file).to_filename(out_file.replace(\".nii.gz\", \"_mean.nii.gz\"))", "ground_truth": "    plot_roi(mask_nii, mean_img(in_4d_nii), output_file=out_plot)", "line_class": "random", "zero_context": true}
{"original_prediction": "        if plugin_args is None:", "prediction_line": "        if plugin_args is None:", "ground_truth": "        super(MultiProcPlugin, self).__init__(plugin_args=plugin_args)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        result[\"result\"] = node.run(updatehash=updatehash)", "prediction_line": "        result[\"result\"] = node.run(updatehash=updatehash)", "ground_truth": "        result[\"result\"] = node.run(updatehash=updatehash)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    self.procs[jobid].run(updatehash=updatehash)", "prediction_line": "                    self.procs[jobid].run(updatehash=updatehash)", "ground_truth": "                    self.procs[jobid].run(updatehash=updatehash)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(DistributedPluginBase, self).__init__(plugin_args)", "prediction_line": "        super(DistributedPluginBase, self).__init__(plugin_args)", "ground_truth": "        super(DistributedPluginBase, self).__init__(plugin_args=plugin_args)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return self._taskresult.get(taskid)", "prediction_line": "        return self._taskresult.get(taskid)", "ground_truth": "        return self._taskresult.get(taskid)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.raise_insufficient = plugin_args.get(\"raise_insufficient\", True)", "prediction_line": "        self.raise_insufficient = plugin_args.get(\"raise_insufficient\", True)", "ground_truth": "        self.processors = self.plugin_args.get(\"n_procs\", mp.cpu_count())", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.memory_gb = self.plugin_args.get(\"memory_gb\", 0.25)", "prediction_line": "        self.memory_gb = self.plugin_args.get(\"memory_gb\", 0.25)", "ground_truth": "        self.memory_gb = self.plugin_args.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "            if node in self.procs:", "prediction_line": "            if node in self.procs:", "ground_truth": "            idx = self.procs.index(node)", "line_class": "common", "zero_context": true}
{"original_prediction": "    def __repr__(self):", "prediction_line": "    def __repr__(self):", "ground_truth": "        self._status_callback = plugin_args.get(\"status_callback\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.raise_insufficient = self.plugin_args.get(\"raise_insufficient\", True)", "prediction_line": "        self.raise_insufficient = self.plugin_args.get(\"raise_insufficient\", True)", "ground_truth": "        self.raise_insufficient = self.plugin_args.get(\"raise_insufficient\", False)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.pending_tasks_lock = mp.Lock()", "prediction_line": "        self.pending_tasks_lock = mp.Lock()", "ground_truth": "        self.max_jobs = self.plugin_args.get(\"max_jobs\", np.inf)", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.non_daemon_pool = None", "prediction_line": "        self.non_daemon_pool = None", "ground_truth": "        mp_context = mp.get_context(self.plugin_args.get(\"mp_context\"))", "line_class": "common", "zero_context": true}
{"original_prediction": "       self._report_crash(self.procs[jobid], result=result)", "prediction_line": "       self._report_crash(self.procs[jobid], result=result)", "ground_truth": "        crashfile = self._report_crash(self.procs[jobid], result=result)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for dep in self.depidx[jobid]:", "prediction_line": "        for dep in self.depidx[jobid]:", "ground_truth": "        return self._remove_node_deps(jobid, crashfile, graph)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Check if any of the jobs are memory or thread consuming", "prediction_line": "        # Check if any of the jobs are memory or thread consuming", "ground_truth": "        jobids = self._sort_jobs(jobids, scheduler=self.plugin_args.get(\"scheduler\"))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self._clean_queue(", "prediction_line": "                    self._clean_queue(", "ground_truth": "                    self._clean_queue(", "line_class": "infile", "zero_context": true}
{"original_prediction": "       self._prerun_check(graph)", "prediction_line": "       self._prerun_check(graph)", "ground_truth": "        self._prerun_check(graph)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    if self._submit_mapnode(jobid):", "prediction_line": "                    if self._submit_mapnode(jobid):", "ground_truth": "                    submit = self._submit_mapnode(jobid)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._generate_structure(graph)", "prediction_line": "        self._generate_structure(graph)", "ground_truth": "        self._generate_dependency_list(graph)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self._status_callback(taskid, jobid)", "prediction_line": "                    self._status_callback(taskid, jobid)", "ground_truth": "                    result = self._get_result(taskid)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    errors.append(exc)", "prediction_line": "                    errors.append(exc)", "ground_truth": "                    notrun.append(self._clean_queue(jobid, graph))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if self._local_hash_check(jobid, graph):", "prediction_line": "            if self._local_hash_check(jobid, graph):", "ground_truth": "            if self._local_hash_check(jobid, graph):", "line_class": "infile", "zero_context": true}
{"original_prediction": "mp_context=mp_context", "prediction_line": "mp_context=mp_context", "ground_truth": "            initializer=process_initializer,", "line_class": "infile", "zero_context": true}
{"original_prediction": "self._clean_queue(jobid, graph))", "prediction_line": "self._clean_queue(jobid, graph))", "ground_truth": "                                self._clean_queue(jobid, graph, result=result)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                            self._update_queue(jobid, graph, result=result)", "prediction_line": "                            self._update_queue(jobid, graph, result=result)", "ground_truth": "                            self._task_finished_cb(jobid)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            except Exception:", "prediction_line": "            except Exception:", "ground_truth": "                self._remove_node_dirs()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                            self._status_callback(", "prediction_line": "                            self._status_callback(", "ground_truth": "                        self._clear_task(taskid)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.procs[jobid].result", "prediction_line": "                self.procs[jobid].result", "ground_truth": "                self._task_finished_cb(jobid, cached=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                pass\n            self._clear_task(jobid)", "prediction_line": "                pass", "ground_truth": "                self._clean_queue(jobid, graph)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                # Check if any processes are done", "prediction_line": "                # Check if any processes are done", "ground_truth": "                self._send_procs_to_workers(updatehash=updatehash, graph=graph)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._postrun_check()", "prediction_line": "        self._postrun_check()", "ground_truth": "        self._postrun_check()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Check if the node has been run before", "prediction_line": "        # Check if the node has been run before", "ground_truth": "        result_future = self.pool.submit(run_node, node, updatehash, self._taskid)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._task_obj[self._taskid] = result_future", "prediction_line": "        self._task_obj[self._taskid] = result_future", "ground_truth": "        result_future.add_done_callback(self._async_callback)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.pending_tasks.append((self._submit_job(self.procs[jobid]), jobid))", "prediction_line": "            self.pending_tasks.append((self._submit_job(self.procs[jobid]), jobid))", "ground_truth": "            tid = self._submit_job(deepcopy(self.procs[jobid]), updatehash=updatehash)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # by running tasks", "prediction_line": "        # by running tasks", "ground_truth": "        free_memory_gb, free_processors = self._check_resources(self.pending_tasks)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for jobid, proc in enumerate(self.procs):", "prediction_line": "        for jobid, proc in enumerate(self.procs):", "ground_truth": "        if config.nipype.remove_node_directories:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if config.nipype.use_parameter_hash:", "prediction_line": "        if config.nipype.use_parameter_hash:", "ground_truth": "        if not config.nipype.local_hash_check:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if config.get(\"execution\", {}).get(\"crashdump_dir\"):", "prediction_line": "        if config.get(\"execution\", {}).get(\"crashdump_dir\"):", "ground_truth": "        if config.nipype.stop_on_first_crash:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            config.nipype.memory_gb * 0.9,", "prediction_line": "            config.nipype.memory_gb * 0.9,", "ground_truth": "            config.environment.total_memory * 0.9,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "Callback for when a task is finished.\"\"\"", "prediction_line": "Callback for when a task is finished.\"\"\"", "ground_truth": "        Extract outputs and assign to inputs of dependent tasks.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    result : tuple", "prediction_line": "    result : tuple", "ground_truth": "    result : dictionary", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def _send_procs_to_workers(self, updatehash=False, graph=None):", "prediction_line": "    def _send_procs_to_workers(self, updatehash=False, graph=None):", "ground_truth": "    def _send_procs_to_workers(self, updatehash=False, graph=None):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import sys\nimport time", "prediction_line": "import sys", "ground_truth": "import sys", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        while self.pending_tasks:", "prediction_line": "        while self.pending_tasks:", "ground_truth": "        notrun = []", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.proc_done = None", "prediction_line": "        self.proc_done = None", "ground_truth": "        self.mapnodesubids = None", "line_class": "random", "zero_context": true}
{"original_prediction": "cached and not updated) and not overwrite and not always_run:", "prediction_line": "cached and not updated) and not overwrite and not always_run:", "ground_truth": "            cached", "line_class": "random", "zero_context": true}
{"original_prediction": "    return result", "prediction_line": "    return result", "ground_truth": "        result[\"result\"] = node.result", "line_class": "random", "zero_context": true}
{"original_prediction": "        self._task_obj[self._taskid] = result_future", "prediction_line": "        self._task_obj[self._taskid] = result_future", "ground_truth": "        self._task_obj[self._taskid] = result_future", "line_class": "random", "zero_context": true}
{"original_prediction": "        for i, post_sel in self._post_selection.items():", "prediction_line": "        for i, post_sel in self._post_selection.items():", "ground_truth": "        fixed = ['0' if self._post_selection.get(i, 0) == 0 else", "line_class": "common", "zero_context": true}
{"original_prediction": "   for tk_op in tk_circ.to_tk().get_commands():", "prediction_line": "   for tk_op in tk_circ.to_tk().get_commands():", "ground_truth": "    for op in tk_circ.__iter__():", "line_class": "common", "zero_context": true}
{"original_prediction": "        return circuit", "prediction_line": "        return circuit", "ground_truth": "        return circuit", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @qml.qnode(dev)", "prediction_line": "    @qml.qnode(dev)", "ground_truth": "    return PennyLaneCircuit(op_list,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @post_selection.setter", "prediction_line": "    @post_selection.setter", "ground_truth": "    @post_selection.setter", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.post_selection = post_selection", "prediction_line": "        self.post_selection = post_selection", "ground_truth": "        self._post_selection = post_selection", "line_class": "infile", "zero_context": true}
{"original_prediction": "                            dev,", "prediction_line": "                            dev,", "ground_truth": "                            post_selection,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def contains_sympy(self):", "prediction_line": "    def contains_sympy(self):", "ground_truth": "        self._valid_states = self.get_valid_states()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if symbols is None:", "prediction_line": "            if symbols is None:", "ground_truth": "            params = self.param_substitution(symbols, weights)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            params = self.param_substitution(symbols, weights)", "prediction_line": "            params = self.param_substitution(symbols, weights)", "ground_truth": "            concrete_params = self.param_substitution(symbols, weights)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        else:\n            concrete_params = [torch.cat(p) if len(p) > 0 else p", "prediction_line": "        else:", "ground_truth": "            return self.post_selected_circuit(concrete_params)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.post_selected_circuit(self.params)", "prediction_line": "            return self.post_selected_circuit(self.params)", "ground_truth": "            return self.post_selected_circuit([torch.cat(p) if len(p) > 0", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.wires = wires", "prediction_line": "        self.wires = wires", "ground_truth": "        self._contains_sympy = self.contains_sympy()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    op_list, params_list, wires_list = extract_ops_from_tk(tk_circ, str_map)", "prediction_line": "    op_list, params_list, wires_list = extract_ops_from_tk(tk_circ, str_map)", "ground_truth": "    op_list, params_list, wires_list = extract_ops_from_tk(tk_circ,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if c is not None:", "prediction_line": "        if c is not None:", "ground_truth": "        q_post_sels[q.index[0]] = tk_circ.post_selection[c.index[0]]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @qml.qnode(dev)", "prediction_line": "    @qml.qnode(dev)", "ground_truth": "    post_selection = get_post_selection_dict(tk_circ)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            op_list.append(tk_op_to_pennylane(op, str_map)[0])", "prediction_line": "            op_list.append(tk_op_to_pennylane(op, str_map)[0])", "ground_truth": "            op, params, wires = tk_op_to_pennylane(op, str_map)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                op(*params, wires=wires)", "prediction_line": "                op(*params, wires=wires)", "ground_truth": "                op(*params, wires=wires)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if len(free_symbols) == 1:", "prediction_line": "            if len(free_symbols) == 1:", "ground_truth": "            sym_subs = {f: str_map[str(f)] for f in free_symbols}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    OpType.CX: qml.CNOT,", "prediction_line": "    OpType.CX: qml.CNOT,", "ground_truth": "    OpType.CX: qml.CNOT,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return OP_MAP[tk_op.op.type](*remapped_params, wires=wires)", "prediction_line": "    return OP_MAP[tk_op.op.type](*remapped_params, wires=wires)", "ground_truth": "    return OP_MAP[tk_op.op.type], remapped_params, wires", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    op_type = tk_op.type", "prediction_line": "    op_type = tk_op.type", "ground_truth": "    wires = [x.index[0] for x in tk_op.qubits]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for i, wire in enumerate(fixed):", "prediction_line": "        for i, wire in enumerate(fixed):", "ground_truth": "        permutations = [''.join(s) for s in product('01',", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    OpType.T: qml.T,", "prediction_line": "    OpType.T: qml.T,", "ground_truth": "    OpType.Sdg: lambda wires: qml.S(wires=wires).inv(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "post_selection,\n                 scalar, n_qubits, dev):", "prediction_line": "post_selection,", "ground_truth": "                 post_selection, scale, n_qubits, device):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.scale = scale", "prediction_line": "        self.scale = scale", "ground_truth": "        self.scale = scale", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            scalar = box.scalar", "prediction_line": "            scalar = box.scalar", "ground_truth": "            scalar *= box.array", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        op, params, wires = tk_op_to_pennylane(op, str_map)", "prediction_line": "        op, params, wires = tk_op_to_pennylane(op, str_map)", "ground_truth": "        if op.op.type != OpType.Measure:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if probabilities:", "prediction_line": "    if probabilities:", "ground_truth": "    for box in disco_circuit.boxes:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            post_selected_states = \\", "prediction_line": "            post_selected_states = \\", "ground_truth": "            post_selected_states = self.scale * post_selected_states", "line_class": "inproject", "zero_context": true}
{"original_prediction": "control=wires[0]),", "prediction_line": "control=wires[0]),", "ground_truth": "                                          control=wires[0]),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    Convert a :class:`discopy.quantum.Circuit` to a PennyLane circuit.", "prediction_line": "    Convert a :class:`discopy.quantum.Circuit` to a PennyLane circuit.", "ground_truth": "    Return a PennyLaneCircuit equivalent to the input DisCoPy", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            Whether the circuit parameters contain SymPy symbols.", "prediction_line": "            Whether the circuit parameters contain SymPy symbols.", "ground_truth": "            Whether the circuit parameters contain SymPy symbols.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def post_selection(self, post_selection):", "prediction_line": "    def post_selection(self, post_selection):", "ground_truth": "    def post_selection(self, post_selection_dict):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            The weights from the original DisCoPy circuit.", "prediction_line": "            The weights from the original DisCoPy circuit.", "ground_truth": "            The weights to substitute for the symbols.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from discopy.quantum.gates import *", "prediction_line": "from discopy.quantum.gates import *", "ground_truth": "from discopy.quantum.gates import Scalar", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "           return qml.probs(wires=range(self.n_qubits))", "prediction_line": "           return qml.probs(wires=range(self.n_qubits))", "ground_truth": "            if self.probs:", "line_class": "random", "zero_context": true}
{"original_prediction": "class CircuitTK(Circuit):", "prediction_line": "class CircuitTK(Circuit):", "ground_truth": "OP_MAP = {", "line_class": "random", "zero_context": true}
{"original_prediction": "    for param in params:", "prediction_line": "    for param in params:", "ground_truth": "    for param in params:", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.device = device", "prediction_line": "        self.device = device", "ground_truth": "        self.device = device", "line_class": "random", "zero_context": true}
{"original_prediction": "        else:\n            params = self.params", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "and (funcm(xtest, seed=funcm.seed) < funcm(x, seed=funcm.seed)-feps))):", "prediction_line": "and (funcm(xtest, seed=funcm.seed) < funcm(x, seed=funcm.seed)-feps))):", "ground_truth": "                   and funcm.test(xtest, x, type_='smaller', alpha=alpha))):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                            and funcm.test(xtest, x, type_='larger', alpha=alpha)))):", "prediction_line": "                            and funcm.test(xtest, x, type_='larger', alpha=alpha)))):", "ground_truth": "                            and funcm.test(xtest, x, type_='equality', alpha=alpha)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                               (errorcontrol and funcm.test(xtest, x, type_='equality', alpha=alpha)))", "prediction_line": "                               (errorcontrol and funcm.test(xtest, x, type_='equality', alpha=alpha)))", "ground_truth": "            (errorcontrol and funcm.test(xtest, x, type_='equality', alpha=alpha)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(AveragedFunction, self).__init__(**kwargs)", "prediction_line": "        super(AveragedFunction, self).__init__(**kwargs)", "ground_truth": "        super(AveragedFunction, self).__init__(**kwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super(DifferenceFunction, self).__init__(**basekwargs)", "prediction_line": "        super(DifferenceFunction, self).__init__(**basekwargs)", "ground_truth": "        super(DifferenceFunction, self).__init__(**basekwargs)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                        and funcm.test(xmid, x, type_='smaller', alpha=alpha))):", "prediction_line": "                        and funcm.test(xmid, x, type_='smaller', alpha=alpha))):", "ground_truth": "                        and funcm.test(xmid, x, type_='smaller', alpha=alpha))):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if not isinstance(func, AverageBase):", "prediction_line": "            if not isinstance(func, AverageBase):", "ground_truth": "            testkwargs.update(dict(type_='smaller', force=True))", "line_class": "common", "zero_context": true}
{"original_prediction": "                # convert to tuple (hashable!)", "prediction_line": "                # convert to tuple (hashable!)", "ground_truth": "                index = ()", "line_class": "common", "zero_context": true}
{"original_prediction": "                        index += tuple(arg)", "prediction_line": "                        index += tuple(arg)", "ground_truth": "                        index += tuple(arg)", "line_class": "common", "zero_context": true}
{"original_prediction": "                        index += (arg, )", "prediction_line": "                        index += (arg, )", "ground_truth": "                        index += (arg, )", "line_class": "common", "zero_context": true}
{"original_prediction": "                        index += tuple(item)", "prediction_line": "                        index += tuple(item)", "ground_truth": "                        index += (float(item), )", "line_class": "common", "zero_context": true}
{"original_prediction": "                # if index is not hashable then we can't cache", "prediction_line": "                # if index is not hashable then we can't cache", "ground_truth": "                if index in self.cache:", "line_class": "common", "zero_context": true}
{"original_prediction": "                    return self.cache[index]", "prediction_line": "                    return self.cache[index]", "ground_truth": "                    return self.cache[index]", "line_class": "common", "zero_context": true}
{"original_prediction": "                    self.cache[index] = value", "prediction_line": "                    self.cache[index] = value", "ground_truth": "                    self.cache[index] = value", "line_class": "common", "zero_context": true}
{"original_prediction": "        self._N = int(value)", "prediction_line": "        self._N = int(value)", "ground_truth": "        N = int(value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if N < 1:", "prediction_line": "        if N < 1:", "ground_truth": "        if self.paired and (N > self._N):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.seeds = list(np.random.randint(0, self.uint32max, size=N))", "prediction_line": "            self.seeds = list(np.random.randint(0, self.uint32max, size=N))", "ground_truth": "            Nadd = N - self._N", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    (errorcontrol and func.test0(mid, **testkwargs)):", "prediction_line": "                    (errorcontrol and func.test0(mid, **testkwargs)):", "ground_truth": "                    (errorcontrol and func.test0(mid, **testkwargs)):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._N = N", "prediction_line": "        self._N = N", "ground_truth": "        self._N = N", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return minimizeCompass(*args, **kwargs)", "prediction_line": "    return minimizeCompass(*args, **kwargs)", "ground_truth": "    return minimizeCompass(*args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        super(DifferenceFunction, self).__init__(**kwargs)", "prediction_line": "        super(DifferenceFunction, self).__init__(**kwargs)", "ground_truth": "        basekwargs = dict(N=kwargs.pop('N', 30),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            while True:", "prediction_line": "            while True:", "ground_truth": "            while (self.test0(x, type_='equality', alpha=alpha, force=False, eps=eps)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    and self.nev < maxN):", "prediction_line": "                    and self.nev < maxN):", "ground_truth": "                    and self.N < maxN):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            func1f = func1", "prediction_line": "            func1f = func1", "ground_truth": "            func1f = func1", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.N *= 2", "prediction_line": "                self.N *= 2", "ground_truth": "                self.N *= 2.0", "line_class": "infile", "zero_context": true}
{"original_prediction": "    N = x0.size", "prediction_line": "    N = x0.size", "ground_truth": "    N = len(x0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            func2f = func2", "prediction_line": "            func2f = func2", "ground_truth": "            func2f = func2", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.func1 = func1f", "prediction_line": "        self.func1 = func1f", "ground_truth": "        self.funcs = [func1f, func2f]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # initialize function evaluations", "prediction_line": "        # initialize function evaluations", "ground_truth": "        funcm = AveragedFunction(", "line_class": "infile", "zero_context": true}
{"original_prediction": "func, args, paired, alpha, funcNinit, funcmultfactor)", "prediction_line": "func, args, paired, alpha, funcNinit, funcmultfactor)", "ground_truth": "            func, fargs=args, paired=paired, N=funcNinit)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        funcm = funcf", "prediction_line": "        funcm = funcf", "ground_truth": "        funcm = _memoized(funcf)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if Nold == self.N:", "prediction_line": "            if Nold == self.N:", "ground_truth": "            if Nold < self.N:", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    Nadd = self.N - Nold", "prediction_line": "                    Nadd = self.N - Nold", "ground_truth": "                    Nadd = self.N - Nold", "line_class": "infile", "zero_context": true}
{"original_prediction": "        else:\n            funcf = func", "prediction_line": "        else:", "ground_truth": "            self.func = funcf", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    values = [func(x, seed=self.seeds[i]) for i in range(self.N)]", "prediction_line": "                    values = [func(x, seed=self.seeds[i]) for i in range(self.N)]", "ground_truth": "                    values = [func(x, seed=self.seeds[i]) for i in range(self.N)]", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    values = [func(x) for i in range(self.N)]", "prediction_line": "                    values = [func(x) for i in range(self.N)]", "ground_truth": "                    values = [func(x) for i in range(self.N)]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.nev += self.N", "prediction_line": "            self.nev += self.N", "ground_truth": "            self.nev += self.N", "line_class": "infile", "zero_context": true}
{"original_prediction": "            xnew, deltaeff = clip(x, d*delta)", "prediction_line": "            xnew, deltaeff = clip(x, d*delta)", "ground_truth": "            xtest, deltaeff = clip(x, delta*d)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                values = [self.func(x, seed=self.seeds[i]) for i in range(self.N)]", "prediction_line": "                values = [self.func(x, seed=self.seeds[i]) for i in range(self.N)]", "ground_truth": "                values = [self.func(x, seed=self.seeds[i]) for i in range(self.N)]", "line_class": "infile", "zero_context": true}
{"original_prediction": "                            and funcm.test(xtest, x, type_='smaller', alpha=alpha)))):", "prediction_line": "                            and funcm.test(xtest, x, type_='smaller', alpha=alpha)))):", "ground_truth": "                            and (funcm.diffse(xtest, x) > feps)))):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                values = [self.func(x) for i in range(self.N)]", "prediction_line": "                values = [self.func(x) for i in range(self.N)]", "ground_truth": "                values = [self.func(x) for i in range(self.N)]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        else:\n            diffse = np.sqrt(f1se**2 + f2se**2)", "prediction_line": "        else:", "ground_truth": "            return diffse", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    funcm.N *= funcmultfactor", "prediction_line": "                    funcm.N *= funcmultfactor", "ground_truth": "                    funcm.N *= funcmultfactor", "line_class": "infile", "zero_context": true}
{"original_prediction": "    res = OptimizeResult(x=x, nit=niter, nfev=2*niter, message=message, success=True)", "prediction_line": "    res = OptimizeResult(x=x, nit=niter, nfev=2*niter, message=message, success=True)", "ground_truth": "    return OptimizeResult(fun=funcf(x), x=x, nit=niter, nfev=2*niter, message=message, success=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            fb = func.test0(b, **testkwargs)", "prediction_line": "            fb = func.test0(b, **testkwargs)", "ground_truth": "            fb = func.test0(b, **testkwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.N = N", "prediction_line": "        self.N = N", "ground_truth": "        self._N = int(N)", "line_class": "infile", "zero_context": true}
{"original_prediction": "and\n             funcm.diffse(xtest, x) > feps))):", "prediction_line": "and", "ground_truth": "                and (funcm.diffse(xtest, x) < feps)))):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                raise BisectException('func(a) and func(b) do not have opposing signs')", "prediction_line": "                raise BisectException('func(a) and func(b) do not have opposing signs')", "ground_truth": "                raise BisectException()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            df = self.N - 1 if self.paired else 2*self.N - 2", "prediction_line": "            df = self.N - 1 if self.paired else 2*self.N - 2", "ground_truth": "            df = self.N-1 if self.paired else 2*self.N-2", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @N.setter", "prediction_line": "    @N.setter", "ground_truth": "    @N.setter", "line_class": "infile", "zero_context": true}
{"original_prediction": "            fa = func(a) < 0", "prediction_line": "            fa = func(a) < 0", "ground_truth": "            fa = func(a) < 0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if not func.test0(a, **testkwargs):", "prediction_line": "            if not func.test0(a, **testkwargs):", "ground_truth": "            fa = func.test0(a, **testkwargs)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if disp:", "prediction_line": "    if disp:", "ground_truth": "            message += '. dim %i is free at optimum' % dim", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    free = np.zeros(N, dtype=bool)", "prediction_line": "    free = np.zeros(N, dtype=bool)", "ground_truth": "    free = np.zeros(x.shape, dtype=bool)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            xk = x + ak*ck*Deltak", "prediction_line": "            xk = x + ak*ck*Deltak", "ground_truth": "            grad = (funcf(x + ck*Deltak, **fkwargs) - funcf(x - ck*Deltak, **fkwargs)) / (2*ck*Deltak)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            x = project(x - ak*grad)", "prediction_line": "            x = project(x - ak*grad)", "ground_truth": "            x = project(x - ak*grad)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        fx = np.array(self.cache[tuple(x)])", "prediction_line": "        fx = np.array(self.cache[tuple(x)])", "ground_truth": "        fx = np.array(self.cache[tuple(x)])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # if values are not paired then test on distribution of function values", "prediction_line": "            # if values are not paired then test on distribution of function values", "ground_truth": "            statistic, pvalue = stats.ttest_ind(fxtest, fx, equal_var=False, axis=None)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            fkwargs['seed'] = np.random.randint(2**31-1, dtype=np.int32)", "prediction_line": "            fkwargs['seed'] = np.random.randint(2**31-1, dtype=np.int32)", "ground_truth": "            fkwargs['seed'] = np.random.randint(0, np.iinfo(np.int32).max)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "at x and xtest", "prediction_line": "at x and xtest", "ground_truth": "        fxtest = np.array(self.cache[tuple(xtest)])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            dclipped = xclipped - x", "prediction_line": "            dclipped = xclipped - x", "ground_truth": "            deltaeff = np.abs(x - xclipped).sum()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # initial pattern size", "prediction_line": "    # initial pattern size", "ground_truth": "    x0 = np.asarray(x0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        reskwargs['fun'] = f", "prediction_line": "        reskwargs['fun'] = f", "ground_truth": "        res = OptimizeResult(fun=f, funse=funse, **reskwargs)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Deltak = np.random.randint(0, 2, N) * 2 - 1", "prediction_line": "        Deltak = np.random.randint(0, 2, N) * 2 - 1", "ground_truth": "        Deltak = np.random.choice([-1, 1], size=N)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.seeds.extend(np.random.randint(0, self.uint32max, size=Nadd))", "prediction_line": "            self.seeds.extend(np.random.randint(0, self.uint32max, size=Nadd))", "ground_truth": "            self.seeds.extend(list(np.random.randint(0, self.uint32max, size=Nadd)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        extra arguments to be supplied to func", "prediction_line": "        extra arguments to be supplied to func", "ground_truth": "        extra arguments to be supplied to func", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            np.clip(xnew, bounds[:, 0], bounds[:, 1], out=xnew)", "prediction_line": "            np.clip(xnew, bounds[:, 0], bounds[:, 1], out=xnew)", "ground_truth": "            # if test point depasses set to boundary instead", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        using the `keys()` method.", "prediction_line": "        using the `keys()` method.", "ground_truth": "        using the `keys()` method.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            Number of iterations performed by the optimizer.", "prediction_line": "            Number of iterations performed by the optimizer.", "ground_truth": "            Number of iterations performed by the optimizer.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    and uses the gradient to update the current iterate.", "prediction_line": "    and uses the gradient to update the current iterate.", "ground_truth": "    along stochastic directions Deltak. The elements of Deltak are drawn from", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        if fargs1 is not None:", "prediction_line": "        if fargs1 is not None:", "ground_truth": "        if fargs1 is not None:", "line_class": "random", "zero_context": true}
{"original_prediction": "    if disp:", "prediction_line": "    if disp:", "ground_truth": "    A = 0.01 * niter", "line_class": "random", "zero_context": true}
{"original_prediction": "        ftest, ftestse = self(xtest)", "prediction_line": "        ftest, ftestse = self(xtest)", "ground_truth": "        ftest, ftestse = self(xtest)", "line_class": "random", "zero_context": true}
{"original_prediction": "            if self.paired:", "prediction_line": "            if self.paired:", "ground_truth": "            if self.paired:", "line_class": "random", "zero_context": true}
{"original_prediction": "                self.cache[xt].extend(values)", "prediction_line": "                self.cache[xt].extend(values)", "ground_truth": "                self.cache[xt].extend(values)", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.patches = []", "prediction_line": "        self.patches = []", "ground_truth": "        super().__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "class Backend(ABC):", "prediction_line": "class Backend(ABC):", "ground_truth": "    __str__ = __repr__", "line_class": "commited", "zero_context": true}
{"original_prediction": "        frames[0].save(path, save_all=True, append_images=frames[1:],", "prediction_line": "        frames[0].save(path, save_all=True, append_images=frames[1:],", "ground_truth": "        frames[0].save(path, format='GIF', append_images=frames[1:],", "line_class": "common", "zero_context": true}
{"original_prediction": "        path=params.get('path', None),", "prediction_line": "        path=params.get('path', None),", "ground_truth": "        params.get('path', None),", "line_class": "common", "zero_context": true}
{"original_prediction": "                node_size=300 * params.get(\"nodesize\", 1),", "prediction_line": "                node_size=300 * params.get(\"nodesize\", 1),", "ground_truth": "                node_size=300 * params.get(\"nodesize\", 1))", "line_class": "common", "zero_context": true}
{"original_prediction": "        tikz_options=params.get('tikz_options', None),", "prediction_line": "        tikz_options=params.get('tikz_options', None),", "ground_truth": "        tikz_options=params.get('tikz_options', None),", "line_class": "common", "zero_context": true}
{"original_prediction": "        pos[node] = position", "prediction_line": "        pos[node] = position", "ground_truth": "        pos.update({node: position})", "line_class": "common", "zero_context": true}
{"original_prediction": "        margins=params.get('margins', DEFAULT['margins']),", "prediction_line": "        margins=params.get('margins', DEFAULT['margins']),", "ground_truth": "        margins=params.get('margins', DEFAULT['margins']),", "line_class": "common", "zero_context": true}
{"original_prediction": "        aspect=params.get('aspect', DEFAULT['aspect']))", "prediction_line": "        aspect=params.get('aspect', DEFAULT['aspect']))", "ground_truth": "        aspect=params.get('aspect', 'equal'))", "line_class": "common", "zero_context": true}
{"original_prediction": "        if path is not None:", "prediction_line": "        if path is not None:", "ground_truth": "        xlim, ylim = params.get(\"xlim\", None), params.get(\"ylim\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "        if xlim is not None:", "prediction_line": "        if xlim is not None:", "ground_truth": "        margins = params.get(\"margins\", DEFAULT['margins'])", "line_class": "common", "zero_context": true}
{"original_prediction": "        textpad = params.get(\"textpad\", DEFAULT['textpad'])", "prediction_line": "        textpad = params.get(\"textpad\", DEFAULT['textpad'])", "ground_truth": "        aspect = params.get(\"aspect\", DEFAULT['aspect'])", "line_class": "common", "zero_context": true}
{"original_prediction": "            swaps = swaps.swap(source.obj, target.obj)", "prediction_line": "            swaps = swaps.swap(source.obj, target.obj)", "ground_truth": "            j = scan.index(source)", "line_class": "common", "zero_context": true}
{"original_prediction": "   from discopy.tensor import Tensor", "prediction_line": "   from discopy.tensor import Tensor", "ground_truth": "    textpad = params.get('textpad', (.1, .2))", "line_class": "common", "zero_context": true}
{"original_prediction": "    fontsize = params.get('fontsize', 12)", "prediction_line": "    fontsize = params.get('fontsize', 12)", "ground_truth": "    textpad_words = params.get('textpad_words', (0, .1))", "line_class": "common", "zero_context": true}
{"original_prediction": "    fontsize = params.get('fontsize', 12)", "prediction_line": "    fontsize = params.get('fontsize', 12)", "ground_truth": "    space = params.get('space', .5)", "line_class": "common", "zero_context": true}
{"original_prediction": "    if pad[1] == 0:", "prediction_line": "    if pad[1] == 0:", "ground_truth": "    scale_x, scale_y = params.get('scale', (1, 1))", "line_class": "common", "zero_context": true}
{"original_prediction": "    height = params.get('height', 1.)", "prediction_line": "    height = params.get('height', 1.)", "ground_truth": "    fontsize = params.get('fontsize', None)", "line_class": "common", "zero_context": true}
{"original_prediction": "        if params.get('to_tikz', False)\\", "prediction_line": "        if params.get('to_tikz', False)\\", "ground_truth": "        if params.get('to_tikz', False)\\", "line_class": "common", "zero_context": true}
{"original_prediction": "                        linewidth=params.get('linewidth', 1))", "prediction_line": "                        linewidth=params.get('linewidth', 1))", "ground_truth": "                        linewidth=params.get('linewidth', 1))", "line_class": "common", "zero_context": true}
{"original_prediction": "        show=params.get('show', True),", "prediction_line": "        show=params.get('show', True),", "ground_truth": "        show=params.get(\"show\", True),", "line_class": "common", "zero_context": true}
{"original_prediction": "**params)", "prediction_line": "**params)", "ground_truth": "        path=params.get('path', None),", "line_class": "common", "zero_context": true}
{"original_prediction": "            self.add_node(i, j, text, options)", "prediction_line": "            self.add_node(i, j, text, options)", "ground_truth": "            if params.get(\"nodesize\", 1) != 1:", "line_class": "common", "zero_context": true}
{"original_prediction": "        output_tikzstyle=params.get('output_tikzstyle', True),", "prediction_line": "        output_tikzstyle=params.get('output_tikzstyle', True),", "ground_truth": "        show=params.get('show', True),", "line_class": "common", "zero_context": true}
{"original_prediction": "        xlim=params.get('xlim', None),", "prediction_line": "        xlim=params.get('xlim', None),", "ground_truth": "        aspect=params.get('aspect', DEFAULT['aspect']))", "line_class": "common", "zero_context": true}
{"original_prediction": "                backend.draw_text(", "prediction_line": "                backend.draw_text(", "ground_truth": "                if params.get('draw_type_labels', True):", "line_class": "common", "zero_context": true}
{"original_prediction": "                label = str(wires[-1].cod[i])", "prediction_line": "                label = str(wires[-1].cod[i])", "ground_truth": "                if params.get('pretty_types', False):", "line_class": "common", "zero_context": true}
{"original_prediction": "        \"\"\" Output the drawing. \"\"\"", "prediction_line": "        \"\"\" Output the drawing. \"\"\"", "ground_truth": "        baseline = params.get(\"baseline\", 0)", "line_class": "common", "zero_context": true}
{"original_prediction": "        aspect = params.get(\"aspect\", DEFAULT[\"aspect\"])", "prediction_line": "        aspect = params.get(\"aspect\", DEFAULT[\"aspect\"])", "ground_truth": "        tikz_options = params.get(\"tikz_options\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "                        fontsize=fontsize, verticalalignment='top')", "prediction_line": "                        fontsize=fontsize, verticalalignment='top')", "ground_truth": "                        fontsize=params.get('fontsize_types', fontsize),", "line_class": "common", "zero_context": true}
{"original_prediction": "            and not params.get(\"tikzstyle_only\", False)", "prediction_line": "            and not params.get(\"tikzstyle_only\", False)", "ground_truth": "            and params.get(\"output_tikzstyle\", True)", "line_class": "common", "zero_context": true}
{"original_prediction": "    asymmetry = params.get('asymmetry', DEFAULT['asymmetry'])", "prediction_line": "    asymmetry = params.get('asymmetry', DEFAULT['asymmetry'])", "ground_truth": "    asymmetry = params.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "        return scan", "prediction_line": "        return scan", "ground_truth": "            if params.get('triangles', False):", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.nodes[node] = (i, j)", "prediction_line": "        self.nodes[node] = (i, j)", "ground_truth": "        self.nodes.update({(i, j): node})", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.axis.text(i, j, text, **params)", "prediction_line": "        self.axis.text(i, j, text, **params)", "ground_truth": "        params['fontsize'] = params.get('fontsize', DEFAULT['fontsize'])", "line_class": "common", "zero_context": true}
{"original_prediction": "marker=params.get('shape', 'o'),", "prediction_line": "marker=params.get('shape', 'o'),", "ground_truth": "            c=COLORS[params.get(\"color\", \"black\")],", "line_class": "common", "zero_context": true}
{"original_prediction": "            marker=SHAPES[params.get(\"shape\", \"circle\")],", "prediction_line": "            marker=SHAPES[params.get(\"shape\", \"circle\")],", "ground_truth": "            marker=SHAPES[params.get(\"shape\", \"circle\")],", "line_class": "common", "zero_context": true}
{"original_prediction": "            s=params.get(\"nodesize\", 1) * 100,", "prediction_line": "            s=params.get(\"nodesize\", 1) * 100,", "ground_truth": "            s=300 * params.get(\"nodesize\", 1),", "line_class": "common", "zero_context": true}
{"original_prediction": "            linewidths=self.linewidth)", "prediction_line": "            linewidths=self.linewidth)", "ground_truth": "            edgecolors=params.get(\"edgecolor\", None))", "line_class": "common", "zero_context": true}
{"original_prediction": "    if params.get('draw_box_labels', True):", "prediction_line": "    if params.get('draw_box_labels', True):", "ground_truth": "    if params.get('draw_box_labels', True):", "line_class": "common", "zero_context": true}
{"original_prediction": "                          fontsize=params.get('fontsize', None))", "prediction_line": "                          fontsize=params.get('fontsize', None))", "ground_truth": "                          fontsize=params.get('fontsize', None))", "line_class": "common", "zero_context": true}
{"original_prediction": "        if 'color' in params:", "prediction_line": "        if 'color' in params:", "ground_truth": "        if params.get('horizontalalignment', 'center') == 'left':", "line_class": "common", "zero_context": true}
{"original_prediction": "                    and target.kind in [\"output\", \"dom\"]:", "prediction_line": "                    and target.kind in [\"output\", \"dom\"]:", "ground_truth": "                    and (params.get('draw_type_labels', True)", "line_class": "common", "zero_context": true}
{"original_prediction": "                         or source.box.draw_as_braid):", "prediction_line": "                         or source.box.draw_as_braid):", "ground_truth": "                         and params.get('draw_box_labels', True)):", "line_class": "common", "zero_context": true}
{"original_prediction": "                text = source.obj.drawing_name", "prediction_line": "                text = source.obj.drawing_name", "ground_truth": "                pad_i, pad_j = params.get('textpad', DEFAULT['textpad'])", "line_class": "common", "zero_context": true}
{"original_prediction": "    timestep = params.pop(\"timestep\", 500)", "prediction_line": "    timestep = params.pop(\"timestep\", 500)", "ground_truth": "    timestep = params.get(\"timestep\", 500)", "line_class": "common", "zero_context": true}
{"original_prediction": "    loop = params.get(\"loop\", False)", "prediction_line": "    loop = params.get(\"loop\", False)", "ground_truth": "    loop = params.get(\"loop\", False)", "line_class": "common", "zero_context": true}
{"original_prediction": "                    fontsize=params.get('fontsize_types', DEFAULT['fontsize']))", "prediction_line": "                    fontsize=params.get('fontsize_types', DEFAULT['fontsize']))", "ground_truth": "                    fontsize=params.get('fontsize_types',", "line_class": "common", "zero_context": true}
{"original_prediction": "DEFAULT['fontsize']))", "prediction_line": "DEFAULT['fontsize']))", "ground_truth": "                                        params.get('fontsize', None)),", "line_class": "common", "zero_context": true}
{"original_prediction": "    for i, word in enumerate(words.boxes):", "prediction_line": "    for i, word in enumerate(words.boxes):", "ground_truth": "    draw_grammar(layers, scan)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        graph.add_node(node)", "prediction_line": "        graph.add_node(node)", "ground_truth": "        graph.add_node(node)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            graph.add_node(box_node)", "prediction_line": "            graph.add_node(box_node)", "ground_truth": "            graph.add_node(box_node)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        super().draw_spiders(graph, positions, draw_box_labels)", "prediction_line": "        super().draw_spiders(graph, positions, draw_box_labels)", "ground_truth": "        super().draw_spiders(graph, positions, draw_box_labels)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            add_node(wire, position)", "prediction_line": "            add_node(wire, position)", "ground_truth": "            add_node(wire, position)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.add_node(*source)", "prediction_line": "            self.add_node(*source)", "ground_truth": "            self.add_node(*source)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            setattr(apply, box.name, box)", "prediction_line": "            setattr(apply, box.name, box)", "ground_truth": "            box._apply = apply", "line_class": "infile", "zero_context": true}
{"original_prediction": "        TikzBackend() if params.get('to_tikz', False) else MatBackend()", "prediction_line": "        TikzBackend() if params.get('to_tikz', False) else MatBackend()", "ground_truth": "        TikzBackend(use_tikzstyles=params.get('use_tikzstyles', None))\\", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.add_node(*target)", "prediction_line": "            self.add_node(*target)", "ground_truth": "            self.add_node(*target)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        else MatBackend(**params)", "prediction_line": "        else MatBackend(**params)", "ground_truth": "        else MatBackend(figsize=params.get('figsize', None),", "line_class": "infile", "zero_context": true}
{"original_prediction": "        wire = Node(\"dom\", obj=obj, i=i, depth=0)", "prediction_line": "        wire = Node(\"dom\", obj=obj, i=i, depth=0)", "ground_truth": "        node = Node(\"input\", obj=obj, i=i)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        else TikzBackend(use_tikzstyles=params.get('use_tikzstyles', None))\\", "prediction_line": "        else TikzBackend(use_tikzstyles=params.get('use_tikzstyles', None))\\", "ground_truth": "        else TikzBackend(use_tikzstyles=params.get('use_tikzstyles', None))\\", "line_class": "infile", "zero_context": true}
{"original_prediction": "        else MatBackend(figsize=params.get('figsize', None),", "prediction_line": "        else MatBackend(figsize=params.get('figsize', None),", "ground_truth": "        else MatBackend(figsize=params.get('figsize', None))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        super().draw_wire(source, target, bend_out=bend_out, bend_in=bend_in)", "prediction_line": "        super().draw_wire(source, target, bend_out=bend_out, bend_in=bend_in)", "ground_truth": "        super().draw_wire(source, target, bend_out=bend_out, bend_in=bend_in)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            node = Node(\"cod\", obj=obj, i=i)", "prediction_line": "            node = Node(\"cod\", obj=obj, i=i)", "ground_truth": "            node = Node(\"output\", obj=obj, i=i)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    .format(node.box.tikzstyle_name, self.format_color(color))", "prediction_line": "                    .format(node.box.tikzstyle_name, self.format_color(color))", "ground_truth": "                    .format(node.box.tikzstyle_name, self.format_color(color))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return decorator", "prediction_line": "    return decorator", "ground_truth": "    return decorator", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        type_str = pretty_type(word.cod[j])", "prediction_line": "                        type_str = pretty_type(word.cod[j])", "ground_truth": "                        type_str = pretty_type(word.cod[j])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.add_node(i, j, text, options)", "prediction_line": "            self.add_node(i, j, text, options)", "ground_truth": "            self.add_node(i, j, text, options)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    ]\n    for name, method in drawing_methods:", "prediction_line": "    ]", "ground_truth": "        (None, draw_box)]", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if asymmetry:", "prediction_line": "    if asymmetry:", "ground_truth": "    height = positions[node][1] - .25", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return equation(*self.terms, **params)", "prediction_line": "        return equation(*self.terms, **params)", "ground_truth": "        return equation(*self.terms, **dict(params, symbol=self.symbol))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # value is (left, right, height, asymmetry)", "prediction_line": "    # value is (left, right, height, asymmetry)", "ground_truth": "    points = [[left, height], [right, height],", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x_pos = make_space(scan, box, off)", "prediction_line": "        x_pos = make_space(scan, box, off)", "ground_truth": "        x_pos = make_space(scan, box, off)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if inside_a_box(source) or inside_a_box(target):", "prediction_line": "            if inside_a_box(source) or inside_a_box(target):", "ground_truth": "            if inside_a_box(source) or inside_a_box(target):", "line_class": "infile", "zero_context": true}
{"original_prediction": "[right, height - .5],", "prediction_line": "[right, height - .5],", "ground_truth": "              [right, height + .5], [left, height + .5]]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        add_node(node, (i, -len(diagram) or -1))", "prediction_line": "        add_node(node, (i, -len(diagram) or -1))", "ground_truth": "        add_node(node, (pos[scan[i]][0], 0))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        super().draw_text(text, i, j, **params)", "prediction_line": "        super().draw_text(text, i, j, **params)", "ground_truth": "        super().draw_text(text, i, j, **params)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if 'tikzstyle_name' in params:", "prediction_line": "        if 'tikzstyle_name' in params:", "ground_truth": "        self.add_node(i, j, text, options=\", \".join(options))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def draw_text(self, text, i, j, **params):", "prediction_line": "    def draw_text(self, text, i, j, **params):", "ground_truth": "        super().draw_node(i, j, **params)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.kind == other.kind and self.data == other.data", "prediction_line": "        return self.kind == other.kind and self.data == other.data", "ground_truth": "        return isinstance(other, Node)\\", "line_class": "infile", "zero_context": true}
{"original_prediction": "        super().draw_polygon(*points, color=color)", "prediction_line": "        super().draw_polygon(*points, color=color)", "ground_truth": "        super().draw_polygon(*points, color=color)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            i, j = point", "prediction_line": "            i, j = point", "ground_truth": "            nodes.append(self.add_node(*point))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                .format(style_name, self.format_color(color))", "prediction_line": "                .format(style_name, self.format_color(color))", "ground_truth": "                .format(style_name, self.format_color(color))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            _diagram.draw(path=tmp_path, **params)", "prediction_line": "            _diagram.draw(path=tmp_path, **params)", "ground_truth": "            _diagram.draw(path=tmp_path, **params)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        (\"draw_as_discards\", draw_discard),", "prediction_line": "        (\"draw_as_discards\", draw_discard),", "ground_truth": "        (\"draw_as_discards\", draw_discard),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif i > j:", "prediction_line": "        elif i > j:", "ground_truth": "    return diagram >> swaps", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            positions[Node(\"cod\", obj=box.cod.inside[i], i=i, depth=depth)][0]", "prediction_line": "            positions[Node(\"cod\", obj=box.cod.inside[i], i=i, depth=depth)][0]", "ground_truth": "            positions[Node(\"cod\", obj=box.cod.inside[i], i=i, depth=depth)][0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        add_node(node, (i, len(diagram) - .5))", "prediction_line": "        add_node(node, (i, len(diagram) - .5))", "ground_truth": "        add_node(node, (i, len(diagram) or 1))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for i, obj in enumerate(box.cod.inside)]", "prediction_line": "            for i, obj in enumerate(box.cod.inside)]", "ground_truth": "            for i, obj in enumerate(box.cod.inside)]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            looseness = 1 + 100 * (1 + sqrt(dx * dx + dy * dy)) / (dx + dy)", "prediction_line": "            looseness = 1 + 100 * (1 + sqrt(dx * dx + dy * dy)) / (dx + dy)", "ground_truth": "            length = sqrt(dx * dx + dy * dy)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def decorator(func):", "prediction_line": "    def decorator(func):", "ground_truth": "    factory = factory or boxes[0].factory", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    for node in outputs:", "prediction_line": "    for node in outputs:", "ground_truth": "    swaps = _id(diagram.cod)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            swaps = swaps.swap(i, offset + i)", "prediction_line": "            swaps = swaps.swap(i, offset + i)", "ground_truth": "            target = Node(\"dom\", obj=obj, i=i, depth=depth)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            node = Node(\"box\", box=box, depth=depth, offset=offset)", "prediction_line": "            node = Node(\"box\", box=box, depth=depth, offset=offset)", "ground_truth": "            box_node = Node(\"box\", box=box, depth=depth, offset=offset)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def draw_diagram(diagram, i, j, **params):", "prediction_line": "    def draw_diagram(diagram, i, j, **params):", "ground_truth": "    pad, max_height = params.get('pad', (0, 0)), max(map(height, diagrams))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                scan_y[2 * off] = new_gap_depth", "prediction_line": "                scan_y[2 * off] = new_gap_depth", "ground_truth": "                backend.draw_wire(midpoint, (x1, - y - h - h), bend_out=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            graph.add_edge(wire, node)", "prediction_line": "            graph.add_edge(wire, node)", "ground_truth": "            if not bubble or bubble_closing and i in [0, len(box.dom) - 1]:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    for node in boxes:", "prediction_line": "    for node in boxes:", "ground_truth": "    for depth, box_node in enumerate(boxes):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if hasattr(diagram, \"terms\"):", "prediction_line": "        if hasattr(diagram, \"terms\"):", "ground_truth": "        scale = (scale_x, scale_y * max_height / height(diagram))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    An equation is a sum of terms.", "prediction_line": "    An equation is a sum of terms.", "ground_truth": "    An equation is a list of diagrams with a dedicated draw method.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def draw_spiders(self, graph, positions, draw_box_labels=True, **params):", "prediction_line": "    def draw_spiders(self, graph, positions, draw_box_labels=True, **params):", "ground_truth": "    def draw_spiders(self, graph, positions, draw_box_labels=True, **params):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class Node(ABC):", "prediction_line": "class Node(ABC):", "ground_truth": "# Default drawing parameters.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __repr__(self):", "prediction_line": "    def __repr__(self):", "ground_truth": "    def __repr__(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        if nodes:", "prediction_line": "        if nodes:", "ground_truth": "        shapes = {node: node.box.shape for node in nodes}", "line_class": "random", "zero_context": true}
{"original_prediction": "                else (box.cod, box.dom[1:-1])", "prediction_line": "                else (box.cod, box.dom[1:-1])", "ground_truth": "                else (box.dom[1:-1], box.cod)", "line_class": "random", "zero_context": true}
{"original_prediction": "                with open(style_path, 'w') as f:", "prediction_line": "                with open(style_path, 'w') as f:", "ground_truth": "                with open(style_path, 'w+') as file:", "line_class": "random", "zero_context": true}
{"original_prediction": "            graph.add_edge(node, scan[off + len(box.dom)])", "prediction_line": "            graph.add_edge(node, scan[off + len(box.dom)])", "ground_truth": "            source_ty, target_ty = (box.dom, box.cod[1:-1]) if bubble_opening\\", "line_class": "random", "zero_context": true}
{"original_prediction": "        if 'color' in params:", "prediction_line": "        if 'color' in params:", "ground_truth": "        if 'color' in params:", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(start, start, label)", "prediction_line": "        super().__init__(start, start, label)", "ground_truth": "        super().__init__(start, start, label)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return f'{self.start}..{self.stop}'", "prediction_line": "        return f'{self.start}..{self.stop}'", "ground_truth": "        return f\"Cell({self.start}, {self.stop}, {self.label})\"", "line_class": "common", "zero_context": true}
{"original_prediction": "                td = SubElement(tr, \"td\")", "prediction_line": "                td = SubElement(tr, \"td\")", "ground_truth": "                if cell.start > offset:", "line_class": "common", "zero_context": true}
{"original_prediction": "            rows.append([Wire(cell.stop, x) for cell in rows[-2]])", "prediction_line": "            rows.append([Wire(cell.stop, x) for cell in rows[-2]])", "ground_truth": "        offset = min([min([0] + [cell.start for cell in row]) for row in rows])", "line_class": "common", "zero_context": true}
{"original_prediction": "                    td.set('class', 'wire')", "prediction_line": "                    td.set('class', 'wire')", "ground_truth": "                    if cell.start == cell.stop:", "line_class": "common", "zero_context": true}
{"original_prediction": "                    td.attrib[\"colspan\"] = str(cell.start - offset)", "prediction_line": "                    td.attrib[\"colspan\"] = str(cell.start - offset)", "ground_truth": "                    td.set('colspan', str(cell.start - offset))", "line_class": "common", "zero_context": true}
{"original_prediction": "                    else:", "prediction_line": "                    else:", "ground_truth": "                if cell.start < cell.stop:", "line_class": "common", "zero_context": true}
{"original_prediction": "                    td.set('colspan', str(cell.stop - cell.start))", "prediction_line": "                    td.set('colspan', str(cell.stop - cell.start))", "ground_truth": "                    td.set(\"colspan\", str(cell.stop - cell.start))", "line_class": "common", "zero_context": true}
{"original_prediction": "        return f\"Wire({self.start}, {self.label})\"", "prediction_line": "        return f\"Wire({self.start}, {self.label})\"", "ground_truth": "        return f\"Wire({self.start}, {self.label})\"", "line_class": "common", "zero_context": true}
{"original_prediction": "                            raise ValueError(\"Cannot layout empty diagram.\")", "prediction_line": "                            raise ValueError(\"Cannot layout empty diagram.\")", "ground_truth": "                            start = 0", "line_class": "common", "zero_context": true}
{"original_prediction": "    start: int", "prediction_line": "    start: int", "ground_truth": "    start: int", "line_class": "common", "zero_context": true}
{"original_prediction": "                        if cell.start >= limit:", "prediction_line": "                        if cell.start >= limit:", "ground_truth": "                        cell.start += space * int(cell.start <= limit)", "line_class": "common", "zero_context": true}
{"original_prediction": "                if cell.start == cell.stop:", "prediction_line": "                if cell.start == cell.stop:", "ground_truth": "                result += (cell.start - len(result)) * \" \"", "line_class": "common", "zero_context": true}
{"original_prediction": "                        cell.start += space * int(cell.start >= limit)", "prediction_line": "                        cell.start += space * int(cell.start >= limit)", "ground_truth": "                        cell.start += space * int(cell.start >= limit)", "line_class": "common", "zero_context": true}
{"original_prediction": "                        cell.stop - cell.start) + \" \"", "prediction_line": "                        cell.stop - cell.start) + \" \"", "ground_truth": "                        cell.stop - cell.start - 1, \"-\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                        + [Wire(start, x) for x in box.cod]\\", "prediction_line": "                        + [Wire(start, x) for x in box.cod]\\", "ground_truth": "                        + [Wire(start + 2 * j + 1, x)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return Grid([[cell + offset for cell in row] for row in self.rows])", "prediction_line": "        return Grid([[cell + offset for cell in row] for row in self.rows])", "ground_truth": "        return Grid([", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for box in layer:", "prediction_line": "            for box in layer:", "ground_truth": "            rows.append([Wire(cell.start, cell.label) for cell in rows[-2]])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def __sub__(self, offset: int):", "prediction_line": "    def __sub__(self, offset: int):", "ground_truth": "    __sub__ = Cell.__sub__", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for i, row in enumerate(rows):", "prediction_line": "        for i, row in enumerate(rows):", "ground_truth": "        return Grid(rows) - offset", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return Wire(self.start + offset, self.label)", "prediction_line": "        return Wire(self.start + offset, self.label)", "ground_truth": "        return Wire(self.start + offset, self.label)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    rows: list[list[Cell]]", "prediction_line": "    rows: list[list[Cell]]", "ground_truth": "    rows: list[list[Cell]]", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if cell.start == cell.stop:", "prediction_line": "                if cell.start == cell.stop:", "ground_truth": "                if isinstance(cell, Wire):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        right = wires[offset].start", "prediction_line": "                        right = wires[offset].start", "ground_truth": "                        make_space(rows, left, min(0, start - left - 2))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Shifts the cell by ``offset``.", "prediction_line": "        \"\"\"", "ground_truth": "        return Cell(self.start + offset, self.stop + offset, self.label)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                        make_space(rows, right, max(0, stop - right - 2))", "prediction_line": "                        make_space(rows, right, max(0, stop - right - 2))", "ground_truth": "                        make_space(rows, right, max(0, stop - right + 1))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    if offset + len(box.dom) < len(wires):", "prediction_line": "                    if offset + len(box.dom) < len(wires):", "ground_truth": "                    if offset + len(box.dom) < len(wires):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    boxes.append(Cell(start, stop, box))", "prediction_line": "                    boxes.append(Cell(start, stop, box))", "ground_truth": "                        stop = max(stop, start + width)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return \"\\n\".join(row_to_ascii(row) for row in self.rows)", "prediction_line": "        return \"\\n\".join(row_to_ascii(row) for row in self.rows)", "ground_truth": "        return '\\n'.join(map(row_to_ascii, self.rows)).strip('\\n')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        start = wires[offset - 1].stop + 2", "prediction_line": "                        start = wires[offset - 1].stop + 2", "ground_truth": "                        start = wires[offset].start - 1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for layer in diagram.layers:", "prediction_line": "        for layer in diagram.layers:", "ground_truth": "        for layer in diagram.inside:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                            start = wires[0].start", "prediction_line": "                            start = wires[0].start", "ground_truth": "                            start = wires[0].start - width", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for box in layer:", "prediction_line": "            for box in layer:", "ground_truth": "            for i, type_or_box in enumerate(layer):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        cell = Cell(", "prediction_line": "                        cell = Cell(", "ground_truth": "                        boxes.append(Wire(wires[offset + j].start, x))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    label: str = ''", "prediction_line": "    label: str = ''", "ground_truth": "    label: Ty | Box = None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for cell in layer:", "prediction_line": "            for cell in layer:", "ground_truth": "            boxes, wires = rows[-2], rows[-1]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        box.dom = [Ty()]", "prediction_line": "                        box.dom = [Ty()]", "ground_truth": "                        if not wires:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    offset += len(box.dom)", "prediction_line": "                    offset += len(box.dom)", "ground_truth": "                    rows[-1] = wires = wires[:offset]\\", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        stop = wires[offset + len(box.dom) - 1].stop + 1", "prediction_line": "                        stop = wires[offset + len(box.dom) - 1].stop + 1", "ground_truth": "                        stop = wires[offset + len(box.dom) - 1].stop + 1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    boxes.append(Cell(start, stop, box))", "prediction_line": "                    boxes.append(Cell(start, stop, box))", "ground_truth": "                    boxes.append(Cell(start, stop, box))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        + wires[offset + len(box.dom):]", "prediction_line": "                        + wires[offset + len(box.dom):]", "ground_truth": "                        + wires[offset + len(box.dom):]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Parameters:", "prediction_line": "        Parameters:", "ground_truth": "        The first row is a list of :class:`Wire` cells, then for each layer of", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "         |        |  |     |", "prediction_line": "         |        |  |     |", "ground_truth": "         |        |  |  o  |", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __sub__(self, offset: int) -> Cell:", "prediction_line": "    def __sub__(self, offset: int) -> Cell:", "ground_truth": "    def __sub__(self, offset: int) -> Cell:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        stop : The right of the cell.", "prediction_line": "        stop : The right of the cell.", "ground_truth": "        stop : The right of the cell.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"\n    rows: list[list[Cell]]", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    stop: int", "prediction_line": "    stop: int", "ground_truth": "    stop: int", "line_class": "random", "zero_context": true}
{"original_prediction": "                offset = cell.stop", "prediction_line": "                offset = cell.stop", "ground_truth": "        return table", "line_class": "random", "zero_context": true}
{"original_prediction": "            rows.append([])", "prediction_line": "            rows.append([])", "ground_truth": "            offset = 0", "line_class": "random", "zero_context": true}
{"original_prediction": "                        cell.stop += space * int(cell.stop >= limit)", "prediction_line": "                        cell.stop += space * int(cell.stop >= limit)", "ground_truth": "                        cell.stop += space * int(cell.stop >= limit)", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(", "prediction_line": "        super().__init__(", "ground_truth": "        super().__init__(", "line_class": "commited", "zero_context": true}
{"original_prediction": "Rx(theta) for theta in thetas))", "prediction_line": "Rx(theta) for theta in thetas))", "ground_truth": "                Id(i) @ CRz(thetas[i]) @ Id(n_qubits - 2 - i)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif len(params_shape) != 2 or params_shape[1] != 3 * n_qubits:", "prediction_line": "        elif len(params_shape) != 2 or params_shape[1] != 3 * n_qubits:", "ground_truth": "        elif (len(params_shape) != 2) or (params_shape[1] != 4 * n_qubits):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                or Tensor.np.shape(params)[0] != n_qubits - 1\\", "prediction_line": "                or Tensor.np.shape(params)[0] != n_qubits - 1\\", "ground_truth": "                or Tensor.np.shape(params)[1] != n_qubits - 1:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    layers = [layer(v, is_last=i == len(params) - 1) for i, v in", "prediction_line": "    layers = [layer(v, is_last=i == len(params) - 1) for i, v in", "ground_truth": "    circuit = [layer(v, is_last=idx == (len(params) - 1)) for", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if entanglement == 'full':", "prediction_line": "        if entanglement == 'full':", "ground_truth": "        rys = Id(0).tensor(*(Ry(v[k]) for k in range(n)))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if entanglement == 'linear':", "prediction_line": "    if entanglement == 'linear':", "ground_truth": "    params = Tensor.np.asarray(params)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                sublayer1 = sublayer1.CX(src, tgt)", "prediction_line": "                sublayer1 = sublayer1.CX(src, tgt)", "ground_truth": "                sublayer1 = sublayer1.CX(src, tgt)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                *(Ry(thetas[i]) for i in range(n_qubits - 1)))", "prediction_line": "                *(Ry(thetas[i]) for i in range(n_qubits - 1)))", "ground_truth": "                *([Ry(theta) for theta in thetas[:n_qubits]]))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    circuit = Id(n_qubits)", "prediction_line": "    circuit = Id(n_qubits)", "ground_truth": "    result = Id(n_qubits)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            rotations = Id(n_qubits).then(*(", "prediction_line": "            rotations = Id(n_qubits).then(*(", "ground_truth": "            sublayer1 = Id().tensor(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        else:\n            circuit = H @ Id(n_qubits - 1)", "prediction_line": "        else:", "ground_truth": "        elif len(Tensor.np.shape(params)) != 2\\", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    circuit = reduce(lambda a, b: a >> b, circuit)", "prediction_line": "    circuit = reduce(lambda a, b: a >> b, circuit)", "ground_truth": "    circuit = reduce(lambda a, b: a >> b, circuit)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "Gate\n    from discopy.quantum.circuit import Id", "prediction_line": "Gate", "ground_truth": "    gateset = gateset or [H, Rx, CX]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                sublayer2 = sublayer2.CX(src, tgt)", "prediction_line": "                sublayer2 = sublayer2.CX(src, tgt)", "ground_truth": "                sublayer2 = sublayer2.CX(src, tgt)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        elif (len(params_shape) != 2) or (params_shape[1] != 3 * n_qubits):", "prediction_line": "        elif (len(params_shape) != 2) or (params_shape[1] != 3 * n_qubits):", "ground_truth": "        elif (len(params_shape) != 2) or (params_shape[1] != 2 * n_qubits):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@ Id(1) >> Id(2) @ T", "prediction_line": "@ Id(1) >> Id(2) @ T", "ground_truth": "    >>> print(random_tiling(3, 2, gateset=[CX, H, T], seed=420))", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "      >> Id(2) @ CRz(0.3)", "prediction_line": "      >> Id(2) @ CRz(0.3)", "ground_truth": "      >> H @ Id(2)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "      >> Id(1) @ Ry(0.7) @ Id(1)", "prediction_line": "      >> Id(1) @ Ry(0.7) @ Id(1)", "ground_truth": "      >> Id(1) @ Ry(0.7) @ Id(1)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "      >> Id(1) @ Ry(0.1) @ Id(1)", "prediction_line": "      >> Id(1) @ Ry(0.1) @ Id(1)", "ground_truth": "      >> Id(1) @ Ry(0.1) @ Id(1)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    >>> print(c)", "prediction_line": "    >>> print(c)", "ground_truth": "    >>> print(c)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "g for g in gateset", "prediction_line": "g for g in gateset", "ground_truth": "                    g for g in gateset", "line_class": "random", "zero_context": true}
{"original_prediction": "            for i in range(n_qubits, 0, -1):", "prediction_line": "            for i in range(n_qubits, 0, -1):", "ground_truth": "            for i in range(n_qubits, 0, -1):", "line_class": "random", "zero_context": true}
{"original_prediction": "            for i in range(n_qubits):", "prediction_line": "            for i in range(n_qubits):", "ground_truth": "            for i in range(n_qubits):", "line_class": "random", "zero_context": true}
{"original_prediction": "        result = result >> line", "prediction_line": "        result = result >> line", "ground_truth": "        result = result >> line", "line_class": "random", "zero_context": true}
{"original_prediction": "Device.MOUSE = Device(", "prediction_line": "Device.MOUSE = Device(", "ground_truth": "Device.MOUSE = Device(", "line_class": "infile", "zero_context": true}
{"original_prediction": "class HID():", "prediction_line": "class HID():", "ground_truth": "Device.CONSUMER_CONTROL = Device(", "line_class": "infile", "zero_context": true}
{"original_prediction": "def enable() -> None:", "prediction_line": "def enable() -> None:", "ground_truth": "atexit.register(disable)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        raise ValueError('No devices specified')", "prediction_line": "        raise ValueError('No devices specified')", "ground_truth": "        disable()", "line_class": "infile", "zero_context": true}
{"original_prediction": "class HID():", "prediction_line": "class HID():", "ground_truth": "devices = [Device.KEYBOARD, Device.MOUSE, Device.CONSUMER_CONTROL]", "line_class": "infile", "zero_context": true}
{"original_prediction": "   def recv_report(self, report_id: int = None):", "prediction_line": "   def recv_report(self, report_id: int = None):", "ground_truth": "Device.KEYBOARD = Device(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        Path('%s/ep0' % device).write_bytes(report)", "prediction_line": "        Path('%s/ep0' % device).write_bytes(report)", "ground_truth": "        with open('/dev/hidg%s' % device, 'rb+') as fd:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            fd.write(report)", "prediction_line": "            fd.write(report)", "ground_truth": "            fd.write(report)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Each function also needs its strings, so a subdirectory must be created", "prediction_line": "        Each function also needs its strings, so a subdirectory must be created", "ground_truth": "          ...", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        or read-write access.", "prediction_line": "        or read-write access.", "ground_truth": "        or read-write access. Where applicable they need to be written to as", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    The gadget must also have a name::", "prediction_line": "    The gadget must also have a name::", "ground_truth": "    A gadget also needs its serial number, manufacturer and product strings.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    This is done by writing the name of the gadget to the UDC file::", "prediction_line": "    This is done by writing the name of the gadget to the UDC file::", "ground_truth": "    ", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    Path('%s/iManufacturer' % gadget_root).write_text('%s' % 1)", "prediction_line": "    Path('%s/iManufacturer' % gadget_root).write_text('%s' % 1)", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            Path('%s/protocol' % function_root).write_text('%s' % 0x02)", "prediction_line": "            Path('%s/protocol' % function_root).write_text('%s' % 0x02)", "ground_truth": "            Path('%s/protocol' % function_root).write_text('%s' % 1)", "line_class": "random", "zero_context": true}
{"original_prediction": "            strings_file.rmdir()", "prediction_line": "            strings_file.rmdir()", "ground_truth": "            strings_file.rmdir()", "line_class": "random", "zero_context": true}
{"original_prediction": "    usage_page=0x1,", "prediction_line": "    usage_page=0x1,", "ground_truth": "    usage_page=0x1,", "line_class": "random", "zero_context": true}
{"original_prediction": "    descriptor=bytes((", "prediction_line": "    descriptor=bytes((", "ground_truth": "    descriptor=b\"05010906a101050719e029e71500250175019508810275089501810175019503050819012903910275019505910175089506150026ff00050719002aff008100c0\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            config_dir.rmdir()", "prediction_line": "            config_dir.rmdir()", "ground_truth": "            config_dir.rmdir()", "line_class": "random", "zero_context": true}
{"original_prediction": "                {\"_id\": existing_id},", "prediction_line": "                {\"_id\": existing_id},", "ground_truth": "                filter={\"_id\": ObjectId(existing_id)}, update={\"$inc\": {\"retries\": 1}}", "line_class": "common", "zero_context": true}
{"original_prediction": "                return IncomingStatus.FAILED_PERMANENTLY, []", "prediction_line": "                return IncomingStatus.FAILED_PERMANENTLY, []", "ground_truth": "                return IncomingStatus.MESSAGE_HANDLED, []", "line_class": "infile", "zero_context": true}
{"original_prediction": "                return IncomingStatus.RETRYING_LATER, []", "prediction_line": "                return IncomingStatus.RETRYING_LATER, []", "ground_truth": "                return IncomingStatus.RETRYING_LATER, []", "line_class": "infile", "zero_context": true}
{"original_prediction": "                return IncomingStatus.FAILED_PERMANENTLY, []", "prediction_line": "                return IncomingStatus.FAILED_PERMANENTLY, []", "ground_truth": "                return IncomingStatus.FAILED_PERMANENTLY, []", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if retrying:", "prediction_line": "                if retrying:", "ground_truth": "                await self._mark_message_for_retry(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    async def _handle_message_confirmation(", "prediction_line": "    async def _handle_message_confirmation(", "ground_truth": "    async def delayed_incoming(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def _get_message_from_db(message_id: ObjectId) -> Optional[Message]:", "prediction_line": "    def _get_message_from_db(message_id: ObjectId) -> Optional[Message]:", "ground_truth": "    async def _mark_message_for_retry(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return IncomingStatus.MESSAGE_HANDLED, bulk_ops", "prediction_line": "            return IncomingStatus.MESSAGE_HANDLED, bulk_ops", "ground_truth": "            return IncomingStatus.MESSAGE_HANDLED, bulk_ops", "line_class": "infile", "zero_context": true}
{"original_prediction": "    async def handle_incoming(", "prediction_line": "    async def handle_incoming(", "ground_truth": "    async def incoming(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        status, bulk_ops = await self.incoming(message, *args, **kwargs)", "prediction_line": "        status, bulk_ops = await self.incoming(message, *args, **kwargs)", "ground_truth": "        status, ops = await self.incoming(message, *args, **kwargs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            try:\n                validate_pending_message(", "prediction_line": "            try:", "ground_truth": "            validated_message = validate_pending_message(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                validated_message = await validate_pending_message(pending_message)", "prediction_line": "                validated_message = await validate_pending_message(pending_message)", "ground_truth": "                content = await self.storage_service.get_message_content(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        message_id: ObjectId,", "prediction_line": "        message_id: ObjectId,", "ground_truth": "        message: BasePendingMessage,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                status = await self.store_message_handler.handle(", "prediction_line": "                status = await self.store_message_handler.handle(", "ground_truth": "                if isinstance(validated_message, ValidatedStoreMessage):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    InvalidMessageType,", "prediction_line": "    InvalidMessageType,", "ground_truth": "    UnknownHashError,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ) -> IncomingStatus:", "prediction_line": "    ) -> IncomingStatus:", "ground_truth": "    ) -> Tuple[IncomingStatus, List[DbBulkOperation]]:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "           updates = make_message_upsert_query(validated_message)", "prediction_line": "           updates = make_message_upsert_query(validated_message)", "ground_truth": "            updates = make_message_upsert_query(validated_message)", "line_class": "inproject", "zero_context": true}
{"original_prediction": ")\nfrom aleph.services.pending_messages import PendingMessagesService", "prediction_line": ")", "ground_truth": "    ValidatedForgetMessage,", "line_class": "inproject", "zero_context": true}
{"original_prediction": ")\nfrom aleph.services.pending_messages import PendingMessagesService", "prediction_line": ")", "ground_truth": "    ValidatedStoreMessage,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                MessageConfirmation(", "prediction_line": "                MessageConfirmation(", "ground_truth": "                MessageConfirmation(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                updates[\"$addToSet\"] = {\"confirmations\": {\"$each\": confirmations}}", "prediction_line": "                updates[\"$addToSet\"] = {\"confirmations\": {\"$each\": confirmations}}", "ground_truth": "                updates = make_confirmation_update_query(confirmations)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        await self.store_message_handler.handle(", "prediction_line": "                        await self.store_message_handler.handle(", "ground_truth": "                        await self.store_message_handler.handle_new_storage(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            LOGGER.debug(\"Saving %s.\" % item_hash)", "prediction_line": "            LOGGER.debug(\"Saving %s.\" % item_hash)", "ground_truth": "            if not await check_sender_authorization(validated_message):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if isinstance(Message, CappedMessage):", "prediction_line": "                if isinstance(Message, CappedMessage):", "ground_truth": "                bulk_ops.append(DbBulkOperation(CappedMessage, update_op))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    make_message_update_query,", "prediction_line": "    make_message_update_query,", "ground_truth": "    validate_pending_message,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from aleph.model.messages import Message", "prediction_line": "from aleph.model.messages import Message", "ground_truth": "from aleph.model.db_bulk_operation import DbBulkOperation", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from aleph.model.pending_message_status import PendingMessageStatus", "prediction_line": "from aleph.model.pending_message_status import PendingMessageStatus", "ground_truth": "from aleph.permissions import check_sender_authorization", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        if updates:", "prediction_line": "        if updates:", "ground_truth": "        if updates:", "line_class": "random", "zero_context": true}
{"original_prediction": "                            validated_message", "prediction_line": "                            validated_message", "ground_truth": "                            validated_message", "line_class": "random", "zero_context": true}
{"original_prediction": "            )\n            if result.modified_count == 0:", "prediction_line": "            )", "ground_truth": "            )", "line_class": "random", "zero_context": true}
{"original_prediction": "    def handle_message(self, message: Message, tx_context: TxContext) -> IncomingStatus:", "prediction_line": "    def handle_message(self, message: Message, tx_context: TxContext) -> IncomingStatus:", "ground_truth": "        self.store_message_handler = StoreMessageHandler(storage_service=storage_service)", "line_class": "random", "zero_context": true}
{"original_prediction": "                    chain_name=chain_name,", "prediction_line": "                    chain_name=chain_name,", "ground_truth": "                    tx_context=tx_context,", "line_class": "random", "zero_context": true}
{"original_prediction": "    # Check confirmation fields/properties", "prediction_line": "    # Check confirmation fields/properties", "ground_truth": "    assert fetched_message.confirmed", "line_class": "commited", "zero_context": true}
{"original_prediction": "    get_message_by_item_hash_and_type,", "prediction_line": "    get_message_by_item_hash_and_type,", "ground_truth": "    get_unconfirmed_messages,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    get_message_by_id,", "prediction_line": "    get_message_by_id,", "ground_truth": "    message_exists,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    get_message_by_id,", "prediction_line": "    get_message_by_id,", "ground_truth": "    forget_message,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    get_message_by_id,", "prediction_line": "    get_message_by_id,", "ground_truth": "    get_message_status,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    get_message_by_id,", "prediction_line": "    get_message_by_id,", "ground_truth": "    append_to_forgotten_by,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    get_message_by_id,", "prediction_line": "    get_message_by_id,", "ground_truth": "    get_forgotten_message,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    get_message_by_id,", "prediction_line": "    get_message_by_id,", "ground_truth": "    make_message_upsert_query,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    get_message_by_id,", "prediction_line": "    get_message_by_id,", "ground_truth": "    make_confirmation_upsert_query,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    get_message_by_id,", "prediction_line": "    get_message_by_id,", "ground_truth": "    get_distinct_channels,", "line_class": "commited", "zero_context": true}
{"original_prediction": "        unconfirmed_messages = list(get_unconfirmed_messages(session))", "prediction_line": "        unconfirmed_messages = list(get_unconfirmed_messages(session))", "ground_truth": "        unconfirmed_messages = list(get_unconfirmed_messages(session))", "line_class": "commited", "zero_context": true}
{"original_prediction": "    Message,\n    MessageConfirmation,", "prediction_line": "    Message,", "ground_truth": "    MessageDb,", "line_class": "commited", "zero_context": true}
{"original_prediction": "        session.add(fixture_message)", "prediction_line": "        session.add(fixture_message)", "ground_truth": "        assert not message_exists(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    MessageConfirmationDb,", "prediction_line": "    MessageConfirmationDb,", "ground_truth": "    MessageStatusDb,", "line_class": "commited", "zero_context": true}
{"original_prediction": "            get_unconfirmed_messages(session, chain=Chain.ETH)", "prediction_line": "            get_unconfirmed_messages(session, chain=Chain.ETH)", "ground_truth": "            get_unconfirmed_messages(session, chain=tx.chain)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert message_exists(", "prediction_line": "        assert message_exists(", "ground_truth": "        assert message_exists(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            get_unconfirmed_messages(session, chain=Chain.ETH)", "prediction_line": "            get_unconfirmed_messages(session, chain=Chain.ETH)", "ground_truth": "            get_unconfirmed_messages(session, chain=Chain.TEZOS)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    session_factory: DbSessionFactory, fixture_message: MessageDb", "prediction_line": "    session_factory: DbSessionFactory, fixture_message: MessageDb", "ground_truth": "    session_factory: DbSessionFactory, fixture_message: MessageDb", "line_class": "commited", "zero_context": true}
{"original_prediction": "            get_unconfirmed_messages(session, limit=1, chain=Chain.TEZOS)", "prediction_line": "            get_unconfirmed_messages(session, limit=1, chain=Chain.TEZOS)", "ground_truth": "            get_unconfirmed_messages(session, chain=Chain.TEZOS, limit=0)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    receiver = \"0x51A58800b26AA1451aaA803d1746687cB88E0500\"", "prediction_line": "    receiver = \"0x51A58800b26AA1451aaA803d1746687cB88E0500\"", "ground_truth": "    return MessageDb(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    with session_factory() as session:", "prediction_line": "    with session_factory() as session:", "ground_truth": "    upsert_stmt = make_confirmation_upsert_query(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    with session_factory() as session:", "prediction_line": "    with session_factory() as session:", "ground_truth": "        channels = list(get_distinct_channels(session=session))", "line_class": "commited", "zero_context": true}
{"original_prediction": "            MessageStatusDb(", "prediction_line": "            MessageStatusDb(", "ground_truth": "            MessageStatusDb(", "line_class": "commited", "zero_context": true}
{"original_prediction": "                status=MessageStatus.confirmed,", "prediction_line": "                status=MessageStatus.confirmed,", "ground_truth": "                status=MessageStatus.PROCESSED,", "line_class": "commited", "zero_context": true}
{"original_prediction": "        forget_message(session=session, item_hash=forget_message_hash)", "prediction_line": "        forget_message(session=session, item_hash=forget_message_hash)", "ground_truth": "        forget_message(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        fetched_message = get_message_by_item_hash(", "prediction_line": "        fetched_message = get_message_by_item_hash(", "ground_truth": "        fetched_message = get_message_by_item_hash(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        message = get_message_by_item_hash(", "prediction_line": "        message = get_message_by_item_hash(", "ground_truth": "        message_status = get_message_status(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert fetched_message.confirmed_at is None", "prediction_line": "    assert fetched_message.confirmed_at is None", "ground_truth": "    assert not fetched_message.confirmed", "line_class": "commited", "zero_context": true}
{"original_prediction": ".status == MessageStatus.FORGOTTEN", "prediction_line": ".status == MessageStatus.FORGOTTEN", "ground_truth": "        assert message_status.status == MessageStatus.FORGOTTEN", "line_class": "commited", "zero_context": true}
{"original_prediction": "    upsert_stmt = make_message_upsert_query(message=message)", "prediction_line": "    upsert_stmt = make_message_upsert_query(message=message)", "ground_truth": "    upsert_stmt = make_message_upsert_query(message)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        message = get_message_by_item_hash(", "prediction_line": "        message = get_message_by_item_hash(", "ground_truth": "        message = get_message_by_item_hash(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        forgotten_message = get_forgotten_message(", "prediction_line": "        forgotten_message = get_forgotten_message(", "ground_truth": "        forgotten_message = get_forgotten_message(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        fetched_message = get_message_by_item_hash(", "prediction_line": "        fetched_message = get_message_by_item_hash(", "ground_truth": "        message_db = get_message_by_item_hash(", "line_class": "commited", "zero_context": true}
{"original_prediction": "       append_to_forgotten_by(", "prediction_line": "       append_to_forgotten_by(", "ground_truth": "        append_to_forgotten_by(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        fetched_message = get_message_by_item_hash(", "prediction_line": "        fetched_message = get_message_by_item_hash(", "ground_truth": "        confirmation_db = session.execute(", "line_class": "common", "zero_context": true}
{"original_prediction": "        session.execute(upsert_stmt)", "prediction_line": "        session.execute(upsert_stmt)", "ground_truth": "        session.execute(upsert_stmt)", "line_class": "common", "zero_context": true}
{"original_prediction": "        upsert_stmt = make_confirmation_upsert_query(", "prediction_line": "        upsert_stmt = make_confirmation_upsert_query(", "ground_truth": "        session.execute(", "line_class": "common", "zero_context": true}
{"original_prediction": "    assert_messages_equal(expected=fixture_message, actual=fetched_message)", "prediction_line": "    assert_messages_equal(expected=fixture_message, actual=fetched_message)", "ground_truth": "    assert_messages_equal(expected=fixture_message, actual=fetched_message)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                item_hash=fixture_message.item_hash, tx_hash=tx.hash", "prediction_line": "                item_hash=fixture_message.item_hash, tx_hash=tx.hash", "ground_truth": "                item_hash=fixture_message.item_hash, tx_hash=tx.hash", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def test_get_unconfirmed_messages(", "prediction_line": "async def test_get_unconfirmed_messages(", "ground_truth": "async def test_message_exists(session_factory: DbSessionFactory, fixture_message):", "line_class": "infile", "zero_context": true}
{"original_prediction": "            session=session, item_hash=fixture_message.item_hash", "prediction_line": "            session=session, item_hash=fixture_message.item_hash", "ground_truth": "            session=session, item_hash=fixture_message.item_hash", "line_class": "infile", "zero_context": true}
{"original_prediction": "        session.add(fixture_message)", "prediction_line": "        session.add(fixture_message)", "ground_truth": "        session.add(fixture_message)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert_messages_equal(fixture_message, unconfirmed_messages[0])", "prediction_line": "        assert_messages_equal(fixture_message, unconfirmed_messages[0])", "ground_truth": "        assert_messages_equal(fixture_message, unconfirmed_messages[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def test_get_unconfirmed_messages(", "prediction_line": "async def test_get_unconfirmed_messages(", "ground_truth": "async def test_upsert_query_confirmation(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    confirmation = ChainTxDb(", "prediction_line": "    confirmation = ChainTxDb(", "ground_truth": "    item_hash = fixture_message.item_hash", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def test_get_distinct_channels(", "prediction_line": "async def test_get_distinct_channels(", "ground_truth": "async def test_get_distinct_channels(", "line_class": "infile", "zero_context": true}
{"original_prediction": "       assert channels == [fixture_message.channel]", "prediction_line": "       assert channels == [fixture_message.channel]", "ground_truth": "    assert channels == [fixture_message.channel]", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def test_forget_message(", "prediction_line": "async def test_forget_message(", "ground_truth": "async def test_forget_message(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                item_hash=fixture_message.item_hash,", "prediction_line": "                item_hash=fixture_message.item_hash,", "ground_truth": "                item_hash=fixture_message.item_hash,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            )\n        )", "prediction_line": "            )", "ground_truth": "                reception_time=fixture_message.time,", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def test_get_message_by_item_hash(", "prediction_line": "async def test_get_message_by_item_hash(", "ground_truth": "async def test_get_message(", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def test_upsert_query_message(", "prediction_line": "async def test_upsert_query_message(", "ground_truth": "async def test_upsert_query_message(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    item_hash = fixture_message.item_hash", "prediction_line": "    item_hash = fixture_message.item_hash", "ground_truth": "    message = copy(fixture_message)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    message.time = pytz.utc.localize(dt.datetime(2022, 10, 1))", "prediction_line": "    message.time = pytz.utc.localize(dt.datetime(2022, 10, 1))", "ground_truth": "    message.time = fixture_message.time - dt.timedelta(seconds=1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def test_get_unconfirmed_messages(", "prediction_line": "async def test_get_unconfirmed_messages(", "ground_truth": "async def test_get_message_with_confirmations(", "line_class": "infile", "zero_context": true}
{"original_prediction": "       assert forgotten_message.item_hash == fixture_message.item_hash", "prediction_line": "       assert forgotten_message.item_hash == fixture_message.item_hash", "ground_truth": "        assert forgotten_message.item_hash == fixture_message.item_hash", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert forgotten_message.forget_message_hash == forget_message_hash", "prediction_line": "        assert forgotten_message.forget_message_hash == forget_message_hash", "ground_truth": "        assert forgotten_message.type == fixture_message.type", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert forgotten_message.content == fixture_message.content", "prediction_line": "        assert forgotten_message.content == fixture_message.content", "ground_truth": "        assert forgotten_message.chain == fixture_message.chain", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert forgotten_message.sender == fixture_message.sender", "prediction_line": "        assert forgotten_message.sender == fixture_message.sender", "ground_truth": "        assert forgotten_message.sender == fixture_message.sender", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert forgotten_message.signature == fixture_message.signature", "prediction_line": "        assert forgotten_message.signature == fixture_message.signature", "ground_truth": "        assert forgotten_message.signature == fixture_message.signature", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert forgotten_message.item_content == fixture_message.item_content", "prediction_line": "        assert forgotten_message.item_content == fixture_message.item_content", "ground_truth": "        assert forgotten_message.item_type == fixture_message.item_type", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert forgotten_message.size == fixture_message.size", "prediction_line": "        assert forgotten_message.size == fixture_message.size", "ground_truth": "        assert forgotten_message.time == fixture_message.time", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert forgotten_message.channel == fixture_message.channel", "prediction_line": "        assert forgotten_message.channel == fixture_message.channel", "ground_truth": "        assert forgotten_message.channel == fixture_message.channel", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def test_get_unconfirmed_messages(", "prediction_line": "async def test_get_unconfirmed_messages(", "ground_truth": "async def test_get_unconfirmed_messages(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    with session_factory() as session:", "prediction_line": "    with session_factory() as session:", "ground_truth": "    fixture_message.confirmations = confirmations", "line_class": "infile", "zero_context": true}
{"original_prediction": "            item_hash=fixture_message.item_hash,", "prediction_line": "            item_hash=fixture_message.item_hash,", "ground_truth": "            forgotten_message_hash=fixture_message.item_hash,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        datetime=pytz.utc.localize(dt.datetime(2022, 10, 1)),", "prediction_line": "        datetime=pytz.utc.localize(dt.datetime(2022, 10, 1)),", "ground_truth": "        datetime=timestamp_to_datetime(1664999900),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            protocol=ChainSyncProtocol.OFF_CHAIN,", "prediction_line": "            protocol=ChainSyncProtocol.OFF_CHAIN,", "ground_truth": "            protocol=ChainSyncProtocol.OFF_CHAIN,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    }\n\n    for confirmation in fetched_message.confirmations:", "prediction_line": "    }", "ground_truth": "    }", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from django.db import models", "prediction_line": "from django.db import models", "ground_truth": "from copy import copy", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "):\n    with session_factory() as session:", "prediction_line": "):", "ground_truth": "):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "if empty string is considered as a channel", "prediction_line": "if empty string is considered as a channel", "ground_truth": "    with session_factory() as session:", "line_class": "random", "zero_context": true}
{"original_prediction": "        session.execute(upsert_stmt)", "prediction_line": "        session.execute(upsert_stmt)", "ground_truth": "        session.add(message)", "line_class": "random", "zero_context": true}
{"original_prediction": "        session.commit()", "prediction_line": "        session.commit()", "ground_truth": "        session.add(chain_tx)", "line_class": "random", "zero_context": true}
{"original_prediction": "\"easy\": \"as\", \"a-b\": \"c\"},", "prediction_line": "\"easy\": \"as\", \"a-b\": \"c\"},", "ground_truth": "            \"address\": sender,", "line_class": "random", "zero_context": true}
{"original_prediction": "            session=session,", "prediction_line": "            session=session,", "ground_truth": "            session=session,", "line_class": "random", "zero_context": true}
{"original_prediction": "    update.allow_amend = False", "prediction_line": "    update.allow_amend = False", "ground_truth": "    update.allow_amend = False", "line_class": "common", "zero_context": true}
{"original_prediction": "    update.created = pytz.utc.localize(dt.datetime(2022, 11, 12, 12, 12, 12))", "prediction_line": "    update.created = pytz.utc.localize(dt.datetime(2022, 11, 12, 12, 12, 12))", "ground_truth": "    update.created = pytz.utc.localize(dt.datetime(2023, 1, 1))", "line_class": "common", "zero_context": true}
{"original_prediction": "    update.runtime.ref = (", "prediction_line": "    update.runtime.ref = (", "ground_truth": "    return update", "line_class": "common", "zero_context": true}
{"original_prediction": "        return session.execute(", "prediction_line": "        return session.execute(", "ground_truth": "        return session.execute(", "line_class": "common", "zero_context": true}
{"original_prediction": "        program_version_db = get_program_version(session)", "prediction_line": "        program_version_db = get_program_version(session)", "ground_truth": "        program_version_db = get_program_version(session)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert program_version_db.last_updated == original_program.created", "prediction_line": "        assert program_version_db.last_updated == original_program.created", "ground_truth": "        assert program_version_db.last_updated == original_program.created", "line_class": "infile", "zero_context": true}
{"original_prediction": "        session.commit()", "prediction_line": "        session.commit()", "ground_truth": "        session.add(program_update)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert program_version_db.last_updated == program_update.created", "prediction_line": "        assert program_version_db.last_updated == program_update.created", "ground_truth": "        assert program_version_db.last_updated == program_update.created", "line_class": "infile", "zero_context": true}
{"original_prediction": "        session.add(original_program)", "prediction_line": "        session.add(original_program)", "ground_truth": "        session.add(original_program)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                version=1,", "prediction_line": "                version=1,", "ground_truth": "                owner=original_program.owner,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                created=pytz.utc.localize(dt.datetime(2022, 11, 11, 11, 11, 11)),", "prediction_line": "                created=pytz.utc.localize(dt.datetime(2022, 11, 11, 11, 11, 11)),", "ground_truth": "                last_updated=program_update.created,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        session.add(program_with_many_volumes)", "prediction_line": "        session.add(program_with_many_volumes)", "ground_truth": "        session.add(program_with_many_volumes)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                owner=program_with_many_volumes.owner,", "prediction_line": "                owner=program_with_many_volumes.owner,", "ground_truth": "                owner=program_with_many_volumes.owner,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                last_updated=program_with_many_volumes.created,", "prediction_line": "                last_updated=program_with_many_volumes.created,", "ground_truth": "                last_updated=program_with_many_volumes.created,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    program = copy.deepcopy(original_program)", "prediction_line": "    program = copy.deepcopy(original_program)", "ground_truth": "    update = copy.deepcopy(original_program)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert_programs_equal(original_program, original_program_db)", "prediction_line": "        assert_programs_equal(original_program, original_program_db)", "ground_truth": "        assert_programs_equal(expected=original_program, actual=original_program_db)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert_programs_equal(expected=program_update, actual=program_update_db)", "prediction_line": "        assert_programs_equal(expected=program_update, actual=program_update_db)", "ground_truth": "        assert_programs_equal(expected=program_update_db, actual=program_update)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert_programs_equal(", "prediction_line": "        assert_programs_equal(", "ground_truth": "        assert_programs_equal(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            expected=program_with_many_volumes_db, actual=program_with_many_volumes", "prediction_line": "            expected=program_with_many_volumes_db, actual=program_with_many_volumes", "ground_truth": "            expected=program_with_many_volumes_db, actual=program_with_many_volumes", "line_class": "infile", "zero_context": true}
{"original_prediction": "   program = ProgramDb(", "prediction_line": "   program = ProgramDb(", "ground_truth": "    program = copy.deepcopy(original_program)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert actual.runtime.comment == expected.runtime.comment", "prediction_line": "        assert actual.runtime.comment == expected.runtime.comment", "ground_truth": "        assert actual.runtime.program_hash == expected.runtime.program_hash", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            session=session, item_hash=program_with_many_volumes.item_hash", "prediction_line": "            session=session, item_hash=program_with_many_volumes.item_hash", "ground_truth": "            session=session, item_hash=program_with_many_volumes.item_hash", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        program_hash=program_hash,", "prediction_line": "        program_hash=program_hash,", "ground_truth": "        item_hash=program_hash,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    program_with_many_volumes: ProgramDb,", "prediction_line": "    program_with_many_volumes: ProgramDb,", "ground_truth": "    program_with_many_volumes: ProgramDb,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert expected.item_hash == actual.item_hash", "prediction_line": "    assert expected.item_hash == actual.item_hash", "ground_truth": "    assert actual.item_hash == expected.item_hash", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ProgramVersionCodeDb,", "prediction_line": "    ProgramVersionCodeDb,", "ground_truth": "    DataVolumeDb,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            session=session,", "prediction_line": "            session=session,", "ground_truth": "            session=session, program_hash=original_program.item_hash", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        PersistentVolumeDb(", "prediction_line": "        PersistentVolumeDb(", "ground_truth": "        PersistentVolumeDb(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        assert program_version_db.current_version == program_hash", "prediction_line": "        assert program_version_db.current_version == program_hash", "ground_truth": "        assert program_version_db.current_version == program_hash", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    original_program: ProgramDb,", "prediction_line": "    original_program: ProgramDb,", "ground_truth": "    original_program: ProgramDb,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    db_session_factory: DbSessionFactory,", "prediction_line": "    db_session_factory: DbSessionFactory,", "ground_truth": "    session_factory: DbSessionFactory,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with session_factory() as session:", "prediction_line": "    with session_factory() as session:", "ground_truth": "    with session_factory() as session:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    data_volume = DataVolumeDb(", "prediction_line": "    data_volume = DataVolumeDb(", "ground_truth": "    runtime = RuntimeDb(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                current_version=ProgramVersion(program_with_many_volumes.item_hash),", "prediction_line": "                current_version=ProgramVersion(program_with_many_volumes.item_hash),", "ground_truth": "                current_version=ProgramVersion(program_with_many_volumes.item_hash),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            session=session, item_hash=program_update.item_hash", "prediction_line": "            session=session, item_hash=program_update.item_hash", "ground_truth": "            session=session, item_hash=program_update.item_hash", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from pydantic import BaseModel, ValidationError, validator", "prediction_line": "from pydantic import BaseModel, ValidationError, validator", "ground_truth": "import pytz", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )\n    data_volume = DataVolumeDb(", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        name=\"My program\",", "prediction_line": "        name=\"My program\",", "ground_truth": "        type=MachineType.vm_function,", "line_class": "random", "zero_context": true}
{"original_prediction": "    program.data_volume = data_volume", "prediction_line": "    program.data_volume = data_volume", "ground_truth": "    program.runtime = runtime", "line_class": "random", "zero_context": true}
{"original_prediction": "        environment_variables=None,", "prediction_line": "        environment_variables=None,", "ground_truth": "        resources_vcpus=1,", "line_class": "random", "zero_context": true}
{"original_prediction": "        assert actual.code_volume.encoding == expected.code_volume.encoding", "prediction_line": "        assert actual.code_volume.encoding == expected.code_volume.encoding", "ground_truth": "        assert actual.code_volume is not None", "line_class": "random", "zero_context": true}
{"original_prediction": "        code_volume=code_volume,", "prediction_line": "        code_volume=code_volume,", "ground_truth": "        created=pytz.utc.localize(dt.datetime(2022, 11, 11, 11, 11, 11)),", "line_class": "random", "zero_context": true}
{"original_prediction": "            session.execute(", "prediction_line": "            session.execute(", "ground_truth": "            get_aggregate_elements(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    mock_config: Config,", "prediction_line": "    mock_config: Config,", "ground_truth": "    mock_config: Config,", "line_class": "commited", "zero_context": true}
{"original_prediction": "@pytest.mark.asyncio", "prediction_line": "@pytest.mark.asyncio", "ground_truth": "        aggregate = get_aggregate_by_key(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    aggregate_updates: Sequence[PendingMessageDb],", "prediction_line": "    aggregate_updates: Sequence[PendingMessageDb],", "ground_truth": "    config: Config,", "line_class": "commited", "zero_context": true}
{"original_prediction": "        # Check the aggregate", "prediction_line": "        # Check the aggregate", "ground_truth": "        content = original.parsed_content", "line_class": "commited", "zero_context": true}
{"original_prediction": "):\n    for message in aggregates:", "prediction_line": "):", "ground_truth": ") -> Sequence[MessageDb]:", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert content[\"content\"][\"a\"] == 1", "prediction_line": "        assert content[\"content\"][\"a\"] == 1", "ground_truth": "        assert isinstance(content, AggregateContent)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    with session_factory() as session:", "prediction_line": "    with session_factory() as session:", "ground_truth": "    pipeline = message_processor.make_pipeline()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    update = PendingMessageDb(", "prediction_line": "    update = PendingMessageDb(", "ground_truth": "    update = PendingMessageDb(", "line_class": "common", "zero_context": true}
{"original_prediction": "            session.query(PendingMessageDb)", "prediction_line": "            session.query(PendingMessageDb)", "ground_truth": "            session.execute(", "line_class": "common", "zero_context": true}
{"original_prediction": "   return [original, update]", "prediction_line": "   return [original, update]", "ground_truth": "    return original, update", "line_class": "common", "zero_context": true}
{"original_prediction": "async def test_process_aggregate_updates(", "prediction_line": "async def test_process_aggregate_updates(", "ground_truth": "async def test_process_aggregates_in_order(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    aggregate_updates: Sequence[PendingMessageDb],", "prediction_line": "    aggregate_updates: Sequence[PendingMessageDb],", "ground_truth": "    aggregate_updates: Sequence[PendingMessageDb],", "line_class": "infile", "zero_context": true}
{"original_prediction": "        original, update = await process_aggregates_one_by_one(", "prediction_line": "        original, update = await process_aggregates_one_by_one(", "ground_truth": "        update, original = await process_aggregates_one_by_one(", "line_class": "infile", "zero_context": true}
{"original_prediction": "@pytest.mark.asyncio", "prediction_line": "@pytest.mark.asyncio", "ground_truth": "async def process_aggregates_one_by_one(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        messages = await process_aggregates_one_by_one(", "prediction_line": "        messages = await process_aggregates_one_by_one(", "ground_truth": "        original, update = await process_aggregates_one_by_one(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            aggregates=reversed(aggregate_updates),", "prediction_line": "            aggregates=reversed(aggregate_updates),", "ground_truth": "            aggregates=reversed(aggregate_updates),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            aggregates=aggregate_updates,", "prediction_line": "            aggregates=aggregate_updates,", "ground_truth": "            aggregates=aggregate_updates,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert original.item_hash == update.item_hash", "prediction_line": "        assert original.item_hash == update.item_hash", "ground_truth": "        assert original.item_hash == aggregate_updates[0].item_hash", "line_class": "infile", "zero_context": true}
{"original_prediction": "        assert update.item_hash == aggregate_updates[1].item_hash", "prediction_line": "        assert update.item_hash == aggregate_updates[1].item_hash", "ground_truth": "        assert update.item_hash == aggregate_updates[1].item_hash", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def test_process_pending_messages(", "prediction_line": "async def test_process_pending_messages(", "ground_truth": "async def test_process_aggregate_first_element(", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def test_process_aggregate_second_element(", "prediction_line": "async def test_process_aggregate_second_element(", "ground_truth": "async def test_process_aggregates(", "line_class": "infile", "zero_context": true}
{"original_prediction": "async def test_process_aggregates_out_of_order(", "prediction_line": "async def test_process_aggregates_out_of_order(", "ground_truth": "async def test_process_aggregates_reverse_order(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    message_handler: MessageHandler,", "prediction_line": "    message_handler: MessageHandler,", "ground_truth": "    message_processor: PendingMessageProcessor,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    message_handler = MessageHandler(", "prediction_line": "    message_handler = MessageHandler(", "ground_truth": "    message_handler = MessageHandler(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    )\n    chain = Chain.ETHEREUM", "prediction_line": "    )", "ground_truth": "        config=mock_config,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    expected_type = content[\"type\"]", "prediction_line": "    expected_type = content[\"type\"]", "ground_truth": "    expected_creation_datetime = timestamp_to_datetime(content[\"time\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        tx_hash=\"0x53c2b16aa84b10878982a2920844625546f5db32337ecd9dd15928095a30381c\",", "prediction_line": "        tx_hash=\"0x53c2b16aa84b10878982a2920844625546f5db32337ecd9dd15928095a30381c\",", "ground_truth": "        time=timestamp_to_datetime(1644859283.101),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            await message_processor.process_pending_message(", "prediction_line": "            await message_processor.process_pending_message(", "ground_truth": "            await process_pending_messages(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    fixture_aggregate_messages: List[Dict],", "prediction_line": "    fixture_aggregate_messages: List[Dict],", "ground_truth": "    fixture_aggregate_messages: List[Dict],", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Test that the first element of an aggregate is processed correctly.", "prediction_line": "    \"\"\"", "ground_truth": "    storage_service = StorageService(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        time=timestamp_to_datetime(1644859283.101),", "prediction_line": "        time=timestamp_to_datetime(1644859283.101),", "ground_truth": "        time=timestamp_to_datetime(1644859283.12),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from aleph.chains.common import get_chain_config", "prediction_line": "from aleph.chains.common import get_chain_config", "ground_truth": "from aleph.db.accessors.aggregates import get_aggregate_by_key, get_aggregate_elements", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from aleph.model.messages import Message", "prediction_line": "from aleph.model.messages import Message", "ground_truth": "from aleph.storage import StorageService", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "):\n    with session_factory() as session:", "prediction_line": "):", "ground_truth": "):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        tx_hash=\"0x53c2b16aa84b10878982a2920844625546f5db32337ecd9dd15928095a30381c\",", "prediction_line": "        tx_hash=\"0x53c2b16aa84b10878982a2920844625546f5db32337ecd9dd15928095a30381c\",", "ground_truth": "        check_message=True,", "line_class": "random", "zero_context": true}
{"original_prediction": "        item_type=ItemType.AGGREGATE,", "prediction_line": "        item_type=ItemType.AGGREGATE,", "ground_truth": "        item_hash=\"53c2b16aa84b10878982a2920844625546f5db32337ecd9dd15928095a30381c\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        assert pending_message.tx.chain == Chain.ETHEREUM", "prediction_line": "        assert pending_message.tx.chain == Chain.ETHEREUM", "ground_truth": "    await message_handler.fetch_and_process_one_message_db(", "line_class": "random", "zero_context": true}
{"original_prediction": "        aggregate = (", "prediction_line": "        aggregate = (", "ground_truth": "        elements = list(", "line_class": "random", "zero_context": true}
{"original_prediction": "    )\n\n    update = PendingMessageDb(", "prediction_line": "    )", "ground_truth": "        fetched=True,", "line_class": "random", "zero_context": true}
{"original_prediction": "        self, session: DbSession, message: MessageDb", "prediction_line": "        self, session: DbSession, message: MessageDb", "ground_truth": "        self, session: DbSession, message: MessageDb", "line_class": "commited", "zero_context": true}
{"original_prediction": "    async def handle_message(", "prediction_line": "    async def handle_message(", "ground_truth": "    async def check_permissions(self, session: DbSession, message: MessageDb):", "line_class": "commited", "zero_context": true}
{"original_prediction": "    MessageStatus,", "prediction_line": "    MessageStatus,", "ground_truth": "    PermissionDenied,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    FileAlreadyStored,", "prediction_line": "    FileAlreadyStored,", "ground_truth": "    FileUnavailable,", "line_class": "commited", "zero_context": true}
{"original_prediction": "    FileAlreadyStored,", "prediction_line": "    FileAlreadyStored,", "ground_truth": "    InvalidMessageFormat,", "line_class": "commited", "zero_context": true}
{"original_prediction": "                raise FileUnavailable(", "prediction_line": "                raise FileUnavailable(", "ground_truth": "                raise FileUnavailable(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    async def forget(self, session: DbSession, messages: List[MessageDb]) -> None:", "prediction_line": "    async def forget(self, session: DbSession, messages: List[MessageDb]) -> None:", "ground_truth": "    async def forget_message(self, session: DbSession, message: MessageDb) -> None:", "line_class": "commited", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Checks if the related content of the message is fetched.", "prediction_line": "        \"\"\"", "ground_truth": "        content = message.parsed_content", "line_class": "commited", "zero_context": true}
{"original_prediction": "        raise InvalidMessageFormat(", "prediction_line": "        raise InvalidMessageFormat(", "ground_truth": "        raise InvalidMessageFormat(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    async def process_message(self, session: DbSession, message: MessageDb):", "prediction_line": "    async def process_message(self, session: DbSession, message: MessageDb):", "ground_truth": "    async def process(self, session: DbSession, messages: List[MessageDb]) -> None:", "line_class": "commited", "zero_context": true}
{"original_prediction": "            raise PermissionDenied(", "prediction_line": "            raise PermissionDenied(", "ground_truth": "            raise PermissionDenied(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    async def process_message(", "prediction_line": "    async def process_message(", "ground_truth": "    async def _pin_and_tag_file(self, session: DbSession, message: MessageDb):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            await self.storage_service.storage_engine.delete(storage_hash)", "prediction_line": "            await self.storage_service.storage_engine.delete(storage_hash)", "ground_truth": "            await self.storage_service.storage_engine.delete(storage_hash)", "line_class": "common", "zero_context": true}
{"original_prediction": "    async def handle_message(", "prediction_line": "    async def handle_message(", "ground_truth": "    async def fetch_related_content(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        content = message.parsed_content", "prediction_line": "        content = message.parsed_content", "ground_truth": "        content = _get_store_content(message)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        file_tag = make_file_tag(", "prediction_line": "        file_tag = make_file_tag(", "ground_truth": "        file_tag = make_file_tag(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            tag=make_file_tag(", "prediction_line": "            tag=make_file_tag(", "ground_truth": "            tag=make_file_tag(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # TODO: should be probably be in the storage service", "prediction_line": "        # TODO: should be probably be in the storage service", "ground_truth": "        await self._garbage_collect(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            content = _get_store_content(message)", "prediction_line": "            content = _get_store_content(message)", "ground_truth": "            await self._pin_and_tag_file(session=session, message=message)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    async def garbage_collect(self, session: DbSession, messages: List[MessageDb]):", "prediction_line": "    async def garbage_collect(self, session: DbSession, messages: List[MessageDb]):", "ground_truth": "    async def _garbage_collect(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    async def handle_message(", "prediction_line": "    async def handle_message(", "ground_truth": "    async def is_related_content_fetched(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        )\n\n        file_tag = make_file_tag(", "prediction_line": "        )", "ground_truth": "            created=timestamp_to_datetime(content.time),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if storage_type == ItemType.ipfs:", "prediction_line": "        if storage_type == ItemType.ipfs:", "ground_truth": "        storage_detected: ItemType = item_type_from_hash(storage_hash)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    raise UnknownHashError(f\"Invalid IPFS hash: '{item_hash}'\") from e", "prediction_line": "                    raise UnknownHashError(f\"Invalid IPFS hash: '{item_hash}'\") from e", "ground_truth": "                    raise UnknownHashError(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if await self.is_related_content_fetched(session, message):", "prediction_line": "        if await self.is_related_content_fetched(session, message):", "ground_truth": "        config = get_config()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                await self.storage_service.storage_engine.fetch(", "prediction_line": "                await self.storage_service.storage_engine.fetch(", "ground_truth": "                file_content = await self.storage_service.get_hash_content(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            ref=content.ref,", "prediction_line": "            ref=content.ref,", "ground_truth": "            last_updated=timestamp_to_datetime(content.time),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            except AlephStorageException as error:", "prediction_line": "            except AlephStorageException as error:", "ground_truth": "            except AlephStorageException:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            ipfs_client = await aioipfs.create(config.ipfs.api_url.value)", "prediction_line": "            ipfs_client = await aioipfs.create(config.ipfs.api_url.value)", "ground_truth": "            if item_type_from_hash(item_hash) != ItemType.ipfs:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                raise UnknownHashError(item_hash)", "prediction_line": "                raise UnknownHashError(item_hash)", "ground_truth": "                raise UnknownHashError(f\"Invalid IPFS hash: '{item_hash}'\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "async def handle_store_content(", "prediction_line": "async def handle_store_content(", "ground_truth": "def _get_store_content(message: MessageDb) -> StoreContent:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        :param session: The database session.", "prediction_line": "        :param session: The database session.", "ground_truth": "        This is typically called after 'forgetting' a message.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            if file_content is None:", "prediction_line": "            if file_content is None:", "ground_truth": "            size = len(file_content)", "line_class": "random", "zero_context": true}
{"original_prediction": "    get_file_hash,", "prediction_line": "    get_file_hash,", "ground_truth": "    delete_file as delete_file_db,", "line_class": "random", "zero_context": true}
{"original_prediction": "        # TODO: this check is useless, remove it", "prediction_line": "        # TODO: this check is useless, remove it", "ground_truth": "        LOGGER.debug(f\"Garbage collecting {storage_hash}\")", "line_class": "random", "zero_context": true}
{"original_prediction": "            ipfs_client = self.storage_service.ipfs_service.ipfs_client", "prediction_line": "            ipfs_client = self.storage_service.ipfs_service.ipfs_client", "ground_truth": "            LOGGER.debug(f\"Removing from IPFS: {storage_hash}\")", "line_class": "random", "zero_context": true}
{"original_prediction": "        if ipfs_enabled:", "prediction_line": "        if ipfs_enabled:", "ground_truth": "        do_standard_lookup = True", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.client.on_connect = self._on_connect", "prediction_line": "        self.client.on_connect = self._on_connect", "ground_truth": "        self.client.on_connect = self._on_connect", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.on_mqtt_command,", "prediction_line": "                self.on_mqtt_command,", "ground_truth": "                self.on_mqtt_command,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def connect(self) -> None:", "prediction_line": "    def connect(self) -> None:", "ground_truth": "        self._start()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._client.publish(topic, payload, retain=retain)", "prediction_line": "        self._client.publish(topic, payload, retain=retain)", "ground_truth": "        self.client.publish(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.publish(", "prediction_line": "            self.publish(", "ground_truth": "            self.publish(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            f\"{self.mqtt_config.topic_prefix}/available\", self.on_mqtt_command", "prediction_line": "            f\"{self.mqtt_config.topic_prefix}/available\", self.on_mqtt_command", "ground_truth": "            f\"{self.mqtt_config.topic_prefix}/restart\", self.on_mqtt_command", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def _start(self) -> None:", "prediction_line": "    def _start(self) -> None:", "ground_truth": "        self.publish(\"available\", \"online\", retain=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._set_initial_topics()", "prediction_line": "        self._set_initial_topics()", "ground_truth": "        client.subscribe(f\"{self.mqtt_config.topic_prefix}/#\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._set_initial_topics()", "prediction_line": "        self._set_initial_topics()", "ground_truth": "        self._set_initial_topics()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.publish(\"available\", \"online\")", "prediction_line": "        self.publish(\"available\", \"online\")", "ground_truth": "        for camera_name, camera in self.config.cameras.items():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.client.on_message = self.on_mqtt_command", "prediction_line": "        self.client.on_message = self.on_mqtt_command", "ground_truth": "        for name in self.config.cameras.keys():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"Initialize the mqtt client.\"\"\"", "prediction_line": "        \"\"\"Initialize the mqtt client.\"\"\"", "ground_truth": "        self.config = config", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.client = mqtt.Client()", "prediction_line": "        self.client = mqtt.Client()", "ground_truth": "        self.mqtt_config = config.mqtt", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                \"ON\" if camera.detect.enabled else \"OFF\",", "prediction_line": "                \"ON\" if camera.detect.enabled else \"OFF\",", "ground_truth": "                \"ON\" if camera.detect.enabled else \"OFF\",", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.client.connect(", "prediction_line": "            self.client.connect(", "ground_truth": "            # https://stackoverflow.com/a/55390477", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                camera.motion.contour_area,  # type: ignore[union-attr]", "prediction_line": "                camera.motion.contour_area,  # type: ignore[union-attr]", "ground_truth": "                camera.motion.contour_area,  # type: ignore[union-attr]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       self.client = mqtt.Client()", "prediction_line": "       self.client = mqtt.Client()", "ground_truth": "    def subscribe(self, receiver: Callable) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                camera.motion.threshold,  # type: ignore[union-attr]", "prediction_line": "                camera.motion.threshold,  # type: ignore[union-attr]", "ground_truth": "                camera.motion.threshold,  # type: ignore[union-attr]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ".ReasonCodes", "prediction_line": ".ReasonCodes", "ground_truth": "    ) -> None:", "line_class": "random", "zero_context": true}
{"original_prediction": "            )\n            self.publish(", "prediction_line": "            )", "ground_truth": "                retain=True,", "line_class": "random", "zero_context": true}
{"original_prediction": "                f\"{camera_name}/motion_threshold_sensitivity/state\",", "prediction_line": "                f\"{camera_name}/motion_threshold_sensitivity/state\",", "ground_truth": "                f\"{camera_name}/motion_contour_area/state\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            )\n            self.client.message_callback_add(", "prediction_line": "            )", "ground_truth": "            )", "line_class": "random", "zero_context": true}
{"original_prediction": "                self.update(t.global_id, t.last_detection.data)", "prediction_line": "                self.update(t.global_id, t.last_detection.data)", "ground_truth": "                self.update(t.global_id, t.last_detection.data)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        matches = self.tracker.match(norfair_detections)", "prediction_line": "        matches = self.tracker.match(norfair_detections)", "ground_truth": "        tracked_objects = self.tracker.update(detections=norfair_detections)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.tracked_objects[id][\"frame_time\"] = obj[\"frame_time\"]", "prediction_line": "        self.tracked_objects[id][\"frame_time\"] = obj[\"frame_time\"]", "ground_truth": "        self.tracked_objects[id].update(obj)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        max_frames = self.detect_config.max_frames.get(", "prediction_line": "        max_frames = self.detect_config.max_frames.get(", "ground_truth": "        max_frames = self.detect_config.stationary.max_frames.objects.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "    distance[0] /= estimate_dim[0]", "prediction_line": "    distance[0] /= estimate_dim[0]", "ground_truth": "    distance[0] /= estimate_dim[0]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            distance_function=frigate_distance,", "prediction_line": "            distance_function=frigate_distance,", "ground_truth": "            distance_function=frigate_distance,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    distance[1] /= estimate_dim[1]", "prediction_line": "    distance[1] /= estimate_dim[1]", "ground_truth": "    distance[1] /= estimate_dim[1]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self.update_position(id, obj[\"box\"]):", "prediction_line": "        if self.update_position(id, obj[\"box\"]):", "ground_truth": "        if self.update_position(id, obj[\"box\"]):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # if there are no detections, return", "prediction_line": "        # if there are no detections, return", "ground_truth": "        self.match_and_update(frame_time, detections=detections)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        else:\n            self.tracked_objects[id][\"motionless_count\"] = 0", "prediction_line": "        else:", "ground_truth": "            if self.is_expired(id):", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.deregister(id)", "prediction_line": "                self.deregister(id)", "ground_truth": "                self.deregister(id)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.register(t.global_id, t.data)", "prediction_line": "                self.register(t.global_id, t.data)", "ground_truth": "                self.register(t.global_id, t.last_detection.data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    distance = np.concatenate([distance, [width_ratio, height_ratio]])", "prediction_line": "    distance = np.concatenate([distance, [width_ratio, height_ratio]])", "ground_truth": "    change = np.append(distance, np.array([width_ratio, height_ratio]))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # get bottom center positions", "prediction_line": "    # get bottom center positions", "ground_truth": "    return distance(detection.points, tracked_object.estimate)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            id = self.track_id_map[e_id]", "prediction_line": "            id = self.track_id_map[e_id]", "ground_truth": "            self.deregister(self.track_id_map[e_id])", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # get distance between bottom center positions", "prediction_line": "    # get distance between bottom center positions", "ground_truth": "    distance = (detection_position - estimate_position).astype(float)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        draw_boxes(", "prediction_line": "        draw_boxes(", "ground_truth": "        draw_boxes(frame, self.tracker.tracked_objects, color=\"green\", draw_ids=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        draw_boxes(frame, active_detections, color=\"red\", draw_ids=True)", "prediction_line": "        draw_boxes(frame, active_detections, color=\"red\", draw_ids=True)", "ground_truth": "        draw_boxes(frame, active_detections, color=\"blue\", draw_ids=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        draw_boxes(frame, missing_detections, color=\"red\", draw_ids=True)", "prediction_line": "        draw_boxes(frame, missing_detections, color=\"red\", draw_ids=True)", "ground_truth": "        draw_boxes(frame, missing_detections, color=\"red\", draw_ids=True)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       position[\"xmins\"].append(xmin)", "prediction_line": "       position[\"xmins\"].append(xmin)", "ground_truth": "        iou = intersection_over_union(position_box, box)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                color=\"red\",", "prediction_line": "                color=\"red\",", "ground_truth": "                color=(255, 0, 0),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.config = config", "prediction_line": "        self.config = config", "ground_truth": "        self.max_disappeared = config.max_disappeared", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.max_distance = config.max_distance", "prediction_line": "        self.max_distance = config.max_distance", "ground_truth": "        self.detect_config = config", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.tracker = Tracker(", "prediction_line": "        self.tracker = Tracker(", "ground_truth": "        # TODO: could also initialize a tracker per object class if there", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        draw_boxes(", "prediction_line": "        draw_boxes(", "ground_truth": "        # draw the estimated bounding box", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            label, score, box, area, ratio, region = obj", "prediction_line": "            label, score, box, area, ratio, region = obj", "ground_truth": "            # centroid is used for other things downstream", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def track_position(self, id, points):", "prediction_line": "    def track_position(self, id, points):", "ground_truth": "    def update_position(self, id, box):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "are multiple\n        self.tracker = Tracker(", "prediction_line": "are multiple", "ground_truth": "        #       was a good reason to have different distance calculations", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            position[\"xmin\"] = np.percentile(position[\"xmins\"], 25)", "prediction_line": "            position[\"xmin\"] = np.percentile(position[\"xmins\"], 25)", "ground_truth": "            position[\"xmin\"] = np.percentile(position[\"xmins\"], 15)", "line_class": "random", "zero_context": true}
{"original_prediction": "                )\n            )", "prediction_line": "                )", "ground_truth": "                )", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.tracked_objects[id][\"frame_time\"] = obj[\"frame_time\"]", "prediction_line": "        self.tracked_objects[id][\"frame_time\"] = obj[\"frame_time\"]", "ground_truth": "            self.tracked_objects[id][\"motionless_count\"] = 0", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"xmax\": xmax,", "prediction_line": "                \"xmax\": xmax,", "ground_truth": "                \"xmax\": xmax,", "line_class": "random", "zero_context": true}
{"original_prediction": "                        \"box\": obj[2],", "prediction_line": "                        \"box\": obj[2],", "ground_truth": "                        \"box\": obj[2],", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(name=\"ptz_auto_tracker\")", "prediction_line": "        super().__init__(name=\"ptz_auto_tracker\")", "ground_truth": "        threading.Thread.__init__(self)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                        pan += queued_pan", "prediction_line": "                        pan += queued_pan", "ground_truth": "                        queued_pan, queued_tilt = self.move_queues[camera].get()", "line_class": "common", "zero_context": true}
{"original_prediction": "            # get the transformation from the motion estimator", "prediction_line": "            # get the transformation from the motion estimator", "ground_truth": "            self.coord_transformations = self.norfair_motion_estimator.update(", "line_class": "common", "zero_context": true}
{"original_prediction": "                    pan, tilt = self.move_queues[camera].get()", "prediction_line": "                    pan, tilt = self.move_queues[camera].get()", "ground_truth": "                    move_data = self.move_queues[camera].get()", "line_class": "common", "zero_context": true}
{"original_prediction": "                    time.sleep(1)", "prediction_line": "                    time.sleep(1)", "ground_truth": "                    if self.ptz_autotracker.tracked_object.get(camera_name):", "line_class": "common", "zero_context": true}
{"original_prediction": "                self.move_threads[camera_name].start()", "prediction_line": "                self.move_threads[camera_name].start()", "ground_truth": "                self.move_threads[camera_name].start()", "line_class": "common", "zero_context": true}
{"original_prediction": "            frame = self.frame_manager.get_frame(frame_id)", "prediction_line": "            frame = self.frame_manager.get_frame(frame_id)", "ground_truth": "            yuv_frame = self.frame_manager.get(", "line_class": "common", "zero_context": true}
{"original_prediction": "        # check if object is moving, if so, increase speed", "prediction_line": "        # check if object is moving, if so, increase speed", "ground_truth": "        self._enqueue_move(camera, -pan, tilt)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self.ptz_autotracker.track_objects(camera_name)", "prediction_line": "                    self.ptz_autotracker.track_objects(camera_name)", "ground_truth": "                    self.ptz_autotracker.camera_maintenance(camera_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.tracked_object[camera_name] = None", "prediction_line": "                self.tracked_object[camera_name] = None", "ground_truth": "                self._autotracker_setup(cam, camera_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    target=self.move_thread,", "prediction_line": "                    target=self.move_thread,", "ground_truth": "                    target=partial(self._process_move_queue, camera_name),", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self._autotrack_move_ptz(camera, obj)", "prediction_line": "                self._autotrack_move_ptz(camera, obj)", "ground_truth": "                self._autotrack_move_ptz(camera, obj)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.config = config", "prediction_line": "        self.config = config", "ground_truth": "        self.ptz_autotracker = PtzAutoTracker(config, onvif, camera_metrics)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if self.coord_transformations is not None:", "prediction_line": "            if self.coord_transformations is not None:", "ground_truth": "            self.frame_manager.close(frame_id)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.motion_queue = queue.Queue()", "prediction_line": "        self.motion_queue = queue.Queue()", "ground_truth": "        logger.debug(f\"Motion estimator init for cam: {config.name}\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.config = config", "prediction_line": "        self.config = config", "ground_truth": "        self.frame_manager = SharedMemoryFrameManager()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.tracked_object = {}", "prediction_line": "        self.tracked_object = {}", "ground_truth": "        self.tracked_object: dict[str, object] = {}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        camera_height = camera_config.frame_shape[0]", "prediction_line": "        camera_height = camera_config.frame_shape[0]", "ground_truth": "        camera_height = camera_config.frame_shape[0]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        camera_config = self.config.cameras[camera]", "prediction_line": "        camera_config = self.config.cameras[camera]", "ground_truth": "        if self.config.cameras[camera].onvif.autotracking.enabled:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # if camera is not moving, returns to preset", "prediction_line": "        # if camera is not moving, returns to preset", "ground_truth": "        autotracker_config = self.config.cameras[camera].onvif.autotracking", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.config = config", "prediction_line": "        self.config = config", "ground_truth": "        self.camera_config = config", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self._autotracker_setup(self.config.cameras[camera], camera)", "prediction_line": "            self._autotracker_setup(self.config.cameras[camera], camera)", "ground_truth": "            self._autotracker_setup(self.config.cameras[camera], camera)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if self.tracked_object[camera] is None:", "prediction_line": "        if self.tracked_object[camera] is None:", "ground_truth": "        camera_config = self.config.cameras[camera]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # frame_width = camera_config.frame_shape[1]", "prediction_line": "        # frame_width = camera_config.frame_shape[1]", "ground_truth": "        camera_width = camera_config.frame_shape[1]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.tracked_object_previous: dict[str, object] = {}", "prediction_line": "        self.tracked_object_previous: dict[str, object] = {}", "ground_truth": "        self.tracked_object_previous: dict[str, object] = {}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                and not obj.previous[\"motionless\"]", "prediction_line": "                and not obj.previous[\"motionless\"]", "ground_truth": "                and not obj.false_positive", "line_class": "inproject", "zero_context": true}
{"original_prediction": "frame_id)\n            if yuv_frame is None:", "prediction_line": "frame_id)", "ground_truth": "                frame_id, self.camera_config.frame_shape_yuv", "line_class": "inproject", "zero_context": true}
{"original_prediction": "or is a new object that's on our camera, has our label, entered the zone, and is not a false positive", "prediction_line": "or is a new object that's on our camera, has our label, entered the zone, and is not a false positive", "ground_truth": "            # and is not initially motionless - or one we're already tracking, which assumes all those things are already true", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def update_coord_transformations(self, coord_transformations):", "prediction_line": "    def update_coord_transformations(self, coord_transformations):", "ground_truth": "    def motion_estimator(self, detections, frame_time, camera_name):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       self.ptz_stopped = {}", "prediction_line": "       self.ptz_stopped = {}", "ground_truth": "        # if cam is set to autotrack, onvif should be set up", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import onvif", "prediction_line": "import onvif", "ground_truth": "from norfair.camera_motion import MotionEstimator, TranslationTransformationGetter", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            and self.camera_metrics[camera][\"ptz_stopped\"].is_set()", "prediction_line": "            and self.camera_metrics[camera][\"ptz_stopped\"].is_set()", "ground_truth": "            and (", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.camera_metrics = camera_metrics", "prediction_line": "        self.camera_metrics = camera_metrics", "ground_truth": "        self.camera_metrics = camera_metrics", "line_class": "random", "zero_context": true}
{"original_prediction": "       if autotracker_config.enabled:", "prediction_line": "       if autotracker_config.enabled:", "ground_truth": "        if not self.autotracker_init[camera]:", "line_class": "random", "zero_context": true}
{"original_prediction": "                and obj.obj_data[\"zone\"] in self.required_zones[camera]", "prediction_line": "                and obj.obj_data[\"zone\"] in self.required_zones[camera]", "ground_truth": "                and set(obj.entered_zones) & set(self.required_zones[camera])", "line_class": "random", "zero_context": true}
{"original_prediction": "                f\"Motion estimator done for {camera_name} - frame time: {frame_time}\"", "prediction_line": "                f\"Motion estimator done for {camera_name} - frame time: {frame_time}\"", "ground_truth": "                f\"Motion estimator transformation: {self.coord_transformations.rel_to_abs((0,0))}\"", "line_class": "random", "zero_context": true}
{"original_prediction": "        start_time=start,", "prediction_line": "        start_time=start,", "ground_truth": "        start_time=start,", "line_class": "common", "zero_context": true}
{"original_prediction": "    ).execute()", "prediction_line": "    ).execute()", "ground_truth": "    ).execute()", "line_class": "common", "zero_context": true}
{"original_prediction": "        router.run()", "prediction_line": "        router.run()", "ground_truth": "        router.run()", "line_class": "common", "zero_context": true}
{"original_prediction": "        _insert_mock_recording(", "prediction_line": "        _insert_mock_recording(", "ground_truth": "        _insert_mock_recording(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _insert_mock_recording(rec_d_id, time_delete, time_delete + 10)", "prediction_line": "        _insert_mock_recording(rec_d_id, time_delete, time_delete + 10)", "ground_truth": "        _insert_mock_recording(rec_d_id, time_delete, time_delete + 10)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _insert_mock_recording(rec_d2_id, time_delete + 10, time_delete + 20)", "prediction_line": "        _insert_mock_recording(rec_d2_id, time_delete + 10, time_delete + 20)", "ground_truth": "        _insert_mock_recording(rec_d2_id, time_delete + 10, time_delete + 20)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _insert_mock_recording(rec_d3_id, time_delete + 20, time_delete + 30)", "prediction_line": "        _insert_mock_recording(rec_d3_id, time_delete + 20, time_delete + 30)", "ground_truth": "        _insert_mock_recording(rec_d3_id, time_delete + 20, time_delete + 30)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _insert_mock_event(id, time_keep, time_keep + 30, True)", "prediction_line": "        _insert_mock_event(id, time_keep, time_keep + 30, True)", "ground_truth": "        _insert_mock_event(id, time_keep, time_keep + 30, True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _insert_mock_recording(", "prediction_line": "        _insert_mock_recording(", "ground_truth": "        _insert_mock_recording(rec_k_id, time_keep, time_keep + 10)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _insert_mock_recording(rec_k2_id, time_keep + 10, time_keep + 20)", "prediction_line": "        _insert_mock_recording(rec_k2_id, time_keep + 10, time_keep + 20)", "ground_truth": "        _insert_mock_recording(rec_k2_id, time_keep + 10, time_keep + 20)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _insert_mock_recording(rec_k3_id, time_keep + 20, time_keep + 30)", "prediction_line": "        _insert_mock_recording(rec_k3_id, time_keep + 20, time_keep + 30)", "ground_truth": "        _insert_mock_recording(rec_k3_id, time_keep + 20, time_keep + 30)", "line_class": "infile", "zero_context": true}
{"original_prediction": "0\n        _insert_mock_event(id2, time_delete, time_delete + 30, True)", "prediction_line": "0", "ground_truth": "        _insert_mock_event(id2, time_delete, time_delete + 30, False)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            Recordings.get(Recordings.id == rec_d2_id)", "prediction_line": "            Recordings.get(Recordings.id == rec_d2_id)", "ground_truth": "            Recordings.get(Recordings.id == rec_d2_id)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return Recordings.insert(", "prediction_line": "    return Recordings.insert(", "ground_truth": "    return Recordings.insert(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        app = create_app(FrigateConfig(self.minimal_config))", "prediction_line": "        app = create_app(FrigateConfig(self.minimal_config))", "ground_truth": "        config = FrigateConfig(**self.double_cam_config)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.db.close()", "prediction_line": "            self.db.close()", "ground_truth": "            self.db.close()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.app = create_app(", "prediction_line": "        self.app = create_app(", "ground_truth": "        migrate_db.close()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        end_time=end,", "prediction_line": "        end_time=end,", "ground_truth": "        end_time=end,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        assert Recordings.get(Recordings.id == rec_k3_id)", "prediction_line": "        assert Recordings.get(Recordings.id == rec_k3_id)", "ground_truth": "        assert Recordings.get(Recordings.id == rec_k3_id)", "line_class": "inproject", "zero_context": true}
{"original_prediction": ") -> Recordings:", "prediction_line": ") -> Recordings:", "ground_truth": ") -> Event:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            Recordings.get(Recordings.id == rec_d3_id)", "prediction_line": "            Recordings.get(Recordings.id == rec_d3_id)", "ground_truth": "            Recordings.get(Recordings.id == rec_d3_id)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        storage = StorageMaintainer(config, MagicMock())", "prediction_line": "        storage = StorageMaintainer(config, MagicMock())", "ground_truth": "        storage = StorageMaintainer(config, MagicMock())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        assert Recordings.get(Recordings.id == rec_k_id)", "prediction_line": "        assert Recordings.get(Recordings.id == rec_k_id)", "ground_truth": "        assert Recordings.get(Recordings.id == rec_k_id)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        config = FrigateConfig(**self.minimal_config)", "prediction_line": "        config = FrigateConfig(**self.minimal_config)", "ground_truth": "        config = FrigateConfig(**self.minimal_config)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.app = create_app(self.db, FrigateConfig())", "prediction_line": "        self.app = create_app(self.db, FrigateConfig())", "ground_truth": "        models = [Event, Recordings]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    event = Event(", "prediction_line": "    event = Event(", "ground_truth": "    return Event.insert(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        frame_height=1080,", "prediction_line": "        frame_height=1080,", "ground_truth": "        area=0,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "import re\nimport shutil", "prediction_line": "import re", "ground_truth": "import unittest", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"Ensure that all recordings are cleaned up when necessary.\"\"\"", "prediction_line": "        \"\"\"Ensure that all recordings are cleaned up when necessary.\"\"\"", "ground_truth": "        \"\"\"Ensure that all recordings are cleaned up when necessary.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"Test that the segment calculations are correct.\"\"\"", "prediction_line": "        \"\"\"Test that the segment calculations are correct.\"\"\"", "ground_truth": "        \"\"\"Ensure segment calculation does not fail when migrating from previous version.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       self.app = create_app(", "prediction_line": "       self.app = create_app(", "ground_truth": "    def tearDown(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        thumbnail_size=0,", "prediction_line": "        thumbnail_size=0,", "ground_truth": "        region=[],", "line_class": "random", "zero_context": true}
{"original_prediction": "            pass\n\n    def test_get_events(self):", "prediction_line": "            pass", "ground_truth": "            pass", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.app = create_app(", "prediction_line": "        self.app = create_app(", "ground_truth": "        self.db = SqliteQueueDatabase(TEST_DB)", "line_class": "random", "zero_context": true}
{"original_prediction": "                    },\n                },", "prediction_line": "                    },", "ground_truth": "                    },", "line_class": "random", "zero_context": true}
{"original_prediction": "            os.remove(TEST_DB)", "prediction_line": "            os.remove(TEST_DB)", "ground_truth": "            for file in TEST_DB_CLEANUPS:", "line_class": "random", "zero_context": true}
{"original_prediction": "        if command == OnvifCommandEnum.init:", "prediction_line": "        if command == OnvifCommandEnum.init:", "ground_truth": "        if command == OnvifCommandEnum.init:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        elif command == OnvifCommandEnum.move_up:", "prediction_line": "        elif command == OnvifCommandEnum.move_up:", "ground_truth": "        elif command == OnvifCommandEnum.move_up:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._stop(camera_name)", "prediction_line": "            self._stop(camera_name)", "ground_truth": "            self._stop(camera_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        elif command == OnvifCommandEnum.move_left:", "prediction_line": "        elif command == OnvifCommandEnum.move_left:", "ground_truth": "        elif command == OnvifCommandEnum.preset:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._move_to_preset(camera_name, param)", "prediction_line": "            self._move_to_preset(camera_name, param)", "ground_truth": "            self._move_to_preset(camera_name, param)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        elif command == OnvifCommandEnum.move_down:", "prediction_line": "        elif command == OnvifCommandEnum.move_down:", "ground_truth": "        elif command == OnvifCommandEnum.move_down:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            command == OnvifCommandEnum.move_left", "prediction_line": "            command == OnvifCommandEnum.move_left", "ground_truth": "            command == OnvifCommandEnum.zoom_in or command == OnvifCommandEnum.zoom_out", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if \"zoom\" not in self.cams[camera_name][\"features\"]:", "prediction_line": "            if \"zoom\" not in self.cams[camera_name][\"features\"]:", "ground_truth": "            self._zoom(camera_name, command)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._move(camera_name, command)", "prediction_line": "            self._move(camera_name, command)", "ground_truth": "            self._move(camera_name, command)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if command == OnvifCommandEnum.zoom_in:", "prediction_line": "        if command == OnvifCommandEnum.zoom_in:", "ground_truth": "        if command == OnvifCommandEnum.zoom_in:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        elif command == OnvifCommandEnum.zoom_out:", "prediction_line": "        elif command == OnvifCommandEnum.zoom_out:", "ground_truth": "        elif command == OnvifCommandEnum.zoom_out:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if not self._init_onvif(camera_name):", "prediction_line": "            if not self._init_onvif(camera_name):", "ground_truth": "            self._init_onvif(camera_name)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if command == OnvifCommandEnum.move_down:", "prediction_line": "        if command == OnvifCommandEnum.move_down:", "ground_truth": "        if command == OnvifCommandEnum.move_left:", "line_class": "infile", "zero_context": true}
{"original_prediction": "self, camera_name: str, command: OnvifCommandEnum) -> None:", "prediction_line": "self, camera_name: str, command: OnvifCommandEnum) -> None:", "ground_truth": "        self, camera_name: str, command: OnvifCommandEnum, param: str = \"\"", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if not self._init_onvif(camera_name):", "prediction_line": "            if not self._init_onvif(camera_name):", "ground_truth": "            if not self._init_onvif(camera_name):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        elif command == OnvifCommandEnum.move_right:", "prediction_line": "        elif command == OnvifCommandEnum.move_right:", "ground_truth": "        elif command == OnvifCommandEnum.move_right:", "line_class": "infile", "zero_context": true}
{"original_prediction": "       self.config = config", "prediction_line": "       self.config = config", "ground_truth": "        for cam_name, cam in config.cameras.items():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if command == OnvifCommandEnum.stop:", "prediction_line": "        if command == OnvifCommandEnum.stop:", "ground_truth": "        elif command == OnvifCommandEnum.stop:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            presets = ptz.GetPresets(profile.token)", "prediction_line": "            presets = ptz.GetPresets(profile.token)", "ground_truth": "            presets: list[dict] = ptz.GetPresets({\"ProfileToken\": profile.token})", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    set_home = \"set_home\"", "prediction_line": "    set_home = \"set_home\"", "ground_truth": "    stop = \"stop\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.config = config", "prediction_line": "        self.config = config", "ground_truth": "        self.cams: dict[str, ONVIFCamera] = {}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def _zoom(self, camera_name: str, command: OnvifCommandEnum) -> None:", "prediction_line": "    def _zoom(self, camera_name: str, command: OnvifCommandEnum) -> None:", "ground_truth": "    def _zoom(self, camera_name: str, command: OnvifCommandEnum) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # setup preset request", "prediction_line": "        # setup preset request", "ground_truth": "        # setup existing presets", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class OnvifCamera:", "prediction_line": "class OnvifCamera:", "ground_truth": "class OnvifController:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"Enum of supported onvif commands.\"\"\"", "prediction_line": "    \"\"\"Enum of supported onvif commands.\"\"\"", "ground_truth": "    \"\"\"Holds all possible move commands\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            \"presets\": list(self.cams[camera_name][\"presets\"].keys()),", "prediction_line": "            \"presets\": list(self.cams[camera_name][\"presets\"].keys()),", "ground_truth": "            \"presets\": list(self.cams[camera_name][\"presets\"].keys()),", "line_class": "random", "zero_context": true}
{"original_prediction": "        onvif.get_service(\"ptz\").ContinuousMove(move_request)", "prediction_line": "        onvif.get_service(\"ptz\").ContinuousMove(move_request)", "ground_truth": "        onvif.get_service(\"ptz\").ContinuousMove(move_request)", "line_class": "random", "zero_context": true}
{"original_prediction": "        try:\n            features = ptz.GetServiceCapabilities()", "prediction_line": "        try:", "ground_truth": "        ptz_config = ptz.GetConfigurationOptions(request)", "line_class": "random", "zero_context": true}
{"original_prediction": "                    }\n                except ONVIFError as err:", "prediction_line": "                    }", "ground_truth": "                        \"active\": False,", "line_class": "random", "zero_context": true}
{"original_prediction": "        move_request.ProfileToken = self.cams[camera_name][\"presets\"][preset]", "prediction_line": "        move_request.ProfileToken = self.cams[camera_name][\"presets\"][preset]", "ground_truth": "        preset_token = self.cams[camera_name][\"presets\"][preset]", "line_class": "random", "zero_context": true}
{"original_prediction": "                return f'{_unparse(node.value)}[{_unparse(node_slice.elts[0])}]'", "prediction_line": "                return f'{_unparse(node.value)}[{_unparse(node_slice.elts[0])}]'", "ground_truth": "                slice_s = f'{_unparse(node_slice.elts[0])},'", "line_class": "infile", "zero_context": true}
{"original_prediction": "            yield ast_to_offset(node), _fix_named_tuple", "prediction_line": "            yield ast_to_offset(node), _fix_named_tuple", "ground_truth": "            func = functools.partial(_fix_named_tuple, call=node.value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                slice_s = f'{_unparse(node_slice.elts[0])}:{_unparse(node_slice.elts[1])}'", "prediction_line": "                slice_s = f'{_unparse(node_slice.elts[0])}:{_unparse(node_slice.elts[1])}'", "ground_truth": "                slice_s = ', '.join(_unparse(elt) for elt in node_slice.elts)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            slice_s = _unparse(node_slice)", "prediction_line": "            slice_s = _unparse(node_slice)", "ground_truth": "            slice_s = _unparse(node_slice)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return f'{_unparse(node.value)}[{slice_s}]'", "prediction_line": "        return f'{_unparse(node.value)}[{slice_s}]'", "ground_truth": "        return f'{_unparse(node.value)}[{slice_s}]'", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # NT = NamedTuple(\"nt\", [(\"a\", int)])", "prediction_line": "    # NT = NamedTuple(\"nt\", [(\"a\", int)])", "ground_truth": "    attrs = '\\n'.join(f'{indent}{k}: {_unparse(v)}' for k, v in types.items())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return '[' + ', '.join(_unparse(elt) for elt in node.elts) + ']'", "prediction_line": "        return '[' + ', '.join(_unparse(elt) for elt in node.elts) + ']'", "ground_truth": "        return '[{}]'.format(', '.join(_unparse(elt) for elt in node.elts))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        end, attrs = _typed_class_replacement(tokens, i, call, types)", "prediction_line": "        end, attrs = _typed_class_replacement(tokens, i, call, types)", "ground_truth": "        end, attrs = _typed_class_replacement(tokens, i, call, types)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    src = f'class {tokens[i].src}(dict):\\n{attrs}'", "prediction_line": "    src = f'class {tokens[i].src}(dict):\\n{attrs}'", "ground_truth": "    src = f'class {tokens[i].src}({_unparse(call.func)}):\\n{attrs}'", "line_class": "infile", "zero_context": true}
{"original_prediction": "            func = functools.partial(_fix_dict_typed_dict, call=node.value)", "prediction_line": "            func = functools.partial(_fix_dict_typed_dict, call=node.value)", "ground_truth": "            func = functools.partial(_fix_dict_typed_dict, call=node.value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            f'{_unparse(call.func)}, total={_unparse(total)}):\\n{attrs}'", "prediction_line": "            f'{_unparse(call.func)}, total={_unparse(total)}):\\n{attrs}'", "ground_truth": "            f'{_unparse(call.func)}, total={total}'", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if isinstance(node.value.args[0], ast.Str):", "prediction_line": "            if isinstance(node.value.args[0], ast.Str):", "ground_truth": "            func = functools.partial(_fix_kw_typed_dict, call=node.value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return f'{_unparse(node.value)}.{node.attr}'", "prediction_line": "        return f'{_unparse(node.value)}.{node.attr}'", "ground_truth": "        return ''.join((_unparse(node.value), '.', node.attr))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            yield ast_to_offset(node), func", "prediction_line": "            yield ast_to_offset(node), func", "ground_truth": "            yield ast_to_offset(node), func", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                # NT = ...(\"NT\", ...)", "prediction_line": "                # NT = ...(\"NT\", ...)", "ground_truth": "                is_name_attr(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            isinstance(node.value.func, ast.Name) and", "prediction_line": "            isinstance(node.value.func, ast.Name) and", "ground_truth": "            not has_starargs(node.value)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def _fix_typed_dict(", "prediction_line": "def _fix_typed_dict(", "ground_truth": "@register(ast.Assign)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        state: State,", "prediction_line": "        state: State,", "ground_truth": "        state: State,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from pyupgrade._data import TokenList", "prediction_line": "from pyupgrade._data import TokenList", "ground_truth": "from pyupgrade._token_helpers import KEYWORDS", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    state.from_imports,", "prediction_line": "                    state.from_imports,", "ground_truth": "                    state.from_imports,", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    }\n    end, attrs = _typed_class_replacement(tokens, i, call, types)", "prediction_line": "    }", "ground_truth": "    }", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "call.args[0].elts, call.args[1].elts)  # type: ignore  # (checked below)", "prediction_line": "call.args[0].elts, call.args[1].elts)  # type: ignore  # (checked below)", "ground_truth": "            call.args[1].keys,  # type: ignore  # (checked below)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        for tup in call.args", "prediction_line": "        for tup in call.args", "ground_truth": "        for tup in call.args[1].elts  # type: ignore  # (checked below)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    ('typing',),", "prediction_line": "                    ('typing',),", "ground_truth": "                    ('typing', 'typing_extensions'),", "line_class": "random", "zero_context": true}
{"original_prediction": "    else:\n        raise AssertionError(f'unexpected node type: {type(node)!r}')", "prediction_line": "    else:", "ground_truth": "    elif isinstance(node, ast.Subscript):", "line_class": "random", "zero_context": true}
{"original_prediction": "i: int, tokens: list[Token], *, call: ast.Call) -> None:", "prediction_line": "i: int, tokens: list[Token], *, call: ast.Call) -> None:", "ground_truth": "        i: int,", "line_class": "random", "zero_context": true}
{"original_prediction": "                isinstance(node.value.args[1], ast.Tuple)", "prediction_line": "                isinstance(node.value.args[1], ast.Tuple)", "ground_truth": "                not node.value.keywords and", "line_class": "random", "zero_context": true}
{"original_prediction": "            len(node.targets) == 1", "prediction_line": "            len(node.targets) == 1", "ground_truth": "            len(node.targets) == 1 and", "line_class": "random", "zero_context": true}
{"original_prediction": "        response = self.client.post('/api/tickets/')", "prediction_line": "        response = self.client.post('/api/tickets/')", "ground_truth": "        response = self.client.post('/api/tickets/')", "line_class": "common", "zero_context": true}
{"original_prediction": "        response = self.client.post('/api/tickets/', {", "prediction_line": "        response = self.client.post('/api/tickets/', {", "ground_truth": "        response = self.client.post('/api/tickets/', {", "line_class": "common", "zero_context": true}
{"original_prediction": "        response = self.client.delete('/api/tickets/%d/' % test_ticket.id)", "prediction_line": "        response = self.client.delete('/api/tickets/%d/' % test_ticket.id)", "ground_truth": "        response = self.client.delete('/api/tickets/%d/' % test_ticket.id)", "line_class": "common", "zero_context": true}
{"original_prediction": "        response = self.client.post('/api/tickets/', {", "prediction_line": "        response = self.client.post('/api/tickets/', {", "ground_truth": "        response = self.client.post(", "line_class": "common", "zero_context": true}
{"original_prediction": "        merge_ticket = Ticket.objects.create(queue=self.queue, title='merge ticket')", "prediction_line": "        merge_ticket = Ticket.objects.create(queue=self.queue, title='merge ticket')", "ground_truth": "        merge_ticket = Ticket.objects.create(queue=self.queue, title='merge ticket')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            title='Test Queue',", "prediction_line": "            title='Test Queue',", "ground_truth": "            title='Test Queue',", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(test_ticket.title, 'Title')", "prediction_line": "        self.assertEqual(test_ticket.title, 'Title')", "ground_truth": "        self.assertEqual(test_ticket.title, 'Title')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(response.data, {", "prediction_line": "        self.assertEqual(response.data, {", "ground_truth": "        created_ticket = Ticket.objects.get()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(test_ticket.description, 'Description')", "prediction_line": "        self.assertEqual(test_ticket.description, 'Description')", "ground_truth": "        self.assertEqual(test_ticket.description, 'Description')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertFalse(Ticket.objects.exists())", "prediction_line": "        self.assertFalse(Ticket.objects.exists())", "ground_truth": "        self.assertFalse(Ticket.objects.exists())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            CustomField.objects.create(", "prediction_line": "            CustomField.objects.create(", "ground_truth": "            CustomField.objects.create(name=field_type, label=field_display, data_type=field_type, **extra_data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        custom_field_1 = CustomField.objects.create(", "prediction_line": "        custom_field_1 = CustomField.objects.create(", "ground_truth": "        for field_type, field_display in CustomField.DATA_TYPE_CHOICES:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(created_ticket.description, 'Test description\\nMulti lines')", "prediction_line": "        self.assertEqual(created_ticket.description, 'Test description\\nMulti lines')", "ground_truth": "        self.assertEqual(created_ticket.description, 'Test description\\nMulti lines')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(test_ticket.status, Ticket.RESOLVED_STATUS)", "prediction_line": "        self.assertEqual(test_ticket.status, Ticket.RESOLVED_STATUS)", "ground_truth": "        self.assertEqual(test_ticket.status, Ticket.RESOLVED_STATUS)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        cls.queue = Queue.objects.create(", "prediction_line": "        cls.queue = Queue.objects.create(", "ground_truth": "        cls.queue = Queue.objects.create(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(created_ticket.description, 'Description')", "prediction_line": "        self.assertEqual(created_ticket.description, 'Description')", "ground_truth": "        self.assertEqual(created_ticket.description, 'Description')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                'priority': 4,", "prediction_line": "                'priority': 4,", "ground_truth": "                'status': Ticket.RESOLVED_STATUS,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(created_ticket.title, 'Title')", "prediction_line": "        self.assertEqual(created_ticket.title, 'Title')", "ground_truth": "        self.assertEqual(created_ticket.title, 'Title')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertEqual(test_ticket.description, 'New description')", "prediction_line": "        self.assertEqual(test_ticket.description, 'New description')", "ground_truth": "        self.assertEqual(test_ticket.description, 'New description')", "line_class": "inproject", "zero_context": true}
{"original_prediction": "from django.core.files.uploadedfile import SimpleUploadedFile", "prediction_line": "from django.core.files.uploadedfile import SimpleUploadedFile", "ground_truth": "from pytz import UTC", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_create_api_ticket_no_queue(self):", "prediction_line": "    def test_create_api_ticket_no_queue(self):", "ground_truth": "    def test_create_api_ticket_wrong_date_format(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_delete_api_ticket(self):", "prediction_line": "    def test_delete_api_ticket(self):", "ground_truth": "    def test_delete_api_ticket(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import json\nimport os", "prediction_line": "import json", "ground_truth": "from datetime import datetime", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            'due_date': '2022-05-01T12:00:00Z'", "prediction_line": "            'due_date': '2022-05-01T12:00:00Z'", "ground_truth": "            'description': 'Test description\\nMulti lines',", "line_class": "random", "zero_context": true}
{"original_prediction": "            {\n                'queue': self.queue.id,", "prediction_line": "            {", "ground_truth": "            {", "line_class": "random", "zero_context": true}
{"original_prediction": "            'custom_email': 'email@test.com',", "prediction_line": "            'custom_email': 'email@test.com',", "ground_truth": "            'custom_email': 'email@test.com',", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.assertEqual(test_ticket.submitter_email, 'test@mail.com')", "prediction_line": "        self.assertEqual(test_ticket.submitter_email, 'test@mail.com')", "ground_truth": "        self.assertEqual(test_ticket.submitter_email, 'test@mail.com')", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.assertTrue(test_ticket.on_hold)", "prediction_line": "        self.assertTrue(test_ticket.on_hold)", "ground_truth": "        self.assertTrue(test_ticket.on_hold)", "line_class": "random", "zero_context": true}
{"original_prediction": "            diff_lists(user_config_pads, used_pads + used_corner_pads),", "prediction_line": "            diff_lists(user_config_pads, used_pads + used_corner_pads),", "ground_truth": "            diff_lists(user_config_pads, used_pads + used_corner_pads),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    padringer()", "prediction_line": "    padringer()", "ground_truth": "    padringer()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # TODO: after calssification, center other pads on each side", "prediction_line": "        # TODO: after calssification, center other pads on each side", "ground_truth": "        north, east, south, west = chunker(used_pads, 4)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                generate_cfg(", "prediction_line": "                generate_cfg(", "ground_truth": "                generate_cfg(north, east, south, west, used_corner_pads, width, height)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        invoke_padring(working_cfg, working_def, lefs)", "prediction_line": "        invoke_padring(working_cfg, working_def, lefs)", "ground_truth": "        invoke_padring(working_cfg, working_def, lefs)", "line_class": "infile", "zero_context": true}
{"original_prediction": "   # Step 5: Apply the pad placements to the design DEF", "prediction_line": "   # Step 5: Apply the pad placements to the design DEF", "ground_truth": "    padframe = OdbReader(lefs, working_def)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        print(\"Using user-provided config file:\", config_file_name)", "prediction_line": "        print(\"Using user-provided config file:\", config_file_name)", "ground_truth": "        with open(config_file_name, \"r\") as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       corner_pads = chunker(used_corner_pads, 4)", "prediction_line": "       corner_pads = chunker(used_corner_pads, 4)", "ground_truth": "        with open(working_cfg, \"w\") as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            f.write(", "prediction_line": "            f.write(", "ground_truth": "            f.write(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # Step 2: read the DEF file and extract the pads", "prediction_line": "    # Step 2: read the DEF file and extract the pads", "ground_truth": "    top = OdbReader(lefs, working_def)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "# Unless required by applicable law or agreed to in writing, software", "prediction_line": "# Unless required by applicable law or agreed to in writing, software", "ground_truth": "# Unless required by applicable law or agreed to in writing, software", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    Generate a padframe for a given design.", "prediction_line": "    Generate a padframe for a given design.", "ground_truth": "    Reads in a structural verilog containing pads and a LEF file that", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        assert os.path.exists(working_def)", "prediction_line": "        assert os.path.exists(working_def)", "ground_truth": "        # TODO: check for errors", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # Step 3: create a simple data structure with pads from the DEF", "prediction_line": "    # Step 3: create a simple data structure with pads from the DEF", "ground_truth": "    print()", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    cmd = \"padring -c {} -o {}\".format(config_file_name, output_file_name)", "prediction_line": "    cmd = \"padring -c {} -o {}\".format(config_file_name, output_file_name)", "ground_truth": "    print(\"Invoking padring to generate a padframe\")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"--lef\",", "prediction_line": "    \"--lef\",", "ground_truth": "    \"-o\",", "line_class": "random", "zero_context": true}
{"original_prediction": "    default=\"\",", "prediction_line": "    default=\"\",", "ground_truth": "    default=\"sky130_fd_io;sky130_ef_io\",", "line_class": "random", "zero_context": true}
{"original_prediction": "   cfg.append(\"PAD_PIN_ORIGINAL_NAMES\")", "prediction_line": "   cfg.append(\"PAD_PIN_ORIGINAL_NAMES\")", "ground_truth": "    assert len(corner_pads) == 4, corner_pads", "line_class": "random", "zero_context": true}
{"original_prediction": "    default=\"./\",", "prediction_line": "    default=\"./\",", "ground_truth": "    default=\".\",", "line_class": "random", "zero_context": true}
{"original_prediction": "       output = p.communicate(openroad_script)", "prediction_line": "       output = p.communicate(openroad_script)", "ground_truth": "        output = p.communicate(openroad_script)", "line_class": "random", "zero_context": true}
{"original_prediction": "                    self.get_token()", "prediction_line": "                    self.get_token()", "ground_truth": "                    self.get_token()", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    raise ParserError(", "prediction_line": "                    raise ParserError(", "ground_truth": "                    token = self.peek_token()", "line_class": "commited", "zero_context": true}
{"original_prediction": "           if self.check_token(FlowSequenceEndToken):", "prediction_line": "           if self.check_token(FlowSequenceEndToken):", "ground_truth": "            if self.check_token(KeyToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            else:\n                self.states.append(self.parse_flow_sequence_entry)", "prediction_line": "            else:", "ground_truth": "            elif not self.check_token(FlowSequenceEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        token = self.get_token()", "prediction_line": "        token = self.get_token()", "ground_truth": "        token = self.get_token()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if not self.check_token(ValueToken, FlowEntryToken, FlowSequenceEndToken):", "prediction_line": "        if not self.check_token(ValueToken, FlowEntryToken, FlowSequenceEndToken):", "ground_truth": "        if not self.check_token(ValueToken, FlowEntryToken, FlowSequenceEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if self.check_token(ValueToken):", "prediction_line": "        if self.check_token(ValueToken):", "ground_truth": "        if self.check_token(ValueToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if not self.check_token(FlowEntryToken, FlowSequenceEndToken):", "prediction_line": "            if not self.check_token(FlowEntryToken, FlowSequenceEndToken):", "ground_truth": "            if not self.check_token(FlowEntryToken, FlowSequenceEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if not self.check_token(FlowMappingEndToken):", "prediction_line": "        if not self.check_token(FlowMappingEndToken):", "ground_truth": "        if not self.check_token(FlowMappingEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                if self.check_token(FlowEntryToken):", "prediction_line": "                if self.check_token(FlowEntryToken):", "ground_truth": "                if self.check_token(FlowEntryToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                if not self.check_token(ValueToken, FlowEntryToken, FlowMappingEndToken):", "prediction_line": "                if not self.check_token(ValueToken, FlowEntryToken, FlowMappingEndToken):", "ground_truth": "                if not self.check_token(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            else:\n                self.state = self.parse_flow_mapping_empty_value", "prediction_line": "            else:", "ground_truth": "            elif not self.check_token(FlowMappingEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if not self.check_token(FlowEntryToken, FlowMappingEndToken):", "prediction_line": "            if not self.check_token(FlowEntryToken, FlowMappingEndToken):", "ground_truth": "            if not self.check_token(FlowEntryToken, FlowMappingEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        token = self.peek_token()", "prediction_line": "        token = self.peek_token()", "ground_truth": "        return self.process_empty_scalar(self.peek_token().start_mark)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        token = self.peek_token()", "prediction_line": "        token = self.peek_token()", "ground_truth": "        if not self.check_token(DirectiveToken, DocumentStartToken, StreamEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        while self.check_token(DocumentEndToken):", "prediction_line": "        while self.check_token(DocumentEndToken):", "ground_truth": "        while self.check_token(DocumentEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        token = self.get_token()", "prediction_line": "        token = self.get_token()", "ground_truth": "        if not self.check_token(StreamEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            end_mark = self.peek_token().start_mark", "prediction_line": "            end_mark = self.peek_token().start_mark", "ground_truth": "            if not self.check_token(DocumentStartToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    \"expected '<document start>', but found %r\"", "prediction_line": "                    \"expected '<document start>', but found %r\"", "ground_truth": "                    \"expected '<document start>', but found %r\" % self.peek_token().id,", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    self.peek_token().start_mark,", "prediction_line": "                    self.peek_token().start_mark,", "ground_truth": "                    self.peek_token().start_mark,", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if self.check_token(DocumentEndToken):", "prediction_line": "        if self.check_token(DocumentEndToken):", "ground_truth": "        if self.check_token(DocumentEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        # Parse the document content.", "prediction_line": "        # Parse the document content.", "ground_truth": "        if self.check_token(", "line_class": "commited", "zero_context": true}
{"original_prediction": "            return self.process_empty_scalar(self.peek_token().start_mark)", "prediction_line": "            return self.process_empty_scalar(self.peek_token().start_mark)", "ground_truth": "            event = self.process_empty_scalar(self.peek_token().start_mark)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        while self.check_token(DirectiveToken):", "prediction_line": "        while self.check_token(DirectiveToken):", "ground_truth": "        while self.check_token(DirectiveToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                handle, prefix = token.value", "prediction_line": "                handle, prefix = token.value", "ground_truth": "                handle, prefix = token.value", "line_class": "commited", "zero_context": true}
{"original_prediction": "                self.tag_handles[handle] = prefix", "prediction_line": "                self.tag_handles[handle] = prefix", "ground_truth": "                self.tag_handles[handle] = prefix", "line_class": "commited", "zero_context": true}
{"original_prediction": "        # Parse a block node or indentless sequence.", "prediction_line": "        # Parse a block node or indentless sequence.", "ground_truth": "        if self.check_token(AliasToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                if self.check_token(AnchorToken):", "prediction_line": "                if self.check_token(AnchorToken):", "ground_truth": "                if self.check_token(AnchorToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                if self.check_token(TagToken):", "prediction_line": "                if self.check_token(TagToken):", "ground_truth": "                if self.check_token(TagToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if self.check_token(TagToken, \"!\") and not tag:", "prediction_line": "            if self.check_token(TagToken, \"!\") and not tag:", "ground_truth": "            elif self.check_token(TagToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                start_mark = end_mark = self.peek_token().start_mark", "prediction_line": "                start_mark = end_mark = self.peek_token().start_mark", "ground_truth": "                start_mark = end_mark = self.peek_token().start_mark", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if self.check_token(ScalarToken):", "prediction_line": "            if self.check_token(ScalarToken):", "ground_truth": "            if indentless_sequence and self.check_token(BlockEntryToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                token = self.get_token()", "prediction_line": "                token = self.get_token()", "ground_truth": "                end_mark = self.peek_token().end_mark", "line_class": "commited", "zero_context": true}
{"original_prediction": "                if self.check_token(ScalarToken):", "prediction_line": "                if self.check_token(ScalarToken):", "ground_truth": "                if self.check_token(ScalarToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                elif self.check_token(FlowSequenceStartToken):", "prediction_line": "                elif self.check_token(FlowSequenceStartToken):", "ground_truth": "                elif self.check_token(FlowSequenceStartToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                elif self.check_token(FlowMappingStartToken):", "prediction_line": "                elif self.check_token(FlowMappingStartToken):", "ground_truth": "                elif self.check_token(FlowMappingStartToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                elif block:", "prediction_line": "                elif block:", "ground_truth": "                elif block and self.check_token(BlockSequenceStartToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    end_mark = self.peek_token().end_mark", "prediction_line": "                    end_mark = self.peek_token().end_mark", "ground_truth": "                    end_mark = self.peek_token().start_mark", "line_class": "commited", "zero_context": true}
{"original_prediction": "                elif block and self.check_token(BlockMappingStartToken):", "prediction_line": "                elif block and self.check_token(BlockMappingStartToken):", "ground_truth": "                elif block and self.check_token(BlockMappingStartToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        token = self.get_token()", "prediction_line": "        token = self.get_token()", "ground_truth": "        if self.check_token(BlockEntryToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self.marks.append(token.end_mark)", "prediction_line": "            self.marks.append(token.end_mark)", "ground_truth": "            if not self.check_token(BlockEntryToken, BlockEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if not self.check_token(BlockEndToken):", "prediction_line": "        if not self.check_token(BlockEndToken):", "ground_truth": "        if not self.check_token(BlockEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if not self.check_token(KeyToken, ValueToken, BlockEndToken):", "prediction_line": "            if not self.check_token(KeyToken, ValueToken, BlockEndToken):", "ground_truth": "            if not self.check_token(KeyToken, ValueToken, BlockEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if not first:", "prediction_line": "        if not first:", "ground_truth": "        if not self.check_token(FlowSequenceEndToken):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.state = self.states.pop()", "prediction_line": "        self.state = self.states.pop()", "ground_truth": "        self.state = self.parse_document_start", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.states.append(self.parse_flow_sequence_entry)", "prediction_line": "                self.states.append(self.parse_flow_sequence_entry)", "ground_truth": "                self.states.append(self.parse_flow_sequence_entry)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.parse_document_start()", "prediction_line": "            return self.parse_document_start()", "ground_truth": "            return self.parse_document_start()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self.states.append(self.parse_flow_mapping_value)", "prediction_line": "                    self.states.append(self.parse_flow_mapping_value)", "ground_truth": "                    self.states.append(self.parse_flow_mapping_value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.states.append(self.parse_flow_sequence_entry_mapping_value)", "prediction_line": "            self.states.append(self.parse_flow_sequence_entry_mapping_value)", "ground_truth": "            self.states.append(self.parse_flow_sequence_entry_mapping_value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.state = self.parse_flow_sequence_entry_mapping_end", "prediction_line": "                self.state = self.parse_flow_sequence_entry_mapping_end", "ground_truth": "                self.state = self.parse_flow_sequence_entry_mapping_end", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.parse_node(block=False)", "prediction_line": "        return self.parse_node(block=False)", "ground_truth": "        return self.parse_node()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.states.append(self.parse_flow_sequence_entry_mapping_end)", "prediction_line": "                self.states.append(self.parse_flow_sequence_entry_mapping_end)", "ground_truth": "                self.states.append(self.parse_flow_sequence_entry_mapping_end)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.state = self.parse_flow_sequence_entry", "prediction_line": "                self.state = self.parse_flow_sequence_entry", "ground_truth": "                self.state = self.parse_flow_sequence_entry_mapping_key", "line_class": "infile", "zero_context": true}
{"original_prediction": "                return self.parse_block_node_or_indentless_sequence()", "prediction_line": "                return self.parse_block_node_or_indentless_sequence()", "ground_truth": "                return self.parse_block_node_or_indentless_sequence()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.state = self.parse_document_content", "prediction_line": "            self.state = self.parse_document_content", "ground_truth": "            self.states.append(self.parse_document_end)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.state = self.parse_block_sequence_entry", "prediction_line": "        self.state = self.parse_block_sequence_entry", "ground_truth": "        return self.parse_block_sequence_entry()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.states.append(self.parse_block_mapping_value)", "prediction_line": "                self.states.append(self.parse_block_mapping_value)", "ground_truth": "                self.states.append(self.parse_block_mapping_value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Parse an unindented scalar.", "prediction_line": "        # Parse an unindented scalar.", "ground_truth": "        return self.parse_node(block=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.parse_block_mapping_key()", "prediction_line": "        return self.parse_block_mapping_key()", "ground_truth": "        return self.parse_block_mapping_key()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.state = self.parse_stream_start", "prediction_line": "        self.state = self.parse_stream_start", "ground_truth": "        self.state = self.parse_stream_start", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self.state = self.parse_flow_mapping_value", "prediction_line": "                    self.state = self.parse_flow_mapping_value", "ground_truth": "                    self.state = self.parse_flow_mapping_value", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.state = self.parse_indentless_sequence_entry", "prediction_line": "                self.state = self.parse_indentless_sequence_entry", "ground_truth": "                self.state = self.parse_indentless_sequence_entry", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.states.append(self.parse_implicit_document_start)", "prediction_line": "        self.states.append(self.parse_implicit_document_start)", "ground_truth": "        self.state = self.parse_implicit_document_start", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.process_empty_scalar(token.start_mark)", "prediction_line": "            return self.process_empty_scalar(token.start_mark)", "ground_truth": "            return self.process_empty_scalar(token.start_mark)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self.state = self.parse_flow_sequence_entry", "prediction_line": "                    self.state = self.parse_flow_sequence_entry", "ground_truth": "                    self.state = self.parse_flow_sequence_first_entry", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.state = self.parse_flow_mapping_key", "prediction_line": "        self.state = self.parse_flow_mapping_key", "ground_truth": "        self.state = self.parse_flow_mapping_key", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.state = self.parse_block_mapping_value", "prediction_line": "                self.state = self.parse_block_mapping_value", "ground_truth": "                self.state = self.parse_block_mapping_value", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.states.append(self.parse_flow_mapping_empty_value)", "prediction_line": "                self.states.append(self.parse_flow_mapping_empty_value)", "ground_truth": "                self.states.append(self.parse_flow_mapping_empty_value)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.states.append(self.parse_flow_mapping_key)", "prediction_line": "                self.states.append(self.parse_flow_mapping_key)", "ground_truth": "                self.states.append(self.parse_flow_mapping_key)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self.state = self.parse_block_mapping_first_key", "prediction_line": "                    self.state = self.parse_block_mapping_first_key", "ground_truth": "                    self.state = self.parse_block_mapping_first_key", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.states.append(self.parse_block_mapping_key)", "prediction_line": "                self.states.append(self.parse_block_mapping_key)", "ground_truth": "                self.states.append(self.parse_block_mapping_key)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self.state = self.parse_block_sequence_first_entry", "prediction_line": "                    self.state = self.parse_block_sequence_first_entry", "ground_truth": "                    self.state = self.parse_block_sequence_first_entry", "line_class": "infile", "zero_context": true}
{"original_prediction": "                return self.parse_block_node()", "prediction_line": "                return self.parse_block_node()", "ground_truth": "                return self.parse_block_node()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self.state = self.parse_flow_mapping_first_key", "prediction_line": "                    self.state = self.parse_flow_mapping_first_key", "ground_truth": "                    self.state = self.parse_flow_mapping_first_key", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.state = self.parse_document_content", "prediction_line": "            self.state = self.parse_document_content", "ground_truth": "            self.state = self.parse_document_content", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.state = self.parse_block_mapping_key", "prediction_line": "            self.state = self.parse_block_mapping_key", "ground_truth": "            self.state = self.parse_block_mapping_key", "line_class": "infile", "zero_context": true}
{"original_prediction": "                return self.parse_flow_node()", "prediction_line": "                return self.parse_flow_node()", "ground_truth": "                return self.parse_flow_node()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.states.append(self.parse_indentless_sequence_entry)", "prediction_line": "                self.states.append(self.parse_indentless_sequence_entry)", "ground_truth": "                self.states.append(self.parse_indentless_sequence_entry)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        token = self.get_token()", "prediction_line": "        token = self.get_token()", "ground_truth": "        self.state = self.parse_flow_sequence_entry", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    raise ParserError(", "prediction_line": "                    raise ParserError(", "ground_truth": "                    raise ParserError(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.parse_flow_mapping_key(first=True)", "prediction_line": "        return self.parse_flow_mapping_key(first=True)", "ground_truth": "        return self.parse_flow_mapping_key(first=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.parse_flow_sequence_entry()", "prediction_line": "        return self.parse_flow_sequence_entry()", "ground_truth": "        return self.parse_flow_sequence_entry(first=True)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.state = self.states.pop()", "prediction_line": "        self.state = self.states.pop()", "ground_truth": "        self.state = self.states.pop()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if token.value is not None:", "prediction_line": "                if token.value is not None:", "ground_truth": "                major, minor = token.value", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if major != 1:", "prediction_line": "                if major != 1:", "ground_truth": "                if major != 1:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            end_mark = token.end_mark", "prediction_line": "            end_mark = token.end_mark", "ground_truth": "            version, tags = self.process_directives()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.marks.pop()", "prediction_line": "        self.marks.pop()", "ground_truth": "        self.marks.pop()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                start_mark, end_mark, version, tags, explicit=True", "prediction_line": "                start_mark, end_mark, version, tags, explicit=True", "ground_truth": "                start_mark, end_mark, explicit=True, version=version, tags=tags", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return self.yaml_version, self.tag_handles", "prediction_line": "            return self.yaml_version, self.tag_handles", "ground_truth": "            value = self.yaml_version, self.tag_handles.copy()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "#                       | block_content", "prediction_line": "#                       | block_content", "ground_truth": "#                       | block_content", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# implicit_document ::= block_node DOCUMENT-END*", "prediction_line": "# implicit_document ::= block_node DOCUMENT-END*", "ground_truth": "# implicit_document ::= block_node DOCUMENT-END*", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# flow_sequence: { FLOW-SEQUENCE-START }", "prediction_line": "# flow_sequence: { FLOW-SEQUENCE-START }", "ground_truth": "# flow_sequence: { FLOW-SEQUENCE-START }", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# block_mapping: { BLOCK-MAPPING-START }", "prediction_line": "# block_mapping: { BLOCK-MAPPING-START }", "ground_truth": "# block_mapping: { BLOCK-MAPPING-START }", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    #                   (flow_mapping_entry FLOW-ENTRY)*", "prediction_line": "    #                   (flow_mapping_entry FLOW-ENTRY)*", "ground_truth": "    #                   (flow_mapping_entry FLOW-ENTRY)*", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    )\n                    self.state = self.parse_block_mapping_first_key", "prediction_line": "                    )", "ground_truth": "                    )", "line_class": "random", "zero_context": true}
{"original_prediction": "        return event", "prediction_line": "        return event", "ground_truth": "        return event", "line_class": "random", "zero_context": true}
{"original_prediction": "ValueToken, FlowEntryToken, FlowMappingEndToken):", "prediction_line": "ValueToken, FlowEntryToken, FlowMappingEndToken):", "ground_truth": "                    ValueToken, FlowEntryToken, FlowMappingEndToken", "line_class": "random", "zero_context": true}
{"original_prediction": "        self.state = None", "prediction_line": "        self.state = None", "ground_truth": "        self.state = None", "line_class": "random", "zero_context": true}
{"original_prediction": "                    event = SequenceStartEvent(anchor, tag, implicit, start_mark, end_mark)", "prediction_line": "                    event = SequenceStartEvent(anchor, tag, implicit, start_mark, end_mark)", "ground_truth": "                    event = SequenceStartEvent(", "line_class": "random", "zero_context": true}
{"original_prediction": "                    self.get_mark(),", "prediction_line": "                    self.get_mark(),", "ground_truth": "                    self.get_mark(),", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return TokenClass(value, start_mark, self.get_mark())", "prediction_line": "        return TokenClass(value, start_mark, self.get_mark())", "ground_truth": "        end_mark = self.get_mark()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        char = self.peek()", "prediction_line": "        char = self.peek()", "ground_truth": "        ch = self.peek()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self.forward()", "prediction_line": "            self.forward()", "ground_truth": "            if self.prefix(2) == \"\\r\\n\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "                self.forward(2)", "prediction_line": "                self.forward(2)", "ground_truth": "                self.forward(2)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                self.forward()", "prediction_line": "                self.forward()", "ground_truth": "                self.forward()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        start_mark = self.get_mark()", "prediction_line": "        start_mark = self.get_mark()", "ground_truth": "        start_mark = self.get_mark()", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    None, None, \"mapping keys are not allowed here\", self.get_mark()", "prediction_line": "                    None, None, \"mapping keys are not allowed here\", self.get_mark()", "ground_truth": "                    None, None, \"mapping keys are not allowed here\", self.get_mark()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self.indent = self.indents.pop()", "prediction_line": "            self.indent = self.indents.pop()", "ground_truth": "            mark = self.get_mark()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        while self.column == indent and self.peek() != \"\\0\":", "prediction_line": "        while self.column == indent and self.peek() != \"\\0\":", "ground_truth": "        while self.column == indent and self.peek() != \"\\0\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if self.peek() == \"\\n\":", "prediction_line": "            if self.peek() == \"\\n\":", "ground_truth": "            leading_non_space = self.peek() not in \" \\t\"", "line_class": "commited", "zero_context": true}
{"original_prediction": "            while self.peek(length) != \"\\0\" and self.peek(length) != \"\\n\":", "prediction_line": "            while self.peek(length) != \"\\0\" and self.peek(length) != \"\\n\":", "ground_truth": "            while self.peek(length) not in \"\\0\\r\\n\\x85\\u2028\\u2029\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if length == 0:", "prediction_line": "            if length == 0:", "ground_truth": "            chunks.append(self.prefix(length))", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    self.forward(length)", "prediction_line": "                    self.forward(length)", "ground_truth": "                    self.forward(length)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if not folded and leading_non_space and self.peek() == \" \":", "prediction_line": "            if not folded and leading_non_space and self.peek() == \" \":", "ground_truth": "            if self.column == indent and self.peek() != \"\\0\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    and breaks", "prediction_line": "                    and breaks", "ground_truth": "                    and self.peek() not in \" \\t\"", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ch = self.peek()", "prediction_line": "            ch = self.peek()", "ground_truth": "            while self.peek() == \" \":", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if self.peek() == \"\\0\":", "prediction_line": "            if self.peek() == \"\\0\":", "ground_truth": "            if self.peek() == \"#\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "            while self.peek() not in \"\\0\\r\\n\\x85\\u2028\\u2029\":", "prediction_line": "            while self.peek() not in \"\\0\\r\\n\\x85\\u2028\\u2029\":", "ground_truth": "            while self.peek() not in \"\\0\\r\\n\\x85\\u2028\\u2029\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "        while self.peek() == \" \":", "prediction_line": "        while self.peek() == \" \":", "ground_truth": "        while self.peek() in \" \\r\\n\\x85\\u2028\\u2029\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "            chunks.append(self.scan_line_break())", "prediction_line": "            chunks.append(self.scan_line_break())", "ground_truth": "            if self.peek() != \" \":", "line_class": "commited", "zero_context": true}
{"original_prediction": "            while self.column < indent and self.peek() == \" \":", "prediction_line": "            while self.column < indent and self.peek() == \" \":", "ground_truth": "            while self.column < indent and self.peek() == \" \":", "line_class": "commited", "zero_context": true}
{"original_prediction": "        while self.peek() in \"\\0\\r\\n\\x85\\u2028\\u2029\":", "prediction_line": "        while self.peek() in \"\\0\\r\\n\\x85\\u2028\\u2029\":", "ground_truth": "        while self.peek() in \"\\r\\n\\x85\\u2028\\u2029\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.forward()", "prediction_line": "        self.forward()", "ground_truth": "        quote = self.peek()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        chunks.extend(self.scan_flow_scalar_spaces(double, start_mark))", "prediction_line": "        chunks.extend(self.scan_flow_scalar_spaces(double, start_mark))", "ground_truth": "        while self.peek() != quote:", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if self.peek() == \"-\" and self.peek(1) == \"-\" and self.peek(2) == \"-\":", "prediction_line": "            if self.peek() == \"-\" and self.peek(1) == \"-\" and self.peek(2) == \"-\":", "ground_truth": "            if self.prefix(3) == \"---\" and self.peek(3) in \"\\0 \\t\\r\\n\\x85\\u2028\\u2029\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if self.prefix(3) == \"...\":", "prediction_line": "            if self.prefix(3) == \"...\":", "ground_truth": "            if self.prefix(3) == \"...\" and self.peek(3) in \"\\0 \\t\\r\\n\\x85\\u2028\\u2029\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "            return self.peek(1) in \"\\0 \\t\\r\\n\\x85\\u2028\\u2029\"", "prediction_line": "            return self.peek(1) in \"\\0 \\t\\r\\n\\x85\\u2028\\u2029\"", "ground_truth": "            return self.peek(1) in \"\\0 \\t\\r\\n\\x85\\u2028\\u2029\"", "line_class": "commited", "zero_context": true}
{"original_prediction": "            while self.peek(length) not in \"\\0\\r\\n\\x85\\u2028\\u2029\":", "prediction_line": "            while self.peek(length) not in \"\\0\\r\\n\\x85\\u2028\\u2029\":", "ground_truth": "            while self.peek(length) not in \"'\\\"\\\\\\0 \\t\\r\\n\\x85\\u2028\\u2029\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if ch == \"'\":", "prediction_line": "            if ch == \"'\":", "ground_truth": "            if not double and ch == \"'\" and self.peek(1) == \"'\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ch in \"-?:,[]{}#&*!|>'\\\"%@`\" and self.peek(1) not in \"\\0 \\t\\r\\n\\x85\\u2028\\u2029\"", "prediction_line": "            ch in \"-?:,[]{}#&*!|>'\\\"%@`\" and self.peek(1) not in \"\\0 \\t\\r\\n\\x85\\u2028\\u2029\"", "ground_truth": "            self.peek(1) not in \"\\0 \\t\\r\\n\\x85\\u2028\\u2029\"", "line_class": "commited", "zero_context": true}
{"original_prediction": "                ch = self.peek()", "prediction_line": "                ch = self.peek()", "ground_truth": "                if self.peek(k) not in \"0123456789ABCDEFabcdef\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "                                % (length, self.peek(k)),", "prediction_line": "                                % (length, self.peek(k)),", "ground_truth": "                                % (length, self.peek(k)),", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    chunks.append(chr(int(self.prefix(length), 16)))", "prediction_line": "                    chunks.append(chr(int(self.prefix(length), 16)))", "ground_truth": "                    code = int(self.prefix(length), 16)", "line_class": "commited", "zero_context": true}
{"original_prediction": "       while self.peek() in \"\\0 \\t\\r\\n\\x85\\u2028\\u2029\":", "prediction_line": "       while self.peek() in \"\\0 \\t\\r\\n\\x85\\u2028\\u2029\":", "ground_truth": "        if self.index == 0 and self.peek() == \"\\uFEFF\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "        while self.peek(length) in \" \\t\":", "prediction_line": "        while self.peek(length) in \" \\t\":", "ground_truth": "        while self.peek(length) in \" \\t\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if length:", "prediction_line": "        if length:", "ground_truth": "        whitespaces = self.prefix(length)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                ch = self.peek(length)", "prediction_line": "                ch = self.peek(length)", "ground_truth": "                ch = self.peek(length)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if self.peek() == \"\\0\":", "prediction_line": "            if self.peek() == \"\\0\":", "ground_truth": "            prefix = self.prefix(3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if prefix == \"\\0\\0\\0\":", "prediction_line": "            if prefix == \"\\0\\0\\0\":", "ground_truth": "            if (prefix == \"---\" or prefix == \"...\") and self.peek(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        value = self.prefix(length)", "prediction_line": "        value = self.prefix(length)", "ground_truth": "        value = self.prefix(length)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            chunks.extend(self.scan_line_break())", "prediction_line": "            chunks.extend(self.scan_line_break())", "ground_truth": "            while self.peek() in \" \\t\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ch = self.peek()", "prediction_line": "            ch = self.peek()", "ground_truth": "            if self.peek() in \"\\r\\n\\x85\\u2028\\u2029\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if self.peek() != \".\":", "prediction_line": "        if self.peek() != \".\":", "ground_truth": "        if self.peek() != \".\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "                \"expected a digit or '.', but found %r\" % self.peek(),", "prediction_line": "                \"expected a digit or '.', but found %r\" % self.peek(),", "ground_truth": "                \"expected a digit or '.', but found %r\" % self.peek(),", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if self.peek() != \"\\0\":", "prediction_line": "        if self.peek() != \"\\0\":", "ground_truth": "        if self.peek() not in \"\\0 \\r\\n\\x85\\u2028\\u2029\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "                \"expected a digit or the end of the %r directive, but found %r\"", "prediction_line": "                \"expected a digit or the end of the %r directive, but found %r\"", "ground_truth": "                \"expected a digit or ' ', but found %r\" % self.peek(),", "line_class": "commited", "zero_context": true}
{"original_prediction": "                        and self.flow_level", "prediction_line": "                        and self.flow_level", "ground_truth": "                        and self.peek(length + 1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        ch = self.peek(length)", "prediction_line": "        ch = self.peek(length)", "ground_truth": "        while \"0\" <= self.peek(length) <= \"9\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "        value = int(self.prefix(length))", "prediction_line": "        value = int(self.prefix(length))", "ground_truth": "        value = int(self.prefix(length))", "line_class": "commited", "zero_context": true}
{"original_prediction": "                and self.flow_level", "prediction_line": "                and self.flow_level", "ground_truth": "                or self.peek() == \"#\"", "line_class": "commited", "zero_context": true}
{"original_prediction": "        prefix = self.scan_tag_directive_prefix(start_mark)", "prediction_line": "        prefix = self.scan_tag_directive_prefix(start_mark)", "ground_truth": "        prefix = self.scan_tag_directive_prefix(start_mark)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return (handle, prefix)", "prediction_line": "        return (handle, prefix)", "ground_truth": "        return (handle, prefix)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        while self.peek(length) in \" \\t\":", "prediction_line": "        while self.peek(length) in \" \\t\":", "ground_truth": "        while self.peek(length) in \" \":", "line_class": "commited", "zero_context": true}
{"original_prediction": "                breaks.append(self.scan_line_break())", "prediction_line": "                breaks.append(self.scan_line_break())", "ground_truth": "                if self.peek() == \" \":", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.forward()", "prediction_line": "        self.forward()", "ground_truth": "        self.forward(3)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.forward()", "prediction_line": "        self.forward()", "ground_truth": "        indicator = self.peek()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        indicator = self.peek()", "prediction_line": "        indicator = self.peek()", "ground_truth": "        ch = self.peek(1)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            ch = self.peek()", "prediction_line": "            ch = self.peek()", "ground_truth": "            if self.peek() != \">\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    \"expected '>', but found %r\" % self.peek(),", "prediction_line": "                    \"expected '>', but found %r\" % self.peek(),", "ground_truth": "                    \"expected '>', but found %r\" % self.peek(),", "line_class": "commited", "zero_context": true}
{"original_prediction": "        while self.peek() == \"%\":", "prediction_line": "        while self.peek() == \"%\":", "ground_truth": "        while self.peek() == \"%\":", "line_class": "commited", "zero_context": true}
{"original_prediction": "                        % self.peek(k),", "prediction_line": "                        % self.peek(k),", "ground_truth": "                        % self.peek(k),", "line_class": "commited", "zero_context": true}
{"original_prediction": "            codes.append(int(self.prefix(2), 16))", "prediction_line": "            codes.append(int(self.prefix(2), 16))", "ground_truth": "            codes.append(int(self.prefix(2), 16))", "line_class": "commited", "zero_context": true}
{"original_prediction": "                    \"while scanning a block\",", "prediction_line": "                    \"while scanning a block\",", "ground_truth": "                    None, None, \"sequence entries are not allowed here\", self.get_mark()", "line_class": "commited", "zero_context": true}
{"original_prediction": "        self.index = index", "prediction_line": "        self.index = index", "ground_truth": "        self.index = index", "line_class": "common", "zero_context": true}
{"original_prediction": "            if key.line < self.tokens_taken or key.index + 1024 < self.tokens_taken:", "prediction_line": "            if key.line < self.tokens_taken or key.index + 1024 < self.tokens_taken:", "ground_truth": "            if key.line != self.line or self.index - key.index > 1024:", "line_class": "common", "zero_context": true}
{"original_prediction": "                self.index,", "prediction_line": "                self.index,", "ground_truth": "                self.index,", "line_class": "common", "zero_context": true}
{"original_prediction": "        if ch == \"?\" and self.check_key():", "prediction_line": "        if ch == \"?\" and self.check_key():", "ground_truth": "        if ch == \"?\" and self.check_key():", "line_class": "infile", "zero_context": true}
{"original_prediction": "            value = self.scan_yaml_directive_value(start_mark)", "prediction_line": "            value = self.scan_yaml_directive_value(start_mark)", "ground_truth": "            value = self.scan_yaml_directive_value(start_mark)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.fetch_plain()", "prediction_line": "            return self.fetch_plain()", "ground_truth": "            return self.fetch_plain()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            spaces = []", "prediction_line": "            spaces = []", "ground_truth": "            spaces = self.scan_plain_spaces(indent, start_mark)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if ch == \"-\":", "prediction_line": "        if ch == \"-\":", "ground_truth": "        if ch == \"-\" and self.check_block_entry():", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.fetch_tag()", "prediction_line": "            return self.fetch_tag()", "ground_truth": "            return self.fetch_tag()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self.possible_simple_keys:", "prediction_line": "        if self.possible_simple_keys:", "ground_truth": "        if self.next_possible_simple_key() == self.tokens_taken:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.tokens.append(self.scan_plain())", "prediction_line": "        self.tokens.append(self.scan_plain())", "ground_truth": "        self.tokens.append(self.scan_plain())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        ch = self.peek()", "prediction_line": "        ch = self.peek()", "ground_truth": "        value = self.scan_tag_handle(\"directive\", start_mark)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.fetch_flow_sequence_end()", "prediction_line": "            return self.fetch_flow_sequence_end()", "ground_truth": "            return self.fetch_flow_sequence_end()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.unwind_indent(-1)", "prediction_line": "        self.unwind_indent(-1)", "ground_truth": "        self.unwind_indent(-1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            suffix = self.scan_tag_uri(\"tag\", start_mark)", "prediction_line": "            suffix = self.scan_tag_uri(\"tag\", start_mark)", "ground_truth": "            suffix = self.scan_tag_uri(\"tag\", start_mark)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.fetch_flow_entry()", "prediction_line": "            return self.fetch_flow_entry()", "ground_truth": "            return self.fetch_flow_entry()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return\n\n        # Is it the document start?", "prediction_line": "            return", "ground_truth": "            return self.fetch_directive()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.possible_simple_keys[self.flow_level] = SimpleKey(", "prediction_line": "            self.possible_simple_keys[self.flow_level] = SimpleKey(", "ground_truth": "            key = SimpleKey(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.fetch_flow_collection_end(FlowMappingEndToken)", "prediction_line": "        self.fetch_flow_collection_end(FlowMappingEndToken)", "ground_truth": "        self.fetch_flow_collection_end(FlowMappingEndToken)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        name = self.scan_directive()", "prediction_line": "        name = self.scan_directive()", "ground_truth": "        self.tokens.append(self.scan_directive())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Set the current indentation to -1.", "prediction_line": "        # Set the current indentation to -1.", "ground_truth": "        self.fetch_flow_collection_start(FlowSequenceStartToken)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.fetch_value()", "prediction_line": "            return self.fetch_value()", "ground_truth": "            return self.fetch_value()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        # Set the current indentation to -1.", "prediction_line": "        # Set the current indentation to -1.", "ground_truth": "        self.fetch_document_indicator(DocumentStartToken)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.fetch_stream_start()", "prediction_line": "        self.fetch_stream_start()", "ground_truth": "        self.fetch_stream_start()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                self.add_indent(key.column)", "prediction_line": "                self.add_indent(key.column)", "ground_truth": "                if self.add_indent(key.column):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if ch == \":\" and self.check_value():", "prediction_line": "        if ch == \":\" and self.check_value():", "ground_truth": "        if ch == \":\" and self.check_value():", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.fetch_block_scalar(style=\">\")", "prediction_line": "        self.fetch_block_scalar(style=\">\")", "ground_truth": "        self.fetch_block_scalar(style=\">\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.fetch_flow_collection_start(FlowMappingStartToken)", "prediction_line": "        self.fetch_flow_collection_start(FlowMappingStartToken)", "ground_truth": "        self.fetch_flow_collection_start(FlowMappingStartToken)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if ch == \"%\":", "prediction_line": "        if ch == \"%\":", "ground_truth": "        if ch == \"%\" and self.check_directive():", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.fetch_more_tokens()", "prediction_line": "            self.fetch_more_tokens()", "ground_truth": "            self.fetch_more_tokens()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            breaks, end_mark = self.scan_block_scalar_breaks(indent)", "prediction_line": "            breaks, end_mark = self.scan_block_scalar_breaks(indent)", "ground_truth": "            breaks, end_mark = self.scan_block_scalar_breaks(indent)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.tokens.append(self.scan_anchor(AliasToken))", "prediction_line": "        self.tokens.append(self.scan_anchor(AliasToken))", "ground_truth": "        self.tokens.append(self.scan_anchor(AliasToken))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.tokens.append(self.scan_flow_scalar(style))", "prediction_line": "        self.tokens.append(self.scan_flow_scalar(style))", "ground_truth": "        self.tokens.append(self.scan_flow_scalar(style))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.fetch_key()", "prediction_line": "            return self.fetch_key()", "ground_truth": "            return self.fetch_key()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                chunks.append(self.scan_uri_escapes(name, start_mark))", "prediction_line": "                chunks.append(self.scan_uri_escapes(name, start_mark))", "ground_truth": "                chunks.append(self.scan_uri_escapes(name, start_mark))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.fetch_block_entry()", "prediction_line": "            return self.fetch_block_entry()", "ground_truth": "            return self.fetch_block_entry()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self.fetch_flow_mapping_end()", "prediction_line": "            return self.fetch_flow_mapping_end()", "ground_truth": "            return self.fetch_flow_mapping_end()", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self.scan_line_break()", "prediction_line": "                    self.scan_line_break()", "ground_truth": "                    self.scan_line_break()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.tokens.append(self.scan_tag())", "prediction_line": "        self.tokens.append(self.scan_tag())", "ground_truth": "        self.tokens.append(self.scan_tag())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        handle = self.scan_tag_handle(start_mark)", "prediction_line": "        handle = self.scan_tag_handle(start_mark)", "ground_truth": "        handle = self.scan_tag_directive_handle(start_mark)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.scan_to_next_token()", "prediction_line": "        self.scan_to_next_token()", "ground_truth": "        self.scan_to_next_token()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        minor = self.scan_yaml_directive_number(start_mark)", "prediction_line": "        minor = self.scan_yaml_directive_number(start_mark)", "ground_truth": "        minor = self.scan_yaml_directive_number(start_mark)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return major, minor", "prediction_line": "        return major, minor", "ground_truth": "        return (major, minor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.indent = self.indents.pop()", "prediction_line": "            self.indent = self.indents.pop()", "ground_truth": "            self.indent = self.indents.pop()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            return self.tokens.pop(0)", "prediction_line": "            return self.tokens.pop(0)", "ground_truth": "            return self.tokens.pop(0)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        major = self.scan_yaml_directive_number(start_mark)", "prediction_line": "        major = self.scan_yaml_directive_number(start_mark)", "ground_truth": "        major = self.scan_yaml_directive_number(start_mark)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "is\n        # `flow_level`; there can be no more than one possible simple key for", "prediction_line": "is", "ground_truth": "        # is `flow_level`; there can be no more that one possible simple key", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# ANCHOR(value)", "prediction_line": "# ANCHOR(value)", "ground_truth": "# ANCHOR(value)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # Add BLOCK-ENTRY.", "prediction_line": "        # Add BLOCK-ENTRY.", "ground_truth": "        # Add BLOCK-ENTRY.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# DOCUMENT-END", "prediction_line": "# DOCUMENT-END", "ground_truth": "# DOCUMENT-END", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        while self.indent > column:", "prediction_line": "        while self.indent > column:", "ground_truth": "        while self.indent > column:", "line_class": "random", "zero_context": true}
{"original_prediction": "                self.tokens.append(BlockMappingStartToken(mark, mark))", "prediction_line": "                self.tokens.append(BlockMappingStartToken(mark, mark))", "ground_truth": "                self.tokens.append(BlockMappingStartToken(mark, mark))", "line_class": "random", "zero_context": true}
{"original_prediction": "                    )\n                self.possible_simple_keys.pop(level)", "prediction_line": "                    )", "ground_truth": "                    )", "line_class": "random", "zero_context": true}
{"original_prediction": "        else:\n            return \"\"", "prediction_line": "        else:", "ground_truth": "        return \"\"", "line_class": "random", "zero_context": true}
{"original_prediction": "                \"while scanning a %YAML directive\",", "prediction_line": "                \"while scanning a %YAML directive\",", "ground_truth": "                \"while scanning a directive\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                (?P<post_l>post|rev|r)", "prediction_line": "                (?P<post_l>post|rev|r)", "ground_truth": "                (?P<post_l>post|rev|r)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            post=_parse_letter_version(match.group(\"post_l\"), match.group(\"post_n1\") or match.group(\"post_n2\")),", "prediction_line": "            post=_parse_letter_version(match.group(\"post_l\"), match.group(\"post_n1\") or match.group(\"post_n2\")),", "ground_truth": "            post=_parse_letter_version(", "line_class": "commited", "zero_context": true}
{"original_prediction": "    if post is None:", "prediction_line": "    if post is None:", "ground_truth": "    if post is None:", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _post = post", "prediction_line": "        _post = post", "ground_truth": "        _post = post", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if self.post is not None:", "prediction_line": "        if self.post is not None:", "ground_truth": "        if self.post is not None:", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if self.post[1] == 0:", "prediction_line": "            if self.post[1] == 0:", "ground_truth": "            parts.append(\".post{0}\".format(self.post))", "line_class": "commited", "zero_context": true}
{"original_prediction": "        _post = self._version.post  # type: Optional[int]", "prediction_line": "        _post = self._version.post  # type: Optional[int]", "ground_truth": "        return self._version.post[1] if self._version.post else None", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self._version.post,", "prediction_line": "            self._version.post,", "ground_truth": "            self._version.post,", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return self.post is not None", "prediction_line": "        return self.post is not None", "ground_truth": "        return self.post is not None", "line_class": "commited", "zero_context": true}
{"original_prediction": "    if not pre and not post and dev and dev[1] == 0:", "prediction_line": "    if not pre and not post and dev and dev[1] == 0:", "ground_truth": "    if pre is None and post is None and dev is not None:", "line_class": "commited", "zero_context": true}
{"original_prediction": "        (?P<post>                                         # post release", "prediction_line": "        (?P<post>                                         # post release", "ground_truth": "        (?P<post>                                         # post release", "line_class": "commited", "zero_context": true}
{"original_prediction": "        part = _legacy_version_replacement_map.get(part, part)", "prediction_line": "        part = _legacy_version_replacement_map.get(part, part)", "ground_truth": "        part = _legacy_version_replacement_map.get(part, part)", "line_class": "common", "zero_context": true}
{"original_prediction": "NegativeInfinity = NegativeInfinityType()", "prediction_line": "NegativeInfinity = NegativeInfinityType()", "ground_truth": "NegativeInfinity = NegativeInfinityType()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return (\n        -1,", "prediction_line": "    return (", "ground_truth": "    epoch = -1", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if dev is None:", "prediction_line": "    if dev is None:", "ground_truth": "    if dev is None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            (?P<pre_l>(a|b|c|rc|alpha|beta|pre|preview))", "prediction_line": "            (?P<pre_l>(a|b|c|rc|alpha|beta|pre|preview))", "ground_truth": "            (?P<pre_l>(a|b|c|rc|alpha|beta|pre|preview))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._key = _cmpkey(", "prediction_line": "        self._key = _cmpkey(", "ground_truth": "        self._key = _cmpkey(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        _dev = dev", "prediction_line": "        _dev = dev", "ground_truth": "        _dev = dev", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.release[2] if len(self.release) >= 3 else 0", "prediction_line": "        return self.release[2] if len(self.release) >= 3 else 0", "ground_truth": "        return self.release[2] if len(self.release) >= 3 else 0", "line_class": "infile", "zero_context": true}
{"original_prediction": "            parts.append(\"\".join(str(x) for x in self.pre))", "prediction_line": "            parts.append(\"\".join(str(x) for x in self.pre))", "ground_truth": "            parts.append(\"\".join(str(x) for x in self.pre))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self.local is not None:", "prediction_line": "        if self.local is not None:", "ground_truth": "        if self.local is not None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return epoch, _release, _pre, _post, _dev, _local", "prediction_line": "    return epoch, _release, _pre, _post, _dev, _local", "ground_truth": "    return epoch, _release, _pre, _post, _dev, _local", "line_class": "infile", "zero_context": true}
{"original_prediction": "            release=tuple(", "prediction_line": "            release=tuple(", "ground_truth": "            release=tuple(int(i) for i in match.group(\"release\").split(\".\")),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            dev=_parse_letter_version(match.group(\"dev_l\"), match.group(\"dev_n\")),", "prediction_line": "            dev=_parse_letter_version(match.group(\"dev_l\"), match.group(\"dev_n\")),", "ground_truth": "            dev=_parse_letter_version(match.group(\"dev_l\"), match.group(\"dev_n\")),", "line_class": "infile", "zero_context": true}
{"original_prediction": "    except InvalidVersion:", "prediction_line": "    except InvalidVersion:", "ground_truth": "    except InvalidVersion:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        reversed(list(itertools.dropwhile(lambda x: x == 0, reversed(release))))", "prediction_line": "        reversed(list(itertools.dropwhile(lambda x: x == 0, reversed(release))))", "ground_truth": "        reversed(list(itertools.dropwhile(lambda x: x == 0, reversed(release))))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        parts.append(\".\".join(str(x) for x in self.release))", "prediction_line": "        parts.append(\".\".join(str(x) for x in self.release))", "ground_truth": "        parts.append(\".\".join(str(x) for x in self.release))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self._version.pre is not None", "prediction_line": "        return self._version.pre is not None", "ground_truth": "        return self.dev is not None or self.pre is not None", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if local is not None:", "prediction_line": "    if local is not None:", "ground_truth": "    if local is not None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        (?:(?P<epoch>[0-9]+)!)?                           # epoch", "prediction_line": "        (?:(?P<epoch>[0-9]+)!)?                           # epoch", "ground_truth": "        (?:(?P<epoch>[0-9]+)!)?                           # epoch", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.release[1] if len(self.release) >= 2 else 0", "prediction_line": "        return self.release[1] if len(self.release) >= 2 else 0", "ground_truth": "        return self.release[1] if len(self.release) >= 2 else 0", "line_class": "infile", "zero_context": true}
{"original_prediction": "    (?:\\+(?P<local>[a-z0-9]+(?:[-_\\.][a-z0-9]+)*))?       # local version", "prediction_line": "    (?:\\+(?P<local>[a-z0-9]+(?:[-_\\.][a-z0-9]+)*))?       # local version", "ground_truth": "    (?:\\+(?P<local>[a-z0-9]+(?:[-_\\.][a-z0-9]+)*))?       # local version", "line_class": "infile", "zero_context": true}
{"original_prediction": "Infinity = InfinityType()", "prediction_line": "Infinity = InfinityType()", "ground_truth": "Infinity = InfinityType()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            _normalize_version_part(part, is_local=True) for part in local", "prediction_line": "            _normalize_version_part(part, is_local=True) for part in local", "ground_truth": "            (i, \"\") if isinstance(i, int) else (NegativeInfinity, i) for i in local", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.release[0]", "prediction_line": "        return self.release[0]", "ground_truth": "        return self.release[0] if len(self.release) >= 1 else 0", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self._version.epoch != 0:", "prediction_line": "        if self._version.epoch != 0:", "ground_truth": "        if self.epoch != 0:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.dev is not None", "prediction_line": "        return self.dev is not None", "ground_truth": "        return self.dev is not None", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self._version.dev[1] if self._version.dev else None", "prediction_line": "        return self._version.dev[1] if self._version.dev else None", "ground_truth": "        return self._version.dev[1] if self._version.dev else None", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return Version(version)", "prediction_line": "        return Version(version)", "ground_truth": "        return Version(version)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    elif pre is None:", "prediction_line": "    elif pre is None:", "ground_truth": "    elif pre is None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            local=_parse_local_version(match.group(\"local\")),", "prediction_line": "            local=_parse_local_version(match.group(\"local\")),", "ground_truth": "            local=_parse_local_version(match.group(\"local\")),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            (?P<dev_l>dev)", "prediction_line": "            (?P<dev_l>dev)", "ground_truth": "            (?P<dev_l>dev)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._version.dev,", "prediction_line": "            self._version.dev,", "ground_truth": "            self._version.dev,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self.dev is not None:", "prediction_line": "        if self.dev is not None:", "ground_truth": "        if self.dev is not None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            epoch=int(match.group(\"epoch\")) if match.group(\"epoch\") else 0,", "prediction_line": "            epoch=int(match.group(\"epoch\")) if match.group(\"epoch\") else 0,", "ground_truth": "            epoch=int(match.group(\"epoch\")) if match.group(\"epoch\") else 0,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            parts.append(\".dev{0}\".format(self.dev))", "prediction_line": "            parts.append(\".dev{0}\".format(self.dev))", "ground_truth": "            parts.append(\".dev{0}\".format(self.dev))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        (?P<release>[0-9]+(?:\\.[0-9]+)*)                 # release segment", "prediction_line": "        (?P<release>[0-9]+(?:\\.[0-9]+)*)                 # release segment", "ground_truth": "        (?P<release>[0-9]+(?:\\.[0-9]+)*)                  # release segment", "line_class": "infile", "zero_context": true}
{"original_prediction": "            pre=self._parse_letter_version(match.group(\"pre_l\")),", "prediction_line": "            pre=self._parse_letter_version(match.group(\"pre_l\")),", "ground_truth": "            pre=_parse_letter_version(match.group(\"pre_l\"), match.group(\"pre_n\")),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._version.local,", "prediction_line": "            self._version.local,", "ground_truth": "            self._version.local,", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Versions without a local segment should sort before those with one.", "prediction_line": "    # Versions without a local segment should sort before those with one.", "ground_truth": "    if local is None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # leading zeros, then reverse it back.", "prediction_line": "    # leading zeros, then reverse it back.", "ground_truth": "    # leading zeros until we come to something non zero, then take the rest", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def minor(self):", "prediction_line": "    def minor(self):", "ground_truth": "    def minor(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # Post-release", "prediction_line": "        # Post-release", "ground_truth": "        # Post-release", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __ge__(self, other):", "prediction_line": "    def __ge__(self, other):", "ground_truth": "    def __ge__(self, other):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # type: () -> Optional[str]", "prediction_line": "        # type: () -> Optional[str]", "ground_truth": "        # type: () -> Optional[str]", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        return False", "prediction_line": "        return False", "ground_truth": "        return False", "line_class": "random", "zero_context": true}
{"original_prediction": "        if number is None:", "prediction_line": "        if number is None:", "ground_truth": "        if number is None:", "line_class": "random", "zero_context": true}
{"original_prediction": "    @property\n    def public(self):", "prediction_line": "    @property", "ground_truth": "    @property", "line_class": "random", "zero_context": true}
{"original_prediction": "        # Pre-release", "prediction_line": "        # Pre-release", "ground_truth": "        return \"\".join(parts)", "line_class": "random", "zero_context": true}
{"original_prediction": "            return NotImplemented", "prediction_line": "            return NotImplemented", "ground_truth": "            return NotImplemented", "line_class": "random", "zero_context": true}
{"original_prediction": "        end = start", "prediction_line": "        end = start", "ground_truth": "        end = f\"{start}_end\"", "line_class": "common", "zero_context": true}
{"original_prediction": "            self.log_to_report(*report)", "prediction_line": "            self.log_to_report(*report)", "ground_truth": "            filename = f\"{self.index}-{report[0]}\"", "line_class": "common", "zero_context": true}
{"original_prediction": "            self.log_to_report(filename, *report)", "prediction_line": "            self.log_to_report(filename, *report)", "ground_truth": "            start = report[1]", "line_class": "common", "zero_context": true}
{"original_prediction": "            if line.strip() == start:", "prediction_line": "            if line.strip() == start:", "ground_truth": "            if line.strip() == start:", "line_class": "common", "zero_context": true}
{"original_prediction": "    def __str__(self):", "prediction_line": "    def __str__(self):", "ground_truth": "        if self.is_valid():", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.path = os.path.join(self.path, self.filename)", "prediction_line": "            self.path = os.path.join(self.path, self.filename)", "ground_truth": "            debug(f\"Resolved {kind}, {step}, {filename} to {self.path}\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.log_to_report(filename, start, end)", "prediction_line": "            self.log_to_report(filename, start, end)", "ground_truth": "            self.log_to_report(filename, start, end)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            debug(f\"Could not resolve {kind}, {step}, {filename}\")", "prediction_line": "            debug(f\"Could not resolve {kind}, {step}, {filename}\")", "ground_truth": "            debug(f\"Failed to resolve {kind}, {step}, {filename}\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        sta_spef_log.generate_reports(", "prediction_line": "        sta_spef_log.generate_reports(", "ground_truth": "        sta_spef_log.generate_reports(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if self.is_valid():", "prediction_line": "        if self.is_valid():", "ground_truth": "        if not self.is_valid():", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return os.path.exists(os.path.join(self.pathname, f\"{self.filename}.logtoreport\"))", "prediction_line": "        return os.path.exists(os.path.join(self.pathname, f\"{self.filename}.logtoreport\"))", "ground_truth": "        return self.is_valid() and os.path.getsize(self.path) > 10 ", "line_class": "infile", "zero_context": true}
{"original_prediction": "        os.makedirs(os.path.dirname(report_path), exist_ok=True)", "prediction_line": "        os.makedirs(os.path.dirname(report_path), exist_ok=True)", "ground_truth": "        if not self.is_logtoreport_valid():", "line_class": "infile", "zero_context": true}
{"original_prediction": "        sta_spef_multi_corner_log.generate_reports(", "prediction_line": "        sta_spef_multi_corner_log.generate_reports(", "ground_truth": "        sta_spef_multi_corner_log.generate_reports(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        parse_to_report(self.path, report_path, start, end)", "prediction_line": "        parse_to_report(self.path, report_path, start, end)", "ground_truth": "        parse_to_report(self.path, report_path, start, end)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        routing_report = Artifact(rp, \"reports\", \"routing\", \"fastroute.rpt\")", "prediction_line": "        routing_report = Artifact(rp, \"reports\", \"routing\", \"fastroute.rpt\")", "ground_truth": "        routing_log.generate_reports(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        routing_sta_log = Artifact(rp, \"logs\", \"routing\", \"fastroute_sta.log\")", "prediction_line": "        routing_sta_log = Artifact(rp, \"logs\", \"routing\", \"fastroute_sta.log\")", "ground_truth": "        sta_spef_log = Artifact(rp, \"logs\", \"routing\", \"spef_extraction_sta\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self.run_path = os.path.join(self.current_directory, \"..\", \"..\", \"..\", \"runs\", self.design_name, self.tag)", "prediction_line": "            self.run_path = os.path.join(self.current_directory, \"..\", \"..\", \"..\", \"runs\", self.design_name, self.tag)", "ground_truth": "            run_path=get_run_path(design=design_path, tag=tag)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                f.write(line + \"\\n\")", "prediction_line": "                f.write(line + \"\\n\")", "ground_truth": "                f.write(line + \"\\n\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            raise Exception(f\"Did not find {start} in {input_log}\")", "prediction_line": "            raise Exception(f\"Did not find {start} in {input_log}\")", "ground_truth": "            f.write(\"SKIPPED!\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        sta_log = Artifact(rp, \"logs\", \"routing\", \"sta\")", "prediction_line": "        sta_log = Artifact(rp, \"logs\", \"routing\", \"sta\")", "ground_truth": "        sta_spef_multi_corner_log = Artifact(rp, \"logs\", \"routing\", \"spef_extraction_multi_corner_sta\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                f.write(\"SKIPPED!\")", "prediction_line": "                f.write(\"SKIPPED!\")", "ground_truth": "                f.write(f\"{self.step}:{self.filename} not found or empty.\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.raw_report = Artifact(self.run_path, \"logs\", \"report\", \"raw.log\")", "prediction_line": "        self.raw_report = Artifact(self.run_path, \"logs\", \"report\", \"raw.log\")", "ground_truth": "        rp = self.run_path", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       self.raw_report = Artifact(rp, \"logs\", \"report\", \"raw.log\")", "prediction_line": "       self.raw_report = Artifact(rp, \"logs\", \"report\", \"raw.log\")", "ground_truth": "        routing_log = Artifact(rp, \"logs\", \"routing\", \"fastroute.log\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       self.find_by_partial_match = find_by_partial_match", "prediction_line": "       self.find_by_partial_match = find_by_partial_match", "ground_truth": "        self.index, self.path = get_name(self.pathname, self.filename, find_by_partial_match)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    :param input_log: The input log file.", "prediction_line": "    :param input_log: The input log file.", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def get_file_name(", "prediction_line": "def get_file_name(", "ground_truth": "def parse_to_report(input_log: str, output_report: str, start: str, end: Optional[str] = None):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    END_MARKER", "prediction_line": "    END_MARKER", "ground_truth": "    END_MARKER", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "# Licensed under the Apache License, Version 2.0 (the \"License\");", "prediction_line": "# Licensed under the Apache License, Version 2.0 (the \"License\");", "ground_truth": "# Licensed under the Apache License, Version 2.0 (the \"License\");", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        )\n\n        routing_sta_log = Artifact(rp, \"logs\", \"routing\", \"fastroute_sta.log\")", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "        'routing_layer2_pct',", "prediction_line": "        'routing_layer2_pct',", "ground_truth": "        'routing_layer2_pct',", "line_class": "random", "zero_context": true}
{"original_prediction": "        'lvs_total_warnings',", "prediction_line": "        'lvs_total_warnings',", "ground_truth": "        'klayout_violations',", "line_class": "random", "zero_context": true}
{"original_prediction": "            (\"spef_extraction_sta.wns.rpt\", \"wns_report\"),", "prediction_line": "            (\"spef_extraction_sta.wns.rpt\", \"wns_report\"),", "ground_truth": "            (\"spef_extraction_sta.min.rpt\", \"min_report\"),", "line_class": "random", "zero_context": true}
{"original_prediction": "        'XNOR',", "prediction_line": "        'XNOR',", "ground_truth": "        'XNOR',", "line_class": "random", "zero_context": true}
{"original_prediction": "    main()", "prediction_line": "    main()", "ground_truth": "    main()", "line_class": "commited", "zero_context": true}
{"original_prediction": "", "prediction_line": "", "ground_truth": "        opt = read_optional_header(f, coff)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        sections = read_sections(f, coff)", "prediction_line": "        sections = read_sections(f, coff)", "ground_truth": "        sections = read_sections(f, coff)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        coff = read_coff_header(f)", "prediction_line": "        coff = read_coff_header(f)", "ground_truth": "        coff = read_coff_header(f)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return list(iter_sections(f, coff))", "prediction_line": "    return list(iter_sections(f, coff))", "ground_truth": "    return list(iter_sections(f, coff))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    return CoffHeader(*struct.unpack(CoffFormat, f.read(struct.calcsize(CoffFormat))))", "prediction_line": "    return CoffHeader(*struct.unpack(CoffFormat, f.read(struct.calcsize(CoffFormat))))", "ground_truth": "    buf = f.read(struct.calcsize(\"I\"))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if len(buf) != 4:", "prediction_line": "    if len(buf) != 4:", "ground_truth": "    (s, ) = struct.unpack_from(\"I\", buf)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return OptionalHeader._make(struct.unpack_from(OptionalFormat, buf))", "prediction_line": "    return OptionalHeader._make(struct.unpack_from(OptionalFormat, buf))", "ground_truth": "    opt = OptionalHeader._make(struct.unpack_from(OptionalFormat, buf))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   buf = f.read(struct.calcsize(CoffFormat))", "prediction_line": "   buf = f.read(struct.calcsize(CoffFormat))", "ground_truth": "    buf = f.read(struct.calcsize(CoffFormat))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    (\n        Signature,", "prediction_line": "    (", "ground_truth": "    coff = CoffHeader._make(struct.unpack_from(CoffFormat, buf))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        buf = f.read(struct.calcsize(SectionFormat))", "prediction_line": "        buf = f.read(struct.calcsize(SectionFormat))", "ground_truth": "        buf = f.read(struct.calcsize(SectionFormat))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        yield SectionHeader._make(struct.unpack_from(SectionFormat, buf))", "prediction_line": "        yield SectionHeader._make(struct.unpack_from(SectionFormat, buf))", "ground_truth": "        yield SectionHeader._make(struct.unpack_from(SectionFormat, buf))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    buf = f.read(struct.calcsize(OptionalFormat))", "prediction_line": "    buf = f.read(struct.calcsize(OptionalFormat))", "ground_truth": "    buf = f.read(coff.SizeOfOptionalHeader)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    return OptionalHeader._make(struct.unpack_from(OptionalFormat, buf))", "prediction_line": "    return OptionalHeader._make(struct.unpack_from(OptionalFormat, buf))", "ground_truth": "    sz = struct.calcsize(OptionalFormat)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with open(sys.argv[1], \"rb\") as f:", "prediction_line": "    with open(sys.argv[1], \"rb\") as f:", "ground_truth": "    with open(sys.argv[1], \"rb\") as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "OptionalHeaderFormat = \"HHHHHHHHHHHHHHHH\"", "prediction_line": "OptionalHeaderFormat = \"HHHHHHHHHHHHHHHH\"", "ground_truth": "class SectionFlags(enum.Flag):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    # that identifies the file as a PE file. [...] The signature is \"PE\\0\\0\".\"", "prediction_line": "    # that identifies the file as a PE file. [...] The signature is \"PE\\0\\0\".\"", "ground_truth": "    # that identifies the file as a PE format image file. This signature is", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    If `coff` is passed in, the file position must point directly after the Optional", "prediction_line": "    If `coff` is passed in, the file position must point directly after the Optional", "ground_truth": "    Like `iter_sections` but returns a list of `SectionHeader` objects.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"SizeOfCode\",", "prediction_line": "        \"SizeOfCode\",", "ground_truth": "        \"SizeOfCode\",", "line_class": "random", "zero_context": true}
{"original_prediction": "CoffHeader = namedtuple(\"CoffHeader\", \"signature num_sections size_of_optional_header\")", "prediction_line": "CoffHeader = namedtuple(\"CoffHeader\", \"signature num_sections size_of_optional_header\")", "ground_truth": "CoffHeader = namedtuple(", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"MajorSubsystemVersion\",", "prediction_line": "        \"MajorSubsystemVersion\",", "ground_truth": "        \"MajorSubsystemVersion\",", "line_class": "random", "zero_context": true}
{"original_prediction": "   return CoffHeader(*struct.unpack(CoffFormat, f.read(struct.calcsize(CoffFormat))))", "prediction_line": "   return CoffHeader(*struct.unpack(CoffFormat, f.read(struct.calcsize(CoffFormat))))", "ground_truth": "    f.seek(0x3c, io.SEEK_SET)", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"PointerToSymbolTable\",", "prediction_line": "        \"PointerToSymbolTable\",", "ground_truth": "        \"PointerToSymbolTable\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                info_raw = json.load(f)", "prediction_line": "                info_raw = json.load(f)", "ground_truth": "                info_raw = json.load(f)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                size = int(f.read())", "prediction_line": "                size = int(f.read())", "ground_truth": "                size = json.load(f)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        if \"creation-boot-id\" in data:", "prediction_line": "        if \"creation-boot-id\" in data:", "ground_truth": "        _creation_boot_id = data.get(\"creation-boot-id\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "        _maximum_size = data.get(\"maximum-size\", None)", "prediction_line": "        _maximum_size = data.get(\"maximum-size\", None)", "ground_truth": "        _maximum_size = data.get(\"maximum-size\", None)", "line_class": "common", "zero_context": true}
{"original_prediction": "        \"\"\"Create and link temporary directory", "prediction_line": "        \"\"\"Create and link temporary directory", "ground_truth": "        \"\"\"Atomically create and lock an anonymous directory", "line_class": "common", "zero_context": true}
{"original_prediction": "        self._info = FsCacheInfo()", "prediction_line": "        self._info = FsCacheInfo()", "ground_truth": "        self._info = FsCacheInfo()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            path_data = self._path(rpath_data)", "prediction_line": "            path_data = self._path(rpath_data)", "ground_truth": "            path_data = self._path(rpath_data)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            info[\"creation-boot-id\"] = self._bootid", "prediction_line": "            info[\"creation-boot-id\"] = self._bootid", "ground_truth": "            info[\"creation-boot-id\"] = self._bootid", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    raise self.MissError()", "prediction_line": "                    raise self.MissError()", "ground_truth": "                    raise self.MissError() from None", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    os.rmdir(self._path(rpath_dir))", "prediction_line": "                    os.rmdir(self._path(rpath_dir))", "ground_truth": "                    os.rmdir(self._path(rpath_dir))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        with self._atomic_file(self._filename_cache_size, self._dirname_objects, ignore_exist=True) as f:", "prediction_line": "        with self._atomic_file(self._filename_cache_size, self._dirname_objects, ignore_exist=True) as f:", "ground_truth": "        with self._atomic_file(self._filename_cache_size, self._dirname_objects, ignore_exist=True) as f:", "line_class": "infile", "zero_context": true}
{"original_prediction": "       else:\n            info_raw = info.to_json()", "prediction_line": "       else:", "ground_truth": "            info = FsCacheInfo.from_json(info_raw)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _lock_cache: Optional[int]", "prediction_line": "    _lock_cache: Optional[int]", "ground_truth": "    _info: FsCacheInfo", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._info = info", "prediction_line": "        self._info = info", "ground_truth": "        self._info = info", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._load_cache_info()", "prediction_line": "            self._load_cache_info()", "ground_truth": "            self._load_cache_info()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            uuidname, lockfd = self._atomic_dir(self._dirname_stage)", "prediction_line": "            uuidname, lockfd = self._atomic_dir(self._dirname_stage)", "ground_truth": "            uuidname, lockfd = self._atomic_dir(self._dirname_objects)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    self._update_cache_size(-info[\"size\"])", "prediction_line": "                    self._update_cache_size(-info[\"size\"])", "ground_truth": "                    self._update_cache_size(-info[\"size\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            # Update the cached information.", "prediction_line": "            # Update the cached information.", "ground_truth": "        self._load_cache_info(info)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            rpath_lock = os.path.join(", "prediction_line": "            rpath_lock = os.path.join(", "ground_truth": "            path_uuid = self._path(rpath_uuid)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            uuidname, lockfd = self._atomic_dir(self._dirname_stage)", "prediction_line": "            uuidname, lockfd = self._atomic_dir(self._dirname_stage)", "ground_truth": "            uuidname, lockfd = self._atomic_dir(self._dirname_stage)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            path_info = self._path(rpath_info)", "prediction_line": "            path_info = self._path(rpath_info)", "ground_truth": "            path_info = self._path(rpath_info)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        Store an object in the cache. The object is identified by its name.", "prediction_line": "        Store an object in the cache. The object is identified by its name.", "ground_truth": "        Create a new entry and store it in the cache with the specified name.", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                return False", "prediction_line": "                return False", "ground_truth": "                size = 0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    suppress.append(errno.EEXIST)", "prediction_line": "                    suppress.append(errno.EEXIST)", "ground_truth": "                    suppress.append(errno.EEXIST)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        This opens a file in the cache and locks it. The lock is released when", "prediction_line": "        This opens a file in the cache and locks it. The lock is released when", "ground_truth": "        Open the cache-file at the specified relative path and acquire a", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    # Acquire a write-lock on the lock-file. This will block", "prediction_line": "                    # Acquire a write-lock on the lock-file. This will block", "ground_truth": "                return (name, lockfd)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            os.mkdir(path_data)", "prediction_line": "            os.mkdir(path_data)", "ground_truth": "            os.mkdir(path_data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        The `appid` is used to identify the cache. It is used to create a", "prediction_line": "        The `appid` is used to identify the cache. It is used to create a", "ground_truth": "        This creates a new file-system cache. It does not create the cache, nor", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                linux.fcntl_flock(lockfd, linux.fcntl.F_UNLCK)", "prediction_line": "                linux.fcntl_flock(lockfd, linux.fcntl.F_UNLCK)", "ground_truth": "                linux.fcntl_flock(lockfd, linux.fcntl.F_UNLCK)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"Open a file in the cache", "prediction_line": "        \"\"\"Open a file in the cache", "ground_truth": "        \"\"\"Atomically open and lock file", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            # Update the size.", "prediction_line": "            # Update the size.", "ground_truth": "            if size + diff < 0:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        oflags: int = 0,", "prediction_line": "        oflags: int = 0,", "ground_truth": "        replace: bool = False,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            else:\n                size += diff", "prediction_line": "            else:", "ground_truth": "            elif (self._info_maximum_size < 0) or (size + diff <= self._info_maximum_size):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        Load a cache entry with the specified name. If the entry does not exist,", "prediction_line": "        Load a cache entry with the specified name. If the entry does not exist,", "ground_truth": "        Find the cache entry with the given name, acquire a read-lock and", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"Return path to cache directory", "prediction_line": "        \"\"\"Return path to cache directory", "ground_truth": "        \"\"\"Return cache path", "line_class": "inproject", "zero_context": true}
{"original_prediction": "This\n                # is an atomic operation and will fail if the file already", "prediction_line": "This", "ground_truth": "                with ctx.suppress_oserror(*suppress):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                with self._atomic_file(self._filename_cache_info, self._dirname_objects, replace=True) as f:", "prediction_line": "                with self._atomic_file(self._filename_cache_info, self._dirname_objects, replace=True) as f:", "ground_truth": "                with self._atomic_file(self._filename_cache_info, self._dirname_objects, replace=True) as f:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class FsCache:", "prediction_line": "class FsCache:", "ground_truth": "class FsCache(contextlib.AbstractContextManager, os.PathLike):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    json.dump(info, f)", "prediction_line": "                    json.dump(info, f)", "ground_truth": "                    json.dump(info, f)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        non-blocking nature of the cache, this is not an error, but a", "prediction_line": "        non-blocking nature of the cache, this is not an error, but a", "ground_truth": "        shared nature of the cache, a caller must be aware that any entry can", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        cache-files.", "prediction_line": "        cache-files.", "ground_truth": "        scaffolding directories and files. This ensures that an existing cache", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        return cls(", "prediction_line": "        return cls(", "ground_truth": "        creation_boot_id = None", "line_class": "random", "zero_context": true}
{"original_prediction": "class FsCacheInfo(NamedTuple):", "prediction_line": "class FsCacheInfo(NamedTuple):", "ground_truth": "MaximumSizeType = Optional[Union[int, str]]", "line_class": "random", "zero_context": true}
{"original_prediction": "caller\n            # and still clean up the lock.", "prediction_line": "caller", "ground_truth": "            # `__enter__()` call on the context-manager. We want to catch", "line_class": "random", "zero_context": true}
{"original_prediction": "                try:\n                    # Link the file into place. If the file already exists,", "prediction_line": "                try:", "ground_truth": "                if ignore_exist:", "line_class": "random", "zero_context": true}
{"original_prediction": "            # Mark the cache as active.", "prediction_line": "            # Mark the cache as active.", "ground_truth": "            self._active = True", "line_class": "random", "zero_context": true}
{"original_prediction": "        with cache._atomic_file(os.path.join(rpath_store, \"file\"), rpath_store, ignore_exist=True) as f:", "prediction_line": "        with cache._atomic_file(os.path.join(rpath_store, \"file\"), rpath_store, ignore_exist=True) as f:", "ground_truth": "        with cache._atomic_file(os.path.join(rpath_store, \"file\"), rpath_store, ignore_exist=True) as f:", "line_class": "commited", "zero_context": true}
{"original_prediction": "    cache = fscache.FsCache(\"osbuild-test-appid\", tmpdir)", "prediction_line": "    cache = fscache.FsCache(\"osbuild-test-appid\", tmpdir)", "ground_truth": "    cache = fscache.FsCache(\"osbuild-test-appid\", tmpdir)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        cache.store(None, None)", "prediction_line": "        cache.store(None, None)", "ground_truth": "        with cache.store(\"foobar\"):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        with cache._atomic_file(os.path.join(rpath_store, \"file\"), rpath_store, replace=True) as f:", "prediction_line": "        with cache._atomic_file(os.path.join(rpath_store, \"file\"), rpath_store, replace=True) as f:", "ground_truth": "        with cache._atomic_file(os.path.join(rpath_store, \"file\"), rpath_store, replace=True) as f:", "line_class": "commited", "zero_context": true}
{"original_prediction": "            with cache.store(\"foobar\"):", "prediction_line": "            with cache.store(\"foobar\"):", "ground_truth": "            with cache.store(\"\"):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            with cache._atomic_file(os.path.join(rpath_store, \"file\"), rpath_store, replace=True, ignore_exist=True):", "prediction_line": "            with cache._atomic_file(os.path.join(rpath_store, \"file\"), rpath_store, replace=True, ignore_exist=True):", "ground_truth": "            with cache._atomic_file(", "line_class": "commited", "zero_context": true}
{"original_prediction": "        with cache.load(\"foobar\"):", "prediction_line": "        with cache.load(\"foobar\"):", "ground_truth": "        with cache.load(\"foobar\"):", "line_class": "commited", "zero_context": true}
{"original_prediction": "   with open(os.path.join(tmpdir, \"dir\", \"file\"), \"w\") as f:", "prediction_line": "   with open(os.path.join(tmpdir, \"dir\", \"file\"), \"w\") as f:", "ground_truth": "    assert fscache.FsCache._calculate_size(os.path.join(tmpdir, \"dir\")) == 0", "line_class": "commited", "zero_context": true}
{"original_prediction": "            with cache.load(\"\"):", "prediction_line": "            with cache.load(\"\"):", "ground_truth": "            with cache.load(\"\"):", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert fscache.FsCache._calculate_size(os.path.join(tmpdir, \"dir\")) == 6", "prediction_line": "    assert fscache.FsCache._calculate_size(os.path.join(tmpdir, \"dir\")) == 6", "ground_truth": "    assert fscache.FsCache._calculate_size(os.path.join(tmpdir, \"dir\")) == 6", "line_class": "commited", "zero_context": true}
{"original_prediction": "            with cache._atomic_dir(\"dir\") as (rpath, lock):", "prediction_line": "            with cache._atomic_dir(\"dir\") as (rpath, lock):", "ground_truth": "            cache._atomic_dir(\"dir\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "        # Create a directory and verify there is almost exactly 1 file in the store.", "prediction_line": "        # Create a directory and verify there is almost exactly 1 file in the store.", "ground_truth": "        (name, lockfd) = cache._atomic_dir(cache._dirname_objects)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        with cache.store(\"foobar\") as (path, lockfd):", "prediction_line": "        with cache.store(\"foobar\") as (path, lockfd):", "ground_truth": "        cache.info = cache.info._replace(maximum_size=1024)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        with cache.store(\"foobar\") as (path, size):", "prediction_line": "        with cache.store(\"foobar\") as (path, size):", "ground_truth": "        with cache.stage() as rpath:", "line_class": "commited", "zero_context": true}
{"original_prediction": "            self.path = path", "prediction_line": "            self.path = path", "ground_truth": "            self._path = path", "line_class": "commited", "zero_context": true}
{"original_prediction": "        with cache.store(\"foo\") as rpath:", "prediction_line": "        with cache.store(\"foo\") as rpath:", "ground_truth": "        with pytest.raises(fscache.FsCache.MissError):", "line_class": "commited", "zero_context": true}
{"original_prediction": "            with cache.load(\"foobar\"):", "prediction_line": "            with cache.load(\"foobar\"):", "ground_truth": "            with cache.load(\"foo\") as rpath:", "line_class": "commited", "zero_context": true}
{"original_prediction": "            return self._path", "prediction_line": "            return self._path", "ground_truth": "            return self._path", "line_class": "commited", "zero_context": true}
{"original_prediction": "        with cache.store(\"foo\") as rpath:", "prediction_line": "        with cache.store(\"foo\") as rpath:", "ground_truth": "        with cache.store(\"foo\") as rpath:", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert fscache.FsCache(dir_str)._path == dir_str", "prediction_line": "    assert fscache.FsCache(dir_str)._path == dir_str", "ground_truth": "    cache1 = fscache.FsCache(\"osbuild-test-appid\", dir_str)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    cache2 = fscache.FsCache(\"osbuild-test-appid\", dir_pathlike)", "prediction_line": "    cache2 = fscache.FsCache(\"osbuild-test-appid\", dir_pathlike)", "ground_truth": "    cache2 = fscache.FsCache(\"osbuild-test-appid\", dir_pathlike)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert os.path.join(cache, \"foobar\") == os.path.join(tmpdir,  \"foobar\")", "prediction_line": "        assert os.path.join(cache, \"foobar\") == os.path.join(tmpdir,  \"foobar\")", "ground_truth": "        assert cache._path() == cache._path_cache", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert cache._path() == cache._path_cache", "prediction_line": "    assert cache._path() == cache._path_cache", "ground_truth": "        assert cache._path(\"dir\") == os.path.join(cache._path_cache, \"dir\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert cache._path(\"dir\", \"file\") == os.path.join(cache._path_cache, \"dir\", \"file\")", "prediction_line": "        assert cache._path(\"dir\", \"file\") == os.path.join(cache._path_cache, \"dir\", \"file\")", "ground_truth": "        assert cache._path(\"dir\", \"file\") == os.path.join(cache._path_cache, \"dir\", \"file\")", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert cache._cache_info == {}", "prediction_line": "        assert cache._cache_info == {}", "ground_truth": "        assert cache._info == fscache.FsCacheInfo()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    with open(os.path.join(tmpdir, cache._filename_cache_info), \"w\", encoding=\"utf8\") as f:", "prediction_line": "    with open(os.path.join(tmpdir, cache._filename_cache_info), \"w\", encoding=\"utf8\") as f:", "ground_truth": "        assert cache.info == cache._info", "line_class": "commited", "zero_context": true}
{"original_prediction": "    with open(os.path.join(tmpdir, cache._filename_cache_info), \"w\", encoding=\"utf8\") as f:", "prediction_line": "    with open(os.path.join(tmpdir, cache._filename_cache_info), \"w\", encoding=\"utf8\") as f:", "ground_truth": "        assert cache.info.maximum_size is None", "line_class": "commited", "zero_context": true}
{"original_prediction": "            cache._atomic_open(\"file\", \"x\")", "prediction_line": "            cache._atomic_open(\"file\", \"x\")", "ground_truth": "            with cache._atomic_open(\"file\", write=False, wait=False) as f:", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert cache.info.creation_boot_id is None", "prediction_line": "        assert cache.info.creation_boot_id is None", "ground_truth": "        assert cache.info.creation_boot_id is None", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert cache.info.creation_timestamp is None", "prediction_line": "        assert cache.info.creation_timestamp is None", "ground_truth": "        cache.info = fscache.FsCacheInfo(maximum_size=1024)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert cache.info.maximum_size is None", "prediction_line": "        assert cache.info.maximum_size is None", "ground_truth": "        assert cache.info.maximum_size == 1024", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert cache.info.maximum_size is None", "prediction_line": "        assert cache.info.maximum_size is None", "ground_truth": "        cache.info = fscache.FsCacheInfo(creation_boot_id=\"0\"*32)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert cache.info.creation_boot_id == \"0\"*32", "prediction_line": "        assert cache.info.creation_boot_id == \"0\"*32", "ground_truth": "        assert cache.info.creation_boot_id == \"0\"*32", "line_class": "commited", "zero_context": true}
{"original_prediction": "        with cache._atomic_open(\"file\", write=True, wait=False) as f:", "prediction_line": "        with cache._atomic_open(\"file\", write=True, wait=False) as f:", "ground_truth": "        with cache._atomic_open(\"file\", write=True, wait=False):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert cache._info.maximum_size == 1024", "prediction_line": "        assert cache._info.maximum_size == 1024", "ground_truth": "        cache.info = fscache.FsCacheInfo(maximum_size=2048, creation_boot_id=\"1\"*32)", "line_class": "commited", "zero_context": true}
{"original_prediction": "                with cache._atomic_open(\"file\", write=False, wait=False):", "prediction_line": "                with cache._atomic_open(\"file\", write=False, wait=False):", "ground_truth": "                with cache._atomic_open(\"file\", write=False, wait=False):", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert cache.info.maximum_size == 2048", "prediction_line": "        assert cache.info.maximum_size == 2048", "ground_truth": "        assert cache.info.maximum_size == 2048", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert cache.info.creation_boot_id == \"1\"*32", "prediction_line": "        assert cache.info.creation_boot_id == \"1\"*32", "ground_truth": "        assert cache.info.creation_boot_id == \"1\"*32", "line_class": "commited", "zero_context": true}
{"original_prediction": "        assert cache._info.maximum_size == 2048", "prediction_line": "        assert cache._info.maximum_size == 2048", "ground_truth": "    assert not fscache.FsCacheInfo().to_json()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert fscache.FsCacheInfo(maximum_size=1024).to_json() == '{\"maximum_size\": 1024}'", "prediction_line": "    assert fscache.FsCacheInfo(maximum_size=1024).to_json() == '{\"maximum_size\": 1024}'", "ground_truth": "    assert fscache.FsCacheInfo(creation_boot_id=\"0\"*32).to_json() == {", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert fscache.FsCacheInfo(maximum_size=1024).to_json() == {", "prediction_line": "    assert fscache.FsCacheInfo(maximum_size=1024).to_json() == {", "ground_truth": "    assert fscache.FsCacheInfo(creation_boot_id=\"0\"*32, maximum_size=1024).to_json() == {", "line_class": "commited", "zero_context": true}
{"original_prediction": "    with open(os.path.join(tmpdir, cache._filename_cache_info), \"r\", encoding=\"utf8\") as f:", "prediction_line": "    with open(os.path.join(tmpdir, cache._filename_cache_info), \"r\", encoding=\"utf8\") as f:", "ground_truth": "    assert fscache.FsCacheInfo.from_json({}) == fscache.FsCacheInfo()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert fscache.FsCacheInfo.from_json({", "prediction_line": "    assert fscache.FsCacheInfo.from_json({", "ground_truth": "    assert fscache.FsCacheInfo.from_json(None) == fscache.FsCacheInfo()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert fscache.FsCacheInfo.from_json({", "prediction_line": "    assert fscache.FsCacheInfo.from_json({", "ground_truth": "    assert fscache.FsCacheInfo.from_json(\"foobar\") == fscache.FsCacheInfo()", "line_class": "commited", "zero_context": true}
{"original_prediction": "    assert fscache.FsCacheInfo.from_json({\"creation-boot-id\": \"0\"*32}) == fscache.FsCacheInfo(creation_boot_id=\"0\"*32)", "prediction_line": "    assert fscache.FsCacheInfo.from_json({\"creation-boot-id\": \"0\"*32}) == fscache.FsCacheInfo(creation_boot_id=\"0\"*32)", "ground_truth": "    assert fscache.FsCacheInfo.from_json({", "line_class": "commited", "zero_context": true}
{"original_prediction": "    }) == fscache.FsCacheInfo(creation_boot_id=\"0\"*32)", "prediction_line": "    }) == fscache.FsCacheInfo(creation_boot_id=\"0\"*32)", "ground_truth": "    }) == fscache.FsCacheInfo(creation_boot_id=\"0\"*32)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        with cache._atomic_file(\"file\") as f:", "prediction_line": "        with cache._atomic_file(\"file\") as f:", "ground_truth": "        with cache._atomic_file(os.path.join(rpath_store, \"file\"), rpath_store) as f:", "line_class": "commited", "zero_context": true}
{"original_prediction": "        \"foobar\": \"barfoo\",", "prediction_line": "        \"foobar\": \"barfoo\",", "ground_truth": "    }) == fscache.FsCacheInfo(creation_boot_id=\"0\"*32, maximum_size=1024)", "line_class": "commited", "zero_context": true}
{"original_prediction": "    dir_wrapper = Wrapper(dir_str)", "prediction_line": "    dir_wrapper = Wrapper(dir_str)", "ground_truth": "    dir_pathlike: Wrapper = Wrapper(os.fspath(tmpdir))", "line_class": "infile", "zero_context": true}
{"original_prediction": "    # Test with a path-like object as argument", "prediction_line": "    # Test with a path-like object as argument", "ground_truth": "    assert os.path.join(cache1, \"foobar\") == os.path.join(tmpdir,  \"foobar\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_cache_info(tmpdir):", "prediction_line": "def test_cache_info(tmpdir):", "ground_truth": "    with open(os.path.join(tmpdir, cache._filename_cache_size), \"r\", encoding=\"utf8\") as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # The directory must be empty.", "prediction_line": "        # The directory must be empty.", "ground_truth": "        assert len(list(os.scandir(os.path.join(tmpdir, cache._dirname_objects)))) == 1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # Create a directory with a file and a subdirectory", "prediction_line": "    # Create a directory with a file and a subdirectory", "ground_truth": "    os.mkdir(os.path.join(tmpdir, \"dir\"))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # The file is gone again.", "prediction_line": "        # The file is gone again.", "ground_truth": "            f.write(\"foo\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "@pytest.fixture", "prediction_line": "@pytest.fixture", "ground_truth": "@pytest.fixture(name=\"tmpdir\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with open(os.path.join(tmpdir, \"dir\", \"file\"), \"w\", encoding=\"utf8\") as f:", "prediction_line": "    with open(os.path.join(tmpdir, \"dir\", \"file\"), \"w\", encoding=\"utf8\") as f:", "ground_truth": "    with open(os.path.join(tmpdir, \"dir\", \"file\"), \"w\", encoding=\"utf8\") as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                f.write(\"foobar\")", "prediction_line": "                f.write(\"foobar\")", "ground_truth": "                f.write(\"foobar\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # Create the directory and verify it exists.", "prediction_line": "        # Create the directory and verify it exists.", "ground_truth": "        assert len(list(os.scandir(os.path.join(tmpdir, cache._dirname_objects)))) == 0", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            assert f.read() == \"bar\"", "prediction_line": "            assert f.read() == \"bar\"", "ground_truth": "            assert f.read() == \"foo\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        # The directory must be empty.", "prediction_line": "        # The directory must be empty.", "ground_truth": "        os.close(lockfd)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        assert f.read() == \"osbuild-test-appid\"", "prediction_line": "        assert f.read() == \"osbuild-test-appid\"", "ground_truth": "        assert f.read() == \"{}\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                f.write(\"bar\")", "prediction_line": "                f.write(\"bar\")", "ground_truth": "                f.write(\"bar\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    replace=True,", "prediction_line": "                    replace=True,", "ground_truth": "                    replace=True,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        rpath_cache = cache._path_cache", "prediction_line": "        rpath_cache = cache._path_cache", "ground_truth": "        path_store = os.path.join(cache._path_cache, rpath_store)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        def __fspath__(self):", "prediction_line": "        def __fspath__(self):", "ground_truth": "        def __fspath__(self) -> str:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    #\n\n    cache = fscache.FsCache(\"osbuild-test-appid\", tmpdir)", "prediction_line": "    #", "ground_truth": "    #", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        # Create a file with \"foo\" as content.", "prediction_line": "        # Create a file with \"foo\" as content.", "ground_truth": "        # Initially the store is empty.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "\"creation-boot-id\": \"0\"*32}) == fscache.FsCacheInfo(creation_boot_id=\"0\"*32)", "prediction_line": "\"creation-boot-id\": \"0\"*32}) == fscache.FsCacheInfo(creation_boot_id=\"0\"*32)", "ground_truth": "        \"creation-boot-id\": \"0\"*32,", "line_class": "random", "zero_context": true}
{"original_prediction": "                pass", "prediction_line": "                pass", "ground_truth": "                pass", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"maximum-size\": \"1024\",", "prediction_line": "        \"maximum-size\": \"1024\",", "ground_truth": "        \"unknown0\": \"foobar\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        # Must never create files.", "prediction_line": "        # Must never create files.", "ground_truth": "        rpath_store = cache._dirname_objects", "line_class": "random", "zero_context": true}
{"original_prediction": "        subprocess.run(", "prediction_line": "        subprocess.run(", "ground_truth": "        subprocess.run(", "line_class": "common", "zero_context": true}
{"original_prediction": "    subprocess.check_call([\"mount\", \"-t\", \"nfs\", src, dst])", "prediction_line": "    subprocess.check_call([\"mount\", \"-t\", \"nfs\", src, dst])", "ground_truth": "    r = subprocess.run(", "line_class": "common", "zero_context": true}
{"original_prediction": "        a = os.path.join(tmpdir, \"a\")", "prediction_line": "        a = os.path.join(tmpdir, \"a\")", "ground_truth": "        _test_atomics_with(tmpdir, tmpdir)", "line_class": "infile", "zero_context": true}
{"original_prediction": "@pytest.mark.skipif(not nfsd_available(), reason=\"NFSv4 daemon required\")", "prediction_line": "@pytest.mark.skipif(not nfsd_available(), reason=\"NFSv4 daemon required\")", "ground_truth": "@pytest.mark.skipif(not nfsd_available(), reason=\"NFSv4 daemon required\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "            \"lock\": _trace_lock,", "prediction_line": "            \"lock\": _trace_lock,", "ground_truth": "            \"_atomic_open:lock\": lambda: _trace_lock(state)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        with mount_nfs(\"/var/tmp\", tmpmnt):", "prediction_line": "        with mount_nfs(\"/var/tmp\", tmpmnt):", "ground_truth": "        with mount_nfs(\"localhost:/\", tmpmnt) as tmpnfs:", "line_class": "infile", "zero_context": true}
{"original_prediction": "    st_a2 = os.stat(os.path.join(a, \"2_foo\"))", "prediction_line": "    st_a2 = os.stat(os.path.join(a, \"2_foo\"))", "ground_truth": "    st_a2 = os.stat(os.path.join(a, \"2_foo\"))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                yield tmpdir", "prediction_line": "                yield tmpdir", "ground_truth": "                dirname = os.path.basename(os.path.normpath(tmpdir))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        fcntl = test.TestBase.fcntl", "prediction_line": "        fcntl = test.TestBase.fcntl", "ground_truth": "        assert os.access(os.path.join(a, \"1_foo\"), os.R_OK)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            check=False,", "prediction_line": "            check=False,", "ground_truth": "            check=True,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        raise RuntimeError(f\"Failed to mount NFS: {r.stdout}\")", "prediction_line": "        raise RuntimeError(f\"Failed to mount NFS: {r.stdout}\")", "ground_truth": "        code = r.returncode", "line_class": "inproject", "zero_context": true}
{"original_prediction": "             mount_nfs(\"localhost:/\", os.path.join(tmpmnt, \"b\")) as tmpnfs:", "prediction_line": "             mount_nfs(\"localhost:/\", os.path.join(tmpmnt, \"b\")) as tmpnfs:", "ground_truth": "                mount_nfs(\"localhost:/\", os.path.join(tmpmnt, \"b\")):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                yield (os.path.join(tmpmnt, \"a\", dirname), os.path.join(tmpmnt, \"b\", dirname))", "prediction_line": "                yield (os.path.join(tmpmnt, \"a\", dirname), os.path.join(tmpmnt, \"b\", dirname))", "ground_truth": "                a = os.path.join(tmpmnt, \"a\", dirname)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    )\n    if r.returncode != 0:", "prediction_line": "    )", "ground_truth": "        stdout=subprocess.PIPE,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if r.returncode != 0:", "prediction_line": "    if r.returncode != 0:", "ground_truth": "    if r.returncode != 0:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        tmpmnt = tempfile.TemporaryDirectory()", "prediction_line": "        tmpmnt = tempfile.TemporaryDirectory()", "ground_truth": "        tmpmnt = tempfile.mkdtemp(prefix=\"osbuild-test-\", dir=\"/var/tmp\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                open(os.path.join(a, \"0_foo\"), \"x\", encoding=\"utf8\")", "prediction_line": "                open(os.path.join(a, \"0_foo\"), \"x\", encoding=\"utf8\")", "ground_truth": "                with open(os.path.join(b, \"0_foo\"), \"x\", encoding=\"utf8\") as f:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    assert f.read() == \"bar\"", "prediction_line": "                    assert f.read() == \"bar\"", "ground_truth": "                    assert f.read() == \"bar\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        stdout=subprocess.PIPE,", "prediction_line": "        stdout=subprocess.PIPE,", "ground_truth": "        stderr=subprocess.STDOUT,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            f.write(\"foo\")", "prediction_line": "            f.write(\"foo\")", "ground_truth": "            f.write(\"foo\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    st_b1 = os.stat(os.path.join(b, \"2_foo\"))", "prediction_line": "    st_b1 = os.stat(os.path.join(b, \"2_foo\"))", "ground_truth": "    st_b1 = os.stat(os.path.join(b, \"2_foo\"))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    # same NFS mount as before, but this time use the FsCache helpers to", "prediction_line": "    # same NFS mount as before, but this time use the FsCache helpers to", "ground_truth": "    # trace-hooks of FsCache to trigger the race-conditions we want to test.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    #\n\n    tmpmnt = None", "prediction_line": "    #", "ground_truth": "    #", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        os.rmdir(tmpmnt)", "prediction_line": "        os.rmdir(tmpmnt)", "ground_truth": "        os.rmdir(tmpmnt)", "line_class": "random", "zero_context": true}
{"original_prediction": "    try:\n        tmpmnt = tempfile.mkdtemp(prefix=\"osbuild-test-\", dir=\"/var/tmp\")", "prediction_line": "    try:", "ground_truth": "    try:", "line_class": "random", "zero_context": true}
{"original_prediction": "            if state[\"attempt\"] == 0:", "prediction_line": "            if state[\"attempt\"] == 0:", "ground_truth": "            if state[\"lock\"] == 0:", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert st_a0.st_ino == st_b0.st_ino", "prediction_line": "    assert st_a0.st_ino == st_b0.st_ino", "ground_truth": "    assert st_a0.st_ino == st_b0.st_ino", "line_class": "random", "zero_context": true}
{"original_prediction": "        try:\n            s.connect((\"localhost\", 2049))", "prediction_line": "        try:", "ground_truth": "        return s.connect_ex((\"localhost\", 2049)) == 0", "line_class": "random", "zero_context": true}
{"original_prediction": "        return json.load(file)", "prediction_line": "        return json.load(file)", "ground_truth": "        data = json.load(file)", "line_class": "common", "zero_context": true}
{"original_prediction": "        data = json.load(file)", "prediction_line": "        data = json.load(file)", "ground_truth": "        return json.load(file)", "line_class": "common", "zero_context": true}
{"original_prediction": "    with open(BIOREGISTRY_PATH, encoding=\"utf-8\") as file:", "prediction_line": "    with open(BIOREGISTRY_PATH, encoding=\"utf-8\") as file:", "ground_truth": "    return _registry_from_path(BIOREGISTRY_PATH)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    mismatches = read_mismatches()", "prediction_line": "    mismatches = read_mismatches()", "ground_truth": "    return external_prefix in read_mismatches().get(bioregistry_prefix, {}).get(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _write_registry(registry)", "prediction_line": "    _write_registry(registry)", "ground_truth": "    write_registry(registry)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    registry = read_registry()", "prediction_line": "    registry = read_registry()", "ground_truth": "    registry = dict(read_registry())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    read_registry.cache_clear()", "prediction_line": "    read_registry.cache_clear()", "ground_truth": "    read_registry.cache_clear()", "line_class": "infile", "zero_context": true}
{"original_prediction": "    registry[resource.prefix] = resource", "prediction_line": "    registry[resource.prefix] = resource", "ground_truth": "    registry[resource.prefix] = resource", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for registry in [Registry.from_jsonld(entry) for entry in data[\"registries\"]]", "prediction_line": "        for registry in [Registry.from_jsonld(entry) for entry in data[\"registries\"]]", "ground_truth": "        for registry in (Registry(**record) for record in data[\"metaregistry\"])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with COLLECTIONS_PATH.open(\"w\", encoding=\"utf-8\") as file:", "prediction_line": "    with COLLECTIONS_PATH.open(\"w\", encoding=\"utf-8\") as file:", "ground_truth": "    for collection in values:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with CONTEXTS_PATH.open() as file:", "prediction_line": "    with CONTEXTS_PATH.open() as file:", "ground_truth": "    for resource in read_registry().values():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                rv[contributor.orcid].add(prefix)", "prediction_line": "                rv[contributor.orcid].add(prefix)", "ground_truth": "                rv[contributor.orcid].add(prefix)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for reviewer in resource.reviewer_extras or []:", "prediction_line": "        for reviewer in resource.reviewer_extras or []:", "ground_truth": "        contact = resource.get_contact()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            rv[resource.contributor.orcid].add(prefix)", "prediction_line": "            rv[resource.contributor.orcid].add(prefix)", "ground_truth": "            rv[resource.contributor.orcid].add(prefix)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if context.contributor and context.contributor.orcid:", "prediction_line": "        if context.contributor and context.contributor.orcid:", "ground_truth": "        for maintainer in context.maintainers:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    registry[resource.prefix] = resource", "prediction_line": "    registry[resource.prefix] = resource", "ground_truth": "    if resource.prefix in registry:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        context.key: context", "prediction_line": "        context.key: context", "ground_truth": "        key: Context(**data)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    for context_id, resource in read_contexts().items():", "prediction_line": "    for context_id, resource in read_contexts().items():", "ground_truth": "    for context_key, context in read_contexts().items():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if collection.contact.orcid:", "prediction_line": "        if collection.contact.orcid:", "ground_truth": "        for author in collection.authors or []:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    with CONTEXTS_PATH.open() as file:", "prediction_line": "    with CONTEXTS_PATH.open() as file:", "ground_truth": "    rv: Dict[str, Attributable] = {}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if contributor.orcid:", "prediction_line": "            if contributor.orcid:", "ground_truth": "            if contributor.orcid:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        collection.validate()", "prediction_line": "        collection.validate()", "ground_truth": "        collection.resources = sorted(set(collection.resources))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def get_contexts() -> Mapping[str, Context]:", "prediction_line": "def get_contexts() -> Mapping[str, Context]:", "ground_truth": "def read_contributors() -> Mapping[str, Attributable]:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    )", "prediction_line": "    )", "ground_truth": "    )", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "__all__ = [", "prediction_line": "__all__ = [", "ground_truth": "from .utils import extended_encoder", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def get_bioregistry() -> Registry:", "prediction_line": "def get_bioregistry() -> Registry:", "ground_truth": "def read_metaregistry() -> Mapping[str, Registry]:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from .utils import get_obo_name, get_obo_synonyms, get_obo_xref, get_obo_xrefs", "prediction_line": "from .utils import get_obo_name, get_obo_synonyms, get_obo_xref, get_obo_xrefs", "ground_truth": "from .schema import Attributable, Collection, Context, Registry, Resource", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        )", "prediction_line": "        )", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "    return {\n        key: Registry(", "prediction_line": "    return {", "ground_truth": "    return {", "line_class": "random", "zero_context": true}
{"original_prediction": "            rv[contact_orcid].add(prefix)", "prediction_line": "            rv[contact_orcid].add(prefix)", "ground_truth": "            rv[contact_orcid].add(prefix)", "line_class": "random", "zero_context": true}
{"original_prediction": "def get_biolink_contexts() -> Dict[str, Context]:", "prediction_line": "def get_biolink_contexts() -> Dict[str, Context]:", "ground_truth": "@lru_cache(maxsize=1)", "line_class": "random", "zero_context": true}
{"original_prediction": "        json.dump(", "prediction_line": "        json.dump(", "ground_truth": "        json.dump(", "line_class": "random", "zero_context": true}
{"original_prediction": "index=False, escape=False)", "prediction_line": "index=False, escape=False)", "ground_truth": "            index=False,", "line_class": "common", "zero_context": true}
{"original_prediction": "a factor of\n            {self.pairwise_to_direct_ratio:.0f} when considering direct mappings between", "prediction_line": "a factor of", "ground_truth": "            {self.pairwise_to_direct_ratio:.1f} times to {self.direct_upper_bound:,} mappings", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return pd.DataFrame(", "prediction_line": "        return pd.DataFrame(", "ground_truth": "        return pd.DataFrame(self._table_rows(), columns=[\"Category\", \"Count\"])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return tabulate(self._table_df(), tablefmt=tablefmt)", "prediction_line": "        return tabulate(self._table_df(), tablefmt=tablefmt)", "ground_truth": "        df = self._table_df()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        {self.external_sizes['ols']:,} in OLS. {self.number_prefixes_novel:,} of these are novel,", "prediction_line": "        {self.external_sizes['ols']:,} in OLS. {self.number_prefixes_novel:,} of these are novel,", "ground_truth": "        {self.external_sizes['n2t']:,} in Name-to-Thing (each accessed on {self.datetime_str}).", "line_class": "infile", "zero_context": true}
{"original_prediction": "    \"\"\"Generate the summary text and table for the Bioregistry manuscript.\"\"\"", "prediction_line": "    \"\"\"Generate the summary text and table for the Bioregistry manuscript.\"\"\"", "ground_truth": "    click.echo(MappingBurdenSummary.make().get_text())", "line_class": "infile", "zero_context": true}
{"original_prediction": "        from tabulate import tabulate", "prediction_line": "        from tabulate import tabulate", "ground_truth": "        return self._table_df().to_latex(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    click.echo(BioregistrySummary.make().get_text())", "prediction_line": "    click.echo(BioregistrySummary.make().get_text())", "ground_truth": "    s = BioregistrySummary.make()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            float_format=\"%.0f\",", "prediction_line": "            float_format=\"%.0f\",", "ground_truth": "            caption=f\"Overview statistics of the Bioregistry on {self.datetime_str}.\",", "line_class": "infile", "zero_context": true}
{"original_prediction": "    click.echo(s.get_text())", "prediction_line": "    click.echo(s.get_text())", "ground_truth": "    click.echo(s.get_text())", "line_class": "infile", "zero_context": true}
{"original_prediction": "   click.echo(s.get_table_latex())", "prediction_line": "   click.echo(s.get_table_latex())", "ground_truth": "    TABLES_SUMMARY_LATEX_PATH.write_text(s.get_table_latex())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    click.echo(\"\")", "prediction_line": "    click.echo(\"\")", "ground_truth": "    click.echo(s.get_table_text())", "line_class": "infile", "zero_context": true}
{"original_prediction": "    _main()", "prediction_line": "    _main()", "ground_truth": "    _main()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            number_mismatches_curated=sum(", "prediction_line": "            number_mismatches_curated=sum(", "ground_truth": "            number_mismatches_curated=sum(len(v) for v in bioregistry.read_mismatches().values()),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            number_collections=len(bioregistry.read_collections()),", "prediction_line": "            number_collections=len(bioregistry.read_collections()),", "ground_truth": "            number_collections=len(bioregistry.read_collections()),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            number_contexts=len(bioregistry.read_contexts()),", "prediction_line": "            number_contexts=len(bioregistry.read_contexts()),", "ground_truth": "            number_contexts=len(bioregistry.read_contexts()),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            number_contributors=len(bioregistry.read_contributors()),", "prediction_line": "            number_contributors=len(bioregistry.read_contributors()),", "ground_truth": "            number_contributors=len(bioregistry.read_contributors(direct_only=True)),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "len(entry.synonyms) for entry in registry.values() if entry.synonyms)", "prediction_line": "len(entry.synonyms) for entry in registry.values() if entry.synonyms)", "ground_truth": "            len(resource.synonyms) for resource in registry.values() if resource.synonyms", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        #: The number of prefixes that have curated metadata", "prediction_line": "        #: The number of prefixes that have curated metadata", "ground_truth": "        metaprefixes = set(bioregistry.read_metaregistry())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        The Bioregistry is a centralized registry of controlled vocabularies for", "prediction_line": "        The Bioregistry is a centralized registry of controlled vocabularies for", "ground_truth": "        The Bioregistry (v{get_version()}) integrates {self.number_registries:,} external registries", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            [\n                \"Number of registries\",", "prediction_line": "            [", "ground_truth": "            (\"Version\", get_version()),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       remaining = sum(", "prediction_line": "       remaining = sum(", "ground_truth": "        registry = bioregistry.read_registry()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for prefix, entry in registry.items():", "prediction_line": "        for prefix, entry in registry.items():", "ground_truth": "        for resource in registry.values():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            for metaprefix, prefix in resource.mappings.items():", "prediction_line": "            for metaprefix, prefix in resource.mappings.items():", "ground_truth": "            for metaprefix, external_prefix in resource.get_mappings().items():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "import requests\nfrom tabulate import tabulate", "prediction_line": "import requests", "ground_truth": "import bioregistry", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import json\nimport os", "prediction_line": "import json", "ground_truth": "import datetime", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def get_table_latex(self):", "prediction_line": "    def get_table_latex(self):", "ground_truth": "    def get_table_latex(self) -> str:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    \"\"\"A container for high-level statistics on the Bioregistry.\"\"\"", "prediction_line": "    \"\"\"A container for high-level statistics on the Bioregistry.\"\"\"", "ground_truth": "    \"\"\"A container for high-level statistics on the remaining mappings to be curated in the Bioregistry.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       registry_to_prefixes[\"bioregistry\"] = set(bioregistry.read_registry())", "prediction_line": "       registry_to_prefixes[\"bioregistry\"] = set(bioregistry.read_registry())", "ground_truth": "        total_pairwise_upper_bound = sum(", "line_class": "random", "zero_context": true}
{"original_prediction": "        return dedent(", "prediction_line": "        return dedent(", "ground_truth": "        return (", "line_class": "random", "zero_context": true}
{"original_prediction": "            metaprefix: set(prefixes) - set(mapped_prefixes)", "prediction_line": "            metaprefix: set(prefixes) - set(mapped_prefixes)", "ground_truth": "            metaprefix: external_prefixes - registry_to_mapped_prefixes[metaprefix]", "line_class": "random", "zero_context": true}
{"original_prediction": "    number_registries_novel: int", "prediction_line": "    number_registries_novel: int", "ground_truth": "    number_prefixes_curated: int", "line_class": "random", "zero_context": true}
{"original_prediction": "    @classmethod", "prediction_line": "    @classmethod", "ground_truth": "    @classmethod", "line_class": "random", "zero_context": true}
{"original_prediction": "        f\"{count:,} of {len(df.index):,} ({count / len(df.index):.0%})\",", "prediction_line": "        f\"{count:,} of {len(df.index):,} ({count / len(df.index):.0%})\",", "ground_truth": "        f\"{count:,} of {len(df.index):,} ({count / len(df.index):.0%})\",", "line_class": "common", "zero_context": true}
{"original_prediction": "        index=df.index,", "prediction_line": "        index=df.index,", "ground_truth": "        index=df.index,", "line_class": "common", "zero_context": true}
{"original_prediction": "            pattern = patterns[_p]", "prediction_line": "            pattern = patterns[_p]", "ground_truth": "            _pattern = patterns.get(_p)", "line_class": "common", "zero_context": true}
{"original_prediction": "    column = _norm_column(df, column)", "prediction_line": "    column = _norm_column(df, column)", "ground_truth": "    column = _norm_column(df, column)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        prefix_column = _norm_column(df, prefix_column)", "prediction_line": "        prefix_column = _norm_column(df, prefix_column)", "ground_truth": "        prefix_column = _norm_column(df, prefix_column)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            normalize_prefixes(df, prefix_column)", "prediction_line": "            normalize_prefixes(df, prefix_column)", "ground_truth": "            normalize_prefixes(df=df, column=prefix_column)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        df.loc[target_column] = _multi_column_map(", "prediction_line": "        df.loc[target_column] = _multi_column_map(", "ground_truth": "        df[target_column] = _multi_column_map(", "line_class": "infile", "zero_context": true}
{"original_prediction": "        raise PrefixLocationError", "prediction_line": "        raise PrefixLocationError", "ground_truth": "        raise PrefixLocationError", "line_class": "infile", "zero_context": true}
{"original_prediction": "        prefix_column = column", "prediction_line": "        prefix_column = column", "ground_truth": "        return _help_validate_identifiers(df, column, prefix)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return _help_validate_identifiers(df, column, prefixes[0])", "prediction_line": "            return _help_validate_identifiers(df, column, prefixes[0])", "ground_truth": "            return _help_validate_identifiers(df, column, list(prefixes)[0])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if use_tqdm:", "prediction_line": "        if use_tqdm:", "ground_truth": "        results = _multi_column_map(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            _validate_lambda,", "prediction_line": "            _validate_lambda,", "ground_truth": "            _validate_lambda,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        df[target_column or column] = _multi_column_map(", "prediction_line": "        df[target_column or column] = _multi_column_map(", "ground_truth": "        df[target_column or column] = _multi_column_map(", "line_class": "infile", "zero_context": true}
{"original_prediction": "    pattern = bioregistry.get_pattern(prefix)", "prediction_line": "    pattern = bioregistry.get_pattern(prefix)", "ground_truth": "    norm_prefix = bioregistry.normalize_prefix(prefix)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            norm_prefix = bioregistry.normalize_prefix(prefix)", "prediction_line": "            norm_prefix = bioregistry.normalize_prefix(prefix)", "ground_truth": "            pattern = bioregistry.get_pattern(prefix)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            functools.partial(bioregistry.get_iri, prefix=norm_prefix),", "prediction_line": "            functools.partial(bioregistry.get_iri, prefix=norm_prefix),", "ground_truth": "            functools.partial(bioregistry.get_iri, prefix=norm_prefix), na_action=\"ignore\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if target_column is None:", "prediction_line": "    if target_column is None:", "ground_truth": "    df[target_column or column] = df[column].map(bioregistry.get_iri, na_action=\"ignore\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            lambda s: f\"{norm_prefix}:{s}\", na_action=\"ignore\"", "prediction_line": "            lambda s: f\"{norm_prefix}:{s}\", na_action=\"ignore\"", "ground_truth": "            functools.partial(bioregistry.curie_to_str, prefix=norm_prefix),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    df[target_column or column] = df[column].map(bioregistry.iri_to_curie, na_action=\"ignore\")", "prediction_line": "    df[target_column or column] = df[column].map(bioregistry.iri_to_curie, na_action=\"ignore\")", "ground_truth": "    df[target_column or column] = df[column].map(bioregistry.curie_from_iri, na_action=\"ignore\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            df, [prefix_column, column], bioregistry.get_iri, use_tqdm=use_tqdm", "prediction_line": "            df, [prefix_column, column], bioregistry.get_iri, use_tqdm=use_tqdm", "ground_truth": "            df, [prefix_column, column], bioregistry.get_iri, use_tqdm=use_tqdm", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            (prefix, bioregistry.normalize_prefix(prefix))", "prediction_line": "            (prefix, bioregistry.normalize_prefix(prefix))", "ground_truth": "            (prefix, bioregistry.normalize_prefix(prefix)) for prefix in unique", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            df,\n            [prefix_column, column],", "prediction_line": "            df,", "ground_truth": "            df, [prefix_column, column], bioregistry.curie_to_str, use_tqdm=use_tqdm", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    df[target_column] = df[column].map(bioregistry.normalize_prefix)", "prediction_line": "    df[target_column] = df[column].map(bioregistry.normalize_prefix)", "ground_truth": "    df[target_column] = df[column].map(bioregistry.normalize_prefix, na_action=\"ignore\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   df[prefix_column_name] = df[column].map(bioregistry.get_prefix, na_action=\"ignore\")", "prediction_line": "   df[prefix_column_name] = df[column].map(bioregistry.get_prefix, na_action=\"ignore\")", "ground_truth": "    prefixes, identifiers = zip(*df[column].map(bioregistry.parse_curie, na_action=\"ignore\"))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if target_column is None:", "prediction_line": "    if target_column is None:", "ground_truth": "    results = df[column].map(lambda x: bioregistry.normalize_prefix(x) == x, na_action=\"ignore\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    df[target_column] = df[column].map(bioregistry.normalize_curie, na_action=\"ignore\")", "prediction_line": "    df[target_column] = df[column].map(bioregistry.normalize_curie, na_action=\"ignore\")", "ground_truth": "    df[target_column] = df[column].map(bioregistry.normalize_curie, na_action=\"ignore\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    :param df: The dataframe", "prediction_line": "    :param df: The dataframe", "ground_truth": "    :param df: A dataframe", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import logging\nimport os", "prediction_line": "import logging", "ground_truth": "import logging", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        Whether to use :mod:`tqdm` to show a progress bar", "prediction_line": "        Whether to use :mod:`tqdm` to show a progress bar", "ground_truth": "        Should a progress bar be shown?", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from bioregistry.utils import get_name_and_pattern", "prediction_line": "from bioregistry.utils import get_name_and_pattern", "ground_truth": "from tqdm.auto import tqdm", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        brpd.curies_to_iris(df, column=4)", "prediction_line": "        brpd.curies_to_iris(df, column=4)", "ground_truth": "        #  i.e., `GO:0003993` becomes `http://amigo.geneontology.org/amigo/term/GO:0003993`", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    df: pd.DataFrame,", "prediction_line": "    df: pd.DataFrame,", "ground_truth": "    df: pd.DataFrame,", "line_class": "random", "zero_context": true}
{"original_prediction": "        if norm_prefix is None:", "prediction_line": "        if norm_prefix is None:", "ground_truth": "        if norm_prefix is None:", "line_class": "random", "zero_context": true}
{"original_prediction": "    df[target_column] = identifiers", "prediction_line": "    df[target_column] = identifiers", "ground_truth": "    df[target_column] = identifiers", "line_class": "random", "zero_context": true}
{"original_prediction": "        target_column = column", "prediction_line": "        target_column = column", "ground_truth": "        target_column = column", "line_class": "random", "zero_context": true}
{"original_prediction": "            _debug_or_raise(msg, strict=strict)", "prediction_line": "            _debug_or_raise(msg, strict=strict)", "ground_truth": "            _debug_or_raise(msg, strict=strict)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    def _add_uri_prefix_prefixes(", "prediction_line": "    def _add_uri_prefix_prefixes(", "ground_truth": "    primary_resources, secondary_resources = _stratify_resources(resource_dict.values())", "line_class": "infile", "zero_context": true}
{"original_prediction": "                _add_synonym(synonym=synonym, prefix=prefix)", "prediction_line": "                _add_synonym(synonym=synonym, prefix=prefix)", "ground_truth": "                _add_synonym(synonym=synonym, prefix=prefix)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                _add_uri_synonym(uri_prefix=uri_prefix, prefix=prefix)", "prediction_line": "                _add_uri_synonym(uri_prefix=uri_prefix, prefix=prefix)", "ground_truth": "                _add_uri_synonym(uri_prefix=uri_prefix, prefix=prefix)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                _add_prefix_prefixes(primary_prefix=primary_prefix, resource=resource, target_prefix=prefix)", "prediction_line": "                _add_prefix_prefixes(primary_prefix=primary_prefix, resource=resource, target_prefix=prefix)", "ground_truth": "                _add_prefix_prefixes(", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    _add_synonym(synonym=synonym, prefix=has_part)", "prediction_line": "                    _add_synonym(synonym=synonym, prefix=has_part)", "ground_truth": "                    _add_synonym(synonym=synonym, prefix=has_part)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    _add_uri_synonym(uri_prefix=uri_prefix, prefix=has_part)", "prediction_line": "                    _add_uri_synonym(uri_prefix=uri_prefix, prefix=has_part)", "ground_truth": "                    _add_uri_synonym(uri_prefix=uri_prefix, prefix=has_part)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for resource in resources", "prediction_line": "        for resource in resources", "ground_truth": "        for resource in resource_dict.values()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for prefix_prefix in _iterate_prefix_prefix(resource, target_prefix):", "prediction_line": "        for prefix_prefix in _iterate_prefix_prefix(resource, target_prefix):", "ground_truth": "        for prefix_prefix in _iterate_prefix_prefix(resource, primary_prefix):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            secondary_resources.append(resource)", "prediction_line": "            secondary_resources.append(resource)", "ground_truth": "            secondary_resources.append(resource)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "prefix: str) -> None:", "prediction_line": "prefix: str) -> None:", "ground_truth": "        primary_prefix: str, resource: Resource, target_prefix: str = None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if include_prefixes:", "prediction_line": "            if include_prefixes:", "ground_truth": "            _add_synonym(synonym=resource.prefix, prefix=prefix)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                # this is a subspace of another resource", "prediction_line": "                # this is a subspace of another resource", "ground_truth": "                del primary_prefixes[resource.prefix]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                        resource=resource,", "prediction_line": "                        resource=resource,", "ground_truth": "                        resource=resource,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "for resource in resources\n    }", "prediction_line": "for resource in resources", "ground_truth": "        for resource in resources", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                continue\n            for uri_prefix in uri_prefixes:", "prediction_line": "                continue", "ground_truth": "                _add_synonym(synonym=resource.prefix, prefix=has_part)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        *extras,", "prediction_line": "        *extras,", "ground_truth": "        resource.get_preferred_prefix(),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        resource.prefix: resource.get_uri_prefix()", "prediction_line": "        resource.prefix: resource.get_uri_prefix()", "ground_truth": "        resource.prefix: cast(str, resource.get_uri_prefix(priority=uri_prefix_priority))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for uri_prefix in resource.get_uri_prefixes():", "prediction_line": "        for uri_prefix in resource.get_uri_prefixes():", "ground_truth": "        for uri_prefix in resource.get_uri_prefixes():", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if reverse_uri_prefix_lookup[prefix_prefix] == target_prefix:", "prediction_line": "                if reverse_uri_prefix_lookup[prefix_prefix] == target_prefix:", "ground_truth": "                if reverse_uri_prefix_lookup[prefix_prefix] == resource.prefix:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if resource.prefix in prefix_resource_blacklist:", "prediction_line": "        if resource.prefix in prefix_resource_blacklist:", "ground_truth": "        if resource.part_of or resource.provides or resource.has_canonical:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if resource.prefix not in prefix_blacklist", "prediction_line": "        if resource.prefix not in prefix_blacklist", "ground_truth": "        if resource.get_uri_prefix() and resource.prefix not in prefix_blacklist", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    Iterable,", "prediction_line": "    Iterable,", "ground_truth": "    Iterable,", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    Iterator,", "prediction_line": "    Iterator,", "ground_truth": "    List,", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "import pyobo\nfrom tqdm import tqdm", "prediction_line": "import pyobo", "ground_truth": "from bioregistry import Resource", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "\"\"\"Generating records for :mod:`curies`.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": ")\n\nimport attr", "prediction_line": ")", "ground_truth": ")", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    primary_prefixes = set(primary_uri_prefixes)", "prediction_line": "    primary_prefixes = set(primary_uri_prefixes)", "ground_truth": "    primary_prefixes: Dict[str, str] = {", "line_class": "random", "zero_context": true}
{"original_prediction": "        reverse_uri_prefix_lookup[primary_uri_prefix] = prefix", "prediction_line": "        reverse_uri_prefix_lookup[primary_uri_prefix] = prefix", "ground_truth": "        reverse_uri_prefix_lookup[primary_uri_prefix] = prefix", "line_class": "random", "zero_context": true}
{"original_prediction": "    ) -> None:", "prediction_line": "    ) -> None:", "ground_truth": "    ) -> None:", "line_class": "random", "zero_context": true}
{"original_prediction": "    \"\"\"Stratify resources into those with and without a prefix.\"\"\"", "prediction_line": "    \"\"\"Stratify resources into those with and without a prefix.\"\"\"", "ground_truth": "    primary_resources, secondary_resources = [], []", "line_class": "random", "zero_context": true}
{"original_prediction": "        reverse_uri_prefix_lookup[uri_prefix] = prefix", "prediction_line": "        reverse_uri_prefix_lookup[uri_prefix] = prefix", "ground_truth": "        else:", "line_class": "random", "zero_context": true}
{"original_prediction": "                res = self.client.get(f\"/api/autocomplete?q={q}\")", "prediction_line": "                res = self.client.get(f\"/api/autocomplete?q={q}\")", "ground_truth": "                res = self.client.get(f\"/api/autocomplete?q={q}\")", "line_class": "common", "zero_context": true}
{"original_prediction": "                self.assertEqual(fmt, res.headers[\"Content-Type\"].split(\";\")[0])", "prediction_line": "                self.assertEqual(fmt, res.headers[\"Content-Type\"].split(\";\")[0])", "ground_truth": "                self.assertEqual(accept, res.request.headers.get(\"Accept\", []))", "line_class": "common", "zero_context": true}
{"original_prediction": "            response = self.client.get(fail_endpoint)", "prediction_line": "            response = self.client.get(fail_endpoint)", "ground_truth": "            res = self.client.get(fail_endpoint)", "line_class": "common", "zero_context": true}
{"original_prediction": "            res = self.client.get(\"/api/registry/3dmet\")", "prediction_line": "            res = self.client.get(\"/api/registry/3dmet\")", "ground_truth": "            res = self.client.get(\"/api/registry/nope\")", "line_class": "common", "zero_context": true}
{"original_prediction": "    def test_api_metacollections(self):", "prediction_line": "    def test_api_metacollections(self):", "ground_truth": "        res = self.client.get(\"/api/collection/0000001?format=context\").json()", "line_class": "common", "zero_context": true}
{"original_prediction": "            res = self.client.get(endpoint)", "prediction_line": "            res = self.client.get(endpoint)", "ground_truth": "            res = self.client.get(endpoint)", "line_class": "common", "zero_context": true}
{"original_prediction": "                res = self.client.get(url)", "prediction_line": "                res = self.client.get(url)", "ground_truth": "                res = self.client.get(url)", "line_class": "common", "zero_context": true}
{"original_prediction": "                res = self.client.get(f\"/ui/resource/{prefix}\", headers={\"Accept\": accept})", "prediction_line": "                res = self.client.get(f\"/ui/resource/{prefix}\", headers={\"Accept\": accept})", "ground_truth": "                res = self.client.get(f\"/registry/{prefix}\", headers={\"Accept\": accept})", "line_class": "common", "zero_context": true}
{"original_prediction": "        res = self.client.get(\"/search?q=chebi\")", "prediction_line": "        res = self.client.get(\"/search?q=chebi\")", "ground_truth": "        res = self.client.get(\"/api/search?q=che\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        fail_endpoint = \"/api/resource?format=FAIL\"", "prediction_line": "        fail_endpoint = \"/api/resource?format=FAIL\"", "ground_truth": "        res = self.client.get(\"/api/registry/3dmet?format=nope\")", "line_class": "common", "zero_context": true}
{"original_prediction": "        self.assert_endpoint(", "prediction_line": "        self.assert_endpoint(", "ground_truth": "        self.assert_endpoint(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            (\"/api/registry\", json.loads),", "prediction_line": "            (\"/api/registry\", json.loads),", "ground_truth": "            (\"/api/registry\", self._parse_registry_json),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            (\"/api/registry?format=json\", self._parse_registry_json),", "prediction_line": "            (\"/api/registry?format=json\", self._parse_registry_json),", "ground_truth": "            (\"/api/registry?format=json\", self._parse_registry_json),", "line_class": "infile", "zero_context": true}
{"original_prediction": "            (\"/api/registry?format=yaml\", self._parse_registry_yaml),", "prediction_line": "            (\"/api/registry?format=yaml\", self._parse_registry_yaml),", "ground_truth": "            (\"/api/registry?format=yaml\", self._parse_registry_yaml),", "line_class": "infile", "zero_context": true}
{"original_prediction": "                res = self.client.get(endpoint)", "prediction_line": "                res = self.client.get(endpoint)", "ground_truth": "                self._test_registry(endpoint, parse_func)", "line_class": "infile", "zero_context": true}
{"original_prediction": "g.query(\"\"\"SELECT ?prefix WHERE { ?resource a bioregistry.schema:0000001 ; bioregistry.schema:0000029 ?prefix }\"\"\"))", "prediction_line": "g.query(\"\"\"SELECT ?prefix WHERE { ?resource a bioregistry.schema:0000001 ; bioregistry.schema:0000029 ?prefix }\"\"\"))", "ground_truth": "                    g.query(\"SELECT ?s WHERE { ?s a <https://bioregistry.io/schema/#0000001> }\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        cls.fastapi = get_app()", "prediction_line": "        cls.fastapi = get_app()", "ground_truth": "        cls.fastapi = get_app()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        for prefix, description, homepage, uri_format, example in graph.query(sparql):", "prediction_line": "        for prefix, description, homepage, uri_format, example in graph.query(sparql):", "ground_truth": "        for record in graph.query(sparql):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            rv[prefix] = Resource(", "prediction_line": "            rv[prefix] = Resource(", "ground_truth": "            rv[prefix] = Resource(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self.assertIn(\"chembl.compound\", registry)", "prediction_line": "        self.assertIn(\"chembl.compound\", registry)", "ground_truth": "        self.assertEqual(\"CHEBI\", registry[\"chebi\"].get_preferred_prefix())", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return {k: Resource.from_dict(v) for k, v in data}", "prediction_line": "        return {k: Resource.from_dict(v) for k, v in data}", "ground_truth": "        return {key: Resource.parse_obj(resource) for key, resource in data}", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            with self.subTest(q=q):", "prediction_line": "            with self.subTest(q=q):", "ground_truth": "            with self.subTest(query=q):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def test_api_metrics(self):", "prediction_line": "    def test_api_metrics(self):", "ground_truth": "    def assert_endpoint(self, endpoint: str, formats: List[str]) -> None:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       self.assertEqual(", "prediction_line": "       self.assertEqual(", "ground_truth": "    def test_autocomplete(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "SELECT ?key ?prefix ?name ?homepage ?description ?provides ?provides_for", "prediction_line": "SELECT ?key ?prefix ?name ?homepage ?description ?provides ?provides_for", "ground_truth": "        SELECT ?prefix ?description ?homepage ?uri_format ?example", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        \"\"\"Test the reference endpoint.\"\"\"", "prediction_line": "        \"\"\"Test the reference endpoint.\"\"\"", "ground_truth": "        \"\"\"Test the reference endpoint.\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        response = self.client.get(fail_endpoint)", "prediction_line": "        response = self.client.get(fail_endpoint)", "ground_truth": "        with self.subTest(endpoint=fail_endpoint):", "line_class": "random", "zero_context": true}
{"original_prediction": "            self.assertIsInstance(res.text, str)", "prediction_line": "            self.assertIsInstance(res.text, str)", "ground_truth": "        for fmt in formats:", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"/api/metaregistry\",", "prediction_line": "            \"/api/metaregistry\",", "ground_truth": "            \"/api/metaregistry\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            lambda res: Resource.parse_obj(yaml.safe_load(res.text)),", "prediction_line": "            lambda res: Resource.parse_obj(yaml.safe_load(res.text)),", "ground_truth": "        )", "line_class": "random", "zero_context": true}
{"original_prediction": "    def test_ui_resource_json(self):", "prediction_line": "    def test_ui_resource_json(self):", "ground_truth": "                g = rdflib.Graph()", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(VOYAGES_CONGESTION_BREAKDOWN, CongestionBreakdownResult)", "prediction_line": "        super().__init__(VOYAGES_CONGESTION_BREAKDOWN, CongestionBreakdownResult)", "ground_truth": "        Search.__init__(self, VOYAGES_CONGESTION_BREAKDOWN)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return self._get(params=api_params, result_class=CongestionBreakdownResult)", "prediction_line": "        return self._get(params=api_params, result_class=CongestionBreakdownResult)", "ground_truth": "        return CongestionBreakdownResult(super().search(**api_params))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            \"commitment_status\": convert_to_list(commitment_status),", "prediction_line": "            \"commitment_status\": convert_to_list(commitment_status),", "ground_truth": "            \"commitment_status\": convert_to_list(commitment_status),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"exclude_overlapping_entries\": exclude_overlapping_entries,", "prediction_line": "            \"exclude_overlapping_entries\": exclude_overlapping_entries,", "ground_truth": "            \"products\": convert_to_list(products),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"destinations\": convert_to_list(destinations),", "prediction_line": "            \"destinations\": convert_to_list(destinations),", "ground_truth": "            \"destinations\": convert_to_list(destinations),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"breakdown_property\": breakdown_property,", "prediction_line": "            \"breakdown_property\": breakdown_property,", "ground_truth": "            \"voyage_id\": convert_to_list(voyage_id),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessel_owners\": convert_to_list(vessel_owners),", "prediction_line": "            \"vessel_owners\": convert_to_list(vessel_owners),", "ground_truth": "            \"vessel_owners\": convert_to_list(vessel_owners),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"commitment_status_excluded\": convert_to_list(commitment_status_excluded),", "prediction_line": "            \"commitment_status_excluded\": convert_to_list(commitment_status_excluded),", "ground_truth": "            \"commitment_status_excluded\": convert_to_list(commitment_status_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"flags_excluded\": convert_to_list(flags_excluded),", "prediction_line": "            \"flags_excluded\": convert_to_list(flags_excluded),", "ground_truth": "            \"flags_excluded\": convert_to_list(flags_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessel_risk_level_excluded\": convert_to_list(vessel_risk_level_excluded),", "prediction_line": "            \"vessel_risk_level_excluded\": convert_to_list(vessel_risk_level_excluded),", "ground_truth": "            \"vessel_risk_level_excluded\": convert_to_list(vessel_risk_level_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessel_propulsion_excluded\": convert_to_list(vessel_propulsion_excluded),", "prediction_line": "            \"vessel_propulsion_excluded\": convert_to_list(vessel_propulsion_excluded),", "ground_truth": "            \"vessel_propulsion_excluded\": convert_to_list(vessel_propulsion_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        vessel_scrubbers_excluded: str = None,", "prediction_line": "        vessel_scrubbers_excluded: str = None,", "ground_truth": "        vessels_tags: Union[Tag, List[Tag]] = None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessels\": convert_to_list(vessels),", "prediction_line": "            \"vessels\": convert_to_list(vessels),", "ground_truth": "            \"flags\": convert_to_list(flags),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"products_excluded\": convert_to_list(products_excluded),", "prediction_line": "            \"products_excluded\": convert_to_list(products_excluded),", "ground_truth": "            \"latest_products\": convert_to_list(latest_products),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessel_risk_level\": convert_to_list(vessel_risk_level),", "prediction_line": "            \"vessel_risk_level\": convert_to_list(vessel_risk_level),", "ground_truth": "            \"vessel_risk_level\": convert_to_list(vessel_risk_level),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessels\": convert_to_list(vessels),", "prediction_line": "            \"vessels\": convert_to_list(vessels),", "ground_truth": "            \"vessels\": convert_to_list(vessels),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"charterers_excluded\": convert_to_list(charterers_excluded),", "prediction_line": "            \"charterers_excluded\": convert_to_list(charterers_excluded),", "ground_truth": "            \"charterers_excluded\": convert_to_list(charterers_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    \"\"\"\n    Get congestion breakdowns for voyages.", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            vessels_tags: ", "prediction_line": "            vessels_tags: ", "ground_truth": "            vessels_tags:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        [\n            {", "prediction_line": "        [", "ground_truth": "        [", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    'label': 'France',", "prediction_line": "                    'label': 'France',", "ground_truth": "                    'label': 'Germany',", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def __init__(self, start_date: datetime, end_date: datetime, **kwargs):", "prediction_line": "    def __init__(self, start_date: datetime, end_date: datetime, **kwargs):", "ground_truth": "    def __init__(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        latest_products_only: bool = None,", "prediction_line": "        latest_products_only: bool = None,", "ground_truth": "        charterers: Union[ID, List[ID]] = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "        vessel_type: Union[ID, List[ID]] = None,", "prediction_line": "        vessel_type: Union[ID, List[ID]] = None,", "ground_truth": "        vessel_age_min: int = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "        vessel_wait_time_max: int = None,", "prediction_line": "        vessel_wait_time_max: int = None,", "ground_truth": "        vessel_wait_time_max: int = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "        port_id: Union[ID, List[ID]] = None,", "prediction_line": "        port_id: Union[ID, List[ID]] = None,", "ground_truth": "        movement_status: Union[str, List[str]] = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "        port_id: Union[ID, List[ID]] = None,", "prediction_line": "        port_id: Union[ID, List[ID]] = None,", "ground_truth": "        voyage_status: Union[str, List[str]] = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "        VoyageCargoEvent(**event)", "prediction_line": "        VoyageCargoEvent(**event)", "ground_truth": "        VoyageCargoEvent(**event)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        VoyageStatusEvent(**event)", "prediction_line": "        VoyageStatusEvent(**event)", "ground_truth": "        VoyageStatusEvent(**event)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        expected = VoyageVesselEvent(", "prediction_line": "        expected = VoyageVesselEvent(", "ground_truth": "        VoyageVesselEvent(**event)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "from vortexasdk.api.voyages import (", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def test_serialize_voyage_cargo_event(self):", "prediction_line": "    def test_serialize_voyage_cargo_event(self):", "ground_truth": "    def test_serialize_voyage_cargo_event(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "class Voyages:", "prediction_line": "class Voyages:", "ground_truth": "class TestVoyageEvents:", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                {\n                    \"id\": \"4534ce5267a46804\",", "prediction_line": "                {", "ground_truth": "                {", "line_class": "random", "zero_context": true}
{"original_prediction": "                },\n                {", "prediction_line": "                },", "ground_truth": "                },", "line_class": "random", "zero_context": true}
{"original_prediction": "                    \"id\": \"470ac6a8077e1480\",", "prediction_line": "                    \"id\": \"470ac6a8077e1480\",", "ground_truth": "                    \"id\": \"a07eaa030bfe925e\",", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"event_group\": \"cargo\",", "prediction_line": "            \"event_group\": \"cargo\",", "ground_truth": "            \"event_group\": \"derived\",", "line_class": "random", "zero_context": true}
{"original_prediction": "                    \"layer\": \"trading_subregion\",", "prediction_line": "                    \"layer\": \"trading_subregion\",", "ground_truth": "                    \"layer\": \"trading_subregion\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__()", "prediction_line": "        super().__init__()", "ground_truth": "        Search.__init__(self, VOYAGES_SEARCH)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        return VoyagesSearchResult(self._get(self._url, params=api_params))", "prediction_line": "        return VoyagesSearchResult(self._get(self._url, params=api_params))", "ground_truth": "        return VoyagesSearchResult(super().search(headers=self._HEADERS, **api_params))", "line_class": "infile", "zero_context": true}
{"original_prediction": "            \"vessels_excluded\": convert_to_list(vessels_excluded),", "prediction_line": "            \"vessels_excluded\": convert_to_list(vessels_excluded),", "ground_truth": "            \"vessels_excluded\": convert_to_list(vessels_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"latest_products_excluded\": convert_to_list(latest_products_excluded),", "prediction_line": "            \"latest_products_excluded\": convert_to_list(latest_products_excluded),", "ground_truth": "            \"latest_products_excluded\": convert_to_list(latest_products_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"destinations_excluded\": convert_to_list(destinations_excluded),", "prediction_line": "            \"destinations_excluded\": convert_to_list(destinations_excluded),", "ground_truth": "            \"destinations_excluded\": convert_to_list(destinations_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessels\": convert_to_list(vessels),", "prediction_line": "            \"vessels\": convert_to_list(vessels),", "ground_truth": "            \"vessels\": convert_to_list(vessels),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"origins_excluded\": convert_to_list(origins_excluded),", "prediction_line": "            \"origins_excluded\": convert_to_list(origins_excluded),", "ground_truth": "            \"origins_excluded\": convert_to_list(origins_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessels_tags\": convert_to_list(vessels_tags),", "prediction_line": "            \"vessels_tags\": convert_to_list(vessels_tags),", "ground_truth": "            \"vessels_tags\": convert_to_list(vessels_tags),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"commitment_status\": convert_to_list(commitment_status),", "prediction_line": "            \"commitment_status\": convert_to_list(commitment_status),", "ground_truth": "            \"commitment_status\": convert_to_list(commitment_status),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessel_owners_excluded\": convert_to_list(vessel_owners_excluded),", "prediction_line": "            \"vessel_owners_excluded\": convert_to_list(vessel_owners_excluded),", "ground_truth": "            \"vessel_owners_excluded\": convert_to_list(vessel_owners_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"time_min\": to_ISODate(time_min),", "prediction_line": "            \"time_min\": to_ISODate(time_min),", "ground_truth": "            \"time_max\": to_ISODate(time_max) if time_max else None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"commitment_status_excluded\": convert_to_list(commitment_status_excluded),", "prediction_line": "            \"commitment_status_excluded\": convert_to_list(commitment_status_excluded),", "ground_truth": "            \"commitment_status_excluded\": convert_to_list(commitment_status_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"movement_status_excluded\": convert_to_list(movement_status_excluded),", "prediction_line": "            \"movement_status_excluded\": convert_to_list(movement_status_excluded),", "ground_truth": "            \"cargo_status_excluded\": convert_to_list(cargo_status_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessel_risk_level\": convert_to_list(vessel_risk_level),", "prediction_line": "            \"vessel_risk_level\": convert_to_list(vessel_risk_level),", "ground_truth": "            \"vessel_risk_level\": convert_to_list(vessel_risk_level),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessel_owners_excluded\": convert_to_list(vessel_owners_excluded),", "prediction_line": "            \"vessel_owners_excluded\": convert_to_list(vessel_owners_excluded),", "ground_truth": "            \"voyage_status_excluded\": convert_to_list(voyage_status_excluded),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"vessel_propulsion\": convert_to_list(vessel_propulsion),", "prediction_line": "            \"vessel_propulsion\": convert_to_list(vessel_propulsion),", "ground_truth": "            \"vessel_propulsion\": convert_to_list(vessel_propulsion),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"time_min\": to_ISODate(time_min),", "prediction_line": "            \"time_min\": to_ISODate(time_min),", "ground_truth": "            \"voyage_id\": convert_to_list(voyage_id),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            ]\n        )", "prediction_line": "            ]", "ground_truth": "            ])", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    'count': 337", "prediction_line": "                    'count': 337", "ground_truth": "                    'count': 405", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                    'value': 88000000,", "prediction_line": "                    'value': 88000000,", "ground_truth": "                    'value': 86652291,", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            vessels_excluded: ", "prediction_line": "            vessels_excluded: ", "ground_truth": "            vessels_excluded: ", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            location_status_excluded: ", "prediction_line": "            location_status_excluded: ", "ground_truth": "            location_status_excluded: ", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        page: int = None,", "prediction_line": "        page: int = None,", "ground_truth": "        offset: int = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "        vessel_type: Union[ID, List[ID]] = None,", "prediction_line": "        vessel_type: Union[ID, List[ID]] = None,", "ground_truth": "        vessel_age_min: int = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"destination_behaviour\": destination_behaviour,", "prediction_line": "            \"destination_behaviour\": destination_behaviour,", "ground_truth": "            \"destination_behaviour\": destination_behaviour,", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"time_min\": to_ISODate(time_min),", "prediction_line": "            \"time_min\": to_ISODate(time_min),", "ground_truth": "            \"exclude_overlapping_entries\": exclude_overlapping_entries,", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"unit\": unit,", "prediction_line": "            \"unit\": unit,", "ground_truth": "            \"unit\": unit,", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__()", "prediction_line": "        super().__init__()", "ground_truth": "        Search.__init__(self, VESSEL_CLASS_BREAKDOWN_RESOURCE)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            \"filter_owners\": convert_to_list(filter_owners),", "prediction_line": "            \"filter_owners\": convert_to_list(filter_owners),", "ground_truth": "            \"filter_vessel_flags\": convert_to_list(filter_vessel_flags),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        exclude_vessel_tags: Union[List[Tag], Tag] = None,", "prediction_line": "        exclude_vessel_tags: Union[List[Tag], Tag] = None,", "ground_truth": "        exclude_vessel_tags: Union[List[Tag], Tag] = None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        filter_vessel_scrubbers_min: int = None,", "prediction_line": "        filter_vessel_scrubbers_min: int = None,", "ground_truth": "        filter_vessel_tags: Union[List[Tag], Tag] = None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_vessel_flags\": convert_to_list(exclude_vessel_flags),", "prediction_line": "            \"filter_vessel_flags\": convert_to_list(exclude_vessel_flags),", "ground_truth": "            \"filter_origins\": convert_to_list(exclude_origins),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_waypoints\": convert_to_list(exclude_waypoints),", "prediction_line": "            \"filter_waypoints\": convert_to_list(exclude_waypoints),", "ground_truth": "            \"filter_waypoints\": convert_to_list(exclude_waypoints),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_origins\": convert_to_list(exclude_origins),", "prediction_line": "            \"filter_origins\": convert_to_list(exclude_origins),", "ground_truth": "            \"filter_vessels\": convert_to_list(exclude_vessels),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_charterers\": convert_to_list(filter_charterers),", "prediction_line": "            \"filter_charterers\": convert_to_list(filter_charterers),", "ground_truth": "            \"filter_destinations\": convert_to_list(filter_destinations),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_origins\": convert_to_list(exclude_origins),", "prediction_line": "            \"filter_origins\": convert_to_list(exclude_origins),", "ground_truth": "            \"filter_products\": convert_to_list(exclude_products),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_origins\": convert_to_list(filter_origins),", "prediction_line": "            \"filter_origins\": convert_to_list(filter_origins),", "ground_truth": "            \"filter_origins\": convert_to_list(filter_origins),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_time_max\": to_ISODate(filter_time_max),", "prediction_line": "            \"filter_time_max\": to_ISODate(filter_time_max),", "ground_truth": "            \"filter_time_max\": to_ISODate(filter_time_max),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return ReferenceBreakdownResult(", "prediction_line": "        return ReferenceBreakdownResult(", "ground_truth": "        return ReferenceBreakdownResult(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_storage_locations\": convert_to_list(exclude_storage_locations),", "prediction_line": "            \"filter_storage_locations\": convert_to_list(exclude_storage_locations),", "ground_truth": "            \"filter_flags\": convert_to_list(exclude_vessel_flags),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return ReferenceBreakdownResult(", "prediction_line": "        return ReferenceBreakdownResult(", "ground_truth": "        response = super().search_with_client(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        }\n\n        api_params.update(exclude_params)", "prediction_line": "        }", "ground_truth": "            \"vessel_tags_excluded\": convert_to_list(exclude_vessel_tags),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_storage_locations\": convert_to_list(", "prediction_line": "            \"filter_storage_locations\": convert_to_list(", "ground_truth": "            \"filter_charterers\": convert_to_list(filter_charterers),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "             exclude_vessels: A vessel ID, or list of vessel IDs to exclude.", "prediction_line": "             exclude_vessels: A vessel ID, or list of vessel IDs to exclude.", "ground_truth": "             exclude_vessel_flags: A vessel flag ID, or list of vessel flag IDs to exclude.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "             A `ReferenceBreakdownResult` object.", "prediction_line": "             A `ReferenceBreakdownResult` object.", "ground_truth": "         `ReferenceBreakdownResult`", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        :param breakdown_unit_average_basis: The basis to use for the breakdown unit average.", "prediction_line": "        :param breakdown_unit_average_basis: The basis to use for the breakdown unit average.", "ground_truth": "         # Arguments", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        breakdown_unit_type: str = None,", "prediction_line": "        breakdown_unit_type: str = None,", "ground_truth": "        filter_activity: str = \"any_activity\",", "line_class": "random", "zero_context": true}
{"original_prediction": "        start_date: datetime,", "prediction_line": "        start_date: datetime,", "ground_truth": "        breakdown_unit_average_basis: str = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "                filter_ship_to_ship_locations", "prediction_line": "                filter_ship_to_ship_locations", "ground_truth": "                filter_ship_to_ship_locations", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"filter_vessel_age_max\": filter_vessel_age_max,", "prediction_line": "            \"filter_vessel_age_max\": filter_vessel_age_max,", "ground_truth": "            \"filter_vessel_age_max\": filter_vessel_age_max,", "line_class": "random", "zero_context": true}
{"original_prediction": "            ),\n            \"filter_vessel_tags\": convert_to_list(exclude_vessel_tags),", "prediction_line": "            ),", "ground_truth": "            ),", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(PARENT_PRODUCT_BREAKDOWN_RESOURCE)", "prediction_line": "        super().__init__(PARENT_PRODUCT_BREAKDOWN_RESOURCE)", "ground_truth": "        Search.__init__(self, PARENT_PRODUCT_BREAKDOWN_RESOURCE)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            \"exclude_destinations\": convert_to_list(exclude_destinations),", "prediction_line": "            \"exclude_destinations\": convert_to_list(exclude_destinations),", "ground_truth": "            \"vessel_tags_excluded\": convert_to_list(exclude_vessel_tags),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_storage_locations\": convert_to_list(", "prediction_line": "            \"filter_storage_locations\": convert_to_list(", "ground_truth": "            \"filter_storage_locations\": convert_to_list(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_ice_class\": convert_to_list(exclude_vessel_ice_class),", "prediction_line": "            \"filter_ice_class\": convert_to_list(exclude_vessel_ice_class),", "ground_truth": "            \"filter_vessel_ice_class\": convert_to_list(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_vessel_classes\": convert_to_list(exclude_vessel_classes),", "prediction_line": "            \"filter_vessel_classes\": convert_to_list(exclude_vessel_classes),", "ground_truth": "            \"filter_charterers\": convert_to_list(exclude_charterers),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        filter_vessel_scrubbers_min: int = None,", "prediction_line": "        filter_vessel_scrubbers_min: int = None,", "ground_truth": "        filter_vessel_tags: Union[List[Tag], Tag] = None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_origins\": convert_to_list(exclude_origins),", "prediction_line": "            \"filter_origins\": convert_to_list(exclude_origins),", "ground_truth": "            \"filter_products\": convert_to_list(exclude_products),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_ship_to_ship\": convert_to_list(", "prediction_line": "            \"filter_ship_to_ship\": convert_to_list(", "ground_truth": "            \"filter_ship_to_ship_locations\": convert_to_list(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_vessel_classes\": convert_to_list(exclude_vessel_classes),", "prediction_line": "            \"filter_vessel_classes\": convert_to_list(exclude_vessel_classes),", "ground_truth": "            \"filter_vessel_classes\": convert_to_list(exclude_vessel_classes),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return ReferenceBreakdownResult(", "prediction_line": "        return ReferenceBreakdownResult(", "ground_truth": "        return ReferenceBreakdownResult(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_vessel_flags\": convert_to_list(exclude_vessel_flags),", "prediction_line": "            \"filter_vessel_flags\": convert_to_list(exclude_vessel_flags),", "ground_truth": "            \"filter_flags\": convert_to_list(exclude_vessel_flags),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_vessel_propulsion\": convert_to_list(", "prediction_line": "            \"filter_vessel_propulsion\": convert_to_list(", "ground_truth": "            \"filter_vessel_propulsion\": convert_to_list(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_vessel_classes\": convert_to_list(filter_vessel_classes),", "prediction_line": "            \"filter_vessel_classes\": convert_to_list(filter_vessel_classes),", "ground_truth": "            \"filter_vessel_classes\": convert_to_list(filter_vessel_classes),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        exclude_vessel_scrubbers: str = \"disabled\",", "prediction_line": "        exclude_vessel_scrubbers: str = \"disabled\",", "ground_truth": "        exclude_vessel_tags: Union[List[Tag], Tag] = None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_vessel_flags\": convert_to_list(exclude_vessel_flags),", "prediction_line": "            \"filter_vessel_flags\": convert_to_list(exclude_vessel_flags),", "ground_truth": "            \"filter_owners\": convert_to_list(exclude_owners),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            \"filter_origins\": convert_to_list(exclude_origins),", "prediction_line": "            \"filter_origins\": convert_to_list(exclude_origins),", "ground_truth": "            \"filter_vessels\": convert_to_list(exclude_vessels),", "line_class": "inproject", "zero_context": true}
{"original_prediction": "#include \"../include/crux/net.h\"", "prediction_line": "#include \"../include/crux/net.h\"", "ground_truth": "\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "         >>> from datetime import datetime", "prediction_line": "         >>> from datetime import datetime", "ground_truth": "         >>> start = datetime(2019, 11, 10)", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "             filter_vessel_propulsion: A propulsion ID, or list of propulsion IDs to filter on.", "prediction_line": "             filter_vessel_propulsion: A propulsion ID, or list of propulsion IDs to filter on.", "ground_truth": "             filter_vessel_propulsion: An propulsion means ID, or list of propulsion means IDs to filter on.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "             exclude_charterers: An commercial entity ID, or list of commercial entity IDs to exclude.", "prediction_line": "             exclude_charterers: An commercial entity ID, or list of commercial entity IDs to exclude.", "ground_truth": "             exclude_vessel_location: A location ID, or list of location IDs to exclude.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "             filter_products: The product ID(s) to filter on.", "prediction_line": "             filter_products: The product ID(s) to filter on.", "ground_truth": "             filter_effective_controllers: An effective controller ID, or list of effective controller IDs to filter on.", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        exclude_charterers: Union[ID, List[ID]] = None,", "prediction_line": "        exclude_charterers: Union[ID, List[ID]] = None,", "ground_truth": "        exclude_vessels: Union[ID, List[ID]] = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "                filter_ship_to_ship_locations", "prediction_line": "                filter_ship_to_ship_locations", "ground_truth": "                filter_ship_to_ship_locations", "line_class": "random", "zero_context": true}
{"original_prediction": "        filter_ports_of_call: Union[ID, List[ID]] = None,", "prediction_line": "        filter_ports_of_call: Union[ID, List[ID]] = None,", "ground_truth": "        filter_storage_locations: Union[ID, List[ID]] = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "            \"breakdown_size\": breakdown_size,", "prediction_line": "            \"breakdown_size\": breakdown_size,", "ground_truth": "            \"breakdown_size\": breakdown_size,", "line_class": "random", "zero_context": true}
{"original_prediction": "        filter_vessel_types: Union[ID, List[ID]] = None,", "prediction_line": "        filter_vessel_types: Union[ID, List[ID]] = None,", "ground_truth": "        filter_vessel_propulsion: Union[ID, List[ID]] = None,", "line_class": "random", "zero_context": true}
{"original_prediction": "    if dir is None:", "prediction_line": "    if dir is None:", "ground_truth": "    df = _f_to_df(f)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    if is_circular(dirs):", "prediction_line": "    if is_circular(dirs):", "ground_truth": "    if is_circular(dirs):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        vmax = np.nanmax(spectrum)", "prediction_line": "        vmax = np.nanmax(spectrum)", "ground_truth": "        vmax = np.nanmax(spectrum)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        colorax = ax.pcolormesh(", "prediction_line": "        colorax = ax.pcolormesh(", "ground_truth": "        colorax = ax.pcolormesh(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        dirs = dir2", "prediction_line": "        dirs = dir2", "ground_truth": "        dirs = dir2.copy()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        directions is None or len(directions) <= 1", "prediction_line": "        directions is None or len(directions) <= 1", "ground_truth": "        directions is None or len(directions) <= 1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        fp1 = np.append(f, f[-1] * freq_factor)", "prediction_line": "        fp1 = np.append(f, f[-1] * freq_factor)", "ground_truth": "        fp1 = np.append(f, f[-1] * freq_factor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        spectrum = spec2.copy()", "prediction_line": "        spectrum = spec2.copy()", "ground_truth": "        spectrum = spec2.copy()", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if rmax is None:", "prediction_line": "    if rmax is None:", "ground_truth": "    dirs = np.radians(directions)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        colorax = ax.contour(", "prediction_line": "        colorax = ax.contour(", "ground_truth": "        colorax = ax.contour(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    freqs = frequencies", "prediction_line": "    freqs = frequencies", "ground_truth": "    freq = frequencies", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            spec2[:, j] = np.interp(dir2, dirs, spectrum[:, j])", "prediction_line": "            spec2[:, j] = np.interp(dir2, dirs, spectrum[:, j])", "ground_truth": "            spec2[:, j] = np.interp(dir2, dirs, spectrum[:, j])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        vmin = np.min(spectrum)", "prediction_line": "        vmin = np.min(spectrum)", "ground_truth": "        vmin = np.nanmin(spectrum)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   from matplotlib.ticker import FuncFormatter", "prediction_line": "   from matplotlib.ticker import FuncFormatter", "ground_truth": "    if (frequencies is None or len(frequencies) <= 1) and (", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        cf = ax.contourf(dirs, freq, spectrum, levels=levels, cmap=cmap, vmin=vmin, vmax=vmax)", "prediction_line": "        cf = ax.contourf(dirs, freq, spectrum, levels=levels, cmap=cmap, vmin=vmin, vmax=vmax)", "ground_truth": "        colorax = ax.contourf(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    if len(f) == 1:", "prediction_line": "    if len(f) == 1:", "ground_truth": "    if np.isclose(np.diff(f).min(), np.diff(f).max()):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        df = np.log(freq_factor) / np.arange(1, len(f))", "prediction_line": "        df = np.log(freq_factor) / np.arange(1, len(f))", "ground_truth": "        fm1 = np.insert(f, 0, f[0] / freq_factor)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    cmap: str, optional", "prediction_line": "    cmap: str, optional", "ground_truth": "    cmap: matplotlib.cm.cmap, optional", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    figsize: tuple(float), optional", "prediction_line": "    figsize: tuple(float), optional", "ground_truth": "    figsize: (float, float), optional", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    df = np.zeros(len(f) - 1)", "prediction_line": "    df = np.zeros(len(f) - 1)", "ground_truth": "    \"\"\"Frequency bins for equidistant or logrithmic frequency axis\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        lower bound of radial axis, default: None", "prediction_line": "        lower bound of radial axis, default: None", "ground_truth": "        mininum frequency/period to be shown, default: None", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        raise ValueError(f\"plot_type {plot_type} not supported\")", "prediction_line": "        raise ValueError(f\"plot_type {plot_type} not supported\")", "ground_truth": "        raise ValueError(", "line_class": "random", "zero_context": true}
{"original_prediction": "        ee = spec[dir, :]", "prediction_line": "        ee = spec[dir, :]", "ground_truth": "        nd = len(dir)", "line_class": "random", "zero_context": true}
{"original_prediction": "    if rmax is not None:", "prediction_line": "    if rmax is not None:", "ground_truth": "    if rmax is not None:", "line_class": "random", "zero_context": true}
{"original_prediction": "        levels = 10", "prediction_line": "        levels = 10", "ground_truth": "        levels = 10", "line_class": "random", "zero_context": true}
{"original_prediction": "        freq = 1 / freq", "prediction_line": "        freq = 1 / freq", "ground_truth": "        freq = 1.0 / np.flip(freq)", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert dfs.n_sigma_layers == 10", "prediction_line": "    assert dfs.n_sigma_layers == 10", "ground_truth": "    assert dfs.n_sigma_layers == 10", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ds.write(outfilename)", "prediction_line": "    ds.write(outfilename)", "ground_truth": "    ds.to_dfs(outfilename)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   assert len(ds.time) == 1", "prediction_line": "   assert len(ds.time) == 1", "ground_truth": "    assert ds.items[0].name != \"Z coordinate\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    ds.to_dfs(outfilename, time=[0, 1])", "prediction_line": "    ds.to_dfs(outfilename, time=[0, 1])", "ground_truth": "    assert ds._zn is not None", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    elem_ids = dfs.get_layer_elements(1)", "prediction_line": "    elem_ids = dfs.get_layer_elements(1)", "ground_truth": "    elem_ids = dfs.get_layer_elements([0, 2])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   dfs.to_mesh(outfilename)", "prediction_line": "   dfs.to_mesh(outfilename)", "ground_truth": "    dfs.to_mesh(outfilename)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_find_nearest_elements_2d():", "prediction_line": "def test_find_nearest_elements_2d():", "ground_truth": "    assert elem_id in dfs.top_elements", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert len(dfs.bottom_elements) == 3700", "prediction_line": "    assert len(dfs.bottom_elements) == 3700", "ground_truth": "    assert len(dfs.bottom_elements) == 3700", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert dfs.n_sigma_layers == 9", "prediction_line": "    assert dfs.n_sigma_layers == 9", "ground_truth": "    assert dfs.n_sigma_layers == 4", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    elem_ids = dfs.find_nearest_profile_elements(333934.1, 6158101.5)", "prediction_line": "    elem_ids = dfs.find_nearest_profile_elements(333934.1, 6158101.5)", "ground_truth": "    elem_ids = dfs.find_nearest_profile_elements(358337, 6196090)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert el2dindx == 2", "prediction_line": "    assert el2dindx == 2", "ground_truth": "    table = dfs.e2_e3_table[el2dindx]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    dfs.write(outfilename, ds)", "prediction_line": "    dfs.write(outfilename, ds)", "ground_truth": "    dfs.write(outfilename, ds)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   dfs.write(outfilename)", "prediction_line": "   dfs.write(outfilename)", "ground_truth": "    ds = dfs.read(items=[0, 1])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    assert ds.items[1].name == \"Salinity\"", "prediction_line": "    assert ds.items[1].name == \"Salinity\"", "ground_truth": "    assert ds.items[1].name == \"Salinity\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    n_top2 = len(dfs2.top_elements)", "prediction_line": "    n_top2 = len(dfs2.top_elements)", "ground_truth": "    assert dfs2.n_elements == n_top1", "line_class": "inproject", "zero_context": true}
{"original_prediction": "def test_find_nearest_elements_in_Zlayer():", "prediction_line": "def test_find_nearest_elements_in_Zlayer():", "ground_truth": "def test_dataset_write_dfsu3d(tmp_path):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "def test_n_sigma_layers_2d():", "prediction_line": "def test_n_sigma_layers_2d():", "ground_truth": "def test_n_z_layers():", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    filename = os.path.join(\"tests\", \"testdata\", \"basin_3d.dfsu\")", "prediction_line": "    filename = os.path.join(\"tests\", \"testdata\", \"basin_3d.dfsu\")", "ground_truth": "    filename = os.path.join(\"tests\", \"testdata\", \"basin_3d.dfsu\")", "line_class": "random", "zero_context": true}
{"original_prediction": "   filename = os.path.join(\"tests\", \"testdata\", \"oresund_sigma_z.dfsu\")", "prediction_line": "   filename = os.path.join(\"tests\", \"testdata\", \"oresund_sigma_z.dfsu\")", "ground_truth": "    sourcefilename = os.path.join(\"tests\", \"testdata\", \"basin_3d.dfsu\")", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert areas[0] == pytest.approx(1.0)", "prediction_line": "    assert areas[0] == pytest.approx(1.0)", "ground_truth": "    assert areas[0] == 350186.43530453625", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert not hasattr(dfs, \"n_z_layers\")", "prediction_line": "    assert not hasattr(dfs, \"n_z_layers\")", "ground_truth": "    assert not hasattr(dfs, \"n_z_layers\")", "line_class": "random", "zero_context": true}
{"original_prediction": "    assert os.path.exists(outfilename)", "prediction_line": "    assert os.path.exists(outfilename)", "ground_truth": "    assert os.path.exists(outfilename)", "line_class": "random", "zero_context": true}
{"original_prediction": "        \"\"\"create equidistant x-axis\"\"\"", "prediction_line": "        \"\"\"create equidistant x-axis\"\"\"", "ground_truth": "        self._x1 = x0 + dx * (nx - 1)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    dx, dy = dxdy", "prediction_line": "                    dx, dy = dxdy", "ground_truth": "                    dx, dy = dxdy", "line_class": "infile", "zero_context": true}
{"original_prediction": "        xinner = np.insert(xinner, 0, x[0])", "prediction_line": "        xinner = np.insert(xinner, 0, x[0])", "ground_truth": "        left = x[0] - (x[1] - x[0]) / 2", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if nx is None:", "prediction_line": "                if nx is None:", "ground_truth": "                if nx is None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._create_meshgrid(self.x, self.y)", "prediction_line": "            self._create_meshgrid(self.x, self.y)", "ground_truth": "            self._create_meshgrid(self.x, self.y)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        bottom = self._y0 - self.dy / 2", "prediction_line": "        bottom = self._y0 - self.dy / 2", "ground_truth": "        bottom = self._y0 - self.dy / 2", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._x = np.linspace(left + dx / 2, right - dx / 2, nx)", "prediction_line": "        self._x = np.linspace(left + dx / 2, right - dx / 2, nx)", "ground_truth": "                nx = int(np.ceil(xr / dx))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        yn = Grid2D._centers_to_nodes(self.y)", "prediction_line": "        yn = Grid2D._centers_to_nodes(self.y)", "ground_truth": "        yn = Grid2D._centers_to_nodes(self.y)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                nx = int(np.ceil(ny * xr / yr))", "prediction_line": "                nx = int(np.ceil(ny * xr / yr))", "ground_truth": "                nx = int(np.ceil(ny * xr / yr))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._ny = ny", "prediction_line": "        self._ny = ny", "ground_truth": "        self._ny = ny", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._dx = x[1] - x[0]", "prediction_line": "        self._dx = x[1] - x[0]", "ground_truth": "        self._x1 = x[-1]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            else:\n                nx = int(np.ceil(xr / dxdy[0]))", "prediction_line": "            else:", "ground_truth": "                dx = xr / nx", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._x1 = right - dx / 2", "prediction_line": "        self._x1 = right - dx / 2", "ground_truth": "        self._dx = dx", "line_class": "infile", "zero_context": true}
{"original_prediction": "        top = self._y1 + self.dy / 2", "prediction_line": "        top = self._y1 + self.dy / 2", "ground_truth": "        top = self._y1 + self.dy / 2", "line_class": "infile", "zero_context": true}
{"original_prediction": "                # x-axis is smaller, use x-spacing", "prediction_line": "                # x-axis is smaller, use x-spacing", "ground_truth": "                nx = 10", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if shape is not None:", "prediction_line": "        if shape is not None:", "ground_truth": "        if dy is not None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._x = np.linspace(left + dx / 2, right - dx / 2, nx)", "prediction_line": "        self._x = np.linspace(left + dx / 2, right - dx / 2, nx)", "ground_truth": "        self._x0 = left + dx / 2", "line_class": "infile", "zero_context": true}
{"original_prediction": "                    dx = dy = dxdy", "prediction_line": "                    dx = dy = dxdy", "ground_truth": "                    dy = dx = dxdy", "line_class": "infile", "zero_context": true}
{"original_prediction": "                # 4 corners", "prediction_line": "                # 4 corners", "ground_truth": "                n1 = ely * self.nx + elx + index_base", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._dx = x[1] - x[0]", "prediction_line": "        self._dx = x[1] - x[0]", "ground_truth": "        self._dx = x[1] - x[0]", "line_class": "infile", "zero_context": true}
{"original_prediction": "                if ny is None:", "prediction_line": "                if ny is None:", "ground_truth": "                if ny is None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return (x[:-1] + x[1:]) / 2", "prediction_line": "        return (x[:-1] + x[1:]) / 2", "ground_truth": "        xinner = (x[1:] + x[:-1]) / 2", "line_class": "infile", "zero_context": true}
{"original_prediction": "           else:\n                bbox = x", "prediction_line": "           else:", "ground_truth": "        if bbox is not None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for j in range(self.ny):", "prediction_line": "        for j in range(self.ny):", "ground_truth": "        for elx in range(self.nx - 1):", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._x = np.linspace(x0, self._x1, nx)", "prediction_line": "        self._x = np.linspace(x0, self._x1, nx)", "ground_truth": "        self._x = np.linspace(x0, self._x1, nx)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return gn.xy", "prediction_line": "        return gn.xy", "ground_truth": "        return gn.xy", "line_class": "infile", "zero_context": true}
{"original_prediction": "        right = self._x1 + self.dx / 2", "prediction_line": "        right = self._x1 + self.dx / 2", "ground_truth": "        right = self._x1 + self.dx / 2", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._dy = y[1] - y[0]", "prediction_line": "        self._dy = y[1] - y[0]", "ground_truth": "        self._dy = y[1] - y[0]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._dx = x[1] - x[0]", "prediction_line": "        self._dx = x[1] - x[0]", "ground_truth": "        self._nx = len(x)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        x_in = np.logical_and(x >= self._x0, x <= self._x1)", "prediction_line": "        x_in = np.logical_and(x >= self._x0, x <= self._x1)", "ground_truth": "        xinside = (self.bbox.left <= x) & (x <= self.bbox.right)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                ny = int(np.ceil(yr / dy))", "prediction_line": "                ny = int(np.ceil(yr / dy))", "ground_truth": "                ny = int(np.ceil(yr / dy))", "line_class": "infile", "zero_context": true}
{"original_prediction": "                raise ValueError(\"dx must be scalar if dy is given\")", "prediction_line": "                raise ValueError(\"dx must be scalar if dy is given\")", "ground_truth": "                dx = dx[0]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            x = xy[:, 0]", "prediction_line": "            x = xy[:, 0]", "ground_truth": "            xy = np.atleast_2d(xy)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return (self.x0, self.y0, self.x1, self.y1)", "prediction_line": "        return (self.x0, self.y0, self.x1, self.y1)", "ground_truth": "        left = self._x0 - self.dx / 2", "line_class": "infile", "zero_context": true}
{"original_prediction": "                n2 = n1 + 1", "prediction_line": "                n2 = n1 + 1", "ground_truth": "                n2 = (ely + 1) * self.nx + elx + index_base", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if y is None:", "prediction_line": "        if y is None:", "ground_truth": "        if y is None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        right = x[-1] + (x[-1] - x[-2]) / 2", "prediction_line": "        right = x[-1] + (x[-1] - x[-2]) / 2", "ground_truth": "        right = x[-1] + (x[-1] - x[-2]) / 2", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._y = np.linspace(y0, self._y1, ny)", "prediction_line": "        self._y = np.linspace(y0, self._y1, ny)", "ground_truth": "        self._y = np.linspace(y0, self._y1, ny)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        out.append(f\"  x0: {self.x0:.2f}\")", "prediction_line": "        out.append(f\"  x0: {self.x0:.2f}\")", "ground_truth": "        out.append(", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        out.append(f\"Grid2D: {self.nx} x {self.ny} cells\")", "prediction_line": "        out.append(f\"Grid2D: {self.nx} x {self.ny} cells\")", "ground_truth": "        out.append(\"<mikeio.Grid2D>\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                n3 = (ely + 1) * self.nx + elx + 1 + index_base", "prediction_line": "                n3 = (ely + 1) * self.nx + elx + 1 + index_base", "ground_truth": "                elem_table.append([n1, n1 + 1, n2 + 1, n2])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        bottom = xy[:, 1].min() - buffer", "prediction_line": "        bottom = xy[:, 1].min() - buffer", "ground_truth": "        bottom = xy[:, 1].min() - buffer", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                nx, ny = shape", "prediction_line": "                nx, ny = shape", "ground_truth": "                if len(shape) != 2:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                nx, ny = shape", "prediction_line": "                nx, ny = shape", "ground_truth": "                nx, ny = shape", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if dxdy is not None:", "prediction_line": "        if dxdy is not None:", "ground_truth": "        if (dxdy is None) and (shape is None):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return \"\\n\".join(out)", "prediction_line": "        return \"\\n\".join(out)", "ground_truth": "        out.append(f\"Number of grid points: {self.n}\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       x = xy[:, 0]", "prediction_line": "       x = xy[:, 0]", "ground_truth": "        left = xy[:, 0].min() - buffer", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        top = xy[:, 1].max() + buffer", "prediction_line": "        top = xy[:, 1].max() + buffer", "ground_truth": "        top = xy[:, 1].max() + buffer", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            bbox = x", "prediction_line": "            bbox = x", "ground_truth": "            if (y is None) or ((dxdy is not None) or (shape is not None)):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if dxdy is None:", "prediction_line": "            if dxdy is None:", "ground_truth": "            if shape is not None:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        xinside = (self.bbox.left <= x) & (x <= self.bbox.right)", "prediction_line": "        xinside = (self.bbox.left <= x) & (x <= self.bbox.right)", "ground_truth": "        ii = (-1) * np.ones_like(x, dtype=int)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            if (x is not None) or (y is not None):", "prediction_line": "            if (x is not None) or (y is not None):", "ground_truth": "            self._create_in_bbox(bbox, dxdy, shape)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        jj = (-1) * np.ones_like(y, dtype=int)", "prediction_line": "        jj = (-1) * np.ones_like(y, dtype=int)", "ground_truth": "        jj = (-1) * np.ones_like(x, dtype=int)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        \"\"\"n-by-2 array of x- and y-coordinates\"\"\"", "prediction_line": "        \"\"\"n-by-2 array of x- and y-coordinates\"\"\"", "ground_truth": "        \"\"\"n-by-2 array of x- and y-coordinates\"\"\"", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def x0(self):", "prediction_line": "    def x0(self):", "ground_truth": "    def x0(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "    def x1(self):", "prediction_line": "    def x1(self):", "ground_truth": "    def x1(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "            buffer = 0", "prediction_line": "            buffer = 0", "ground_truth": "            buffer = 0", "line_class": "random", "zero_context": true}
{"original_prediction": "    _y = None", "prediction_line": "    _y = None", "ground_truth": "    _y = None", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__()", "prediction_line": "        super().__init__()", "ground_truth": "        self._x_axis = None", "line_class": "random", "zero_context": true}
{"original_prediction": "        return np.array(elem_table)", "prediction_line": "        return np.array(elem_table)", "ground_truth": "        return elem_table", "line_class": "random", "zero_context": true}
{"original_prediction": "        return xinside & yinside", "prediction_line": "        return xinside & yinside", "ground_truth": "        return xinside & yinside", "line_class": "random", "zero_context": true}
{"original_prediction": "        if self.item is None:", "prediction_line": "        if self.item is None:", "ground_truth": "        return self.item.name", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @property\n    def unit(self) -> EUMUnit:", "prediction_line": "    @property", "ground_truth": "    @name.setter", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self.item.name = value", "prediction_line": "        self.item.name = value", "ground_truth": "        self.item.name = value", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.item.type", "prediction_line": "        return self.item.type", "ground_truth": "        return self.item.type", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.item.unit", "prediction_line": "        return self.item.unit", "ground_truth": "        return self.item.unit", "line_class": "infile", "zero_context": true}
{"original_prediction": "        \"\"\"\n        Return a new DataArray with the same time axis, but with a subset of the data", "prediction_line": "        \"\"\"", "ground_truth": "        da = self.copy()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if ax is None:", "prediction_line": "        if ax is None:", "ground_truth": "        if self.ndim != 1:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        ax.set_ylabel(self.item.name)", "prediction_line": "        ax.set_ylabel(self.item.name)", "ground_truth": "        ax.set_ylabel(f\"{self.name} [{self.unit.name}]\")", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.__add__(other)", "prediction_line": "        return self.__add__(other)", "ground_truth": "        return self.__add__(other)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if self.time != other.time:", "prediction_line": "            if self.time != other.time:", "ground_truth": "            return self._add_dataarray(other)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self._add_scalar(other)", "prediction_line": "            return self._add_scalar(other)", "ground_truth": "            return self._add_value(other)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.__sub__(other)", "prediction_line": "        return self.__sub__(other)", "ground_truth": "        ds = self.__mul__(-1.0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self._sub_dataarray(other)", "prediction_line": "            return self._sub_dataarray(other)", "ground_truth": "            return self._add_dataarray(other, sign=-1.0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self._add_value(other, sign=-1.0)", "prediction_line": "            return self._add_value(other, sign=-1.0)", "ground_truth": "            return self._add_value(-other)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.__mul__(other)", "prediction_line": "        return self.__mul__(other)", "ground_truth": "        return self.__mul__(other)", "line_class": "infile", "zero_context": true}
{"original_prediction": "            return self._mul_value(other)", "prediction_line": "            return self._mul_value(other)", "ground_truth": "            return self._multiply_value(other)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        da = self.copy()", "prediction_line": "        da = self.copy()", "ground_truth": "        new_da = self.copy()", "line_class": "infile", "zero_context": true}
{"original_prediction": "            data = value * self.data", "prediction_line": "            data = value * self.data", "ground_truth": "            data = value * self.data", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if data.ndim == 1:", "prediction_line": "        if data.ndim == 1:", "ground_truth": "        if not hasattr(data, \"dtype\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       \"\"\"\n        Create a DataArray object", "prediction_line": "       \"\"\"", "ground_truth": "        if not hasattr(data, \"shape\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        out.append(f\"Time: {self.time}\")", "prediction_line": "        out.append(f\"Time: {self.time}\")", "ground_truth": "        out.append(f\"Time: {self.time[0]} - {self.time[-1]}\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       da = self.copy()", "prediction_line": "       da = self.copy()", "ground_truth": "        self.data = np.flip(self.data, axis=1)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if data.ndim != 2:", "prediction_line": "        if data.ndim != 2:", "ground_truth": "        self.data: np.ndarray = data", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            data = self.data + value", "prediction_line": "            data = self.data + value", "ground_truth": "            data = value + self.data", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if not hasattr(data, \"dtype\"):", "prediction_line": "        if not hasattr(data, \"dtype\"):", "ground_truth": "        if not hasattr(data, \"ndim\"):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "       new_da.data = data", "prediction_line": "       new_da.data = data", "ground_truth": "        new_da.data = data", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self.data.ndim", "prediction_line": "        return self.data.ndim", "ground_truth": "        return self.data.ndim", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        out.append(f\"Type: {self.type}\")", "prediction_line": "        out.append(f\"Type: {self.type}\")", "ground_truth": "        out.append(f\"Dimensions: {self.shape}\")", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        return self.data.dtype", "prediction_line": "        return self.data.dtype", "ground_truth": "        return self.data.dtype", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        da.data = self.data[key]", "prediction_line": "        da.data = self.data[key]", "ground_truth": "        da.data = da.data[key]", "line_class": "inproject", "zero_context": true}
{"original_prediction": "   \"\"\"\n    A DataArray is a TimeSeries with a single item.", "prediction_line": "   \"\"\"", "ground_truth": "    deletevalue = 1.0e-35", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            dt = (self.time[1] - self.time[0]).total_seconds()", "prediction_line": "            dt = (self.time[1] - self.time[0]).total_seconds()", "ground_truth": "            if self.is_equidistant:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def is_equidistant(self) -> bool:", "prediction_line": "    def is_equidistant(self) -> bool:", "ground_truth": "    def shape(self):", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "from collections import OrderedDict", "prediction_line": "from collections import OrderedDict", "ground_truth": "from mikeio.eum import EUMType, EUMUnit, ItemInfo", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "       return f\"DataArray(name={self.name}, unit={self.unit.name}, shape={self.shape})\"", "prediction_line": "       return f\"DataArray(name={self.name}, unit={self.unit.name}, shape={self.shape})\"", "ground_truth": "        out = [\"<mikeio.DataArray>\"]", "line_class": "random", "zero_context": true}
{"original_prediction": "    @property\n    def name(self):", "prediction_line": "    @property", "ground_truth": "    @property", "line_class": "random", "zero_context": true}
{"original_prediction": "        return ds.__add__(other)", "prediction_line": "        return ds.__add__(other)", "ground_truth": "        return other + ds", "line_class": "random", "zero_context": true}
{"original_prediction": "            raise ValueError(\"Can only plot 1D data\")", "prediction_line": "            raise ValueError(\"Can only plot 1D data\")", "ground_truth": "            raise NotImplementedError()", "line_class": "random", "zero_context": true}
{"original_prediction": "        super().__init__(", "prediction_line": "        super().__init__(", "ground_truth": "        super().__init__(", "line_class": "commited", "zero_context": true}
{"original_prediction": "                cnts = np.logical_or(", "prediction_line": "                cnts = np.logical_or(", "ground_truth": "                in_domain = mp.Path(exterior.xy).contains_points(points)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            maxnodes = max(maxnodes, len(local_nodes))", "prediction_line": "            maxnodes = max(maxnodes, len(local_nodes))", "ground_truth": "            n = len(local_nodes)", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if n > maxnodes:", "prediction_line": "            if n > maxnodes:", "ground_truth": "            if n > maxnodes:", "line_class": "commited", "zero_context": true}
{"original_prediction": "                maxnodes = n", "prediction_line": "                maxnodes = n", "ground_truth": "                maxnodes = n", "line_class": "commited", "zero_context": true}
{"original_prediction": "            in_hole = mp.Path(interior.xy).contains_points(points)", "prediction_line": "            in_hole = mp.Path(interior.xy).contains_points(points)", "ground_truth": "            in_hole = mp.Path(interior.xy).contains_points(points)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        super().__init__(", "prediction_line": "        super().__init__(", "ground_truth": "        super().__init__()", "line_class": "commited", "zero_context": true}
{"original_prediction": "            xy = np.array([self._nc[polyline, 0], self._nc[polyline, 1]]).T", "prediction_line": "            xy = np.array([self._nc[polyline, 0], self._nc[polyline, 1]]).T", "ground_truth": "            xy = self.geometry2d.node_coordinates[polyline, :2]", "line_class": "commited", "zero_context": true}
{"original_prediction": "xy[1, :] - xy[0, :]) * (xy[0, 1] + xy[1, 1] + xy[2, 1])", "prediction_line": "xy[1, :] - xy[0, :]) * (xy[0, 1] + xy[1, 1] + xy[2, 1])", "ground_truth": "                np.dot(xy[:, 1], np.roll(xy[:, 0], 1))", "line_class": "commited", "zero_context": true}
{"original_prediction": "                - np.dot(xy[:, 0], np.roll(xy[:, 1], 1))", "prediction_line": "                - np.dot(xy[:, 0], np.roll(xy[:, 1], 1))", "ground_truth": "                - np.dot(xy[:, 0], np.roll(xy[:, 1], 1))", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if area > 0:", "prediction_line": "            if area > 0:", "ground_truth": "            xy = self.geometry2d.node_coordinates[poly_line, 0:2]", "line_class": "commited", "zero_context": true}
{"original_prediction": "            if area > 0:", "prediction_line": "            if area > 0:", "ground_truth": "            poly = Polyline(len(polyline), poly_line, xy, area)", "line_class": "commited", "zero_context": true}
{"original_prediction": "        path = mp.Path(exterior)", "prediction_line": "        path = mp.Path(exterior)", "ground_truth": "        cnts = mp.Path(exterior.xy).contains_points(points)", "line_class": "commited", "zero_context": true}
{"original_prediction": "           face_remains = np.delete(face_remains, index_to_delete, axis=0)", "prediction_line": "           face_remains = np.delete(face_remains, index_to_delete, axis=0)", "ground_truth": "            face_remains = np.delete(face_remains, index_to_delete, axis=0)", "line_class": "common", "zero_context": true}
{"original_prediction": "        # calculate center coordinates", "prediction_line": "        # calculate center coordinates", "ground_truth": "        n_elements = len(element_table)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for i, local_nodes in enumerate(element_table):", "prediction_line": "        for i, local_nodes in enumerate(element_table):", "ground_truth": "        nnodes_per_elem = np.zeros(n_elements)", "line_class": "infile", "zero_context": true}
{"original_prediction": "    @property", "prediction_line": "    @property", "ground_truth": "        self._n_axis = 0 if (self.n_elements == 0) else 1", "line_class": "infile", "zero_context": true}
{"original_prediction": "            for exterior in self.boundary_polylines.exteriors[1:]:", "prediction_line": "            for exterior in self.boundary_polylines.exteriors[1:]:", "ground_truth": "            for exterior in self.boundary_polylines.exteriors[1:]:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        directions=None,", "prediction_line": "        directions=None,", "ground_truth": "        directions=None,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            element_table = element_table[elements]", "prediction_line": "            element_table = element_table[elements]", "ground_truth": "            element_table = element_table[elements]", "line_class": "infile", "zero_context": true}
{"original_prediction": "       return cnts", "prediction_line": "       return cnts", "ground_truth": "        if self.boundary_polylines.n_exteriors > 1:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            ycoords[:nnodes, j] = node_coordinates[idx[:nnodes], 1]", "prediction_line": "            ycoords[:nnodes, j] = node_coordinates[idx[:nnodes], 1]", "ground_truth": "            ycoords[:nnodes, j] = node_coordinates[idx[:nnodes], 1]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if elements is None:", "prediction_line": "        if elements is None:", "ground_truth": "        node_coordinates = self._nc", "line_class": "infile", "zero_context": true}
{"original_prediction": "node_coordinates)", "prediction_line": "node_coordinates)", "ground_truth": "                node_coordinates=node_coordinates,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        from shapely.geometry import Polygon, MultiPolygon, LineString", "prediction_line": "        from shapely.geometry import Polygon, MultiPolygon, LineString", "ground_truth": "        boundary_faces = self._get_boundary_faces()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        self._ec = np.asarray(element_table)", "prediction_line": "        self._ec = np.asarray(element_table)", "ground_truth": "        self._element_table = element_table", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self.set_nodes(node_coordinates)", "prediction_line": "            self.set_nodes(node_coordinates)", "ground_truth": "            self._set_nodes(", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._boundary_polylines = self._calc_boundary_polylines()", "prediction_line": "            self._boundary_polylines = self._calc_boundary_polylines()", "ground_truth": "            self._boundary_polylines = self._get_boundary_polylines()", "line_class": "infile", "zero_context": true}
{"original_prediction": "       if points.shape[1] != 2:", "prediction_line": "       if points.shape[1] != 2:", "ground_truth": "        exterior = self.boundary_polylines.exteriors[0]", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for element in element_table:", "prediction_line": "        for element in element_table:", "ground_truth": "        for el in element_table:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        if node_coordinates is not None:", "prediction_line": "        if node_coordinates is not None:", "ground_truth": "        self._nc = np.asarray(node_coordinates)", "line_class": "infile", "zero_context": true}
{"original_prediction": "       self._tree3d = None", "prediction_line": "       self._tree3d = None", "ground_truth": "        if node_coordinates is not None:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._ec = self._get_element_coordinates()", "prediction_line": "            self._ec = self._get_element_coordinates()", "ground_truth": "            self._ec = self._calc_element_coordinates()", "line_class": "infile", "zero_context": true}
{"original_prediction": "        ycoords = np.zeros([maxnodes, n_elements])", "prediction_line": "        ycoords = np.zeros([maxnodes, n_elements])", "ground_truth": "        ycoords = np.zeros([maxnodes, n_elements])", "line_class": "infile", "zero_context": true}
{"original_prediction": "        zcoords = np.zeros([maxnodes, n_elements])", "prediction_line": "        zcoords = np.zeros([maxnodes, n_elements])", "ground_truth": "        zcoords = np.zeros([maxnodes, n_elements])", "line_class": "infile", "zero_context": true}
{"original_prediction": "                node_coordinates = node_coordinates[zn]", "prediction_line": "                node_coordinates = node_coordinates[zn]", "ground_truth": "                idx = np.unique(np.hstack(element_table))", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return self.max_nodes_per_element == 3", "prediction_line": "        return self.max_nodes_per_element == 3", "ground_truth": "        return self.max_nodes_per_element == 3 or self.max_nodes_per_element == 6", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for e in self.element_table:", "prediction_line": "        for e in self.element_table:", "ground_truth": "        for local_nodes in self.element_table:", "line_class": "infile", "zero_context": true}
{"original_prediction": "            0 if (self.n_elements == 0) else 1", "prediction_line": "            0 if (self.n_elements == 0) else 1", "ground_truth": "            self._n_axis + int(self.n_frequencies > 0) + int(self.n_directions > 0)", "line_class": "infile", "zero_context": true}
{"original_prediction": "                element_table=element_table,", "prediction_line": "                element_table=element_table,", "ground_truth": "                element_table=element_table,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        node_coordinates=None,", "prediction_line": "        node_coordinates=None,", "ground_truth": "        frequencies=None,", "line_class": "infile", "zero_context": true}
{"original_prediction": "            local_nodes = element_table[j]", "prediction_line": "            local_nodes = element_table[j]", "ground_truth": "            nodes = element_table[j]", "line_class": "infile", "zero_context": true}
{"original_prediction": "           xcoords[:nnodes, j] = node_coordinates[idx, 0]", "prediction_line": "           xcoords[:nnodes, j] = node_coordinates[idx, 0]", "ground_truth": "            xcoords[:nnodes, j] = node_coordinates[idx[:nnodes], 0]", "line_class": "infile", "zero_context": true}
{"original_prediction": "            self._set_elements(", "prediction_line": "            self._set_elements(", "ground_truth": "            self._set_elements(", "line_class": "infile", "zero_context": true}
{"original_prediction": "       if elements is None:", "prediction_line": "       if elements is None:", "ground_truth": "        element_table = self.element_table", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return len(self._frequencies)", "prediction_line": "        return len(self._frequencies)", "ground_truth": "        return 0 if self.frequencies is None else len(self.frequencies)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        n_nodes = len(node_coordinates)", "prediction_line": "        n_nodes = len(node_coordinates)", "ground_truth": "        ec = np.empty([n_elements, 3])", "line_class": "infile", "zero_context": true}
{"original_prediction": "            if len(element_table.shape) == 2:", "prediction_line": "            if len(element_table.shape) == 2:", "ground_truth": "            if self.max_nodes_per_element < 5:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        node_coordinates=None,", "prediction_line": "        node_coordinates=None,", "ground_truth": "        node_coordinates=None,", "line_class": "infile", "zero_context": true}
{"original_prediction": "        return 0 if self.directions is None else len(self.directions)", "prediction_line": "        return 0 if self.directions is None else len(self.directions)", "ground_truth": "        return 0 if self.directions is None else len(self.directions)", "line_class": "infile", "zero_context": true}
{"original_prediction": "        for interior in self.boundary_polylines.interiors:", "prediction_line": "        for interior in self.boundary_polylines.interiors:", "ground_truth": "        for interior in self.boundary_polylines.interiors:", "line_class": "infile", "zero_context": true}
{"original_prediction": "        element_table=None,", "prediction_line": "        element_table=None,", "ground_truth": "        element_table=None,", "line_class": "infile", "zero_context": true}
{"original_prediction": "                node_coordinates[:, 2] = zn", "prediction_line": "                node_coordinates[:, 2] = zn", "ground_truth": "                node_coordinates[:, 2] = zn", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            node_ids = np.arange(len(node_coordinates))", "prediction_line": "            node_ids = np.arange(len(node_coordinates))", "ground_truth": "            node_ids = np.arange(len(codes))", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            node_coordinates[:, 2] = zn", "prediction_line": "            node_coordinates[:, 2] = zn", "ground_truth": "            if len(zn) == len(node_coordinates[:, 2]):", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if element_ids is None:", "prediction_line": "        if element_ids is None:", "ground_truth": "        if element_ids is None:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "            self._codes = np.ones(self._nc.shape[0], dtype=np.int32)", "prediction_line": "            self._codes = np.ones(self._nc.shape[0], dtype=np.int32)", "ground_truth": "            codes = np.zeros(len(node_coordinates), dtype=int)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                if count > 1000:", "prediction_line": "                if count > 1000:", "ground_truth": "                if count > face_remains.shape[0] or polyline[0] == end_points:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        x = np.empty(maxnodes)", "prediction_line": "        x = np.empty(maxnodes)", "ground_truth": "        idx = np.zeros(maxnodes, dtype=int)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                projection_string=projection_string,", "prediction_line": "                projection_string=projection_string,", "ground_truth": "                node_ids=None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                    end_points = face_remains[next_point_index[0][0], 0]", "prediction_line": "                    end_points = face_remains[next_point_index[0][0], 0]", "ground_truth": "                    index_to_delete.append(next_point_index[0][0])", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        self._element_ids = np.asarray(element_ids)", "prediction_line": "        self._element_ids = np.asarray(element_ids)", "ground_truth": "        self._element_ids = np.asarray(element_ids)", "line_class": "inproject", "zero_context": true}
{"original_prediction": "                node_coordinates = node_coordinates[idx]", "prediction_line": "                node_coordinates = node_coordinates[idx]", "ground_truth": "                node_coordinates[idx, 2] = zn", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        codes=None,", "prediction_line": "        codes=None,", "ground_truth": "        codes=None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if node_ids is None:", "prediction_line": "        if node_ids is None:", "ground_truth": "        if node_ids is None:", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        projection=None,", "prediction_line": "        projection=None,", "ground_truth": "        projection_string=None,", "line_class": "inproject", "zero_context": true}
{"original_prediction": "        if self._type is None:", "prediction_line": "        if self._type is None:", "ground_truth": "        return self._type.name if self._type else \"Mesh\"", "line_class": "inproject", "zero_context": true}
{"original_prediction": "    def _set_nodes(", "prediction_line": "    def _set_nodes(", "ground_truth": "    def _set_nodes(", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "        -------\n        bool array", "prediction_line": "        -------", "ground_truth": "        -------", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "(float)\n            x,y,z-coordinates of the center of each element", "prediction_line": "(float)", "ground_truth": "            x,y,z of each element", "line_class": "non_informative", "zero_context": true}
{"original_prediction": "                cnts = np.logical_or(cnts, in_domain)", "prediction_line": "                cnts = np.logical_or(cnts, in_domain)", "ground_truth": "                cnts = np.logical_or(cnts, in_domain)", "line_class": "random", "zero_context": true}
{"original_prediction": "        boundary_polylines = []", "prediction_line": "        boundary_polylines = []", "ground_truth": "        polylines = []", "line_class": "random", "zero_context": true}
{"original_prediction": "        return len(self._nc)", "prediction_line": "        return len(self._nc)", "ground_truth": "        return len(self._node_ids)", "line_class": "random", "zero_context": true}
{"original_prediction": "        self._projection_string = None", "prediction_line": "        self._projection_string = None", "ground_truth": "        self._element_table = None", "line_class": "random", "zero_context": true}
{"original_prediction": "    def _get_element_table_from_mikecore(self):", "prediction_line": "    def _get_element_table_from_mikecore(self):", "ground_truth": "    @property", "line_class": "random", "zero_context": true}
{"original_prediction": "    file = next(raw_path.glob(f'_iblrig_{label}Camera.GPIO*.bin'), None)", "prediction_line": "    file = next(raw_path.glob(f'_iblrig_{label}Camera.GPIO*.bin'), None)", "ground_truth": "    label = assert_valid_label(label)", "line_class": "commited", "zero_context": false}
{"original_prediction": "        settings = json.load(f)", "prediction_line": "        settings = json.load(f)", "ground_truth": "        settings = json.load(f)", "line_class": "common", "zero_context": false}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1Low\", [np.nan])", "prediction_line": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1Low\", [np.nan])", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1Low\", [np.nan])", "line_class": "common", "zero_context": false}
{"original_prediction": "        data.drop(data.index[0], inplace=True)", "prediction_line": "        data.drop(data.index[0], inplace=True)", "ground_truth": "        data.drop(data.loc[:drop_first].index, inplace=True)", "line_class": "common", "zero_context": false}
{"original_prediction": "    \"\"\"\n    Save a boolean value to the database", "prediction_line": "    \"\"\"", "ground_truth": "    if isinstance(save, bool):", "line_class": "common", "zero_context": false}
{"original_prediction": "        return save\n    if isinstance(save, str):", "prediction_line": "        return save", "ground_truth": "        out = save", "line_class": "common", "zero_context": false}
{"original_prediction": "    elif isinstance(save, str):", "prediction_line": "    elif isinstance(save, str):", "ground_truth": "    elif isinstance(save, list):", "line_class": "common", "zero_context": false}
{"original_prediction": "        out = save == dataset_type", "prediction_line": "        out = save == dataset_type", "ground_truth": "        out = (dataset_type in save) or (Path(dataset_type).stem in save)", "line_class": "common", "zero_context": false}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2High\", [np.nan])", "prediction_line": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2High\", [np.nan])", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2High\", [np.nan])", "line_class": "common", "zero_context": false}
{"original_prediction": "    # check that the wheel position is within the expected range", "prediction_line": "    # check that the wheel position is within the expected range", "ground_truth": "    data.drop(data.loc[data.bns_ts.apply(len) != 33].index, inplace=True)", "line_class": "common", "zero_context": false}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2Low\", [np.nan])", "prediction_line": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2Low\", [np.nan])", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC2Low\", [np.nan])", "line_class": "common", "zero_context": false}
{"original_prediction": "                    for x in tr[\"behavior_data\"][\"BNC1\"][\"times\"]", "prediction_line": "                    for x in tr[\"behavior_data\"][\"BNC1\"][\"times\"]", "ground_truth": "                    for x in tr[\"behavior_data\"][\"Events timestamps\"].get(\"BNC1High\", [np.nan])", "line_class": "common", "zero_context": false}
{"original_prediction": "        return _load_encoder_positions_file_lt5(path)", "prediction_line": "        return _load_encoder_positions_file_lt5(path)", "ground_truth": "        return _load_encoder_positions_file_lt5(path)", "line_class": "infile", "zero_context": false}
{"original_prediction": "        data = [trial_times_to_times(t) for t in data]", "prediction_line": "        data = [trial_times_to_times(t) for t in data]", "ground_truth": "        data = [trial_times_to_times(t) for t in data]", "line_class": "infile", "zero_context": false}
{"original_prediction": "        df = load_camera_frame_data(session_path, camera=label)", "prediction_line": "        df = load_camera_frame_data(session_path, camera=label)", "ground_truth": "        df = load_camera_frame_data(session_path, camera=label)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "prediction_line": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "ground_truth": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": false}
{"original_prediction": "        return _load_encoder_events_file_lt5(path)", "prediction_line": "        return _load_encoder_events_file_lt5(path)", "ground_truth": "        return _load_encoder_events_file_lt5(path)", "line_class": "infile", "zero_context": false}
{"original_prediction": "        return load_camera_frame_data(session_path, camera, raw=True)", "prediction_line": "        return load_camera_frame_data(session_path, camera, raw=True)", "ground_truth": "        df = load_camera_frame_data(session_path, camera=camera)", "line_class": "infile", "zero_context": false}
{"original_prediction": "        df = load_camera_frame_data(session_path, camera=label)", "prediction_line": "        df = load_camera_frame_data(session_path, camera=label)", "ground_truth": "        df = load_camera_frame_data(session_path, camera=label, raw=False)", "line_class": "infile", "zero_context": false}
{"original_prediction": "        settings = load_settings(session_path)", "prediction_line": "        settings = load_settings(session_path)", "ground_truth": "        settings = load_settings(session_path)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    data['re_ts'] = data['re_ts'].astype(np.int64)", "prediction_line": "    data['re_ts'] = data['re_ts'].astype(np.int64)", "ground_truth": "    return _groom_wheel_data_lt5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    gpio = load_camera_gpio(session_path, label, raw=raw)", "prediction_line": "    gpio = load_camera_gpio(session_path, label, raw=raw)", "ground_truth": "    gpio = load_camera_gpio(session_path, label, as_dicts=not raw)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "prediction_line": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "ground_truth": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderEvents.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": false}
{"original_prediction": "        converted_events.update({k: [convert(i) for i in v]})", "prediction_line": "        converted_events.update({k: [convert(i) for i in v]})", "ground_truth": "        converted_events.update({k: [convert(i) for i in v]})", "line_class": "infile", "zero_context": false}
{"original_prediction": "        data = load_data(session_path)", "prediction_line": "        data = load_data(session_path)", "ground_truth": "        data = load_data(session_path)", "line_class": "infile", "zero_context": false}
{"original_prediction": "        converted_states.update({k: [[convert(i) for i in x] for x in v]})", "prediction_line": "        converted_states.update({k: [[convert(i) for i in x] for x in v]})", "ground_truth": "        converted_states.update({k: [[convert(i) for i in x] for x in v]})", "line_class": "infile", "zero_context": false}
{"original_prediction": "        data = pd.read_csv(path, sep=' ', header=None, error_bad_lines=False)", "prediction_line": "        data = pd.read_csv(path, sep=' ', header=None, error_bad_lines=False)", "ground_truth": "        return _load_encoder_events_file_ge5(path)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "prediction_line": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "ground_truth": "    return _groom_wheel_data_ge5(data, label='_iblrig_encoderPositions.raw.ssv', path=file_path)", "line_class": "infile", "zero_context": false}
{"original_prediction": "        return _load_encoder_positions_file_ge5(path)", "prediction_line": "        return _load_encoder_positions_file_ge5(path)", "ground_truth": "        return _load_encoder_positions_file_ge5(path)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    :param session_path: Absolute path of session folder", "prediction_line": "    :param session_path: Absolute path of session folder", "ground_truth": "    Assumes that a folder called \"raw_behavior_data\" exists in folder.", "line_class": "non_informative", "zero_context": false}
{"original_prediction": "_ibl_trials.relativeHumidity", "prediction_line": "_ibl_trials.relativeHumidity", "ground_truth": "    _ibl_trials.relativeHumidity", "line_class": "non_informative", "zero_context": false}
{"original_prediction": "   Bpod timestamps are in microseconds (µs)", "prediction_line": "   Bpod timestamps are in microseconds (µs)", "ground_truth": "    Bpod timestamps are in microseconds (µs)", "line_class": "non_informative", "zero_context": false}
{"original_prediction": "    data = _clean_wheel_dataframe(data, label, path)", "prediction_line": "    data = _clean_wheel_dataframe(data, label, path)", "ground_truth": "    data = _clean_wheel_dataframe(data, label, path)", "line_class": "non_informative", "zero_context": false}
{"original_prediction": "   :param session_path: Absolute path of session folder", "prediction_line": "   :param session_path: Absolute path of session folder", "ground_truth": "    The raw binary file contains uint32 values (saved as doubles) where the first 4 bits", "line_class": "non_informative", "zero_context": false}
{"original_prediction": "        # find the one that matches the derivative of the current event", "prediction_line": "        # find the one that matches the derivative of the current event", "ground_truth": "        dec = np.abs(dt0[i0] - dt1[isearch]) < diff_threshold", "line_class": "random", "zero_context": false}
{"original_prediction": "            return\n        if as_dicts:", "prediction_line": "            return", "ground_truth": "            return [None] * 4 if as_dicts else None", "line_class": "random", "zero_context": false}
{"original_prediction": "    \"\"\"\n    Synchronize two time series using robust methods.", "prediction_line": "    \"\"\"", "ground_truth": "    \"\"\"", "line_class": "random", "zero_context": false}
{"original_prediction": "    BNC1_fronts = BNC1_fronts[1:]", "prediction_line": "    BNC1_fronts = BNC1_fronts[1:]", "ground_truth": "    BNC1_fronts = BNC1_fronts[1:, :]", "line_class": "random", "zero_context": false}
{"original_prediction": "        self.__dict__.update(us)", "prediction_line": "        self.__dict__.update(us)", "ground_truth": "        self.__dict__.update(us)", "line_class": "common", "zero_context": false}
{"original_prediction": "        self.__dict__.update(spc.__dict__)", "prediction_line": "        self.__dict__.update(spc.__dict__)", "ground_truth": "        self.__dict__.update(spc.__dict__)", "line_class": "common", "zero_context": false}
{"original_prediction": "        self.task_settings = Bunch(ts)", "prediction_line": "        self.task_settings = Bunch(ts)", "ground_truth": "        self.__dict__.update(ts)", "line_class": "common", "zero_context": false}
{"original_prediction": "            log.info(\"Cameras launched\")", "prediction_line": "            log.info(\"Cameras launched\")", "ground_truth": "            return bonsai.start_camera_recording(self)", "line_class": "infile", "zero_context": false}
{"original_prediction": "       _task_settings.USE_SOUND_STIMULUS = False", "prediction_line": "       _task_settings.USE_SOUND_STIMULUS = False", "ground_truth": "    sph = SessionParamHandler(_task_settings, _user_settings, debug=True, fmake=False)", "line_class": "infile", "zero_context": false}
{"original_prediction": "        return misc.get_port_events(events, name=name)", "prediction_line": "        return misc.get_port_events(events, name=name)", "ground_truth": "        return misc.get_port_events(events, name=name)", "line_class": "infile", "zero_context": false}
{"original_prediction": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "prediction_line": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "ground_truth": "            d[\"PYBPOD_SUBJECT_EXTRA\"] = remove_from_dict(d[\"PYBPOD_SUBJECT_EXTRA\"])", "line_class": "infile", "zero_context": false}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "            self.bpod_lights(0)", "line_class": "infile", "zero_context": false}
{"original_prediction": "            iotasks.save_task_code(self)", "prediction_line": "            iotasks.save_task_code(self)", "ground_truth": "            iotasks.copy_task_code(self)", "line_class": "inproject", "zero_context": false}
{"original_prediction": "        self.ADAPTIVE_GAIN = adaptive.init_adaptive_gain()", "prediction_line": "        self.ADAPTIVE_GAIN = adaptive.init_adaptive_gain()", "ground_truth": "        self.REWARD_VALVE_TIME = adaptive.init_reward_valve_time(self)", "line_class": "inproject", "zero_context": false}
{"original_prediction": "        self.SOUND_SAMPLE_RATE = 48000", "prediction_line": "        self.SOUND_SAMPLE_RATE = 48000", "ground_truth": "        self.SOUND_SAMPLE_FREQ = sound.sound_sample_freq(self.SOFT_SOUND)", "line_class": "inproject", "zero_context": false}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "        self.OUT_TONE = (\"SoftCode\", 1) if self.SOFT_SOUND else (\"Serial3\", 5)", "line_class": "inproject", "zero_context": false}
{"original_prediction": "            self.save_settings_file()", "prediction_line": "            self.save_settings_file()", "ground_truth": "            iotasks.save_session_settings(self)", "line_class": "inproject", "zero_context": false}
{"original_prediction": "            return False", "prediction_line": "            return False", "ground_truth": "            return bonsai.start_mic_recording(self)", "line_class": "inproject", "zero_context": false}
{"original_prediction": "       self.GO_TONE_PHASE = float(self.GO_TONE_PHASE)", "prediction_line": "       self.GO_TONE_PHASE = float(self.GO_TONE_PHASE)", "ground_truth": "        self.SD = sound.configure_sounddevice(", "line_class": "inproject", "zero_context": false}
{"original_prediction": "        self.ROTARY_ENCODER_DATA = MyRotaryEncoder(", "prediction_line": "        self.ROTARY_ENCODER_DATA = MyRotaryEncoder(", "ground_truth": "        self.ROTARY_ENCODER = MyRotaryEncoder(", "line_class": "inproject", "zero_context": false}
{"original_prediction": "            self.CALIB_FUNC = \"exp\"", "prediction_line": "            self.CALIB_FUNC = \"exp\"", "ground_truth": "            self.CALIB_FUNC = adaptive.init_calib_func()", "line_class": "inproject", "zero_context": false}
{"original_prediction": "        self.SD.stop()", "prediction_line": "        self.SD.stop()", "ground_truth": "        self.SD.stop()", "line_class": "inproject", "zero_context": false}
{"original_prediction": "        self.ADAPTIVE_GAIN = None", "prediction_line": "        self.ADAPTIVE_GAIN = None", "ground_truth": "        self.CALIB_FUNC_RANGE = adaptive.init_calib_func_range()", "line_class": "inproject", "zero_context": false}
{"original_prediction": "        self.sc = SessionPathCreator(self.PYBPOD_SUBJECTS_DIR, self.SUBJECT_NAME)", "prediction_line": "        self.sc = SessionPathCreator(self.PYBPOD_SUBJECTS_DIR, self.SUBJECT_NAME)", "ground_truth": "        self = iotasks.deserialize_pybpod_user_settings(self)", "line_class": "inproject", "zero_context": false}
{"original_prediction": "        \"\"\"\n        Saves ambient sensor reading to file", "prediction_line": "        \"\"\"", "ground_truth": "        return ambient_sensor.get_reading(bpod_instance, save_to=self.SESSION_RAW_DATA_FOLDER)", "line_class": "inproject", "zero_context": false}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "            iotasks.save_task_code(self)", "line_class": "inproject", "zero_context": false}
{"original_prediction": "            self.SOUND_BOARD_BPOD_PORT = \"Serial4\"", "prediction_line": "            self.SOUND_BOARD_BPOD_PORT = \"Serial4\"", "ground_truth": "            sound.configure_sound_card(", "line_class": "inproject", "zero_context": false}
{"original_prediction": "    def stop_tone(self):", "prediction_line": "    def stop_tone(self):", "ground_truth": "    def stop_sound(self):", "line_class": "non_informative", "zero_context": false}
{"original_prediction": "import iblrig.user_input as user_input", "prediction_line": "import iblrig.user_input as user_input", "ground_truth": "import iblrig.user_input as user", "line_class": "non_informative", "zero_context": false}
{"original_prediction": "import iblrig.path_helper as ph", "prediction_line": "import iblrig.path_helper as ph", "ground_truth": "from sys import platform", "line_class": "non_informative", "zero_context": false}
{"original_prediction": "    def reprJSON(self):", "prediction_line": "    def reprJSON(self):", "ground_truth": "    def reprJSON(self):", "line_class": "non_informative", "zero_context": false}
{"original_prediction": "import iblrig.path_helper as ph", "prediction_line": "import iblrig.path_helper as ph", "ground_truth": "from pythonosc import udp_client", "line_class": "non_informative", "zero_context": false}
{"original_prediction": "        self.OSC_CLIENT_IP = \"127.0.0.1\"", "prediction_line": "        self.OSC_CLIENT_IP = \"127.0.0.1\"", "ground_truth": "        self.OSC_CLIENT_IP = \"127.0.0.1\"", "line_class": "random", "zero_context": false}
{"original_prediction": "        # =====================================================================", "prediction_line": "        # =====================================================================", "ground_truth": "        if self.SOFT_SOUND is None:", "line_class": "random", "zero_context": false}
{"original_prediction": "        else:\n            make = True  # True makes raw_behavior_data and raw_video_data folders", "prediction_line": "        else:", "ground_truth": "        else:", "line_class": "random", "zero_context": false}
{"original_prediction": "                sx[\"water_administration\"] = None", "prediction_line": "                sx[\"water_administration\"] = None", "ground_truth": "                sx[\"water_administration\"] = None", "line_class": "random", "zero_context": false}
{"original_prediction": "        self.CALIB_FUNC_RANGE = None", "prediction_line": "        self.CALIB_FUNC_RANGE = None", "ground_truth": "        if self.AUTOMATIC_CALIBRATION:", "line_class": "random", "zero_context": false}
{"original_prediction": "   ax_bars.clear()", "prediction_line": "   ax_bars.clear()", "ground_truth": "    bar_data = get_barplot_data(tph)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    ax_bars.clear()", "prediction_line": "    ax_bars.clear()", "ground_truth": "    psych_data = get_psych_data(tph)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    chron_data = get_chron_data(tph)", "prediction_line": "    chron_data = get_chron_data(tph)", "ground_truth": "    chron_data = get_chron_data(tph)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    vars_data = get_vars_data(tph)", "prediction_line": "    vars_data = get_vars_data(tph)", "ground_truth": "    vars_data = get_vars_data(tph)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    prop_resp_ccw08 = get_prop_ccw_resp(0.8)", "prediction_line": "    prop_resp_ccw08 = get_prop_ccw_resp(0.8)", "ground_truth": "    prop_resp_ccw08 = get_prop_ccw_resp(0.8)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    ax_bars.clear()", "prediction_line": "    ax_bars.clear()", "ground_truth": "    plot_bars(bar_data, ax=ax_bars)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    plot_psych(psych_data, ax=ax_psych)", "prediction_line": "    plot_psych(psych_data, ax=ax_psych)", "ground_truth": "    plot_psych(psych_data, ax=ax_psych)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    plot_chron(chron_data, ax=ax_chron)", "prediction_line": "    plot_chron(chron_data, ax=ax_chron)", "ground_truth": "    plot_chron(chron_data, ax=ax_chron)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    plot_vars(vars_data, ax=ax_vars)", "prediction_line": "    plot_vars(vars_data, ax=ax_vars)", "ground_truth": "    plot_vars(vars_data, ax=ax_vars, ax2=ax_vars2)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    rts02 = get_rts(0.2)", "prediction_line": "    rts02 = get_rts(0.2)", "ground_truth": "    rts02, rts05, rts08 = get_rts(0.2), get_rts(0.5), get_rts(0.8)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    prop_resp_ccw_0 = get_prop_ccw_resp(0)", "prediction_line": "    prop_resp_ccw_0 = get_prop_ccw_resp(0)", "ground_truth": "    prop_resp_ccw02 = get_prop_ccw_resp(0.2)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    prop_resp_ccw05 = get_prop_ccw_resp(0.5)", "prediction_line": "    prop_resp_ccw05 = get_prop_ccw_resp(0.5)", "ground_truth": "    prop_resp_ccw05 = get_prop_ccw_resp(0.5)", "line_class": "infile", "zero_context": false}
{"original_prediction": "    sig_contrasts_all = sig_contrasts_all[sig_contrasts_all != 0]", "prediction_line": "    sig_contrasts_all = sig_contrasts_all[sig_contrasts_all != 0]", "ground_truth": "    sig_contrasts_all = np.append(sig_contrasts_all, [-x for x in sig_contrasts_all if x != 0])", "line_class": "inproject", "zero_context": false}
