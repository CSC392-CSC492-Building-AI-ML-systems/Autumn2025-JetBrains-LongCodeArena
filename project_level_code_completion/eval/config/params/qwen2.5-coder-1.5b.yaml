preprocess_params:
  model: "huggingface"
  composers: "none"
  tokenizer: "Qwen/Qwen2.5-Coder-1.5B"

inference_params :
    model: "qwen2.5-coder-1.5b"
    seq_max_len: 1334
    input_data_path: ""
    context_max: -1

eval_params:
    device: cuda
